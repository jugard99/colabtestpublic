{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvlUixv-QGw7"
      },
      "source": [
        "# [1.2] Intro to Mechanistic Interpretability: TransformerLens & induction circuits (exercises)\n",
        "\n",
        "> **ARENA [Streamlit Page](https://arena-chapter1-transformer-interp.streamlit.app/02_[1.2]_Intro_to_Mech_Interp)**\n",
        ">\n",
        "> **Colab: [exercises](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter1_transformer_interp/exercises/part2_intro_to_mech_interp/1.2_Intro_to_Mech_Interp_exercises.ipynb?t=20250530) | [solutions](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter1_transformer_interp/exercises/part2_intro_to_mech_interp/1.2_Intro_to_Mech_Interp_solutions.ipynb?t=20250530)**\n",
        "\n",
        "Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-2zick19fl-6GY1yoGaoUozyM3wObwmnQ), and ask any questions on the dedicated channels for this chapter of material.\n",
        "\n",
        "You can collapse each section so only the headers are visible, by clicking the arrow symbol on the left hand side of the markdown header cells.\n",
        "\n",
        "Links to all other chapters: [(0) Fundamentals](https://arena-chapter0-fundamentals.streamlit.app/), [(1) Transformer Interpretability](https://arena-chapter1-transformer-interp.streamlit.app/), [(2) RL](https://arena-chapter2-rl.streamlit.app/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQVsW9uFQGxB"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/headers/header-12.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bzbukyNQGxC"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_AeyKX6QGxD"
      },
      "source": [
        "These pages are designed to get you introduced to the core concepts of mechanistic interpretability, via Neel Nanda's **TransformerLens** library.\n",
        "\n",
        "Most of the sections are constructed in the following way:\n",
        "\n",
        "1. A particular feature of TransformerLens is introduced.\n",
        "2. You are given an exercise, in which you have to apply the feature.\n",
        "\n",
        "The running theme of the exercises is **induction circuits**. Induction circuits are a particular type of circuit in a transformer, which can perform basic in-context learning. You should read the [corresponding section of Neel's glossary](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=_Jzi6YHRHKP1JziwdE02qdYZ), before continuing. This [LessWrong post](https://www.lesswrong.com/posts/TvrfY4c9eaGLeyDkE/induction-heads-illustrated) might also help; it contains some diagrams (like the one below) which walk through the induction mechanism step by step.\n",
        "\n",
        "Each exercise will have a difficulty and importance rating out of 5, as well as an estimated maximum time you should spend on these exercises and sometimes a short annotation. You should interpret the ratings & time estimates relatively (e.g. if you find yourself spending about 50% longer on the exercises than the time estimates, adjust accordingly). Please do skip exercises / look at solutions if you don't feel like they're important enough to be worth doing, and you'd rather get to the good stuff!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFKTdqpHQGxE"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/kcomp_diagram.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ecftrc7QGxF"
      },
      "source": [
        "## Content & Learning Objectives\n",
        "\n",
        "### 1️⃣ TransformerLens: Introduction\n",
        "\n",
        "This section is designed to get you up to speed with the TransformerLens library. You'll learn how to load and run models, and learn about the shared architecture template for all of these models (the latter of which should be familiar to you if you've already done the exercises that come before these, since many of the same design principles are followed).\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Load and run a `HookedTransformer` model\n",
        "> - Understand the basic architecture of these models\n",
        "> - Use the model's tokenizer to convert text to tokens, and vice versa\n",
        "> - Know how to cache activations, and to access activations from the cache\n",
        "> - Use `circuitsvis` to visualise attention heads\n",
        "\n",
        "### 2️⃣ Finding induction heads\n",
        "\n",
        "Here, you'll learn about induction heads, how they work and why they are important. You'll also learn how to identify them from the characteristic induction head stripe in their attention patterns when the model input is a repeating sequence.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand what induction heads are, and the algorithm they are implementing\n",
        "> - Inspect activation patterns to identify basic attention head patterns, and write your own functions to detect attention heads for you\n",
        "> - Identify induction heads by looking at the attention patterns produced from a repeating random sequence\n",
        "\n",
        "### 3️⃣ TransformerLens: Hooks\n",
        "\n",
        "Next, you'll learn about hooks, which are a great feature of TransformerLens allowing you to access and intervene on activations within the model. We will mainly focus on the basics of hooks and using them to access activations (we'll mainly save the causal interventions for the later IOI exercises). You will also build some tools to perform logit attribution within your model, so you can identify which components are responsible for your model's performance on certain tasks.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand what hooks are, and how they are used in TransformerLens\n",
        "> - Use hooks to access activations, process the results, and write them to an external tensor\n",
        "> - Build tools to perform attribution, i.e. detecting which components of your model are responsible for performance on a given task\n",
        "> - Understand how hooks can be used to perform basic interventions like **ablation**\n",
        "\n",
        "### 4️⃣ Reverse-engineering induction circuits\n",
        "\n",
        "Lastly, these exercises show you how you can reverse-engineer a circuit by looking directly at a transformer's weights (which can be considered a \"gold standard\" of interpretability; something not possible in every situation). You'll examine QK and OV circuits by multiplying through matrices (and learn how the FactoredMatrix class makes matrices like these much easier to analyse). You'll also look for evidence of composition between two induction heads, and once you've found it then you'll investigate the functionality of the full circuit formed from this composition.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand the difference between investigating a circuit by looking at activation patterns, and reverse-engineering a circuit by looking directly at the weights\n",
        "> - Use the factored matrix class to inspect the QK and OV circuits within an induction circuit\n",
        "> - Perform further exploration of induction circuits: composition scores, and targeted ablations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eaov4iZJQGxG"
      },
      "source": [
        "## Setup code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "r_Yab4q2QGxH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import pkg_resources\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "chapter = \"chapter1_transformer_interp\"\n",
        "repo = \"ARENA_3.0\"\n",
        "branch = \"main\"\n",
        "\n",
        "# Install dependencies\n",
        "installed_packages = [pkg.key for pkg in pkg_resources.working_set]\n",
        "if \"transformer-lens\" not in installed_packages:\n",
        "    %pip install transformer_lens==2.11.0 einops eindex-callum jaxtyping git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
        "\n",
        "# Get root directory, handling 3 different cases: (1) Colab, (2) notebook not in ARENA repo, (3) notebook in ARENA repo\n",
        "root = (\n",
        "    \"/content\"\n",
        "    if IN_COLAB\n",
        "    else \"/root\"\n",
        "    if repo not in os.getcwd()\n",
        "    else str(next(p for p in Path.cwd().parents if p.name == repo))\n",
        ")\n",
        "\n",
        "if Path(root).exists() and not Path(f\"{root}/{chapter}\").exists():\n",
        "    if not IN_COLAB:\n",
        "        !sudo apt-get install unzip\n",
        "        %pip install jupyter ipython --upgrade\n",
        "\n",
        "    if not os.path.exists(f\"{root}/{chapter}\"):\n",
        "        !wget -P {root} https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/{branch}.zip\n",
        "        !unzip {root}/{branch}.zip '{repo}-{branch}/{chapter}/exercises/*' -d {root}\n",
        "        !mv {root}/{repo}-{branch}/{chapter} {root}/{chapter}\n",
        "        !rm {root}/{branch}.zip\n",
        "        !rmdir {root}/ARENA_3.0-{branch}\n",
        "\n",
        "\n",
        "if f\"{root}/{chapter}/exercises\" not in sys.path:\n",
        "    sys.path.append(f\"{root}/{chapter}/exercises\")\n",
        "\n",
        "os.chdir(f\"{root}/{chapter}/exercises\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FtQ9SbhsQGxJ"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Callable\n",
        "\n",
        "import circuitsvis as cv\n",
        "import einops\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from eindex import eindex\n",
        "from IPython.display import display\n",
        "from jaxtyping import Float, Int\n",
        "from torch import Tensor\n",
        "from tqdm import tqdm\n",
        "from transformer_lens import (\n",
        "    ActivationCache,\n",
        "    FactoredMatrix,\n",
        "    HookedTransformer,\n",
        "    HookedTransformerConfig,\n",
        "    utils,\n",
        ")\n",
        "from transformer_lens.hook_points import HookPoint\n",
        "\n",
        "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Make sure exercises are in the path\n",
        "chapter = \"chapter1_transformer_interp\"\n",
        "section = \"part2_intro_to_mech_interp\"\n",
        "root_dir = next(p for p in Path.cwd().parents if (p / chapter).exists())\n",
        "exercises_dir = root_dir / chapter / \"exercises\"\n",
        "section_dir = exercises_dir / section\n",
        "\n",
        "import part2_intro_to_mech_interp.tests as tests\n",
        "from plotly_utils import hist, imshow, plot_comp_scores, plot_logit_attribution, plot_loss_difference\n",
        "\n",
        "# Saves computation time, since we don't need it for the contents of this notebook\n",
        "t.set_grad_enabled(False)\n",
        "\n",
        "MAIN = __name__ == \"__main__\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DDKT_ICQGxK"
      },
      "source": [
        "# 1️⃣ TransformerLens: Introduction\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Load and run a `HookedTransformer` model\n",
        "> - Understand the basic architecture of these models\n",
        "> - Use the model's tokenizer to convert text to tokens, and vice versa\n",
        "> - Know how to cache activations, and to access activations from the cache\n",
        "> - Use `circuitsvis` to visualise attention heads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYAFRrTUQGxK"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "*Note - most of this is written from the POV of Neel Nanda.*\n",
        "\n",
        "This is a demo notebook for [TransformerLens](https://github.com/neelnanda-io/TransformerLens), **a library I ([Neel Nanda](neelnanda.io)) wrote for doing [mechanistic interpretability](https://distill.pub/2020/circuits/zoom-in/) of GPT-2 Style language models.** The goal of mechanistic interpretability is to take a trained model and reverse engineer the algorithms the model learned during training from its weights. It is a fact about the world today that we have computer programs that can essentially speak English at a human level (GPT-3, PaLM, etc), yet we have no idea how they work nor how to write one ourselves. This offends me greatly, and I would like to solve this! Mechanistic interpretability is a very young and small field, and there are a *lot* of open problems - if you would like to help, please try working on one! **Check out my [list of concrete open problems](https://docs.google.com/document/d/1WONBzNqfKIxERejrrPlQMyKqg7jSFW92x5UMXNrMdPo/edit#) to figure out where to start.**\n",
        "\n",
        "I wrote this library because after I left the Anthropic interpretability team and started doing independent research, I got extremely frustrated by the state of open source tooling. There's a lot of excellent infrastructure like HuggingFace and DeepSpeed to *use* or *train* models, but very little to dig into their internals and reverse engineer how they work. **This library tries to solve that**, and to make it easy to get into the field even if you don't work at an industry org with real infrastructure! The core features were heavily inspired by [Anthropic's excellent Garcon tool](https://transformer-circuits.pub/2021/garcon/index.html). Credit to Nelson Elhage and Chris Olah for building Garcon and showing me the value of good infrastructure for accelerating exploratory research!\n",
        "\n",
        "The core design principle I've followed is to enable exploratory analysis - one of the most fun parts of mechanistic interpretability compared to normal ML is the extremely short feedback loops! The point of this library is to keep the gap between having an experiment idea and seeing the results as small as possible, to make it easy for **research to feel like play** and to enter a flow state. This notebook demonstrates how the library works and how to use it, but if you want to see how well it works for exploratory research, check out [my notebook analysing Indirect Objection Identification](https://github.com/neelnanda-io/TransformerLens/blob/main/Exploratory_Analysis_Demo.ipynb) or [my recording of myself doing research](https://www.youtube.com/watch?v=yo4QvDn-vsU)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4rGpcFBQGxL"
      },
      "source": [
        "## Loading and Running Models\n",
        "\n",
        "TransformerLens comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. For this demo notebook we'll look at GPT-2 Small, an 80M parameter model, see the Available Models section for info on the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1JF47liQGxL",
        "outputId": "9ba09ec6-4907-4c47-cc28-55e20fdd49ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "gpt2_small: HookedTransformer = HookedTransformer.from_pretrained(\"gpt2-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmaAMLLXQGxM"
      },
      "source": [
        "### HookedTransformerConfig\n",
        "\n",
        "Alternatively, you can define a config object, then call `HookedTransformer.from_config(cfg)` to define your model. This is particularly useful when you want to have finer control over the architecture of your model. We'll see an example of this in the next section, when we define an attention-only model to study induction heads.\n",
        "\n",
        "Even if you don't define your model in this way, you can still access the config object through the `cfg` attribute of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJvx1dHFQGxM"
      },
      "source": [
        "### Exercise - inspect your model\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴⚪⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        "> ```\n",
        "\n",
        "Use `gpt2_small.cfg` to find the following, for your GPT-2 Small model:\n",
        "\n",
        "* Number of layers\n",
        "* Number of heads per layer\n",
        "* Maximum context window\n",
        "\n",
        "You might have to check out the documentation page for some of these. If you're in VSCode then you can reach it by right-clicking on `HookedTransformerConfig` and choosing \"Go to definition\". If you're in Colab, then you can read the [GitHub page](https://github.com/neelnanda-io/TransformerLens).\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "The following parameters in the config object give you the answers:\n",
        "\n",
        "```\n",
        "cfg.n_layers == 12\n",
        "cfg.n_heads == 12\n",
        "cfg.n_ctx == 1024\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2d0h1lOQGxM"
      },
      "source": [
        "### Running your model\n",
        "\n",
        "Models can be run on a single string or a tensor of tokens (shape: `[batch, position]`, all integers). The possible return types are:\n",
        "\n",
        "* `\"logits\"` (shape `[batch, position, d_vocab]`, floats),\n",
        "* `\"loss\"` (the cross-entropy loss when predicting the next token),\n",
        "* `\"both\"` (a tuple of `(logits, loss)`)\n",
        "* `None` (run the model, but don't calculate the logits - this is faster when we only want to use intermediate activations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kyxAzrfQGxM",
        "outputId": "0b94b39b-dfdc-4268-d916-f63d0a4abb2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loss: tensor(4.3443)\n"
          ]
        }
      ],
      "source": [
        "model_description_text = \"\"\"## Loading Models\n",
        "\n",
        "HookedTransformer comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. Each model is loaded into the consistent HookedTransformer architecture, designed to be clean, consistent and interpretability-friendly.\n",
        "\n",
        "For this demo notebook we'll look at GPT-2 Small, an 80M parameter model. To try the model the model out, let's find the loss on this paragraph!\"\"\"\n",
        "\n",
        "loss = gpt2_small(model_description_text, return_type=\"loss\")\n",
        "print(\"Model loss:\", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jy8jgjXQGxN"
      },
      "source": [
        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model loss: tensor(4.3443, device='cuda:0')</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbPJtwtdQGxO"
      },
      "source": [
        "## Transformer architecture\n",
        "\n",
        "HookedTransformer is a somewhat adapted GPT-2 architecture, but is computationally identical. The most significant changes are to the internal structure of the attention heads:\n",
        "\n",
        "* The weights `W_K`, `W_Q`, `W_V` mapping the residual stream to queries, keys and values are 3 separate matrices, rather than big concatenated one.\n",
        "* The weight matrices `W_K`, `W_Q`, `W_V`, `W_O` and activations have separate `head_index` and `d_head` axes, rather than flattening them into one big axis.\n",
        "    * The activations all have shape `[batch, position, head_index, d_head]`.\n",
        "    * `W_K`, `W_Q`, `W_V` have shape `[head_index, d_model, d_head]` and `W_O` has shape `[head_index, d_head, d_model]`\n",
        "* **Important - we generally follow the convention that weight matrices multiply on the right rather than the left.** In other words, they have shape `[input, output]`, and we have `new_activation = old_activation @ weights + bias`.\n",
        "    * Click the dropdown below for examples of this, if it seems unintuitive.\n",
        "\n",
        "<details>\n",
        "<summary>Examples of matrix multiplication in our model</summary>\n",
        "\n",
        "* **Query matrices**\n",
        "    * Each query matrix `W_Q` for a particular layer and head has shape `[d_model, d_head]`.\n",
        "    * So if a vector `x` in the residual stream has length `d_model`, then the corresponding query vector is `x @ W_Q`, which has length `d_head`.\n",
        "* **Embedding matrix**\n",
        "    * The embedding matrix `W_E` has shape `[d_vocab, d_model]`.\n",
        "    * So if `A` is a one-hot-encoded vector of length `d_vocab` corresponding to a particular token, then the embedding vector for this token is `A @ W_E`, which has length `d_model`.\n",
        "\n",
        "</details>\n",
        "\n",
        "The actual code is a bit of a mess, as there's a variety of Boolean flags to make it consistent with the various different model families in TransformerLens - to understand it and the internal structure, I instead recommend reading the code in [CleanTransformerDemo](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/clean-transformer-demo/Clean_Transformer_Demo.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgdHuU0pQGxO"
      },
      "source": [
        "### Parameters and Activations\n",
        "\n",
        "It's important to distinguish between parameters and activations in the model.\n",
        "\n",
        "* **Parameters** are the weights and biases that are learned during training.\n",
        "    * These don't change when the model input changes.\n",
        "    * They can be accessed directly from the model, e.g. `model.W_E` for the embedding matrix.\n",
        "* **Activations** are temporary numbers calculated during a forward pass, that are functions of the input.\n",
        "    * We can think of these values as only existing for the duration of a single forward pass, and disappearing afterwards.\n",
        "    * We can use hooks to access these values during a forward pass (more on hooks later), but it doesn't make sense to talk about a model's activations outside the context of some particular input.\n",
        "    * Attention scores and patterns are activations (this is slightly non-intuitve because they're used in a matrix multiplication with another activation).\n",
        "\n",
        "The link below shows a diagram of a single layer (called a `TransformerBlock`) for an attention-only model with no biases. Each box corresponds to an **activation** (and also tells you the name of the corresponding hook point, which we will eventually use to access those activations). The red text below each box tells you the shape of the activation (ignoring the batch dimension). Each arrow corresponds to an operation on an activation; where there are **parameters** involved these are labelled on the arrows.\n",
        "\n",
        "[Link to diagram](https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/small-merm.svg)\n",
        "\n",
        "The next link is to a diagram of a `TransformerBlock` with full features (including biases, layernorms, and MLPs). Don't worry if not all of this makes sense at first - we'll return to some of the details later. As we work with these transformers, we'll get more comfortable with their architecture.\n",
        "\n",
        "[Link to diagram](https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/full-merm.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQEKLcd4QGxP"
      },
      "source": [
        "A few shortctus to make your lives easier when using these models:\n",
        "\n",
        "* You can index weights like `W_Q` directly from the model via e.g. `model.blocks[0].attn.W_Q` (which gives you the `[nheads, d_model, d_head]` query weights for all heads in layer 0).\n",
        "    * But an easier way is just to index with `model.W_Q`, which gives you the `[nlayers, nheads, d_model, d_head]` tensor containing **every** query weight in the model.\n",
        "* Similarly, there exist shortcuts `model.W_E`, `model.W_U` and `model.W_pos` for the embeddings, unembeddings and positional embeddings respectively.\n",
        "* With models containing MLP layers, you also have `model.W_in` and `model.W_out` for the linear layers.\n",
        "* The same is true for all biases (e.g. `model.b_Q` for all query biases)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaHBtlXOQGxP"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "The tokenizer is stored inside the model, and you can access it using `model.tokenizer`. There are also a few helper methods that call the tokenizer under the hood, for instance:\n",
        "\n",
        "* `model.to_str_tokens(text)` converts a string into a list of tokens-as-strings (or a list of strings into a list of lists of tokens-as-strings).\n",
        "* `model.to_tokens(text)` converts a string into a tensor of tokens.\n",
        "* `model.to_string(tokens)` converts a tensor of tokens into a string.\n",
        "\n",
        "Examples of use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9fa6NmXQGxQ",
        "outputId": "159327b8-7a50-4706-9496-40ff4aa71752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|endoftext|>', 'g', 'pt', '2']\n",
            "[['<|endoftext|>', 'g', 'pt', '2'], ['<|endoftext|>', 'g', 'pt', '2']]\n",
            "tensor([[50256,    70,   457,    17]])\n",
            "<|endoftext|>gpt2\n"
          ]
        }
      ],
      "source": [
        "print(gpt2_small.to_str_tokens(\"gpt2\"))\n",
        "print(gpt2_small.to_str_tokens([\"gpt2\", \"gpt2\"]))\n",
        "print(gpt2_small.to_tokens(\"gpt2\"))\n",
        "print(gpt2_small.to_string([50256, 70, 457, 17]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk2RFFAIQGxQ"
      },
      "source": [
        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">['<|endoftext|>', 'g', 'pt', '2']\n",
        "[['<|endoftext|>', 'g', 'pt', '2'], ['<|endoftext|>', 'g', 'pt', '2']]\n",
        "tensor([[50256,    70,   457,    17]], device='cuda:0')\n",
        "<|endoftext|>gpt2</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOAfCwXvQGxQ"
      },
      "source": [
        "<details>\n",
        "<summary>Aside - <code><|endoftext|></code></summary>\n",
        "\n",
        "A weirdness you may have noticed in the above is that `to_tokens` and `to_str_tokens` added a weird `<|endoftext|>` to the start of each prompt. We encountered this in the previous set of exercises, and noted that this was the **Beginning of Sequence (BOS)** token (which for GPT-2 is also the same as the EOS and PAD tokens - index `50256`.\n",
        "\n",
        "TransformerLens appends this token by default, and it can easily trip up new users. Notably, **this includes** `model.forward` (which is what's implicitly used when you do eg `model(\"Hello World\")`). You can disable this behaviour by setting the flag `prepend_bos=False` in `to_tokens`, `to_str_tokens`, `model.forward` and any other function that converts strings to multi-token tensors.\n",
        "\n",
        "`prepend_bos` is a bit of a hack, and I've gone back and forth on what the correct default here is. The reason I do this is that transformers tend to treat the first token weirdly - this doesn't really matter in training (where all inputs are >1000 tokens), but this can be a big issue when investigating short prompts! The reason for this is that attention patterns are a probability distribution and so need to add up to one, so to simulate being \"off\" they normally look at the first token. Giving them a BOS token lets the heads rest by looking at that, preserving the information in the first \"real\" token.\n",
        "\n",
        "Further, *some* models are trained to need a BOS token (OPT and my interpretability-friendly models are, GPT-2 and GPT-Neo are not). But despite GPT-2 not being trained with this, empirically it seems to make interpretability easier.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPYZ3NNOQGxR"
      },
      "source": [
        "### Exercise - how many tokens does your model guess correctly?\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Consider the `model_description_text` you fed into your model above. How many tokens did your model guess correctly? Which tokens were correct?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbPgswtPQGxR",
        "outputId": "24ef9655-99fb-43c4-d855-6575f12a48e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##\n",
            "\n",
            "\n",
            "...\n",
            "\n",
            "##uge\n",
            "incorrect\n",
            "Loading\n",
            "onformer\n",
            "\n",
            "incorrect\n",
            "Models\n",
            "\n",
            "HookedTransformer\n",
            "with\n",
            "incorrect\n",
            "comes\n",
            "with\n",
            "incorrect\n",
            "loaded\n",
            "all100\n",
            "incorrect\n",
            "with\n",
            "models\n",
            "incorrect\n",
            ">40\n",
            "models\n",
            "incorrect\n",
            "open\n",
            "modelsIM\n",
            "incorrect\n",
            "source\n",
            "modelsbased\n",
            "incorrect\n",
            "GPT-style\n",
            "models.\n",
            "\n",
            "incorrect\n",
            "models.\n",
            "can\n",
            "incorrect\n",
            "You\n",
            "use\n",
            "incorrect\n",
            "can\n",
            "them\n",
            "incorrect\n",
            "load\n",
            "of\n",
            "incorrect\n",
            "any\n",
            "these\n",
            "incorrect\n",
            "of\n",
            "from\n",
            "incorrect\n",
            "them\n",
            "your\n",
            "incorrect\n",
            "in\n",
            "thehookedTransformer`.load`modelend_modelULE_NAME,`.\n",
            "\n",
            "incorrect\n",
            "with\n",
            "model\n",
            "incorrect\n",
            "`HookedTransformer.from_pretrained(MODEL_NAME)`.\n",
            "has\n",
            "incorrect\n",
            "Each\n",
            "a\n",
            "incorrect\n",
            "model\n",
            "with\n",
            "incorrect\n",
            "is\n",
            "the\n",
            "incorrect\n",
            "loaded\n",
            "`\n",
            "incorrect\n",
            "into\n",
            "`TransTransformer..\n",
            "incorrect\n",
            "the\n",
            "and\n",
            "incorrect\n",
            "consistent\n",
            "to\n",
            "incorrect\n",
            "HookedTransformer\n",
            "be\n",
            "incorrect\n",
            "architecture,\n",
            "used\n",
            "incorrect\n",
            "designed\n",
            "and\n",
            "incorrect\n",
            "to\n",
            "easy\n",
            "incorrect\n",
            "be\n",
            "and\n",
            "incorrect\n",
            "clean,\n",
            "easyable-free.\n",
            "\n",
            "##\n",
            "incorrect\n",
            "consistent\n",
            "example\n",
            "incorrect\n",
            "and\n",
            "tutorial,,\n",
            "incorrect\n",
            "interpretability-friendly.\n",
            "\n",
            "For\n",
            "will\n",
            "incorrect\n",
            "this\n",
            "use\n",
            "incorrect\n",
            "demo\n",
            "at\n",
            "incorrect\n",
            "notebook\n",
            "thePT-style.,\n",
            "incorrect\n",
            "we'll\n",
            "Medium\n",
            "incorrect\n",
            "look\n",
            "openxbized\n",
            "incorrect\n",
            "at\n",
            "with\n",
            "\n",
            "incorrect\n",
            "GPT-2\n",
            "load\n",
            "incorrect\n",
            "Small,\n",
            "out\n",
            "incorrect\n",
            "an\n",
            "model,\n",
            "incorrect\n",
            "80M\n",
            "following\n",
            "incorrect\n",
            "parameter\n",
            "is,\n",
            "incorrect\n",
            "model.\n",
            "you's\n",
            "incorrect\n",
            "To\n",
            "use\n",
            "incorrect\n",
            "try\n",
            "the\n",
            "incorrect\n",
            "the\n",
            "`less\n",
            "incorrect\n",
            "model\n",
            "the\n",
            "incorrect\n",
            "the\n",
            "model:\n",
            "incorrect\n"
          ]
        }
      ],
      "source": [
        "logits: Tensor = gpt2_small(model_description_text, return_type=\"logits\")\n",
        "prediction = logits.argmax(dim=-1).squeeze()[:-1]\n",
        "wordpred = gpt2_small.to_string(prediction).split(\" \")\n",
        "check = model_description_text.split(\" \")\n",
        "for i in range(len(wordpred)):\n",
        "  print(check[i])\n",
        "  print(wordpred[i])\n",
        "  if check[i] == wordpred[i]:\n",
        "    print(\"correct\")\n",
        "  else:\n",
        "    print(\"incorrect\")\n",
        "\n",
        "# YOUR CODE HERE - get the model's prediction on the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlSQx-z4QGxR"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Use `return_type=\"logits\"` to get the model's predictions, then take argmax across the vocab dimension. Then, compare these predictions with the actual tokens, derived from the `model_description_text`.\n",
        "\n",
        "Remember, you should be comparing the `[:-1]`th elements of this tensor of predictions with the `[1:]`th elements of the input tokens (because your model's output represents a probability distribution over the *next* token, not the current one).\n",
        "\n",
        "Also, remember to handle the batch dimension (since `logits`, and the output of `to_tokens`, will both have batch dimensions by default).\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Answer - what you should see</summary>\n",
        "\n",
        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model accuracy: 33/111\n",
        "Correct tokens: ['\\n', '\\n', 'former', ' with', ' models', '.', ' can', ' of', 'ooked', 'Trans', 'former', '_', 'NAME', '`.', ' model', ' the', 'Trans', 'former', ' to', ' be', ' and', '-', '.', '\\n', '\\n', ' at', 'PT', '-', ',', ' model', ',', \"'s\", ' the']\n",
        "</pre>\n",
        "\n",
        "So the model got 33 out of 111 tokens correct. Not too bad!\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "logits: Tensor = gpt2_small(model_description_text, return_type=\"logits\")\n",
        "prediction = logits.argmax(dim=-1).squeeze()[:-1]\n",
        "\n",
        "true_tokens = gpt2_small.to_tokens(model_description_text).squeeze()[1:]\n",
        "is_correct = prediction == true_tokens\n",
        "\n",
        "print(f\"Model accuracy: {is_correct.sum()}/{len(true_tokens)}\")\n",
        "print(f\"Correct tokens: {gpt2_small.to_str_tokens(prediction[is_correct])}\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSz0sfrMQGxS"
      },
      "source": [
        "**Induction heads** are a special kind of attention head which we'll examine a lot more in coming exercises. They allow a model to perform in-context learning of a specific form: generalising from one observation that token `B` follows token `A`, to predict that token `B` will follow `A` in future occurrences of `A`, even if these two tokens had never appeared together in the model's training data.\n",
        "\n",
        "**Can you see evidence of any induction heads at work, on this text?**\n",
        "\n",
        "<details>\n",
        "<summary>Evidence of induction heads</summary>\n",
        "\n",
        "The evidence for induction heads comes from the fact that the model successfully predicted `'ooked', 'Trans', 'former'` following the token `'H'`. This is because it's the second time that `HookedTransformer` had appeared in this text string, and the model predicted it the second time but not the first. (The model did predict `former` the first time, but we can reasonably assume that `Transformer` is a word this model had already been exposed to during training, so this prediction wouldn't require the induction capability, unlike `HookedTransformer`.)\n",
        "\n",
        "```python\n",
        "print(gpt2_small.to_str_tokens(\"HookedTransformer\", prepend_bos=False))     # --> ['H', 'ooked', 'Trans', 'former']\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hubEvfXyQGxS"
      },
      "source": [
        "## Caching all Activations\n",
        "\n",
        "The first basic operation when doing mechanistic interpretability is to break open the black box of the model and look at all of the internal activations of a model. This can be done with `logits, cache = model.run_with_cache(tokens)`. Let's try this out, on the first sentence from the GPT-2 paper.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - a note on <code>remove_batch_dim</code></summary>\n",
        "\n",
        "Every activation inside the model begins with a batch dimension. Here, because we only entered a single batch dimension, that dimension is always length 1 and kinda annoying, so passing in the `remove_batch_dim=True` keyword removes it.\n",
        "\n",
        "`gpt2_cache_no_batch_dim = gpt2_cache.remove_batch_dim()` would have achieved the same effect.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv1XbiEfQGxT",
        "outputId": "de985e99-a861-4c5d-f715-7419bf556de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'transformer_lens.ActivationCache.ActivationCache'>\n"
          ]
        }
      ],
      "source": [
        "gpt2_text = \"Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets.\"\n",
        "gpt2_tokens = gpt2_small.to_tokens(gpt2_text)\n",
        "gpt2_logits, gpt2_cache = gpt2_small.run_with_cache(gpt2_tokens, remove_batch_dim=True)\n",
        "\n",
        "print(type(gpt2_logits), type(gpt2_cache))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXH8buJuQGxT"
      },
      "source": [
        "If you inspect the `gpt2_cache` object, you should see that it contains a very large number of keys, each one corresponding to a different activation in the model. You can access the keys by indexing the cache directly, or by a more convenient indexing shorthand. For instance, here are 2 ways to extract the attention patterns for layer 0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "StOdGBUcQGxU"
      },
      "outputs": [],
      "source": [
        "attn_patterns_from_shorthand = gpt2_cache[\"pattern\", 0]\n",
        "attn_patterns_from_full_name = gpt2_cache[\"blocks.0.attn.hook_pattern\"]\n",
        "\n",
        "t.testing.assert_close(attn_patterns_from_shorthand, attn_patterns_from_full_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqoysYuIQGxU"
      },
      "source": [
        "<details>\n",
        "<summary>Aside: <code>utils.get_act_name</code></summary>\n",
        "\n",
        "The reason these are the same is that, under the hood, the first example actually indexes by `utils.get_act_name(\"pattern\", 0)`, which evaluates to `\"blocks.0.attn.hook_pattern\"`.\n",
        "\n",
        "In general, `utils.get_act_name` is a useful function for getting the full name of an activation, given its short name and layer number.\n",
        "\n",
        "You can use the diagram from the **Transformer Architecture** section to help you find activation names.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYbqLx1xQGxU"
      },
      "source": [
        "### Exercise - verify activations\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        ">\n",
        "> If you're already comfortable implementing things like attention calculations (e.g. having gone through Neel's transformer walkthrough) you can skip this exercise. However, it might serve as a useful refresher.\n",
        "> ```\n",
        "\n",
        "Verify that `hook_q`, `hook_k` and `hook_pattern` are related to each other in the way implied by the diagram. Do this by computing `layer0_pattern_from_cache` (the attention pattern taken directly from the cache, for layer 0) and `layer0_pattern_from_q_and_k` (the attention pattern calculated from `hook_q` and `hook_k`, for layer 0). Remember that attention pattern is the probabilities, so you'll need to scale and softmax appropriately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzV_xP9BQGxU",
        "outputId": "c16fba4f-cd32-41d9-a5cc-2624b5dc74fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tests passed!\n"
          ]
        }
      ],
      "source": [
        "layer0_pattern_from_cache = gpt2_cache[\"pattern\", 0]\n",
        "\n",
        "# YOUR CODE HERE - define `layer0_pattern_from_q_and_k` manually, by manually performing the steps of the attention calculation (dot product, masking, scaling, softmax)\n",
        "hook_q = gpt2_cache[\"q\",0]\n",
        "hook_k = gpt2_cache[\"k\",0]\n",
        "seqQ,nhead,dhead = hook_q.shape\n",
        "seqK,nhead,dhead = hook_k.shape\n",
        "\n",
        "pattern_unmasked = einops.einsum(hook_q,hook_k,\"seqQ nhead dhead,seqK nhead dhead -> nhead seqQ seqK\")\n",
        "blankmask = t.full((nhead,seqQ,seqK),-1e9)\n",
        "mask = t.triu(blankmask,1)\n",
        "attn_nomax = pattern_unmasked + mask\n",
        "layer0_pattern_from_q_and_k = (attn_nomax/dhead**0.5).softmax(-1)\n",
        "t.testing.assert_close(layer0_pattern_from_cache, layer0_pattern_from_q_and_k)\n",
        "print(\"Tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPFKxmcOQGxV"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "You'll need to use three different cache indexes in all:\n",
        "\n",
        "* `gpt2_cache[\"pattern\", 0]` to get the attention patterns, which have shape `[nhead, seqQ, seqK]`\n",
        "* `gpt2_cache[\"q\", 0]` to get the query vectors, which have shape `[seqQ, nhead, headsize]`\n",
        "* `gpt2_cache[\"k\", 0]` to get the key vectors, which have shape `[seqK, nhead, headsize]`\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "layer0_pattern_from_cache = gpt2_cache[\"pattern\", 0]\n",
        "\n",
        "q, k = gpt2_cache[\"q\", 0], gpt2_cache[\"k\", 0]\n",
        "seq, nhead, headsize = q.shape\n",
        "layer0_attn_scores = einops.einsum(q, k, \"seqQ n h, seqK n h -> n seqQ seqK\")\n",
        "mask = t.triu(t.ones((seq, seq), dtype=t.bool), diagonal=1).to(device)\n",
        "layer0_attn_scores.masked_fill_(mask, -1e9)\n",
        "layer0_pattern_from_q_and_k = (layer0_attn_scores / headsize**0.5).softmax(-1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoDKRDH9QGxV"
      },
      "source": [
        "## Visualising Attention Heads\n",
        "\n",
        "A key insight from the Mathematical Frameworks paper is that we should focus on interpreting the parts of the model that are intrinsically interpretable - the input tokens, the output logits and the attention patterns. Everything else (the residual stream, keys, queries, values, etc) are compressed intermediate states when calculating meaningful things. So a natural place to start is classifying heads by their attention patterns on various texts.\n",
        "\n",
        "When doing interpretability, it's always good to begin by visualising your data, rather than taking summary statistics. Summary statistics can be super misleading! But now that we have visualised the attention patterns, we can create some basic summary statistics and use our visualisations to validate them! (Accordingly, being good at web dev/data visualisation is a surprisingly useful skillset! Neural networks are very high-dimensional object.)\n",
        "\n",
        "Let's visualize the attention pattern of all the heads in layer 0, using [Alan Cooney's CircuitsVis library](https://github.com/alan-cooney/CircuitsVis) (based on Anthropic's PySvelte library). If you did the previous set of exercises, you'll have seen this library before.\n",
        "\n",
        "We will use the function `cv.attention.attention_patterns`, which takes two important arguments:\n",
        "\n",
        "* `attention`: the attention head patterns, of shape `[n_heads, seq_len, seq_len]`. This consists of the stacked grid of attention probabilities for each head, i.e. `attention[head, d, s]` is the attention probability from destination position `d` to source position `s` in attention head `head`.\n",
        "* `tokens`: List of tokens, which should have the same length as the `seq_len` dimension of `attention`. Make sure you're not accidentally passing in a list with a dummy dimension, or that differs from `seq_len` because of the BOS token!\n",
        "\n",
        "This visualization is interactive! Try hovering over a token or head, and click to lock. The grid on the top left and for each head is the attention pattern as a destination position by source position grid. It's lower triangular because GPT-2 has **causal attention**, attention can only look backwards, so information can only move forwards in the network.\n",
        "\n",
        "> Note - you can also use the `cv.attention.attention_heads` function, which presents the data in a different way (the syntax is exactly the same as `attention_patterns`). Note, if you display this in VSCode then it may exhibit a bug where the main plot continually shrinks in size - if this happens, you should instead save the HTML (i.e. with `html = cv.attention.attention_heads(...); with open(\"attn_heads.html\", \"w\") as f: f.write(str(html))`) and open the plot in your browser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "8UJHk9IFQGxV",
        "outputId": "dd72af77-67e2-4020-83a6-cfd75999afc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformer_lens.ActivationCache.ActivationCache'>\n",
            "torch.Size([12, 33, 33])\n",
            "Layer 0 Head Attention Patterns:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7e6c1646c2d0>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-e6a45736-5785\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-e6a45736-5785\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"<|endoftext|>\", \"Natural\", \" language\", \" processing\", \" tasks\", \",\", \" such\", \" as\", \" question\", \" answering\", \",\", \" machine\", \" translation\", \",\", \" reading\", \" comprehension\", \",\", \" and\", \" summar\", \"ization\", \",\", \" are\", \" typically\", \" approached\", \" with\", \" supervised\", \" learning\", \" on\", \" tasks\", \"pe\", \"cific\", \" datasets\", \".\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639418721199036, 0.03605814278125763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8389372825622559, 0.11828784644603729, 0.042774830013513565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4743613004684448, 0.13382022082805634, 0.27371740341186523, 0.1181010901927948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3560643494129181, 0.10184912383556366, 0.23054225742816925, 0.20397400856018066, 0.10757029801607132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6660143136978149, 0.1686638593673706, 0.04535672813653946, 0.03885500505566597, 0.06775479763746262, 0.0133552560582757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38626962900161743, 0.2851092219352722, 0.07609009742736816, 0.05908381938934326, 0.07223352789878845, 0.039796341210603714, 0.08141744136810303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3775394856929779, 0.1883881837129593, 0.11723991483449936, 0.0868559405207634, 0.0666918084025383, 0.03500015661120415, 0.09693009406328201, 0.03135443851351738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4869752824306488, 0.06781316548585892, 0.07952877879142761, 0.08480790257453918, 0.1590261608362198, 0.029577815905213356, 0.02568591758608818, 0.016474612057209015, 0.05011039599776268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29065507650375366, 0.0401349775493145, 0.14614856243133545, 0.09940596669912338, 0.1538919061422348, 0.03900161758065224, 0.024988971650600433, 0.03184131532907486, 0.10222820937633514, 0.07170344144105911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39624103903770447, 0.09694176912307739, 0.027270672842860222, 0.02355135791003704, 0.03723450377583504, 0.006502409465610981, 0.08118758350610733, 0.013088470324873924, 0.06990595906972885, 0.24043095111846924, 0.007645336911082268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24864788353443146, 0.1380205750465393, 0.0923532247543335, 0.0867612287402153, 0.1381969153881073, 0.05914194881916046, 0.03223859891295433, 0.03158240392804146, 0.030489441007375717, 0.038734838366508484, 0.06671839952468872, 0.037114497274160385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1914844512939453, 0.1617259532213211, 0.07445938140153885, 0.07740944623947144, 0.021961113438010216, 0.03392127901315689, 0.05125021934509277, 0.01951923966407776, 0.03132447972893715, 0.04020152986049652, 0.03874269127845764, 0.21578852832317352, 0.04221167042851448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37043169140815735, 0.08681419491767883, 0.02458467148244381, 0.021616321057081223, 0.03238872066140175, 0.005422735586762428, 0.07275225222110748, 0.011272803880274296, 0.06329693645238876, 0.217268168926239, 0.006367161870002747, 0.02960382215678692, 0.050998471677303314, 0.007182058412581682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19737647473812103, 0.046039972454309464, 0.0439998134970665, 0.13373452425003052, 0.054248202592134476, 0.02547571435570717, 0.027563493698835373, 0.02157093770802021, 0.05171824246644974, 0.06458097696304321, 0.028064634650945663, 0.23551598191261292, 0.019129790365695953, 0.029963519424200058, 0.021017687395215034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08907235413789749, 0.01928834617137909, 0.16653531789779663, 0.07281260192394257, 0.04738641902804375, 0.024487903341650963, 0.02898733876645565, 0.019370365887880325, 0.02667303942143917, 0.0731663927435875, 0.025704577565193176, 0.04242357611656189, 0.05869462341070175, 0.02893270179629326, 0.18119071424007416, 0.0952736958861351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.281672865152359, 0.06441289186477661, 0.018008548766374588, 0.01616962067782879, 0.02318389154970646, 0.0037532944697886705, 0.05472246930003166, 0.00790976732969284, 0.046164702624082565, 0.1694725900888443, 0.004361644387245178, 0.021011359989643097, 0.03549070656299591, 0.004932567942887545, 0.09555221349000931, 0.1472633183002472, 0.005917447619140148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2130548059940338, 0.0591236874461174, 0.03382088243961334, 0.027476875111460686, 0.028393540531396866, 0.008422899059951305, 0.040085308253765106, 0.011629271320998669, 0.05295189097523689, 0.1540464162826538, 0.00983181782066822, 0.036101944744586945, 0.04737287014722824, 0.011069186963140965, 0.09972471743822098, 0.13971354067325592, 0.013185334391891956, 0.013994951732456684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15871694684028625, 0.04387889429926872, 0.08712150156497955, 0.08998466283082962, 0.030738575384020805, 0.034148938953876495, 0.0249172393232584, 0.03139195218682289, 0.0248238705098629, 0.01979033090174198, 0.03625483810901642, 0.020694417878985405, 0.04284067824482918, 0.038208987563848495, 0.06234658509492874, 0.10919704288244247, 0.0413760170340538, 0.04916759952902794, 0.05440091714262962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10485511273145676, 0.12122288346290588, 0.06487482041120529, 0.08768720179796219, 0.03434052690863609, 0.017483947798609734, 0.034151818603277206, 0.015289152041077614, 0.023312130942940712, 0.02830648608505726, 0.0187204722315073, 0.028111929073929787, 0.04190531745553017, 0.0209895521402359, 0.046785082668066025, 0.08659634739160538, 0.02363184094429016, 0.024273181334137917, 0.16702403128147125, 0.010438220575451851, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22901973128318787, 0.05184381082653999, 0.013585193082690239, 0.012337246909737587, 0.01800544001162052, 0.0027703631203621626, 0.04238129034638405, 0.0058562601916491985, 0.036144886165857315, 0.13039223849773407, 0.0031534284353256226, 0.015672583132982254, 0.027800407260656357, 0.0035543241538107395, 0.07460814714431763, 0.11298281699419022, 0.00427227234467864, 0.006832204293459654, 0.18569739162921906, 0.018073637038469315, 0.005016355309635401, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18869920074939728, 0.03438711538910866, 0.022344758734107018, 0.019972747191786766, 0.016354041174054146, 0.006856544874608517, 0.020859047770500183, 0.005696007516235113, 0.034159161150455475, 0.07260986417531967, 0.00785721093416214, 0.0180402509868145, 0.026904471218585968, 0.009020394645631313, 0.06876447051763535, 0.1757873296737671, 0.01072007231414318, 0.009284541942179203, 0.1925639510154724, 0.025180324912071228, 0.01263907365500927, 0.021299351006746292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1195831149816513, 0.022259404882788658, 0.032947149127721786, 0.02017025649547577, 0.03565331548452377, 0.013459899462759495, 0.017516469582915306, 0.010057872161269188, 0.025856446474790573, 0.059559550136327744, 0.01508451346307993, 0.015008737333118916, 0.05317465960979462, 0.016597602516412735, 0.04155528545379639, 0.13129332661628723, 0.019296662881970406, 0.015855051577091217, 0.17925086617469788, 0.016183823347091675, 0.02229553461074829, 0.01546340249478817, 0.10187702625989914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14615531265735626, 0.02672751434147358, 0.016624554991722107, 0.01898769475519657, 0.06278639286756516, 0.015317168086767197, 0.01979224570095539, 0.014227775856852531, 0.02545814774930477, 0.04530351981520653, 0.01636434532701969, 0.03749305382370949, 0.013288660906255245, 0.01749655045568943, 0.0399458110332489, 0.058817531913518906, 0.01926097832620144, 0.024616044014692307, 0.03821968287229538, 0.02157779224216938, 0.02094990201294422, 0.07973216474056244, 0.05017606168985367, 0.17068105936050415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11321669816970825, 0.03674635291099548, 0.01178658101707697, 0.010274861939251423, 0.020370660349726677, 0.005243885796517134, 0.015918835997581482, 0.005266787484288216, 0.024891739711165428, 0.06593260169029236, 0.005933654960244894, 0.018209027126431465, 0.021020209416747093, 0.006667498033493757, 0.034828800708055496, 0.13742125034332275, 0.007927052676677704, 0.008618668653070927, 0.11377192288637161, 0.013557428494095802, 0.009277831763029099, 0.026121370494365692, 0.08499343693256378, 0.19073913991451263, 0.011263744905591011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13337713479995728, 0.02621660940349102, 0.038271527737379074, 0.0715256780385971, 0.053177691996097565, 0.013925840146839619, 0.007084188051521778, 0.013450142927467823, 0.009841453284025192, 0.011789786629378796, 0.013537588529288769, 0.03815499693155289, 0.04193305969238281, 0.013882278464734554, 0.03707147389650345, 0.13838453590869904, 0.014846325851976871, 0.03156952187418938, 0.05598176643252373, 0.015536676160991192, 0.01595636084675789, 0.045455560088157654, 0.016699673607945442, 0.025325771421194077, 0.0367189422249794, 0.08028544485569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10608974099159241, 0.019107727333903313, 0.024468647316098213, 0.027496375143527985, 0.016365813091397285, 0.0050114234909415245, 0.010413103736937046, 0.006081144325435162, 0.005301064345985651, 0.011143162846565247, 0.004565386101603508, 0.018969912081956863, 0.004321118351072073, 0.00481497822329402, 0.02940940298140049, 0.028682013973593712, 0.005097254645079374, 0.007234351709485054, 0.03412593528628349, 0.010370595380663872, 0.005643266253173351, 0.007283586077392101, 0.029389571398496628, 0.01003879401832819, 0.009134513325989246, 0.546663224697113, 0.012777911499142647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10467307269573212, 0.03321940079331398, 0.015341237187385559, 0.009373540058732033, 0.026595454663038254, 0.005787800066173077, 0.013571344316005707, 0.00455488683655858, 0.028058892115950584, 0.02610723115503788, 0.006353443488478661, 0.013315824791789055, 0.02662823349237442, 0.006888873875141144, 0.062047477811574936, 0.05890703946352005, 0.008068048395216465, 0.007557098288089037, 0.08522788435220718, 0.01707574538886547, 0.009256887249648571, 0.019695738330483437, 0.12617804110050201, 0.13061514496803284, 0.011351024731993675, 0.0898437574505806, 0.04638151824474335, 0.007325290702283382, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08561894297599792, 0.02143894135951996, 0.05641259625554085, 0.05706658959388733, 0.01980220153927803, 0.006727494299411774, 0.005809155758470297, 0.00451626256108284, 0.0031647509895265102, 0.01761520467698574, 0.006174600217491388, 0.08767974376678467, 0.012299856171011925, 0.006350455805659294, 0.017522133886814117, 0.14295217394828796, 0.006585482973605394, 0.00787569023668766, 0.030078914016485214, 0.013907486572861671, 0.007376696448773146, 0.007684790994971991, 0.022160828113555908, 0.01238502562046051, 0.011890066787600517, 0.08669780194759369, 0.19902536273002625, 0.013594485819339752, 0.029586223885416985, 0.0, 0.0, 0.0, 0.0], [0.1406458467245102, 0.013298697769641876, 0.01570296101272106, 0.017357872799038887, 0.02233150787651539, 0.02967226319015026, 0.04172082990407944, 0.018995430320501328, 0.038277123123407364, 0.04863560199737549, 0.03094690851867199, 0.016023898497223854, 0.02088090032339096, 0.032438237220048904, 0.030558133497834206, 0.022808346897363663, 0.035377588123083115, 0.031451594084501266, 0.034971147775650024, 0.018679115921258926, 0.03821910172700882, 0.022578874602913857, 0.06819558888673782, 0.04214096814393997, 0.028620852157473564, 0.037750035524368286, 0.0185780618339777, 0.03376871347427368, 0.03641697019338608, 0.012956843711435795, 0.0, 0.0, 0.0], [0.07168618589639664, 0.06924440711736679, 0.01930689997971058, 0.014161988161504269, 0.01682320423424244, 0.0193806029856205, 0.019257429987192154, 0.02200368233025074, 0.013706534169614315, 0.0357837900519371, 0.01846517249941826, 0.05207168683409691, 0.02008516900241375, 0.019862132146954536, 0.020662108436226845, 0.047251589596271515, 0.021076735109090805, 0.036787249147892, 0.024324078112840652, 0.003827548585832119, 0.02392066828906536, 0.00853323470801115, 0.026241622865200043, 0.027380075305700302, 0.034612007439136505, 0.022884182631969452, 0.10047898441553116, 0.06913501769304276, 0.025474585592746735, 0.06495603919029236, 0.030615346506237984, 0.0, 0.0], [0.0691077932715416, 0.03701226785778999, 0.03862114995718002, 0.05933321639895439, 0.015923552215099335, 0.007918553426861763, 0.010371049866080284, 0.006615662947297096, 0.0025200797244906425, 0.0260193832218647, 0.007905225269496441, 0.029652034863829613, 0.04000624269247055, 0.00845133513212204, 0.010741152800619602, 0.050275616347789764, 0.009428860619664192, 0.013601029291749, 0.05036922171711922, 0.03176712244749069, 0.010793033987283707, 0.0072168041951954365, 0.006478430237621069, 0.0148005997762084, 0.021585972979664803, 0.15769490599632263, 0.08884759247303009, 0.019016938284039497, 0.029729334637522697, 0.03316134959459305, 0.050883643329143524, 0.0341508574783802, 0.0], [0.14375509321689606, 0.016811035573482513, 0.009386667050421238, 0.006830308586359024, 0.01165685337036848, 0.0015672279987484217, 0.019711481407284737, 0.0023980382829904556, 0.02123589813709259, 0.04683678224682808, 0.0016905140364542603, 0.005827190354466438, 0.011979990638792515, 0.0018251386936753988, 0.042313333600759506, 0.054913729429244995, 0.002178653609007597, 0.002417013281956315, 0.09604069590568542, 0.0057528759352862835, 0.002557790372520685, 0.007121228612959385, 0.08889926970005035, 0.10852088779211044, 0.005179052706807852, 0.03657734394073486, 0.024719927459955215, 0.003734763478860259, 0.03107706643640995, 0.016887929290533066, 0.094508595764637, 0.07171524316072464, 0.0033723211381584406]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004246659518685192, 0.9995753169059753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005621908348985016, 0.01640728861093521, 0.9830306172370911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0011627586791291833, 0.0216820165514946, 0.003762046108022332, 0.9733933210372925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.724443740793504e-05, 0.0001720233412925154, 0.0002814398321788758, 0.0027421461418271065, 0.9967671632766724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00826844573020935, 0.00023985578445717692, 7.36189613235183e-05, 6.437728006858379e-05, 0.00017566324095241725, 0.9911779761314392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012215046444907784, 0.00540045415982604, 0.0016716319369152188, 0.00040775653906166553, 0.0006163661018945277, 0.0010931191500276327, 0.9895892143249512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001245975960046053, 0.0009121220791712403, 0.0005976713728159666, 0.00013656872033607215, 0.0003304101701360196, 0.0015722772805020213, 0.003880807664245367, 0.9913241863250732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00028217461658641696, 0.004068182315677404, 0.0026605194434523582, 0.0013093105517327785, 0.008030476048588753, 0.0002879090898204595, 0.00022922919015400112, 0.0003948427038267255, 0.9827372431755066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.47393324773293e-05, 0.00039538476266898215, 0.00013272723299451172, 0.00025852309772744775, 0.0010855591390281916, 9.198043699143454e-05, 0.00032670784275978804, 0.0005427454598248005, 0.006105933338403702, 0.9910256266593933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0033785076811909676, 5.090876584290527e-05, 1.6452078853035346e-05, 1.6926183889154345e-05, 4.181411713943817e-05, 0.49394041299819946, 0.0001298127754125744, 0.0008837342611514032, 3.221200677216984e-05, 2.7252099243924022e-05, 0.5014819502830505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.416055788984522e-05, 0.0013417234877124429, 0.0012613608269020915, 0.0021450743079185486, 0.004042360465973616, 0.0004830540856346488, 0.0001158266604761593, 0.00015203609655145556, 2.6925305064651184e-05, 0.00012675137259066105, 0.00031289938488043845, 0.9899077415466309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00037822307785972953, 0.000983756734058261, 0.03934124484658241, 0.0027322471141815186, 0.00366801954805851, 0.00011039181117666885, 0.00012931021046824753, 0.00021743500838056207, 0.00010623285197652876, 0.0007748190546408296, 6.647672853432596e-05, 0.0003148665127810091, 0.9511770009994507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00210172007791698, 2.4436882085865363e-05, 7.788777111272793e-06, 8.651618372823577e-06, 2.0140030756010674e-05, 0.29971376061439514, 7.525253022322431e-05, 0.0004898309707641602, 1.8459460989106447e-05, 1.534453986096196e-05, 0.32833874225616455, 4.175802678219043e-05, 6.469185791502241e-06, 0.3691376745700836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00014968313917052, 0.00011296597222099081, 0.0003629484854172915, 0.00018591186380945146, 0.00016460877668578178, 4.1432256693951786e-05, 2.8764718081220053e-05, 7.786935748299584e-05, 0.0009200984495691955, 0.010340185835957527, 2.7572339604375884e-05, 1.7833221136243083e-05, 0.0003305449790786952, 2.4375704015255906e-05, 0.9872152805328369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00010753796232165769, 0.002178182825446129, 0.002042605308815837, 0.004251915030181408, 0.006989872083067894, 2.5118699340964667e-05, 0.0007779006846249104, 0.0005783525411970913, 0.002937830751761794, 0.03322531282901764, 1.719921601761598e-05, 0.0008936444064602256, 0.0015238532796502113, 1.4656765415566042e-05, 0.006222618278115988, 0.9382133483886719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013634879142045975, 1.3226036571722943e-05, 4.013935267721536e-06, 4.803057436220115e-06, 1.0257443136652e-05, 0.19665947556495667, 4.527255077846348e-05, 0.00027762597892433405, 1.1714434549503494e-05, 9.47331227507675e-06, 0.22919593751430511, 2.6430629077367485e-05, 4.1018447518581524e-06, 0.26576098799705505, 8.515356967109255e-06, 4.536017513601109e-06, 0.30660009384155273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008924750727601349, 0.00013490796845871955, 4.779836308443919e-05, 5.803714520880021e-05, 0.00010480164200998843, 0.012799101881682873, 0.0007168236770667136, 0.032579515129327774, 2.6449932192917913e-05, 0.00011185064067831263, 0.011884260922670364, 4.010270276921801e-05, 5.5553988204337656e-05, 0.01237786840647459, 0.00010783460311358795, 5.404365947470069e-05, 0.013122137635946274, 0.9148864150047302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.075309672974981e-06, 4.396138319862075e-05, 3.398504850338213e-05, 7.940286013763398e-05, 5.4779007768956944e-05, 7.921543101474526e-07, 9.313333066529594e-06, 7.727078809693921e-06, 8.597262058174238e-05, 0.0001227404281962663, 5.141488941262651e-07, 1.702793611002562e-06, 3.834182643913664e-05, 4.450971005098836e-07, 0.00013928208500146866, 0.0003275803755968809, 3.994800863438286e-07, 3.948134235542966e-06, 0.999043881893158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.346216393169016e-05, 0.001839574659243226, 0.0025233160704374313, 0.01808728091418743, 0.0029363802168518305, 0.00027335836784914136, 4.872979116044007e-05, 0.00042127820779569447, 0.00015624375373590738, 0.0009748361771926284, 0.00020533644419629127, 0.0010228854371234775, 0.001954806037247181, 0.00019470401457510889, 0.0011294216383248568, 0.0016656133811920881, 0.0001873407600214705, 0.0009503461769782007, 0.0004455185553524643, 0.9648895859718323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010859699686989188, 8.512331987731159e-06, 2.530730625949218e-06, 3.0625258204963757e-06, 5.9751278058683965e-06, 0.13292624056339264, 3.345325603731908e-05, 0.00018891270156018436, 8.477753908664454e-06, 6.540426056744764e-06, 0.16445893049240112, 1.8130069292965345e-05, 3.0627477372036083e-06, 0.19719161093235016, 6.429846507671755e-06, 3.444732328716782e-06, 0.2331714779138565, 0.0022796255070716143, 3.7134359445190057e-06, 3.528808520059101e-05, 0.268558531999588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004197950765956193, 0.00011805014219135046, 0.0001424048823537305, 3.796788223553449e-05, 0.00019043161591980606, 0.0017651217058300972, 0.0005709825200028718, 0.0005008853622712195, 8.840746158966795e-05, 0.0001420867774868384, 0.0016639818204566836, 3.3481079299235716e-05, 2.441395918140188e-05, 0.0017546487506479025, 6.520311580970883e-05, 2.414262417005375e-05, 0.0018299140501767397, 0.001569102518260479, 3.9748771087033674e-05, 0.00015712401363998652, 0.0018554466078057885, 0.9870065450668335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.501784421037883e-05, 0.0014379840577021241, 6.345157453324646e-05, 0.00010864839714486152, 0.00015633183647878468, 3.2101231681735953e-06, 0.002203276613727212, 0.0002207657671533525, 5.2403069275896996e-05, 4.88158839289099e-05, 2.264461500089965e-06, 1.5327248547691852e-05, 4.157144758210052e-06, 2.0228408175171353e-06, 6.2968028942123055e-06, 4.8486737796338275e-05, 1.992900934055797e-06, 3.247004497097805e-05, 0.0012695139739662409, 1.96326454897644e-05, 1.8090934190695407e-06, 0.0005810291040688753, 0.9936450719833374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.450144039466977e-05, 0.0006139380275271833, 0.0009361191187053919, 0.0008487799786962569, 0.002850631484761834, 1.0365030902903527e-05, 0.00021614256547763944, 0.00017397513147443533, 0.002050836570560932, 0.0058052996173501015, 8.055229955061805e-06, 8.086584421107545e-05, 0.0007702436414547265, 7.288177130249096e-06, 0.001057614921592176, 0.002275596372783184, 6.663255135208601e-06, 0.0001162100670626387, 0.0005972448270767927, 8.736289601074532e-05, 6.332331849989714e-06, 6.0964473959757015e-05, 6.090577517170459e-05, 0.9812840819358826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005848738364875317, 0.0001590918836882338, 1.0836472029041033e-05, 7.365470082731918e-05, 0.00011349524720571935, 0.0008256656583398581, 0.00031910985126160085, 0.01852995902299881, 1.0226591257378459e-05, 4.9587179091759026e-05, 0.0007716414402239025, 4.4548200094141066e-05, 9.86501618172042e-06, 0.0008067172020673752, 2.2673864805256017e-05, 1.246411648025969e-05, 0.0008449104498140514, 0.008790099062025547, 3.579234180506319e-05, 3.662859307951294e-05, 0.0008917524828575552, 0.001079176552593708, 0.000370846304576844, 0.00010837137961061671, 0.9654980301856995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.6459925973322242e-05, 0.00017152438522316515, 3.2083211408462375e-05, 0.00010234182263957337, 0.0026318759191781282, 9.886184670904186e-06, 3.2508516596863046e-05, 3.741757609532215e-05, 0.00012631528079509735, 4.9912112444872037e-05, 8.302548849314917e-06, 8.443414844805375e-05, 3.127968739136122e-05, 7.633363566128537e-06, 1.0101362931891344e-05, 5.6673809012863785e-05, 7.442136393365217e-06, 2.7689680791809224e-05, 1.841835728555452e-05, 2.8794345325877657e-06, 6.840427886345424e-06, 4.279879249224905e-06, 0.0004317661514505744, 0.00017617484263610095, 8.995590906124562e-05, 0.9958257675170898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.6368023100076243e-05, 0.00018008674669545144, 0.00018082918541040272, 0.0003046466445084661, 0.0003939079470001161, 4.674831507145427e-05, 2.7231642889091745e-05, 4.8734815209172666e-05, 0.000291316129732877, 0.0004206165031064302, 3.804632797255181e-05, 0.0002524509036447853, 5.606727427220903e-05, 3.820361598627642e-05, 0.0015365086728706956, 0.0012537215370684862, 3.593418296077289e-05, 2.3036574930301867e-05, 0.0001803622581064701, 0.00012266065459698439, 3.517777076922357e-05, 6.924665649421513e-05, 0.00011267283844063058, 0.0008507365128025413, 0.0001436186139471829, 0.0002352791343582794, 0.9930958151817322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007048248080536723, 5.6753891840344295e-05, 3.3512924346723594e-06, 7.472657671314664e-06, 1.785946005838923e-05, 0.0008156524272635579, 4.952948074787855e-05, 0.0013530971482396126, 3.741763430298306e-05, 0.00014378006744664162, 0.0007639332907274365, 9.991685146815144e-06, 2.8844385724369204e-06, 0.0007552222232334316, 0.00010159601515624672, 3.120541123280418e-06, 0.0008060948457568884, 0.0011406756239011884, 1.4343104339786805e-05, 9.910167136695236e-06, 0.0008649178198538721, 8.663265907671303e-05, 3.4695473004831e-05, 0.00010265821038046852, 0.007663471158593893, 4.1878953197738156e-05, 3.4908730413008016e-06, 0.9844048619270325, 0.0, 0.0, 0.0, 0.0, 0.0], [2.0288294763304293e-05, 2.9542699849116616e-05, 5.0375034334138036e-05, 0.0009778320090845227, 0.3728252649307251, 6.66130017634714e-06, 1.573364352225326e-05, 3.981243571615778e-05, 0.00022353220265358686, 0.00012674322351813316, 5.118435637996299e-06, 0.00024116132408380508, 1.2973826414963696e-05, 4.800686838279944e-06, 2.3321617845795117e-05, 7.723527232883498e-05, 4.5934334593766835e-06, 1.9647124645416625e-05, 0.00021129944070708007, 1.1453501429059543e-05, 4.380481641419465e-06, 1.4442671272263397e-05, 3.676746564451605e-05, 0.000118453215691261, 3.7977195461280644e-05, 0.0007802759064361453, 0.0004048359696753323, 1.042955591401551e-05, 0.6236649751663208, 0.0, 0.0, 0.0, 0.0], [2.058288737316616e-05, 8.831225568428636e-05, 0.00020454842888284475, 0.00030188896926119924, 8.223879558499902e-05, 1.970437733689323e-05, 0.0001408507232554257, 2.8963118893443607e-05, 7.669370461371727e-06, 3.724609632627107e-05, 1.6736737961764447e-05, 6.404684245353565e-05, 0.0006910574156790972, 1.6027539459173568e-05, 0.0001560363598400727, 0.00014825885591562837, 1.5700039512012154e-05, 9.155373118119314e-05, 8.525074372300878e-05, 4.904507932224078e-06, 1.5784366041771136e-05, 5.293096910463646e-05, 0.0005298344185575843, 0.0005658384179696441, 6.167318497318774e-05, 6.729484448442236e-05, 0.000307743699522689, 1.0369129086029716e-05, 6.79933000355959e-05, 0.9960988759994507, 0.0, 0.0, 0.0], [1.3371331988309976e-05, 0.0009821540443226695, 0.0004154812777414918, 0.0001144233756349422, 0.0003873077221214771, 5.660860551870428e-06, 0.0012746269349008799, 0.0005708065000362694, 0.0006383624277077615, 0.0005776658072136343, 4.127733518544119e-06, 9.161743037111592e-06, 9.142841736320406e-05, 3.774864126171451e-06, 1.3575295270129573e-05, 0.0002916179655585438, 3.4474890071578557e-06, 7.899177580839023e-05, 0.003189122537150979, 4.885083853878314e-06, 3.165286670991918e-06, 1.4087455383560155e-05, 0.0001567144354339689, 0.00035448907874524593, 0.00017265455971937627, 0.0013050627894699574, 0.00021867647592443973, 2.6776719096233137e-05, 0.00026460207300260663, 1.3334529285202734e-05, 0.9888005256652832, 0.0, 0.0], [2.745508936641272e-05, 0.00016438262537121773, 7.996430940693244e-05, 0.001191497198306024, 0.0007883626385591924, 2.658417088241549e-06, 3.0057650292292237e-05, 7.457976153091295e-06, 0.00014940995606593788, 2.885718822653871e-05, 1.8738293192654965e-06, 0.0003328806778881699, 5.16086547577288e-05, 1.7577482367414632e-06, 0.00012656577746383846, 0.00014267012011259794, 1.6954487591647194e-06, 2.1952595488983206e-05, 0.00023040804080665112, 4.4293432438280433e-05, 1.6103322195704095e-06, 2.7008076358470134e-05, 0.0002388486755080521, 0.0001904603559523821, 9.49615514400648e-06, 0.00044664356391876936, 0.00022095811436884105, 5.379181402531685e-06, 0.0006956409779377282, 0.00015470781363546848, 0.0002548544143792242, 0.9943286776542664, 0.0], [0.006231046747416258, 9.722806862555444e-05, 6.871596269775182e-06, 2.1151136024855077e-05, 5.828053326695226e-05, 0.007238905411213636, 2.098789809679147e-05, 0.00025459096650592983, 6.243865209398791e-05, 2.09246627491666e-05, 0.007872136309742928, 5.5853244703030214e-05, 9.868757842923515e-06, 0.009169397875666618, 7.203003042377532e-05, 7.068680588417919e-06, 0.010345976799726486, 0.0013096530456095934, 3.803680374403484e-05, 8.022697147680447e-05, 0.012053255923092365, 4.071998773724772e-05, 3.6860749332845444e-06, 3.471342279226519e-05, 0.0005061830161139369, 8.918932871893048e-05, 2.9112088668625802e-05, 0.0012772815534844995, 8.489656465826556e-05, 0.00018447409092914313, 0.00013425741053652018, 6.813048094045371e-05, 0.9425214529037476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.943029522895813, 0.05697045475244522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9185556173324585, 0.03280003368854523, 0.04864436388015747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8779287934303284, 0.05643429234623909, 0.04271192103624344, 0.022925030440092087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.804131805896759, 0.02909821644425392, 0.07556727528572083, 0.05643591657280922, 0.034766778349876404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4943104684352875, 0.02018355205655098, 0.02796657383441925, 0.01831907592713833, 0.0314420685172081, 0.40777820348739624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6057478189468384, 0.029242414981126785, 0.09491509944200516, 0.07609348744153976, 0.06614662706851959, 0.08705782145261765, 0.04079665243625641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44838201999664307, 0.04542431980371475, 0.07401479780673981, 0.06864849478006363, 0.09376626461744308, 0.0877426341176033, 0.06534271687269211, 0.11667871475219727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4916927218437195, 0.13782072067260742, 0.03955019265413284, 0.061533186584711075, 0.04539967328310013, 0.04073144495487213, 0.06228701025247574, 0.05861866474151611, 0.06236641854047775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5404125452041626, 0.044426657259464264, 0.03957854583859444, 0.04188805818557739, 0.07529857754707336, 0.0466950349509716, 0.0484752394258976, 0.05500519275665283, 0.08293059468269348, 0.025289513170719147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28273555636405945, 0.014234174974262714, 0.017647748813033104, 0.011433064937591553, 0.021741721779108047, 0.266653835773468, 0.015403537079691887, 0.047349292784929276, 0.01776754856109619, 0.013926065526902676, 0.29110750555992126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.344966322183609, 0.046116799116134644, 0.05771547183394432, 0.11131860315799713, 0.11289367079734802, 0.027930330485105515, 0.038591887801885605, 0.05656527727842331, 0.05864057317376137, 0.0664859265089035, 0.026114365085959435, 0.05266084149479866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4699217975139618, 0.03201570361852646, 0.10772896558046341, 0.02700677700340748, 0.044658832252025604, 0.02277354709804058, 0.023117078468203545, 0.025491517037153244, 0.04950270056724548, 0.02657395601272583, 0.019708868116140366, 0.06337954849004745, 0.08812075853347778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20661760866641998, 0.010379291139543056, 0.012261935509741306, 0.00831909291446209, 0.016007086262106895, 0.1952774077653885, 0.01145328488200903, 0.03475673869252205, 0.01307358592748642, 0.010938980616629124, 0.21602492034435272, 0.005866493564099073, 0.02364230342209339, 0.23538129031658173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3399347960948944, 0.029161639511585236, 0.09540718793869019, 0.03395186364650726, 0.08440461754798889, 0.012559536844491959, 0.02935863845050335, 0.024564174935221672, 0.10622431337833405, 0.04689214378595352, 0.011469585821032524, 0.006369189824908972, 0.11145279556512833, 0.011317994445562363, 0.056931477040052414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4040881395339966, 0.024195684120059013, 0.03891001269221306, 0.014727428555488586, 0.024456579238176346, 0.038450006395578384, 0.039230331778526306, 0.037171389907598495, 0.06030002608895302, 0.041985440999269485, 0.037167154252529144, 0.016391245648264885, 0.03928966447710991, 0.03772980347275734, 0.13448576629161835, 0.01142128836363554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15876436233520508, 0.008203903213143349, 0.009295260533690453, 0.006221720017492771, 0.011793217621743679, 0.15069788694381714, 0.008851953782141209, 0.026313554495573044, 0.010186922736465931, 0.008433726616203785, 0.1676223874092102, 0.004420032259076834, 0.018211789429187775, 0.18350806832313538, 0.02092733606696129, 0.006447782274335623, 0.2001000940799713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1753920167684555, 0.020569654181599617, 0.018291426822543144, 0.009298018179833889, 0.01737789437174797, 0.04253477230668068, 0.020701566711068153, 0.050443943589925766, 0.02543802745640278, 0.01721823401749134, 0.043115369975566864, 0.01334981806576252, 0.028528621420264244, 0.045972537249326706, 0.034088198095560074, 0.01983419992029667, 0.04992840066552162, 0.3679172992706299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26033326983451843, 0.017148379236459732, 0.03745277225971222, 0.07594801485538483, 0.04674705117940903, 0.018068520352244377, 0.03134645149111748, 0.037415143102407455, 0.07175806909799576, 0.05872539058327675, 0.017078710719943047, 0.040305912494659424, 0.05706358328461647, 0.0171135775744915, 0.10491336137056351, 0.04670536145567894, 0.017230205237865448, 0.024682141840457916, 0.01996397040784359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30547067523002625, 0.05190495401620865, 0.043468963354825974, 0.021846864372491837, 0.02101719379425049, 0.03390473127365112, 0.04190473258495331, 0.03909287974238396, 0.028871947899460793, 0.023003434762358665, 0.0320579931139946, 0.023334499448537827, 0.07110598683357239, 0.03290087729692459, 0.06164192408323288, 0.03183261677622795, 0.033767662942409515, 0.04571490362286568, 0.03501521423459053, 0.022141896188259125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12242947518825531, 0.006105298176407814, 0.006670295726507902, 0.004581778310239315, 0.00933779589831829, 0.11381791532039642, 0.006783361081033945, 0.019719919189810753, 0.007580864708870649, 0.006613645236939192, 0.12765930593013763, 0.0035026560071855783, 0.014002328738570213, 0.14000985026359558, 0.015684885904192924, 0.005092608276754618, 0.1533621847629547, 0.03527417406439781, 0.022465622052550316, 0.006954459473490715, 0.1723516285419464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20538491010665894, 0.034778520464897156, 0.014682922512292862, 0.03118332475423813, 0.030931271612644196, 0.021952766925096512, 0.032908644527196884, 0.05740534886717796, 0.05587517097592354, 0.04864276573061943, 0.023520752787590027, 0.01510855183005333, 0.027386317029595375, 0.024518456310033798, 0.060604527592659, 0.03477614372968674, 0.026137834414839745, 0.05168437957763672, 0.06281402707099915, 0.020291468128561974, 0.028601735830307007, 0.09081020206212997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23978590965270996, 0.03132351115345955, 0.05037754774093628, 0.01586943119764328, 0.03901459649205208, 0.022805538028478622, 0.04285356402397156, 0.02888232097029686, 0.04046262055635452, 0.034107256680727005, 0.022644517943263054, 0.03923071548342705, 0.07238573580980301, 0.022345516830682755, 0.049581050872802734, 0.03193335607647896, 0.023325590416789055, 0.04521363228559494, 0.03055436909198761, 0.022876493632793427, 0.024732299149036407, 0.05549483001232147, 0.014199567027390003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2358168214559555, 0.020558306947350502, 0.04375005513429642, 0.0297048669308424, 0.03703878074884415, 0.014953462406992912, 0.040043093264102936, 0.027184367179870605, 0.04576181620359421, 0.03809260576963425, 0.014181884005665779, 0.03789154440164566, 0.06518244743347168, 0.014182931743562222, 0.054894935339689255, 0.023720962926745415, 0.014592780731618404, 0.025570042431354523, 0.07356180250644684, 0.039182357490062714, 0.014925516210496426, 0.046288661658763885, 0.02780105359852314, 0.015118876472115517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14254961907863617, 0.012010164558887482, 0.016881290823221207, 0.020742563530802727, 0.03245177119970322, 0.029626021161675453, 0.03029518760740757, 0.056208718568086624, 0.02960873395204544, 0.029481830075383186, 0.03263988345861435, 0.010038227774202824, 0.04078619182109833, 0.03462786599993706, 0.03391636908054352, 0.020155729725956917, 0.03684321045875549, 0.06064695864915848, 0.04744711145758629, 0.03252530097961426, 0.04040035605430603, 0.05947759747505188, 0.03129401057958603, 0.04792545735836029, 0.0714198648929596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22229067981243134, 0.059111349284648895, 0.0370267890393734, 0.04059012234210968, 0.027254492044448853, 0.01917477883398533, 0.03171537071466446, 0.020462162792682648, 0.03811328113079071, 0.019927892833948135, 0.01853892207145691, 0.015436709858477116, 0.04536491632461548, 0.0193557720631361, 0.05035829171538353, 0.03328137844800949, 0.020179763436317444, 0.03679434582591057, 0.043313875794410706, 0.028476420789957047, 0.021317342296242714, 0.04771285504102707, 0.013107025995850563, 0.026336045935750008, 0.03021138906478882, 0.03454805910587311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28438133001327515, 0.023870114237070084, 0.04641878232359886, 0.010260084643959999, 0.033909864723682404, 0.018301473930478096, 0.02370886504650116, 0.02476685121655464, 0.0257677361369133, 0.022968832403421402, 0.016735466197133064, 0.013406947255134583, 0.045986615121364594, 0.016673246398568153, 0.08106391131877899, 0.05033260956406593, 0.01672617346048355, 0.019904818385839462, 0.03032534383237362, 0.01014631986618042, 0.017318226397037506, 0.01904095895588398, 0.011081119067966938, 0.052046407014131546, 0.033353518694639206, 0.038808856159448624, 0.012695521116256714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11854352056980133, 0.013350939378142357, 0.013422021642327309, 0.0302731990814209, 0.026162942871451378, 0.020776191726326942, 0.021280208602547646, 0.037989355623722076, 0.03536440432071686, 0.03665180504322052, 0.022004010155797005, 0.015380024909973145, 0.030023114755749702, 0.02329968847334385, 0.03000754863023758, 0.014861365780234337, 0.0245219599455595, 0.03999800980091095, 0.03900158032774925, 0.03600766882300377, 0.026851218193769455, 0.06795872002840042, 0.03893132507801056, 0.05725807696580887, 0.06659837067127228, 0.03075684979557991, 0.023343218490481377, 0.059382691979408264, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25091859698295593, 0.011351891793310642, 0.023033946752548218, 0.01884976029396057, 0.013208831660449505, 0.016430387273430824, 0.03763696178793907, 0.02151942066848278, 0.03823147714138031, 0.031223101541399956, 0.01608109287917614, 0.017179002985358238, 0.0823965072631836, 0.015775403007864952, 0.049693115055561066, 0.03397902101278305, 0.016469139605760574, 0.025656115263700485, 0.053269315510988235, 0.024380968883633614, 0.017032910138368607, 0.03106255829334259, 0.014834254048764706, 0.04310779646039009, 0.0278183463960886, 0.015127943828701973, 0.012749834917485714, 0.026852663606405258, 0.014129591174423695, 0.0, 0.0, 0.0, 0.0], [0.19256944954395294, 0.022833673283457756, 0.014495889656245708, 0.028055019676685333, 0.03290428966283798, 0.018577082082629204, 0.02377673052251339, 0.014988926239311695, 0.027755478397011757, 0.01995215192437172, 0.018426889553666115, 0.02680845372378826, 0.040261976420879364, 0.018957344815135002, 0.01998024247586727, 0.039050307124853134, 0.01949433796107769, 0.030714334920048714, 0.07932320982217789, 0.03619769960641861, 0.020379599183797836, 0.023319294676184654, 0.018723847344517708, 0.05692766606807709, 0.02392755076289177, 0.039243265986442566, 0.021783530712127686, 0.020374223589897156, 0.041788313537836075, 0.008409240283071995, 0.0, 0.0, 0.0], [0.18919387459754944, 0.014352075755596161, 0.0278293676674366, 0.018936043605208397, 0.054552335292100906, 0.024302400648593903, 0.020752547308802605, 0.03050178848206997, 0.016900410875678062, 0.029904045164585114, 0.02311178483068943, 0.021664844825863838, 0.0333598330616951, 0.023050503805279732, 0.027927033603191376, 0.026253478601574898, 0.024257969111204147, 0.02439497970044613, 0.017666680738329887, 0.022081071510910988, 0.02544151246547699, 0.023996727541089058, 0.015941409394145012, 0.021863479167222977, 0.048762742429971695, 0.010234068147838116, 0.025762980803847313, 0.061923276633024216, 0.06737106293439865, 0.018184129148721695, 0.00952551607042551, 0.0, 0.0], [0.27111953496932983, 0.05460578203201294, 0.03970597684383392, 0.03512894734740257, 0.020313767716288567, 0.008183852769434452, 0.022556617856025696, 0.014036444947123528, 0.026198463514447212, 0.03235536068677902, 0.007185027468949556, 0.01081349328160286, 0.05162609741091728, 0.007057543378323317, 0.04232776165008545, 0.018505984917283058, 0.006952994968742132, 0.012550849467515945, 0.037855181843042374, 0.014787377789616585, 0.007130765821784735, 0.018956730142235756, 0.010758972726762295, 0.02354053035378456, 0.01625620760023594, 0.007915407419204712, 0.03652311861515045, 0.014562279917299747, 0.019251449033617973, 0.010911819525063038, 0.0343967080116272, 0.06592902541160583, 0.0], [0.14836539328098297, 0.014506885781884193, 0.007646287325769663, 0.01103874109685421, 0.02630249410867691, 0.013194814324378967, 0.027184873819351196, 0.017392195761203766, 0.016122113913297653, 0.03288079425692558, 0.014050282537937164, 0.007167341653257608, 0.0161200612783432, 0.01464702095836401, 0.018450897186994553, 0.013102118857204914, 0.015283250249922276, 0.014542998746037483, 0.05961218848824501, 0.022383900359272957, 0.016796976327896118, 0.10928261280059814, 0.07263996452093124, 0.08393712341785431, 0.02524900995194912, 0.03774847835302353, 0.01622692681849003, 0.02495388500392437, 0.042165789753198624, 0.004525812342762947, 0.01449135784059763, 0.019145702943205833, 0.02284165285527706]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09646999090909958, 0.903529942035675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.043252408504486084, 0.08177754282951355, 0.8749701380729675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09995390474796295, 0.025312701240181923, 0.020108036696910858, 0.854625403881073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024889355525374413, 0.00320735527202487, 0.0018421602435410023, 0.022361503913998604, 0.9476996660232544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10732372850179672, 0.01784166693687439, 0.01955333724617958, 0.0433332584798336, 0.10211502760648727, 0.7098329663276672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006426361855119467, 0.0004479786439333111, 0.00014756617019884288, 0.00046936815488152206, 0.001441190019249916, 0.0038596985395997763, 0.98720782995224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010354582918807864, 0.0001990183664020151, 0.0001602039410499856, 6.937277794349939e-05, 0.000386741739930585, 0.005171590019017458, 0.8964056372642517, 0.09657198190689087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012883353047072887, 0.0003233459428884089, 0.0002652723924256861, 0.00025490688858553767, 0.00020129882614128292, 0.00010049015691038221, 0.0005700902547687292, 0.00040913093835115433, 0.9965871572494507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001874162262538448, 1.619654540263582e-05, 4.2281080823158845e-06, 0.0002875888312701136, 1.1125715900561772e-05, 9.805656191019807e-06, 0.0001556719362270087, 7.632971392013133e-05, 0.0034869094379246235, 0.9957647323608398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015741519629955292, 0.0006393605144694448, 0.0004571522295009345, 0.0009912526002153754, 0.0021140349563211203, 0.018089747056365013, 0.0471203550696373, 0.07010902464389801, 0.061528366059064865, 0.27690407633781433, 0.5063050389289856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000616659817751497, 0.0005207078065723181, 4.61151976196561e-05, 0.001461300882510841, 0.0005623759934678674, 4.4476037146523595e-05, 0.00036539699067361653, 0.0002860168751794845, 0.004506122786551714, 0.005816523917019367, 0.0007244537118822336, 0.9850499033927917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010478587355464697, 3.062820542254485e-05, 0.00017345046217087656, 5.423139737104066e-05, 6.388442125171423e-05, 1.12611596705392e-05, 1.7169008060591295e-05, 1.3931321518612094e-05, 0.002076044213026762, 0.0002692685811780393, 0.00015268517017830163, 0.0036844443529844284, 0.992405116558075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010746264830231667, 0.0002535430248826742, 0.00015322912076953799, 0.0002928699250333011, 0.0005376791814342141, 0.004423539154231548, 0.00988432765007019, 0.012843023985624313, 0.012738605961203575, 0.05966855585575104, 0.10772986710071564, 0.024745658040046692, 0.07808699458837509, 0.6778957843780518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041218000114895403, 2.6218713173875585e-05, 1.77559231815394e-05, 0.00019181902462150902, 3.2979460229398683e-06, 3.912674856110243e-06, 1.043809788825456e-05, 4.906844878860284e-06, 0.000586855923756957, 0.0030381556134670973, 3.693124745041132e-05, 0.0007724311435595155, 0.009622619487345219, 0.00016094425518531352, 0.9851114153862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00010886562085943297, 3.58454167326272e-06, 5.191652689973125e-06, 3.083834599237889e-05, 1.840872755565215e-05, 7.954750458338822e-07, 3.353204192535486e-06, 6.574371127499035e-06, 0.0007270933128893375, 0.0018232447328045964, 7.853259376133792e-06, 0.00030627453816123307, 0.006975044962018728, 3.4850869269575924e-05, 0.0282927043735981, 0.9616552591323853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006073995493352413, 8.815199544187635e-05, 4.583775080391206e-05, 8.250488463090733e-05, 0.00012720438826363534, 0.000931252259761095, 0.0016700000269338489, 0.0019381919410079718, 0.002101697726175189, 0.010131681337952614, 0.016047311946749687, 0.003835386596620083, 0.012242159806191921, 0.10037077963352203, 0.07853133976459503, 0.10997357219457626, 0.6558089256286621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002186299068853259, 1.189292743219994e-05, 1.6735941244405694e-05, 2.081546699628234e-05, 2.1162548364372924e-05, 0.0007714926614426076, 0.0008652099058963358, 0.0005560303688980639, 0.00015655897732358426, 0.0019499945919960737, 0.010891207493841648, 0.00039543010643683374, 0.001514473813585937, 0.06916320323944092, 0.004308105446398258, 0.004035164602100849, 0.4939698576927185, 0.4091663956642151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.9797989807557315e-05, 4.972393412572274e-07, 9.165694869750496e-09, 1.3230416584519844e-07, 5.601832597790235e-08, 1.1903876995233986e-08, 6.153105118755775e-07, 4.068542835966582e-08, 4.517441993812099e-06, 1.4017764442542102e-05, 1.6456900198136282e-07, 1.0863833495022845e-06, 7.444068614859134e-06, 1.00566455785156e-06, 2.7594995117397048e-05, 0.00031378038693219423, 6.20114269622718e-06, 8.213378350774292e-06, 0.9995948672294617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.497162758023478e-06, 8.692020401213085e-07, 1.405140778842906e-06, 3.770490479837463e-07, 3.3291667023149785e-07, 6.104973948595216e-08, 2.542995680698823e-08, 1.1067781713336444e-07, 3.6708741390611976e-05, 5.70481461181771e-07, 6.172353437250422e-07, 0.00015627966786269099, 0.0001473798620281741, 3.0103849439910846e-06, 6.130666588433087e-05, 0.00177699641790241, 1.8545975763117895e-05, 3.4263168345205486e-05, 0.9233516454696655, 0.07440308481454849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0036490089260041714, 3.749436655198224e-05, 1.7470789316575974e-05, 2.8449203455238603e-05, 3.312428088975139e-05, 0.00019569222058635205, 0.0002647594374138862, 0.00024690417922101915, 0.0002803316747304052, 0.0013949201675131917, 0.0017910292372107506, 0.00042467910679988563, 0.0014623713213950396, 0.009717762470245361, 0.008053941652178764, 0.013200568035244942, 0.06315956264734268, 0.07152795046567917, 0.0752311572432518, 0.024205081164836884, 0.7250778079032898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006410888745449483, 3.925701548723737e-06, 1.1607372698563267e-06, 1.5375495650005178e-06, 9.072633133655472e-07, 8.058204912231304e-06, 1.3223946552898269e-05, 4.619919764081715e-06, 3.678829671116546e-05, 4.5651795517187566e-05, 7.577831274829805e-05, 2.2741733118891716e-05, 5.6684690207475796e-05, 0.0004737513663712889, 0.0003640766954049468, 0.00042400186066515744, 0.003757331520318985, 0.00436313496902585, 0.007395221386104822, 0.005022627301514149, 0.05575621873140335, 0.9215314984321594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000537768064532429, 8.122559620460379e-07, 2.3018583306111395e-06, 1.47003993333783e-06, 1.8703644855122548e-06, 6.024494041412254e-07, 4.127825377508998e-06, 1.6705714642739622e-06, 2.0471920834097546e-06, 7.43004638934508e-05, 3.5942262002208736e-06, 7.171494871727191e-06, 3.052817555726506e-05, 1.892773616418708e-05, 0.0002543877635616809, 0.0001949636498466134, 0.00012626526586245745, 0.0001823053607949987, 0.0037352198269218206, 0.000672711234074086, 0.001579830888658762, 0.011177674867212772, 0.9813894629478455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.512824570061639e-05, 4.870875613960379e-07, 1.2458967830752954e-06, 2.0811336298720562e-07, 1.9242880000547302e-07, 3.70403121507934e-08, 4.5552522465186485e-07, 5.504545796952698e-08, 1.532037913420936e-06, 5.083314590592636e-06, 2.1401001504273154e-07, 1.4595307220588438e-06, 1.4768388609809335e-05, 1.063502395481919e-06, 2.9461507438099943e-05, 5.7288165407953784e-05, 6.615693564526737e-06, 7.84422445576638e-06, 0.00015063813771121204, 0.00022636937501374632, 7.97359534772113e-05, 0.00013040847261436284, 0.010868419893085957, 0.9883312582969666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041663245065137744, 2.2503695618070196e-06, 5.270543169899611e-06, 2.7549147489480674e-05, 3.9630536775803193e-05, 7.51473589843954e-06, 8.100932973320596e-06, 1.1581341823330149e-05, 1.3205953109718394e-05, 6.750722968718037e-05, 2.5212764739990234e-05, 1.4860672308714129e-05, 7.52170235500671e-05, 0.00011457463551778346, 0.00025745289167389274, 0.00036668599932454526, 0.0006904734764248133, 0.0014518474927172065, 0.003246019361540675, 0.0006353409844450653, 0.008745579980313778, 0.015190845355391502, 0.01815016381442547, 0.13303308188915253, 0.8174033761024475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.6739300917834044e-05, 8.245334015555272e-08, 3.25739257789337e-08, 2.8737504820242066e-08, 1.621771161808283e-07, 1.5275413156601303e-09, 2.327868919849152e-08, 5.576728856482305e-09, 1.2825790918213897e-07, 1.342952486993454e-07, 6.160572496582972e-09, 2.5232574785150064e-07, 3.205760094715515e-06, 2.627727724302531e-08, 7.619977395734168e-07, 7.901960088929627e-06, 1.3940493204245286e-07, 1.9552594210381358e-07, 0.0003202258376404643, 8.173685728252167e-07, 1.5630005236744182e-06, 3.763166887438274e-06, 0.0007450513658113778, 0.003715230617672205, 3.9344242395600304e-05, 0.995144248008728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023842263908591121, 5.040105861553457e-06, 1.320860292253201e-06, 8.599827197031118e-06, 5.166048595128814e-06, 1.347093672166011e-07, 6.710809543619689e-07, 2.6996977453563886e-07, 6.345730525936233e-06, 4.417830496095121e-05, 2.7445037176221376e-07, 2.0171210053376853e-05, 1.6526657418580726e-05, 8.122790404740954e-07, 0.00010771022061817348, 0.00012397441605571657, 3.5075884170510108e-06, 8.505847290507518e-06, 6.980274338275194e-05, 0.0002681366167962551, 2.8792892408091575e-05, 0.00011957916285609826, 0.0001296167611144483, 0.007425940595567226, 0.0007109721773304045, 0.005815021228045225, 0.984840452671051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00040899476152844727, 6.095366416047909e-07, 1.9963897557317978e-06, 9.310323548561428e-06, 3.7690506360377185e-06, 1.9876508758898126e-06, 4.5765477807435673e-07, 1.06907145891455e-06, 3.0871688068145886e-06, 9.211416909238324e-06, 4.724366135633318e-06, 1.2070046295775683e-06, 5.095616870676167e-06, 1.8047086996375583e-05, 4.857865860685706e-05, 4.1693794628372416e-05, 0.00010537506022956222, 0.00022466850350610912, 0.00011528616596478969, 0.0002492897037882358, 0.0013673118082806468, 0.0016190301394090056, 0.00132751592900604, 0.0034917863085865974, 0.06305655837059021, 0.006469059269875288, 0.09512630850076675, 0.8262879252433777, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003180466592311859, 1.4181814549374394e-06, 3.1855009297032666e-07, 2.7823105028801365e-06, 5.388593490351923e-05, 4.300602540752152e-08, 5.38626068191661e-07, 8.497841008647811e-08, 5.999703489578678e-07, 4.110322151973378e-06, 7.099385612718834e-08, 8.454292128590168e-07, 2.526610387576511e-06, 2.1983822762194904e-07, 6.098234734963626e-06, 2.112996662617661e-05, 9.41176608648675e-07, 9.950366575139924e-07, 3.041357376787346e-05, 2.976983751068474e-06, 8.453844202449545e-06, 2.600699008326046e-05, 0.00023055807105265558, 0.001338335918262601, 0.00021758218645118177, 0.007014384958893061, 0.017923979088664055, 0.000530267134308815, 0.9722622632980347, 0.0, 0.0, 0.0, 0.0], [1.8505296850435116e-07, 5.565692351439111e-09, 7.262711543276623e-10, 7.745998509278706e-09, 1.507951097323712e-08, 8.228537295984495e-10, 1.7915484651354063e-09, 1.7345679337310571e-09, 1.096253487986587e-08, 5.0033129639359686e-08, 3.9228313930550485e-09, 1.001394380750753e-07, 2.333783655217303e-08, 1.6555286919128775e-08, 5.171339623188942e-08, 1.614605764643784e-07, 9.827901692460728e-08, 2.707459714201832e-07, 5.411987331171986e-06, 2.5083886612264905e-07, 1.1806023394456133e-06, 2.8004308205709094e-06, 4.61038098364952e-06, 0.00022679254470858723, 5.794259050162509e-05, 0.0004519563226494938, 0.00011976490350207314, 0.00023980853438843042, 0.001874009263701737, 0.9970145225524902, 0.0, 0.0, 0.0], [4.347461799625307e-05, 2.968866283481475e-06, 3.919368225524522e-07, 9.117064223573834e-07, 4.3644891434269084e-07, 4.686581345225704e-09, 9.240376641628245e-08, 1.241937130913584e-08, 7.188949524561394e-08, 6.304542807811231e-07, 6.1088996083924485e-09, 1.9987159305401292e-07, 1.4578700984202442e-06, 1.4727342012577083e-08, 1.7957290765480138e-07, 2.6422658265801147e-05, 5.112665846240816e-08, 4.710682333097793e-08, 0.001576117007061839, 2.1989408196532167e-06, 3.333985034714715e-07, 2.1814789761265274e-06, 0.0001624042197363451, 0.0017777644097805023, 1.174922817881452e-05, 0.00361609342508018, 6.199476774781942e-05, 3.516826109262183e-05, 0.001148871029727161, 0.016085602343082428, 0.975442111492157, 0.0, 0.0], [0.0011562933214008808, 6.199030394782312e-06, 6.137789227977919e-07, 3.1026631859276677e-06, 8.228416277233919e-07, 4.36601119702118e-08, 9.36323729661126e-08, 2.7735437058140633e-08, 5.109505423206429e-07, 1.2355309308986762e-06, 3.825297056891941e-08, 1.1272275060036918e-06, 1.9008989511348773e-06, 8.714057031511402e-08, 5.398172561399406e-06, 7.3934234023909084e-06, 3.1288666946238664e-07, 3.0146313179102435e-07, 0.0001359532616334036, 1.334382250206545e-05, 2.3996476556931157e-06, 3.871273293043487e-05, 0.0008219640585593879, 0.0006131274858489633, 2.151845910702832e-05, 0.004140730947256088, 0.0008760871132835746, 0.00011684626952046528, 0.0021590713877230883, 0.02752530761063099, 0.04434975981712341, 0.9179997444152832, 0.0], [0.003194286022335291, 4.6816610847599804e-05, 3.499119702610187e-05, 2.7043071895604953e-05, 1.400027576892171e-05, 1.708509080344811e-05, 8.051882105064578e-06, 3.9098295019357465e-06, 1.0716913493524771e-05, 1.793078990885988e-05, 1.4207491403794847e-05, 2.6911246095551178e-05, 2.6411986254970543e-05, 3.1100214982870966e-05, 1.1198586435057223e-05, 5.485487054102123e-05, 0.00011474463099148124, 0.00010493670561118051, 0.00028063016361556947, 0.00020839045464526862, 0.0009329259628430009, 0.0018989999080076814, 0.0011267592199146748, 0.0019257249077782035, 0.003917154390364885, 0.007499453146010637, 0.0106959268450737, 0.023199843242764473, 0.03039816953241825, 0.12729336321353912, 0.04325321689248085, 0.17668063938617706, 0.5669296383857727]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25308626890182495, 0.7469137907028198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30671602487564087, 0.3290638327598572, 0.36422017216682434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07416975498199463, 0.16189667582511902, 0.05432593822479248, 0.7096075415611267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16688226163387299, 0.03901785984635353, 0.03822459653019905, 0.21398362517356873, 0.5418916344642639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1948363482952118, 0.21119245886802673, 0.05150560662150383, 0.08703835308551788, 0.229995459318161, 0.22543172538280487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13900133967399597, 0.02974863536655903, 0.038606978952884674, 0.051332734525203705, 0.19284239411354065, 0.08012380450963974, 0.46834418177604675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08969774097204208, 0.04080598056316376, 0.034733086824417114, 0.08414526283740997, 0.09911048412322998, 0.07059450447559357, 0.13616575300693512, 0.4447471797466278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05986514315009117, 0.020190445706248283, 0.018785327672958374, 0.10584729164838791, 0.057948824018239975, 0.027517717331647873, 0.0566631518304348, 0.08226766437292099, 0.5709145069122314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010379279963672161, 0.004698257893323898, 0.004143994301557541, 0.007291416637599468, 0.0062567018903791904, 0.003318049944937229, 0.00917502585798502, 0.018754417076706886, 0.03393152728676796, 0.9020513892173767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0727011114358902, 0.04776482656598091, 0.01050033699721098, 0.0161594208329916, 0.04617820680141449, 0.05249457061290741, 0.05184565857052803, 0.21189527213573456, 0.035158224403858185, 0.17267188429832458, 0.28263047337532043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015126868151128292, 0.004731183405965567, 0.002322629326954484, 0.006575732491910458, 0.01836243085563183, 0.003339658956974745, 0.008784198202192783, 0.007409723941236734, 0.006289792712777853, 0.07638929039239883, 0.012003449723124504, 0.8386650681495667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.032331958413124084, 0.010628974065184593, 0.0026151672936975956, 0.0011762939393520355, 0.0030932873487472534, 0.00150555360596627, 0.007079716771841049, 0.0028344711754471064, 0.005003888159990311, 0.01203258614987135, 0.003987773787230253, 0.05187242105603218, 0.8658378720283508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.050455864518880844, 0.026538824662566185, 0.005783269181847572, 0.00808729324489832, 0.021799379959702492, 0.025670353323221207, 0.022779015824198723, 0.09139913320541382, 0.015017377212643623, 0.07093919813632965, 0.12448625266551971, 0.12668342888355255, 0.061021383851766586, 0.34933918714523315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05474120005965233, 0.05296842381358147, 0.00398812722414732, 0.012351608835160732, 0.004415616393089294, 0.0035962751135230064, 0.011385679244995117, 0.00982806459069252, 0.01474972628057003, 0.07078820466995239, 0.011209171265363693, 0.051640551537275314, 0.19734397530555725, 0.027129260823130608, 0.4738641083240509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007163074798882008, 0.0049638510681688786, 0.0027692264411598444, 0.0019424431957304478, 0.010544744320213795, 0.0014144869055598974, 0.0036636609584093094, 0.0031499466858804226, 0.005481296218931675, 0.021614039316773415, 0.003922193311154842, 0.07935071736574173, 0.2247791737318039, 0.009166942909359932, 0.027402691543102264, 0.5926714539527893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03461107611656189, 0.015296346507966518, 0.003095124149695039, 0.003899093484506011, 0.009989401325583458, 0.011446869932115078, 0.009189348667860031, 0.03356512635946274, 0.005761214066296816, 0.025581039488315582, 0.043846841901540756, 0.045213643461465836, 0.020553411915898323, 0.11962327361106873, 0.15673257410526276, 0.13173453509807587, 0.32986098527908325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.017253858968615532, 0.004397520795464516, 0.004968684632331133, 0.007064307574182749, 0.006634886842221022, 0.006910951808094978, 0.011386895552277565, 0.01617850922048092, 0.02031775750219822, 0.020396798849105835, 0.023422079160809517, 0.01890912838280201, 0.0402420274913311, 0.06200673431158066, 0.1164536327123642, 0.07975101470947266, 0.16864453256130219, 0.37506064772605896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002459116280078888, 0.00024919791030697525, 3.400469358894043e-05, 0.0002113294176524505, 0.00020066798606421798, 0.00012589257676154375, 0.00036506823380477726, 0.0003735981590580195, 0.00013798549480270594, 0.0004702214209828526, 0.00027151801623404026, 0.0034170830622315407, 0.0006049814983271062, 0.0005454604397527874, 0.0008937679813243449, 0.0015852140495553613, 0.0012150746770203114, 0.0028212708421051502, 0.9840186238288879, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00015282449021469802, 0.03892357647418976, 0.00047151927719824016, 0.0003731812466867268, 3.271793684689328e-05, 1.0635613762133289e-05, 3.82458756575943e-06, 1.324470758845564e-05, 6.418924022000283e-05, 2.7344371119397692e-05, 2.8319987904978916e-05, 0.0022295680828392506, 0.0013866389635950327, 7.163518603192642e-05, 0.00014025568088982254, 0.00824644137173891, 0.00019678636454045773, 0.00020546688756439835, 0.8976381421089172, 0.049783799797296524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02645810879766941, 0.010410881601274014, 0.0021332567557692528, 0.0024560168385505676, 0.005542594939470291, 0.005954573396593332, 0.004195827059447765, 0.01345154270529747, 0.002351952949538827, 0.009471964091062546, 0.015433412045240402, 0.014804958365857601, 0.006865768227726221, 0.03787313401699066, 0.04744938015937805, 0.04547279700636864, 0.10199157148599625, 0.08666396886110306, 0.06470183283090591, 0.1016075611114502, 0.3947088420391083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021157877519726753, 0.00354843121021986, 0.001744113047607243, 0.0035093037877231836, 0.004201893694698811, 0.0025777805130928755, 0.004015853628516197, 0.004599003586918116, 0.003955155145376921, 0.0064558410085737705, 0.005907890386879444, 0.0037331627681851387, 0.009013410657644272, 0.013927983120083809, 0.029895808547735214, 0.020082315430045128, 0.03804437443614006, 0.06883098930120468, 0.0815289169549942, 0.038340236991643906, 0.1516025811433792, 0.4833270013332367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014211690286174417, 0.0004069015849381685, 0.0002714423753786832, 0.0014869242440909147, 0.0006475155241787434, 0.0002567152841947973, 0.00027297638007439673, 0.0005059854011051357, 0.00017537508392706513, 0.0012059608707204461, 0.0005902891862206161, 0.0004307391936890781, 0.0003699962398968637, 0.0013322837185114622, 0.0007594277849420905, 0.002518308814615011, 0.003599978983402252, 0.0047567193396389484, 0.011892938055098057, 0.0034102171193808317, 0.013851102441549301, 0.05907326936721802, 0.8907637596130371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005058860406279564, 0.000882354099303484, 0.0015358275268226862, 0.0016909866826608777, 0.0013438730966299772, 0.0004949701833538711, 0.0006572249112650752, 0.000552159093786031, 0.000581209606025368, 0.002054559765383601, 0.0008380856597796082, 0.0010067481780424714, 0.0011300848564133048, 0.001613991684280336, 0.00502287270501256, 0.014576866291463375, 0.0037143270019441843, 0.00468147499486804, 0.00791381485760212, 0.00677838921546936, 0.01229135412722826, 0.02773299440741539, 0.10214640945196152, 0.7957004904747009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004004694987088442, 0.00045769716962240636, 0.0015645220410078764, 0.003137202700600028, 0.001993744168430567, 0.0003789264301303774, 0.0004957786295562983, 0.0005698024178855121, 0.0010052063735201955, 0.0023432238958775997, 0.0005772150470875204, 0.0016756131080910563, 0.0030787368305027485, 0.0012285251868888736, 0.005278326105326414, 0.006328050512820482, 0.003151729004457593, 0.005319306161254644, 0.021383114159107208, 0.006147704552859068, 0.012332224287092686, 0.0740215927362442, 0.12114027142524719, 0.5611116290092468, 0.16127507388591766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001128658070228994, 4.988930231775157e-05, 4.129138324060477e-05, 9.24963824218139e-05, 5.51363846170716e-05, 3.8617330574197695e-05, 5.59204381715972e-05, 0.0001489632559241727, 5.509230959432898e-06, 6.817452958784997e-05, 3.6204492062097415e-05, 4.623966015060432e-05, 0.0010655045043677092, 5.919886825722642e-05, 7.787275535520166e-05, 0.00038421317003667355, 0.00011692449334077537, 0.00022428261581808329, 0.0005083996220491827, 0.000156281515955925, 0.0003233152092434466, 0.0007086835685186088, 0.0009207437979057431, 0.000855972757562995, 0.004414450377225876, 0.9884170889854431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0024299686774611473, 0.0036596376448869705, 0.0006344975554384291, 0.0006202647928148508, 0.0029876769986003637, 0.0003476363781373948, 0.0005059159593656659, 0.0004114970506634563, 0.0002132159424945712, 0.0006509348750114441, 0.00039556872798129916, 0.16986438632011414, 0.00218889769166708, 0.0006812370265834033, 0.0008683771593496203, 0.008905136026442051, 0.001463850843720138, 0.0013394582783803344, 0.006495129782706499, 0.00763870682567358, 0.004619393032044172, 0.0031617912463843822, 0.01420089416205883, 0.04639661684632301, 0.022786036133766174, 0.21939244866371155, 0.477140873670578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01561034843325615, 0.000964807637501508, 0.0010281838476657867, 0.007148519158363342, 0.005316654685884714, 0.0005432687466964126, 0.0007839889149181545, 0.00047083027311600745, 0.0022980389185249805, 0.005463102366775274, 0.000548307434655726, 0.0008661496685817838, 0.0009035562397912145, 0.000925196975003928, 0.008375940844416618, 0.0014478119555860758, 0.0020614906679838896, 0.0036933852825313807, 0.017008868977427483, 0.006138673983514309, 0.007041901350021362, 0.041287098079919815, 0.06922487914562225, 0.2661719024181366, 0.05024213343858719, 0.1144513264298439, 0.13764901459217072, 0.23233459889888763, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02189529314637184, 0.0013514538295567036, 0.0013727964833378792, 0.005157722160220146, 0.010932797566056252, 0.0004452221328392625, 0.0016178287332877517, 0.0005713263526558876, 0.0007700271671637893, 0.0030935355462133884, 0.00036163386539556086, 0.000932903029024601, 0.0019032390555366874, 0.000525438750628382, 0.0007036192109808326, 0.0015780625399202108, 0.0010200463002547622, 0.0009346720762550831, 0.005167576018720865, 0.0007855418953113258, 0.0028796831611543894, 0.006337143015116453, 0.049514152109622955, 0.021886909380555153, 0.030046813189983368, 0.06941599398851395, 0.02995389513671398, 0.06111619994044304, 0.6677284836769104, 0.0, 0.0, 0.0, 0.0], [0.00029466592241078615, 8.085126319201663e-05, 0.00011992641520919278, 0.0001715401012916118, 0.00038990104803815484, 8.630267984699458e-05, 5.25372197444085e-05, 6.616386963287368e-05, 0.0001137840372393839, 6.200086500030011e-05, 0.00011238036677241325, 0.0005867322906851768, 9.78500975179486e-05, 0.00021334874327294528, 0.0004044429515488446, 0.00047262446605600417, 0.0004730731307063252, 0.0005199533188715577, 0.0008571154903620481, 0.00022720213746652007, 0.0015976789873093367, 0.0014780652709305286, 0.0016501445788890123, 0.009339648298919201, 0.012792675755918026, 0.012606960721313953, 0.0216596107929945, 0.028867468237876892, 0.0778479129076004, 0.826757550239563, 0.0, 0.0, 0.0], [0.0006396547541953623, 0.0001992026373045519, 0.0003378460824023932, 0.0003228614223189652, 0.00038839818444103, 2.2511421775561757e-05, 0.00011559668928384781, 1.968370816030074e-05, 8.749762491788715e-05, 0.00016675732331350446, 2.1353202100726776e-05, 0.0001825768267735839, 0.002879622858017683, 3.2708350772736594e-05, 6.355990626616403e-05, 0.0009078503935597837, 6.314194615697488e-05, 4.954513497068547e-05, 0.005010182503610849, 0.00021555769490078092, 0.00018923310562968254, 0.00023579836124554276, 0.0021191718988120556, 0.003475247649475932, 0.0004957503406330943, 0.012673018500208855, 0.0026274595875293016, 0.001192636787891388, 0.028011472895741463, 0.14214564859867096, 0.7951083779335022, 0.0, 0.0], [0.005492149852216244, 0.0014179619029164314, 6.310044409474358e-05, 0.0009282372775487602, 0.0004675877280533314, 9.701230737846345e-05, 5.678696106770076e-05, 6.82406680425629e-05, 4.054810415254906e-05, 0.00021011468197684735, 6.534693238791078e-05, 0.00011957802053075284, 9.082323231268674e-05, 9.077353024622425e-05, 0.00013827483053319156, 0.0004122828249819577, 0.00016900571063160896, 0.00013570708688348532, 0.002428323496133089, 0.00020654767286032438, 0.0004959602956660092, 0.00016561975644435734, 0.0018254045862704515, 0.0016808181535452604, 0.0010187349980697036, 0.015071484260261059, 0.003408379852771759, 0.003384194802492857, 0.018865535035729408, 0.010037437081336975, 0.008259563706815243, 0.923088550567627, 0.0], [0.009386110119521618, 0.0017380572389811277, 0.0018091698875650764, 0.0014350239653140306, 0.0016812816029414535, 0.0019791293889284134, 0.0014143430162221193, 0.0021127830259501934, 0.0012016951804980636, 0.0010467651300132275, 0.0012532471446320415, 0.0012125695357099175, 0.0006952418480068445, 0.0016850184183567762, 0.001290497137233615, 0.0014949421165511012, 0.0030524602625519037, 0.00617641257122159, 0.003993147984147072, 0.002994519891217351, 0.008827606216073036, 0.009542392566800117, 0.010477352887392044, 0.021451443433761597, 0.062213558703660965, 0.026861032471060753, 0.03390643745660782, 0.11987607926130295, 0.05027468875050545, 0.026796849444508553, 0.03116568736732006, 0.10728628933429718, 0.4436681270599365]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10520488768815994, 0.8947951793670654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03907214477658272, 0.0020172251388430595, 0.9589105248451233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015578627586364746, 0.000839252898003906, 0.0006979765021242201, 0.9828841090202332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008856466971337795, 9.934287845680956e-06, 1.1174843166372739e-05, 0.00030247055110521615, 0.9908198714256287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3544497787952423, 0.0305892676115036, 0.05988960340619087, 0.022903529927134514, 0.047475915402173996, 0.48469194769859314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.044769011437892914, 0.0015664660604670644, 0.0003773849457502365, 0.00025073293363675475, 0.00040889650699682534, 0.00026065585552714765, 0.952366828918457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09058350324630737, 0.0011470741592347622, 0.0060273464769124985, 0.0005468479357659817, 0.001709422329440713, 0.0037850849330425262, 0.0026845429092645645, 0.8935161232948303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006010731682181358, 2.428904736007098e-05, 0.00031266716541722417, 1.868290019046981e-05, 0.0002979242999572307, 9.904515536618419e-06, 6.619554824283114e-06, 7.912206569926639e-07, 0.9933184385299683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0045468187890946865, 0.00020019362273160368, 0.0002992024237755686, 0.001336391898803413, 0.0003267655265517533, 8.741358215047512e-07, 1.7415721231373027e-05, 2.7834167326545867e-07, 0.00029665298643521965, 0.9929754734039307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12262556701898575, 0.023926571011543274, 0.03827652707695961, 0.01617196388542652, 0.030366230756044388, 0.2937593460083008, 0.10661351680755615, 0.0705995187163353, 0.04190010204911232, 0.01783309504389763, 0.2379276007413864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008121061837300658, 0.00011546615860424936, 0.00013500892964657396, 5.539286939892918e-05, 0.00013174118066672236, 1.0027158623415744e-06, 1.3799076441500802e-06, 1.6001598623915925e-07, 1.8972953057527775e-06, 5.419655622063146e-07, 4.753091502607276e-07, 0.9987448453903198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013333045644685626, 0.00010533037857385352, 0.0007669601473025978, 0.0009021877776831388, 3.570836042854353e-06, 8.120475740724942e-07, 1.403809051225835e-07, 9.56129397877703e-08, 1.6865070620042388e-06, 2.9789011023240164e-05, 4.381340659165289e-07, 1.1965798876190092e-06, 0.9968544840812683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08159801363945007, 0.02138885296881199, 0.028877170756459236, 0.012675784528255463, 0.02493157796561718, 0.22996489703655243, 0.1040123701095581, 0.06472097337245941, 0.034600939601659775, 0.015198715031147003, 0.1856415718793869, 0.020528046414256096, 0.005003849510103464, 0.170857235789299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013488875702023506, 8.921194239519536e-05, 0.000685996375977993, 0.0006963209598325193, 2.1248602934065275e-05, 3.7633867577824276e-07, 6.226732125469425e-07, 4.307212293497287e-07, 7.091874067555182e-06, 0.0013103681849315763, 1.6113720846533397e-07, 9.548743946652394e-07, 0.00016453607531730086, 1.1531915333762299e-07, 0.9956737160682678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010867511155083776, 0.00040724765858612955, 0.00010700341954361647, 0.000678271462675184, 0.00011028484004782513, 1.3184225622353551e-07, 2.660271150034532e-07, 4.6195683012228983e-07, 8.409730980929453e-06, 0.0007784883491694927, 5.109439982220465e-08, 8.792070502749993e-07, 4.9342852435074747e-05, 3.4893165690164096e-08, 0.000114411988761276, 0.9966580867767334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05868089199066162, 0.018785733729600906, 0.024067318066954613, 0.011013144627213478, 0.02145637758076191, 0.1911056935787201, 0.09902717173099518, 0.060658663511276245, 0.03016272373497486, 0.014801906421780586, 0.15370333194732666, 0.016615163534879684, 0.0043853819370269775, 0.14085334539413452, 0.01501499954611063, 0.005390208680182695, 0.13427796959877014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07323038578033447, 0.028374578803777695, 0.021058257669210434, 0.007611887063831091, 0.010053583420813084, 0.06553954631090164, 0.1455976814031601, 0.08620846271514893, 0.01024126447737217, 0.0074257394298911095, 0.045262716710567474, 0.00662145996466279, 0.0011621782323345542, 0.03923855721950531, 0.008256876841187477, 0.003065689466893673, 0.036122649908065796, 0.4049285352230072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.944500976009294e-05, 1.8382105508862878e-06, 3.7134324060161816e-08, 1.557527866680175e-05, 3.4723757380561437e-06, 1.3165046830465599e-09, 2.7038657535172206e-08, 1.718662012706318e-08, 9.2322629541286e-08, 1.350637921859743e-05, 4.4787801245504966e-10, 2.0416692780855783e-09, 5.542018044479846e-08, 3.063855003038185e-10, 4.2177114778496616e-07, 7.065867521305336e-06, 2.4244301011222547e-10, 1.4397331105087119e-09, 0.9998784065246582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002934500575065613, 0.0005883863777853549, 0.004250314552336931, 0.004028473515063524, 0.00011592977534746751, 4.331634045229293e-06, 6.773919267288875e-06, 7.076480687828735e-05, 0.00024952771491371095, 0.0003159341576974839, 2.082445462292526e-06, 4.409225221024826e-05, 0.0003044698678422719, 1.4702602584293345e-06, 0.00019761378644034266, 0.0013599281664937735, 1.2478686812755768e-06, 6.875201052025659e-06, 0.00019261165289208293, 0.9853246808052063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0405653677880764, 0.017898330464959145, 0.020600976422429085, 0.009821103885769844, 0.01788281463086605, 0.15654000639915466, 0.09208228439092636, 0.05628824234008789, 0.02666134014725685, 0.014471275731921196, 0.12537623941898346, 0.013986770063638687, 0.003927926532924175, 0.11453618109226227, 0.013395378366112709, 0.004846667870879173, 0.10880251228809357, 0.04953394830226898, 0.005186409689486027, 0.004420872312039137, 0.10317535698413849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024536319077014923, 0.0031243376433849335, 0.0009699301444925368, 4.6315424697240815e-05, 0.00013434777793008834, 0.0006453940295614302, 0.011668842285871506, 0.00032713435939513147, 0.0004573049955070019, 2.3976073862286285e-05, 0.00034454185515642166, 4.996423376724124e-05, 2.575737926235888e-05, 0.0002821774687618017, 6.525323442474473e-06, 4.981808615411865e-06, 0.00023554022482130677, 0.0002664511266630143, 2.5311152057838626e-05, 2.976109135488514e-05, 0.00018809246830642223, 0.9566068649291992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0020759969484061003, 0.00014591761282645166, 5.289893306326121e-05, 4.2180658056167886e-05, 4.7387107770191506e-05, 4.1423194829803833e-07, 0.00012964275083504617, 2.4250975911854766e-05, 1.8034011191048194e-06, 1.4839239383945824e-06, 1.4489953059637628e-07, 4.199924660497345e-06, 4.106825457483865e-08, 1.0260462346423083e-07, 8.285448984679533e-07, 5.7818925824904e-07, 7.695144432773304e-08, 6.669597496511415e-08, 6.472609675256535e-05, 1.5700858284617425e-06, 5.641820521873342e-08, 4.403023922350258e-06, 0.9974013566970825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005159099819138646, 0.00011814597382908687, 3.2705549529055133e-05, 0.00021188679966144264, 4.5635159040102735e-05, 2.9248755595290277e-07, 3.0579308258893434e-06, 7.607346219629108e-08, 0.000137536451802589, 0.0005283522768877447, 1.1575992431289706e-07, 4.028569492220413e-06, 2.0792908799194265e-06, 8.805391615851477e-08, 0.00010051658318843693, 4.4316107960185036e-05, 6.963698950812613e-08, 9.373004417057018e-08, 3.337762609589845e-05, 1.5888857888057828e-05, 5.610664643995733e-08, 7.05262834799214e-08, 9.389261322212406e-06, 0.9981963038444519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0691523477435112, 0.0140320910140872, 0.005599102005362511, 0.0012576858280226588, 0.0008468004525639117, 0.009601176716387272, 0.008965776301920414, 0.052476946264505386, 0.0002502838906366378, 0.0009063857141882181, 0.005419907625764608, 0.0007309210486710072, 0.0001918795460369438, 0.004396581556648016, 0.005964719224721193, 0.00035585390287451446, 0.0038770181126892567, 0.009727220050990582, 0.001102349371649325, 0.0003644291136879474, 0.003413958242163062, 0.003052355023100972, 0.005698255263268948, 0.0002955732343252748, 0.7923204302787781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010461597703397274, 1.955721563717816e-05, 1.7359042203679564e-06, 3.103058406850323e-05, 2.7308056814945303e-05, 1.0180717602281675e-08, 4.815781835532107e-07, 1.7494296855602443e-07, 7.3124517996348e-08, 7.983091450114443e-07, 3.464323272694969e-09, 4.906740741716931e-06, 1.0718952836441531e-07, 2.35255281921809e-09, 2.3834166995584383e-07, 1.3731373655900825e-06, 1.8288706105096253e-09, 6.247633965728028e-09, 9.208364645019174e-06, 1.6384317405027105e-06, 1.2523946324449753e-09, 8.27128976421676e-10, 8.456793693767395e-06, 3.1186914384306874e-06, 9.241437837204103e-09, 0.9988435506820679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010544945253059268, 0.00021373217168729752, 0.0002815716725308448, 0.00113733671605587, 0.00014783968799747527, 2.0068493995495373e-06, 4.831355909118429e-06, 3.482335159787908e-06, 5.100349881104194e-06, 0.000124204860185273, 9.301510885961761e-07, 1.058263296727091e-05, 1.1688275662891101e-05, 7.077505301822384e-07, 0.0034115940798074007, 0.00019905276712961495, 5.995612468723266e-07, 4.6430378120021487e-07, 1.9585138943511993e-05, 0.00011087791790487245, 4.7500583377768635e-07, 3.2808816285978537e-07, 4.535354491963517e-06, 5.161709486856125e-05, 3.2474736144649796e-07, 1.3071360626781825e-05, 0.9931889772415161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02420077472925186, 0.0028201299719512463, 0.004319300409406424, 0.0009108305675908923, 0.0017753951251506805, 0.003809915855526924, 0.002953325165435672, 0.0167147908359766, 0.0013931754510849714, 0.005003185477107763, 0.002276089508086443, 0.000587641610763967, 0.0009901636512950063, 0.0018066938500851393, 0.003131241537630558, 0.00023389386478811502, 0.0016082727815955877, 0.009910304099321365, 0.002853953745216131, 0.00020495163334999233, 0.001371265621855855, 0.006919005420058966, 0.0010336586274206638, 0.00014528397878166288, 0.01748979091644287, 0.00046553160063922405, 0.00030240879277698696, 0.884769082069397, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005256084259599447, 3.528643219397054e-06, 1.703766429272946e-06, 9.408168261870742e-05, 0.6647974252700806, 1.6531473079339776e-07, 9.51110109781439e-07, 8.886889304449141e-07, 1.701670953480061e-05, 3.742182161659002e-05, 6.832264176637182e-08, 9.81090579443844e-06, 7.548720759587013e-08, 4.963250432865607e-08, 2.0393883914948674e-06, 7.686544449825305e-06, 4.0668499678986336e-08, 2.6744308101456227e-08, 3.3431806514272466e-05, 4.3410815919742163e-07, 3.007987459113792e-08, 3.2060558652347027e-08, 4.900573458144208e-06, 3.0609417080995627e-06, 1.4603192433071399e-08, 2.214551204815507e-05, 9.21116861718474e-06, 3.1642709785728584e-08, 0.33442816138267517, 0.0, 0.0, 0.0, 0.0], [0.004677004646509886, 0.0002802134840749204, 8.346102549694479e-05, 3.1570123155688634e-06, 4.065346672632586e-07, 1.3343500882001536e-07, 2.6423611416248605e-05, 1.1439977498639564e-07, 2.787237463053316e-07, 3.7496099594136467e-06, 4.652897445112103e-08, 1.721399939924595e-06, 1.8165600579322927e-07, 3.148475968828279e-08, 1.8334230844629928e-07, 5.2147463236451586e-08, 2.5215808108214333e-08, 3.078440968806717e-08, 7.142029545548212e-08, 1.6640171907056356e-08, 1.7768222448921733e-08, 8.634525272555038e-08, 2.80096719507128e-06, 8.454143767266942e-07, 3.098357126418705e-08, 2.927866091795295e-07, 5.67622805647261e-07, 5.055421414823513e-09, 2.9141034474378102e-08, 0.9949179887771606, 0.0, 0.0, 0.0], [5.636792411678471e-05, 0.0002002374967560172, 1.6319110045515117e-06, 1.5089327689565835e-06, 1.7779768313630484e-05, 5.95644145118257e-10, 6.94038226356497e-06, 5.034010541749012e-09, 2.1682893702745787e-07, 1.7164256860269234e-06, 1.9326265587871205e-10, 1.8911425314627195e-08, 9.538840117784275e-08, 1.2946883842790413e-10, 8.07715050399338e-09, 4.386615546536632e-05, 9.768665043541347e-11, 5.256080015669795e-10, 6.93216934450902e-05, 7.505880716962565e-08, 7.069290985928234e-11, 3.988046870517792e-08, 1.0610266144794878e-05, 2.2120727862784406e-06, 8.688617048058234e-10, 9.928487088473048e-06, 5.390094592883088e-09, 1.1354458345769203e-10, 3.0600433547078865e-06, 3.8945626101849484e-07, 0.9995738863945007, 0.0, 0.0], [0.0003556974115781486, 1.9489458281896077e-05, 9.160975423583295e-06, 1.3085226783005055e-05, 2.3808830519556068e-05, 2.9718961513935938e-08, 4.1605944716138765e-05, 1.7756491388354334e-07, 6.896235049680399e-07, 1.050622017828573e-06, 1.2230765733534099e-08, 4.290539891371736e-06, 3.2958240581137943e-07, 9.211071905212975e-09, 1.7466379631514428e-06, 4.682780854636803e-06, 7.44272554698e-09, 9.673800427378865e-09, 3.9665097574470565e-05, 7.324884450099489e-07, 5.5436903956262995e-09, 1.0396686178637538e-07, 1.4401590306079015e-05, 8.873331353242975e-06, 5.9894045278952035e-09, 1.5627783795935102e-05, 2.981124680445646e-06, 6.874342872720263e-09, 4.854650796914939e-06, 7.0722649070376065e-06, 6.210680112417322e-06, 0.999423623085022, 0.0], [0.05455268174409866, 0.016429055482149124, 0.01600833609700203, 0.006986877880990505, 0.024884145706892014, 0.07376931607723236, 0.07933785766363144, 0.05594551935791969, 0.02726820856332779, 0.013368774205446243, 0.055903077125549316, 0.007223024964332581, 0.005426575895398855, 0.05012328177690506, 0.008279063738882542, 0.0030609651003032923, 0.04682298004627228, 0.047518469393253326, 0.00284494343213737, 0.007037975825369358, 0.04282715171575546, 0.051381900906562805, 0.02728237584233284, 0.026375344023108482, 0.02615921013057232, 0.011997979134321213, 0.006220123264938593, 0.03648780658841133, 0.01112469844520092, 0.005218563135713339, 0.0025592001620680094, 0.002604028908535838, 0.14697043597698212]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9192657470703125, 0.08073429018259048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4543737471103668, 0.42650437355041504, 0.11912190169095993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5267522931098938, 0.2232162356376648, 0.12420623749494553, 0.12582524120807648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39034879207611084, 0.1709941178560257, 0.06872710585594177, 0.18371818959712982, 0.1862117350101471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1974421739578247, 0.2543684244155884, 0.1448846310377121, 0.18925857543945312, 0.20821942389011383, 0.0058267852291464806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19473567605018616, 0.13241828978061676, 0.14391931891441345, 0.1512073427438736, 0.30024465918540955, 0.020584644749760628, 0.05688999220728874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.126966655254364, 0.21597377955913544, 0.1608932763338089, 0.1969882994890213, 0.1884462684392929, 0.013544926419854164, 0.07520709931850433, 0.021979715675115585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.291212260723114, 0.059542279690504074, 0.11079410463571548, 0.09717857092618942, 0.22345605492591858, 0.016262579709291458, 0.08719442039728165, 0.024762261658906937, 0.08959741145372391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22981958091259003, 0.038026776164770126, 0.160138338804245, 0.11780403554439545, 0.1618119180202484, 0.03552818298339844, 0.07561115175485611, 0.020756017416715622, 0.10670632123947144, 0.053797684609889984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1331443041563034, 0.1885865330696106, 0.10808101296424866, 0.15994970500469208, 0.17739209532737732, 0.003598014358431101, 0.02506207674741745, 0.012862928211688995, 0.07453099638223648, 0.11275240778923035, 0.004039985593408346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.167464017868042, 0.1435522735118866, 0.061185725033283234, 0.17358075082302094, 0.10113829374313354, 0.01755346730351448, 0.03239528089761734, 0.007995491847395897, 0.05453447997570038, 0.07883201539516449, 0.01725820265710354, 0.1445099264383316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2699681520462036, 0.13029073178768158, 0.06605684757232666, 0.06156139820814133, 0.08437128365039825, 0.019846616312861443, 0.016312789171934128, 0.012965921312570572, 0.03231465443968773, 0.05254793539643288, 0.019868606701493263, 0.1369563788175583, 0.09693866968154907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09820347279310226, 0.1361863911151886, 0.08005785197019577, 0.12152862548828125, 0.1357938051223755, 0.0024323563557118177, 0.017789501696825027, 0.009086486883461475, 0.05637528374791145, 0.08521634340286255, 0.002753336215391755, 0.1520378738641739, 0.09946723282337189, 0.003071403130888939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1701289266347885, 0.08885715156793594, 0.09089689701795578, 0.08085784316062927, 0.11427336931228638, 0.01090148277580738, 0.014788416214287281, 0.0054973699152469635, 0.05151257663965225, 0.05330682918429375, 0.010595808736979961, 0.0944228246808052, 0.1309812068939209, 0.01115368027240038, 0.07182563096284866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.103658527135849, 0.03588540107011795, 0.08803563565015793, 0.060879360884428024, 0.08348328620195389, 0.03080574981868267, 0.029615940526127815, 0.010918696410953999, 0.04049994423985481, 0.04288605973124504, 0.03219295293092728, 0.1500813364982605, 0.12658780813217163, 0.034902188926935196, 0.05825437605381012, 0.0713128000497818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0704709142446518, 0.09600996226072311, 0.05621582269668579, 0.0869988352060318, 0.09934128820896149, 0.0016298776026815176, 0.01240861788392067, 0.006380435544997454, 0.041014041751623154, 0.06348711997270584, 0.0018482193117961287, 0.11387643218040466, 0.07328981161117554, 0.002071293769404292, 0.07246166467666626, 0.20012786984443665, 0.002367777982726693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.056594423949718475, 0.08906204998493195, 0.047032430768013, 0.09457871317863464, 0.08793891221284866, 0.001972164260223508, 0.017767684534192085, 0.005990440491586924, 0.06014855206012726, 0.08834963291883469, 0.002263767411932349, 0.10461527109146118, 0.06079372763633728, 0.002556623425334692, 0.07818624377250671, 0.19496025145053864, 0.002929993672296405, 0.004259060136973858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.159706249833107, 0.026096459478139877, 0.04515179246664047, 0.03497577831149101, 0.08030678331851959, 0.05469036474823952, 0.04078544303774834, 0.026513004675507545, 0.027251940220594406, 0.039198171347379684, 0.053514327853918076, 0.0484292097389698, 0.0626426711678505, 0.05558210611343384, 0.05559666082262993, 0.04792959615588188, 0.05676325038075447, 0.048923008143901825, 0.03594321012496948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08663120865821838, 0.09557435661554337, 0.03673810139298439, 0.06946706026792526, 0.056814610958099365, 0.008190208114683628, 0.022195827215909958, 0.007642820477485657, 0.031468283385038376, 0.0755520835518837, 0.008965260349214077, 0.05263481289148331, 0.044911064207553864, 0.00993504747748375, 0.04481375962495804, 0.15198466181755066, 0.010933397337794304, 0.007993672043085098, 0.16402560472488403, 0.013528089970350266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04783450439572334, 0.06669352948665619, 0.03798922151327133, 0.06040368974208832, 0.06899043917655945, 0.0010267274919897318, 0.008172677829861641, 0.004158171825110912, 0.028268275782465935, 0.044072382152080536, 0.001158646191470325, 0.07832911610603333, 0.050829000771045685, 0.0013004970969632268, 0.04904298111796379, 0.14145003259181976, 0.0014934330247342587, 0.0025566823314875364, 0.17534081637859344, 0.12910202145576477, 0.0017870542360469699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04114088416099548, 0.04766073450446129, 0.03586999699473381, 0.06666101515293121, 0.07969272881746292, 0.0023650778457522392, 0.020340194925665855, 0.004854496102780104, 0.06436203420162201, 0.06737150996923447, 0.0027073684614151716, 0.055960532277822495, 0.056486647576093674, 0.003076723776757717, 0.053543880581855774, 0.15165933966636658, 0.0035397191531956196, 0.004673931282013655, 0.1640271693468094, 0.05968153104186058, 0.004154942464083433, 0.010169513523578644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0662880539894104, 0.04092540591955185, 0.02732267789542675, 0.045053672045469284, 0.06575216352939606, 0.01565755158662796, 0.027881883084774017, 0.013711248524487019, 0.03174295276403427, 0.05280745029449463, 0.015447767451405525, 0.032181113958358765, 0.032901059836149216, 0.016298862174153328, 0.02663664147257805, 0.09772850573062897, 0.017114197835326195, 0.0169194545596838, 0.09847064316272736, 0.047879092395305634, 0.018412547186017036, 0.015331598930060863, 0.17753542959690094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09801428020000458, 0.026328807696700096, 0.035868145525455475, 0.05713058263063431, 0.06943872570991516, 0.01212895568460226, 0.02090909518301487, 0.008747953921556473, 0.02699965052306652, 0.03726676478981972, 0.01171633880585432, 0.08499540388584137, 0.055013373494148254, 0.012196715921163559, 0.035639114677906036, 0.08789661526679993, 0.012970106676220894, 0.01085102278739214, 0.06408385187387466, 0.059639208018779755, 0.014492185786366463, 0.006093737669289112, 0.09761442244052887, 0.05396495759487152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027693239971995354, 0.040737707167863846, 0.03122355230152607, 0.05879037827253342, 0.05601825937628746, 0.0015714785549789667, 0.011908049695193768, 0.0033397923689335585, 0.05176554620265961, 0.052912432700395584, 0.0018259822390973568, 0.060300346463918686, 0.02835717797279358, 0.0020878107752650976, 0.050864774733781815, 0.07898838073015213, 0.002398707205429673, 0.002904823748394847, 0.11135736107826233, 0.0458601638674736, 0.002884918823838234, 0.011431250721216202, 0.1234055906534195, 0.13488471508026123, 0.006487554870545864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1539076715707779, 0.023786786943674088, 0.05320247262716293, 0.039638858288526535, 0.05711062625050545, 0.015628939494490623, 0.020206080749630928, 0.009252365678548813, 0.021311869844794273, 0.029029950499534607, 0.014741908758878708, 0.06123840808868408, 0.10112593322992325, 0.01515782717615366, 0.04335403069853783, 0.040907204151153564, 0.015732651576399803, 0.02007342129945755, 0.053749311715364456, 0.03468617424368858, 0.016989391297101974, 0.006368501577526331, 0.040420182049274445, 0.031060412526130676, 0.01393716037273407, 0.06738190352916718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08555091917514801, 0.03505741432309151, 0.05885257199406624, 0.03497910127043724, 0.05178741738200188, 0.002511990023776889, 0.0041512236930429935, 0.0020859187934547663, 0.014081122353672981, 0.024491356685757637, 0.00237600551918149, 0.09535115957260132, 0.07766137272119522, 0.0024908825289458036, 0.04572679474949837, 0.05774116516113281, 0.0026603781152516603, 0.003347759833559394, 0.04799826443195343, 0.026788828894495964, 0.002958715660497546, 0.0046557895839214325, 0.036070987582206726, 0.021599190309643745, 0.004788636229932308, 0.2205219864845276, 0.03371305391192436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02070671133697033, 0.03719405084848404, 0.019723715260624886, 0.03894224017858505, 0.03182699903845787, 0.0012253670720383525, 0.008815755136311054, 0.00240529328584671, 0.03457954525947571, 0.047298040241003036, 0.0013953752350062132, 0.05148204788565636, 0.020486745983362198, 0.0015608381945639849, 0.03826119378209114, 0.04863754287362099, 0.0017825315007939935, 0.0025446058716624975, 0.06541351228952408, 0.0418856218457222, 0.002096060197800398, 0.00940138939768076, 0.08460032194852829, 0.09019994735717773, 0.005403279792517424, 0.22932566702365875, 0.05692273750901222, 0.0058829220943152905, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08582809567451477, 0.03967175632715225, 0.014841830357909203, 0.056536201387643814, 0.05960613861680031, 0.0069875153712928295, 0.010110095143318176, 0.002887723734602332, 0.015322854742407799, 0.025928769260644913, 0.0068304408341646194, 0.03354894369840622, 0.021093543618917465, 0.007213155273348093, 0.019323399290442467, 0.05298228561878204, 0.007658611051738262, 0.00515784602612257, 0.0652317926287651, 0.018170015886425972, 0.00853470154106617, 0.004368166904896498, 0.026912439614534378, 0.04962793365120888, 0.004404325969517231, 0.1938866674900055, 0.03933224827051163, 0.005363550502806902, 0.11263899505138397, 0.0, 0.0, 0.0, 0.0], [0.07040347903966904, 0.059261616319417953, 0.015334845520555973, 0.024139033630490303, 0.01572885550558567, 0.01949208974838257, 0.017311519011855125, 0.017303064465522766, 0.020563246682286263, 0.0451558493077755, 0.021815843880176544, 0.07079728692770004, 0.030063945800065994, 0.02354060672223568, 0.0206844974309206, 0.02116367034614086, 0.02644512988626957, 0.023540055379271507, 0.0566372349858284, 0.033694811165332794, 0.03070726804435253, 0.015993354842066765, 0.015474077314138412, 0.0308036208152771, 0.03180556744337082, 0.07969610393047333, 0.034374870359897614, 0.03453714773058891, 0.030624380335211754, 0.06290692090988159, 0.0, 0.0, 0.0], [0.05338500440120697, 0.029621530324220657, 0.021030081436038017, 0.02369570918381214, 0.03343641385436058, 0.018393803387880325, 0.024060698226094246, 0.022810012102127075, 0.013972371816635132, 0.028813567012548447, 0.01905973069369793, 0.015371969901025295, 0.02533531002700329, 0.019971946254372597, 0.014075735583901405, 0.038844525814056396, 0.02134619653224945, 0.01932143047451973, 0.05632656440138817, 0.021360019221901894, 0.023394571617245674, 0.023136626929044724, 0.06416381895542145, 0.06724690645933151, 0.0346950925886631, 0.0434902124106884, 0.030327260494232178, 0.03285713121294975, 0.053275082260370255, 0.0659981369972229, 0.0411824993789196, 0.0, 0.0], [0.1817709058523178, 0.01953316666185856, 0.028002936393022537, 0.029110195115208626, 0.04134833812713623, 0.018019482493400574, 0.01047173049300909, 0.008382907137274742, 0.015335801988840103, 0.02183944173157215, 0.016893355175852776, 0.03806138038635254, 0.03643865883350372, 0.017464272677898407, 0.026129066944122314, 0.040115050971508026, 0.0183172095566988, 0.012488226406276226, 0.05136965215206146, 0.019443852826952934, 0.019889751449227333, 0.0035764507483690977, 0.026232965290546417, 0.018429184332489967, 0.011723744682967663, 0.0327298529446125, 0.034808218479156494, 0.012035044841468334, 0.060302965342998505, 0.007873311638832092, 0.04227292165160179, 0.07958997040987015, 0.0], [0.01500339712947607, 0.020334864035248756, 0.00781344249844551, 0.016553569585084915, 0.016466114670038223, 0.0002380963123869151, 0.001959895482286811, 0.0006898263236507773, 0.006483224220573902, 0.01073406357318163, 0.0002443528501316905, 0.014634675346314907, 0.009247622452676296, 0.0002605919726192951, 0.009339914657175541, 0.04272659495472908, 0.00028863942134194076, 0.00038116759969852865, 0.05474936217069626, 0.09452767670154572, 0.0003421130240894854, 0.0017270189709961414, 0.04745934158563614, 0.026613805443048477, 0.0010238662362098694, 0.1653798222541809, 0.014187117107212543, 0.0013092365115880966, 0.04770656302571297, 0.011198500171303749, 0.22050751745700836, 0.1394260972738266, 0.00044186264858581126]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9333657622337341, 0.06663419306278229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32452353835105896, 0.5923717617988586, 0.083104707300663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14159759879112244, 0.514380931854248, 0.28144127130508423, 0.0625801831483841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2526226341724396, 0.058340635150671005, 0.1045888215303421, 0.4411159157752991, 0.14333190023899078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1805155873298645, 0.09828896820545197, 0.1087396889925003, 0.12262703478336334, 0.0999554991722107, 0.3898732364177704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17192280292510986, 0.023320937529206276, 0.12332724034786224, 0.060765013098716736, 0.05971726030111313, 0.34759166836738586, 0.21335498988628387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0962703675031662, 0.04683612659573555, 0.028257345780730247, 0.03239244595170021, 0.05865050107240677, 0.1582932472229004, 0.30996495485305786, 0.26933497190475464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09948237985372543, 0.06464175879955292, 0.02867184951901436, 0.07305674999952316, 0.029787175357341766, 0.1396002322435379, 0.20754709839820862, 0.26580220460891724, 0.09141051769256592, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0563204400241375, 0.029885875061154366, 0.013419931754469872, 0.002407551510259509, 0.013245484791696072, 0.04564542695879936, 0.05522558465600014, 0.1002708226442337, 0.65799880027771, 0.025580082088708878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04266996681690216, 0.010426468215882778, 0.010652237571775913, 0.01344663929194212, 0.009353145025670528, 0.04015975818037987, 0.0710517019033432, 0.1373765766620636, 0.10423267632722855, 0.2173662781715393, 0.34326452016830444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029683886095881462, 0.0025616372004151344, 0.0044074878096580505, 0.034248724579811096, 0.014238736592233181, 0.02800186164677143, 0.022288046777248383, 0.0710596814751625, 0.04026233032345772, 0.5543041825294495, 0.17333056032657623, 0.025612974539399147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04039591923356056, 0.008631567470729351, 0.005494223907589912, 0.003864137688651681, 0.023363124579191208, 0.02720697410404682, 0.02567731775343418, 0.05048515647649765, 0.0510561540722847, 0.050417810678482056, 0.14164334535598755, 0.5115286111831665, 0.060235679149627686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028706416487693787, 0.004808458499610424, 0.004723657388240099, 0.005382596980780363, 0.0034560468047857285, 0.01447016280144453, 0.02403738722205162, 0.04162624478340149, 0.03567296266555786, 0.07060734182596207, 0.10830997675657272, 0.058116115629673004, 0.20621225237846375, 0.39387041330337524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05342649295926094, 0.011923289857804775, 0.015572250820696354, 0.002112323185428977, 0.0058510382659733295, 0.022170910611748695, 0.038184668868780136, 0.02741154097020626, 0.05464289337396622, 0.04910832643508911, 0.123283751308918, 0.05287175625562668, 0.07545655965805054, 0.3701530396938324, 0.09783122688531876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008346715942025185, 0.00027852662606164813, 0.0011786009417846799, 0.0021395485382527113, 0.002476171124726534, 0.002918292535468936, 0.004576900042593479, 0.003965593408793211, 0.0049730269238352776, 0.011347766034305096, 0.013014056719839573, 0.005545963998883963, 0.0208955816924572, 0.03838542103767395, 0.8750316500663757, 0.004926194902509451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021700305864214897, 0.002678663469851017, 0.002383927581831813, 0.002815626095980406, 0.0015562345506623387, 0.006139403209090233, 0.00903981551527977, 0.013740858063101768, 0.012412196956574917, 0.024686496704816818, 0.0340690053999424, 0.017561456188559532, 0.060829490423202515, 0.12004058808088303, 0.11516808718442917, 0.1266368329524994, 0.42854100465774536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019681409001350403, 0.0028661920223385096, 0.0027528645005077124, 0.0023642026353627443, 0.0022205752320587635, 0.00477696442976594, 0.005015392787754536, 0.007020771503448486, 0.0066029978916049, 0.01582488790154457, 0.021779092028737068, 0.02237590402364731, 0.03905550763010979, 0.07342642545700073, 0.07227571308612823, 0.08103621006011963, 0.25563231110572815, 0.36529263854026794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.034438684582710266, 0.0024295076727867126, 0.0027038753032684326, 0.0010108916321769357, 0.0028212442994117737, 0.009310654364526272, 0.007474057842046022, 0.010526394471526146, 0.019342610612511635, 0.006583379115909338, 0.03052523173391819, 0.008166540414094925, 0.023945633322000504, 0.08047981560230255, 0.04428933188319206, 0.04886505752801895, 0.23266322910785675, 0.38709738850593567, 0.04732643440365791, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0036976796109229326, 0.0064509655348956585, 0.0004921727231703699, 0.00030695926398038864, 0.00012400785635691136, 0.0010727376211434603, 0.0008858796209096909, 0.0013806353090330958, 0.0008200184092856944, 0.00027311863959766924, 0.002783061470836401, 0.03529426082968712, 0.003561372635886073, 0.007148307748138905, 0.001647408353164792, 0.016731644049286842, 0.019172830507159233, 0.022339239716529846, 0.8733668327331543, 0.0024509585928171873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013628782704472542, 0.0014384430833160877, 0.0012188631808385253, 0.001291585387662053, 0.00061180250486359, 0.00214003655128181, 0.002746960148215294, 0.0033360449597239494, 0.0030918733682483435, 0.0059889135882258415, 0.00723721319809556, 0.003547741798684001, 0.012891959398984909, 0.022229162976145744, 0.02082422375679016, 0.026295319199562073, 0.07648168504238129, 0.1626145839691162, 0.1263865828514099, 0.10034429281949997, 0.4056539535522461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02143297716975212, 0.0007291641086339951, 0.0010889690602198243, 0.0008559610578231514, 0.0010556622873991728, 0.002354246564209461, 0.001863330602645874, 0.002486985642462969, 0.004011374898254871, 0.0036456298548728228, 0.00663661677390337, 0.0024591649416834116, 0.008106634020805359, 0.019501395523548126, 0.01394551433622837, 0.016831588000059128, 0.06727852672338486, 0.10203754156827927, 0.07506174594163895, 0.03785502165555954, 0.34741589426994324, 0.2633460462093353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018374430015683174, 0.0016340144211426377, 0.0002648663939908147, 0.0006277090287767351, 0.0007212907075881958, 0.0022947133984416723, 0.0014375776518136263, 0.0024335694033652544, 0.001022504991851747, 0.002173098735511303, 0.005665965843945742, 0.0005857065552845597, 0.004730310756713152, 0.015789609402418137, 0.009121064096689224, 0.006447882391512394, 0.04965192824602127, 0.07221108675003052, 0.04530428349971771, 0.022536247968673706, 0.23380516469478607, 0.2810094356536865, 0.2221575230360031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016010282561182976, 0.00041907670674845576, 0.0016793166287243366, 0.0020331651903688908, 0.001112604746595025, 0.002304120920598507, 0.0016414872370660305, 0.002045227447524667, 0.0008826442644931376, 0.003531813155859709, 0.004660748410969973, 0.0011461268877610564, 0.0040252795442938805, 0.011729458346962929, 0.006906011141836643, 0.005978971719741821, 0.03413613513112068, 0.05391993746161461, 0.07536923885345459, 0.015544150955975056, 0.15307289361953735, 0.21672506630420685, 0.23267336189746857, 0.15245288610458374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016415491700172424, 0.0010880987392738461, 0.0013027036329731345, 0.001233563176356256, 0.0010325232287868857, 0.0013605270069092512, 0.0011352720903232694, 0.0009713192121125758, 0.001758021884597838, 0.0023549937177449465, 0.0022677970118820667, 0.0026170003693550825, 0.0032849623821675777, 0.005564447958022356, 0.007287738379091024, 0.006582648493349552, 0.01691109873354435, 0.023348167538642883, 0.033363789319992065, 0.0120608601719141, 0.08410528302192688, 0.10776980221271515, 0.12741322815418243, 0.2500956058502197, 0.2886750400066376, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.031117744743824005, 0.0015063051832839847, 0.001083932351320982, 0.002421521581709385, 0.0013826879439875484, 0.0037937189918011427, 0.0016339285066351295, 0.003119518281891942, 0.0012812626082450151, 0.0020685228519141674, 0.004760123323649168, 0.0008757315226830542, 0.008592117577791214, 0.009353641420602798, 0.011993247084319592, 0.005962998140603304, 0.02202821709215641, 0.03411329910159111, 0.009586771950125694, 0.013681817799806595, 0.08417052775621414, 0.08917819708585739, 0.10806845873594284, 0.1556077003479004, 0.37236857414245605, 0.02024947851896286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014838477596640587, 0.000575731392018497, 0.0047436547465622425, 0.00045677294838242233, 0.0007412272389046848, 0.0014999984996393323, 0.0008866075659170747, 0.0008452081237919629, 0.00010359247244196013, 0.0009065139456652105, 0.0018096774583682418, 0.060291070491075516, 0.0015377565287053585, 0.0033079434651881456, 0.0013713666703552008, 0.0020826756954193115, 0.00864399690181017, 0.00908886268734932, 0.007760948967188597, 0.005808332469314337, 0.03386512026190758, 0.03987189754843712, 0.053745534271001816, 0.03694772720336914, 0.12259428948163986, 0.5718705654144287, 0.013804461807012558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018570004031062126, 0.001214314834214747, 0.0012880462454631925, 0.0010612563928589225, 0.0007490042480640113, 0.0010485613020136952, 0.0008687864174135029, 0.0005973855149932206, 0.0012938276631757617, 0.0014042491093277931, 0.0011055080685764551, 0.0005003443802706897, 0.0020262575708329678, 0.0021463108714669943, 0.002873790916055441, 0.002641367493197322, 0.005802980158478022, 0.00819135271012783, 0.00833907164633274, 0.005543302278965712, 0.02655869536101818, 0.03308916091918945, 0.03250738978385925, 0.09199853241443634, 0.10410477966070175, 0.16861769556999207, 0.20895430445671082, 0.26690366864204407, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01665443368256092, 0.00072486512362957, 0.0008980674901977181, 0.003161684377118945, 0.0005522819701582193, 0.0016607240540906787, 0.0007486115791834891, 0.0009652787121012807, 0.0003842800797428936, 0.002257774816825986, 0.0015545623609796166, 0.0007036992465145886, 0.0014688160736113787, 0.0027998806908726692, 0.0030139745213091373, 0.005369033198803663, 0.006552340462803841, 0.0087015675380826, 0.007138855289667845, 0.006516315974295139, 0.026185564696788788, 0.03929200395941734, 0.031550053507089615, 0.024343017488718033, 0.10670771449804306, 0.15159796178340912, 0.13674210011959076, 0.32013967633247375, 0.09161487221717834, 0.0, 0.0, 0.0, 0.0], [0.03722681477665901, 0.000744272954761982, 0.001918031251989305, 0.001429059891961515, 0.00255973101593554, 0.0032928287982940674, 0.0009007241460494697, 0.0015445075696334243, 0.00035572113119997084, 0.0004492724547162652, 0.00266881356947124, 0.001404664828442037, 0.0017281001200899482, 0.0045427302829921246, 0.0012941044988110662, 0.004677655175328255, 0.009138202294707298, 0.008992942050099373, 0.005343649536371231, 0.0020318408496677876, 0.030930889770388603, 0.021215278655290604, 0.036399755626916885, 0.056794602423906326, 0.11195952445268631, 0.011458119377493858, 0.03353290632367134, 0.2658853828907013, 0.24695426225662231, 0.09262567013502121, 0.0, 0.0, 0.0], [0.04408876225352287, 0.001108294352889061, 0.0033875873778015375, 0.0048531824722886086, 0.0028643254190683365, 0.004500851966440678, 0.0014518089592456818, 0.002192496554926038, 0.0007902360521256924, 0.0006717371288686991, 0.0035771559923887253, 0.0005131770740263164, 0.012861708179116249, 0.005116846412420273, 0.0030142529867589474, 0.005887457635253668, 0.010453438386321068, 0.013818331062793732, 0.008691059425473213, 0.011229281313717365, 0.0314008928835392, 0.023181650787591934, 0.03044440597295761, 0.035206787288188934, 0.09999871999025345, 0.006090168841183186, 0.14714208245277405, 0.16393038630485535, 0.12749525904655457, 0.19357767701148987, 0.0004599914245773107, 0.0, 0.0], [0.0371740460395813, 0.005006891209632158, 0.001611231011338532, 0.0028301456477493048, 0.0005118506960570812, 0.0027071244549006224, 0.0020970292389392853, 0.00123287970200181, 0.0006310886819846928, 0.0017632452072575688, 0.0017868784489110112, 0.0002528328914195299, 0.0010720744030550122, 0.0026448301505297422, 0.001566156861372292, 0.0038084066472947598, 0.005276741925626993, 0.00693025765940547, 0.013310822658240795, 0.0035816472955048084, 0.01830451190471649, 0.026684748008847237, 0.01997152902185917, 0.032155733555555344, 0.07432045787572861, 0.02392224408686161, 0.08761470019817352, 0.1800754964351654, 0.027492599561810493, 0.059722479432821274, 0.19122706353664398, 0.16271227598190308, 0.0], [0.008116928860545158, 0.0008723047212697566, 0.0003707280848175287, 0.000473485590191558, 0.00017832992307376117, 0.0003994707658421248, 0.00029511755565181375, 0.00018311967141926289, 0.00016714565572328866, 0.00023702485486865044, 0.00025333566009067, 0.00012855020759161562, 0.00020213171956129372, 0.00039944867603480816, 0.00016511800640728325, 0.00046228672727011144, 0.0008780235075391829, 0.0011140466667711735, 0.0020708779338747263, 0.001963674323633313, 0.0035278580617159605, 0.004475219640880823, 0.004463491961359978, 0.007312541361898184, 0.014446226879954338, 0.03503049165010452, 0.020014144480228424, 0.043885815888643265, 0.0194367878139019, 0.11325745284557343, 0.07277626544237137, 0.16196811199188232, 0.4804743826389313]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9473748207092285, 0.05262519419193268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8785884380340576, 0.055394649505615234, 0.06601689755916595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7270771265029907, 0.1370987445116043, 0.04866088926792145, 0.08716321736574173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4651746451854706, 0.1342930644750595, 0.1535816788673401, 0.1747254878282547, 0.0722251608967781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17035967111587524, 0.01184193603694439, 0.023650838062167168, 0.021745804697275162, 0.025856323540210724, 0.7465453743934631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14214570820331573, 0.04383270442485809, 0.05021180957555771, 0.045165035873651505, 0.05872130021452904, 0.511153519153595, 0.14876997470855713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08473348617553711, 0.020369818434119225, 0.037461623549461365, 0.03195910155773163, 0.03419601544737816, 0.4350069463253021, 0.1189405769109726, 0.23733240365982056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3423079550266266, 0.03593634441494942, 0.07259216159582138, 0.10352766513824463, 0.08196531236171722, 0.07694562524557114, 0.14196321368217468, 0.09896712005138397, 0.045794617384672165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37114864587783813, 0.06278744339942932, 0.05806949734687805, 0.055662766098976135, 0.13124842941761017, 0.07535628229379654, 0.10726623982191086, 0.07924024015665054, 0.030107339844107628, 0.029113223776221275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06430105119943619, 0.005169104319065809, 0.01101298164576292, 0.009054876863956451, 0.011748064309358597, 0.31885024905204773, 0.03684945032000542, 0.08319542557001114, 0.012068144045770168, 0.01467620488256216, 0.4330744445323944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23777922987937927, 0.03812997788190842, 0.019743354991078377, 0.0750802680850029, 0.14420796930789948, 0.062449246644973755, 0.07018381357192993, 0.06523611396551132, 0.04883222281932831, 0.034600336104631424, 0.06439773738384247, 0.13935981690883636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2901448607444763, 0.04085763916373253, 0.06965623050928116, 0.06467736512422562, 0.11515604704618454, 0.07279440015554428, 0.05406035855412483, 0.04095995053648949, 0.03646121919155121, 0.03709696605801582, 0.08112155646085739, 0.06249445304274559, 0.034518949687480927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04191604629158974, 0.00338806607760489, 0.00708235427737236, 0.005899201612919569, 0.007586190477013588, 0.20389807224273682, 0.023296764120459557, 0.05173070728778839, 0.00781681202352047, 0.009731385856866837, 0.27760201692581177, 0.008386759087443352, 0.016172701492905617, 0.33549293875694275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1512935310602188, 0.04240790382027626, 0.04383379966020584, 0.09706762433052063, 0.14943550527095795, 0.04439878091216087, 0.06174500659108162, 0.041995152831077576, 0.018608782440423965, 0.031412459909915924, 0.05092645809054375, 0.06660285592079163, 0.094162218272686, 0.05761292949318886, 0.04849696904420853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29958033561706543, 0.07432074099779129, 0.030061950907111168, 0.016736464574933052, 0.03856483846902847, 0.051068708300590515, 0.09408655017614365, 0.05606793239712715, 0.05458230897784233, 0.04522043839097023, 0.05638071149587631, 0.015378035604953766, 0.04082852602005005, 0.06084693595767021, 0.03081105835735798, 0.035464461892843246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030439969152212143, 0.0024933929089456797, 0.005298203323036432, 0.004223390016704798, 0.005517448764294386, 0.14508461952209473, 0.016034148633480072, 0.03598649054765701, 0.0057580494321882725, 0.007398172281682491, 0.1961347907781601, 0.0060908859595656395, 0.011465121060609818, 0.23737995326519012, 0.008031773380935192, 0.005861478857696056, 0.2768021523952484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015668924897909164, 0.0019133499590680003, 0.0067479307763278484, 0.005610877647995949, 0.006710363551974297, 0.10858529061079025, 0.013436978682875633, 0.030674783512949944, 0.008698036894202232, 0.005958769004791975, 0.15696421265602112, 0.006401257123798132, 0.014357196167111397, 0.19220459461212158, 0.009938814677298069, 0.008154558017849922, 0.22861388325691223, 0.17936018109321594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2751207649707794, 0.046356093138456345, 0.025782734155654907, 0.02037108689546585, 0.045191291719675064, 0.04741504415869713, 0.05800829827785492, 0.05449458584189415, 0.021855849772691727, 0.0286741741001606, 0.05054798722267151, 0.035789452493190765, 0.01434398628771305, 0.05505193769931793, 0.019970901310443878, 0.025070643052458763, 0.0598367415368557, 0.10591267794370651, 0.01020571868866682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12210459262132645, 0.02900637313723564, 0.027926085516810417, 0.030763661488890648, 0.06431961804628372, 0.05075862631201744, 0.05746714025735855, 0.03854452073574066, 0.02881442941725254, 0.03641034662723541, 0.055306993424892426, 0.02755570225417614, 0.05062384530901909, 0.06039684638381004, 0.03790903463959694, 0.03416256979107857, 0.06550320982933044, 0.08224613219499588, 0.08903142064809799, 0.011148831807076931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019922718405723572, 0.0015991267282515764, 0.0035362686030566692, 0.002760607050731778, 0.003674750216305256, 0.091985784471035, 0.009868190623819828, 0.021762728691101074, 0.0036746240220963955, 0.004800301045179367, 0.1232718899846077, 0.003948225639760494, 0.0077277058735489845, 0.14901939034461975, 0.0050945039838552475, 0.0038495443295687437, 0.17433799803256989, 0.14503765106201172, 0.0031391752418130636, 0.0039015652146190405, 0.21708731353282928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025169124826788902, 0.0025891440454870462, 0.0079044783487916, 0.002818176057189703, 0.008317497558891773, 0.06284768134355545, 0.016097379848361015, 0.02483357861638069, 0.007658040151000023, 0.011317078024148941, 0.08451008051633835, 0.012135403230786324, 0.022048382088541985, 0.10017251968383789, 0.015103279612958431, 0.0201522596180439, 0.11906807124614716, 0.14148969948291779, 0.006576648913323879, 0.0070740580558776855, 0.14850659668445587, 0.15361084043979645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08679645508527756, 0.015818683430552483, 0.009913158603012562, 0.005941123701632023, 0.011749119497835636, 0.04402250796556473, 0.049411579966545105, 0.047211624681949615, 0.02244851179420948, 0.028144177049398422, 0.05249372124671936, 0.013664904050529003, 0.038044534623622894, 0.05856489762663841, 0.016008734703063965, 0.028531746938824654, 0.06752396374940872, 0.10004056990146637, 0.026074495166540146, 0.01816527172923088, 0.08061446994543076, 0.14588378369808197, 0.03293200582265854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1220332682132721, 0.026796920225024223, 0.034712765365839005, 0.01660085655748844, 0.05098601058125496, 0.03362342715263367, 0.03376288339495659, 0.03289439156651497, 0.022763608023524284, 0.034695446491241455, 0.03710823133587837, 0.027503039687871933, 0.03050803393125534, 0.040704939514398575, 0.019409824162721634, 0.03338808938860893, 0.046037912368774414, 0.0814194306731224, 0.025792930275201797, 0.017713351175189018, 0.05326376482844353, 0.06955212354660034, 0.07340098917484283, 0.03532777354121208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012632702477276325, 0.0031967288814485073, 0.008999628014862537, 0.0037871047388762236, 0.005590218584984541, 0.06018747389316559, 0.01017302367836237, 0.026063406839966774, 0.008280324749648571, 0.0059984405525028706, 0.08480246365070343, 0.007755734492093325, 0.014807665720582008, 0.10079343616962433, 0.011636026203632355, 0.007885102182626724, 0.12061367183923721, 0.1281987428665161, 0.006487110164016485, 0.0032305715139955282, 0.15047506988048553, 0.10557684302330017, 0.01548060867935419, 0.01902632601559162, 0.07832161337137222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11176051944494247, 0.01863556168973446, 0.056223705410957336, 0.04677280783653259, 0.03736496344208717, 0.022993413731455803, 0.03136527165770531, 0.026408882811665535, 0.043359220027923584, 0.05663556605577469, 0.021786415949463844, 0.02382213994860649, 0.03064166195690632, 0.023289259523153305, 0.054304927587509155, 0.068811796605587, 0.024489402770996094, 0.047770895063877106, 0.036271773278713226, 0.022222528234124184, 0.026998937129974365, 0.021766120567917824, 0.03442491590976715, 0.028240270912647247, 0.05891920626163483, 0.024719825014472008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10639798641204834, 0.03710790351033211, 0.08273960649967194, 0.01785685494542122, 0.020950015634298325, 0.018305247649550438, 0.02262009307742119, 0.018192268908023834, 0.02185117080807686, 0.012518538162112236, 0.019214095547795296, 0.030340095981955528, 0.07187619060277939, 0.02078801579773426, 0.03963521122932434, 0.06151585280895233, 0.023179292678833008, 0.04398040100932121, 0.0461922287940979, 0.020667990669608116, 0.027080878615379333, 0.043865546584129333, 0.03276738151907921, 0.04369065538048744, 0.05080845206975937, 0.04029493033885956, 0.025563016533851624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015084543265402317, 0.0038223823066800833, 0.005877262447029352, 0.0049718511290848255, 0.005370152648538351, 0.05223647877573967, 0.016127679497003555, 0.03182991221547127, 0.008211130276322365, 0.01147382240742445, 0.0670468807220459, 0.010528383776545525, 0.010598228313028812, 0.07938900589942932, 0.007211721036583185, 0.006271459627896547, 0.09142372012138367, 0.10866517573595047, 0.003973816521465778, 0.005621667951345444, 0.10983319580554962, 0.09237749129533768, 0.022960500791668892, 0.019314918667078018, 0.08864136040210724, 0.018464699387550354, 0.01102225948125124, 0.09165028482675552, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09854122251272202, 0.03967056795954704, 0.05052143335342407, 0.047943927347660065, 0.019531873986124992, 0.015683405101299286, 0.02507474087178707, 0.01499791070818901, 0.02772342413663864, 0.016418181359767914, 0.016389025375247, 0.026316560804843903, 0.034359268844127655, 0.01775798387825489, 0.02336267940700054, 0.03763512149453163, 0.019405601546168327, 0.034421682357788086, 0.04902299866080284, 0.030190542340278625, 0.022159069776535034, 0.03754066675901413, 0.038793161511421204, 0.04032415151596069, 0.042312659323215485, 0.06829201430082321, 0.02531413920223713, 0.04330072179436684, 0.03699522837996483, 0.0, 0.0, 0.0, 0.0], [0.10688817501068115, 0.036595746874809265, 0.005083095747977495, 0.010160424746572971, 0.013297361321747303, 0.041752055287361145, 0.026246795430779457, 0.030128560960292816, 0.013482403010129929, 0.01822318695485592, 0.0458262637257576, 0.025558775290846825, 0.01561881322413683, 0.05039897561073303, 0.011657019145786762, 0.01165912114083767, 0.05515517294406891, 0.05091661214828491, 0.019206790253520012, 0.013998426496982574, 0.06383472681045532, 0.029088884592056274, 0.016710449010133743, 0.026095259934663773, 0.05484984815120697, 0.03806673362851143, 0.03896070644259453, 0.05375230684876442, 0.02367916889488697, 0.05310814082622528, 0.0, 0.0, 0.0], [0.10871608555316925, 0.06286413967609406, 0.023045092821121216, 0.012493222020566463, 0.009688261896371841, 0.0237207543104887, 0.025617308914661407, 0.02828286960721016, 0.01952311582863331, 0.015187139622867107, 0.02461576834321022, 0.01885579340159893, 0.013071908615529537, 0.025697486475110054, 0.010639778338372707, 0.007336428388953209, 0.028488246724009514, 0.04087510332465172, 0.023693950846791267, 0.028460804373025894, 0.03178119286894798, 0.03399212285876274, 0.01690451055765152, 0.04699757322669029, 0.054809171706438065, 0.060481660068035126, 0.02113782800734043, 0.05147767812013626, 0.01530434750020504, 0.07868863642215729, 0.037551965564489365, 0.0, 0.0], [0.16510625183582306, 0.013307341374456882, 0.02282034605741501, 0.03222496435046196, 0.028327805921435356, 0.011912108398973942, 0.021759113296866417, 0.012591330334544182, 0.025371313095092773, 0.015923485159873962, 0.01174505427479744, 0.021340148523449898, 0.02265850454568863, 0.012097017839550972, 0.05877393111586571, 0.04114292189478874, 0.012866122648119926, 0.021896688267588615, 0.027385754510760307, 0.01541272085160017, 0.014822260476648808, 0.013198774307966232, 0.029060134664177895, 0.04031304642558098, 0.02303694374859333, 0.05035790055990219, 0.04650072380900383, 0.03221072629094124, 0.045741382986307144, 0.011448167264461517, 0.051484815776348114, 0.047162190079689026, 0.0], [0.019862733781337738, 0.0006941378815099597, 0.0017670636298134923, 0.0019038196187466383, 0.002311579417437315, 0.05924392119050026, 0.0051649510860443115, 0.008714542724192142, 0.002490669023245573, 0.003057960420846939, 0.07585161924362183, 0.0023905509151518345, 0.003177350852638483, 0.08945119380950928, 0.003065295284613967, 0.00162091467063874, 0.10312026739120483, 0.06259164214134216, 0.0020582969300448895, 0.00223221885971725, 0.12742048501968384, 0.024703852832317352, 0.0035101929679512978, 0.0049941763281822205, 0.028317108750343323, 0.005874201655387878, 0.006215331610292196, 0.03686559572815895, 0.005438114050775766, 0.004061863292008638, 0.004735518712550402, 0.004534383304417133, 0.292558491230011]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9726406335830688, 0.02735934779047966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8850566744804382, 0.08160645514726639, 0.03333684802055359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.784497857093811, 0.09046003222465515, 0.1072097048163414, 0.017832357436418533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6679065227508545, 0.10135099291801453, 0.10997921228408813, 0.06990877538919449, 0.05085451155900955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.586279034614563, 0.06960930675268173, 0.06798024475574493, 0.06058965623378754, 0.08339769393205643, 0.13214407861232758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5015710592269897, 0.06227878853678703, 0.07209987938404083, 0.0559091791510582, 0.0814688503742218, 0.12033160775899887, 0.10634062439203262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4001609981060028, 0.05525399371981621, 0.06347677856683731, 0.05413787066936493, 0.07119624316692352, 0.11230526119470596, 0.12489721924066544, 0.11857160180807114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4018532335758209, 0.08579415082931519, 0.05644883215427399, 0.07181122153997421, 0.08318918943405151, 0.07845646888017654, 0.09191887080669403, 0.0776887759566307, 0.05283930152654648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3827159106731415, 0.07976950705051422, 0.06207751855254173, 0.06360233575105667, 0.08211030066013336, 0.07804949581623077, 0.08597435802221298, 0.07506491243839264, 0.06327842175960541, 0.027357222512364388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34041672945022583, 0.045351944863796234, 0.04658911004662514, 0.0403917171061039, 0.0548904649913311, 0.08179008215665817, 0.08906515687704086, 0.09645894169807434, 0.055649708956480026, 0.06398672610521317, 0.08540944010019302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31186193227767944, 0.09540000557899475, 0.07292015105485916, 0.0697687417268753, 0.07777833193540573, 0.0673503577709198, 0.061614058911800385, 0.05481072515249252, 0.052520133554935455, 0.05022517964243889, 0.07299350202083588, 0.012756953947246075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3665284216403961, 0.06308671832084656, 0.03947843238711357, 0.04609527066349983, 0.05740760639309883, 0.063483327627182, 0.0523846372961998, 0.055016204714775085, 0.04584016650915146, 0.06228690966963768, 0.06589912623167038, 0.05806362256407738, 0.024429524317383766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2856442928314209, 0.03804025799036026, 0.03942389041185379, 0.03423863276839256, 0.046394024044275284, 0.06771665066480637, 0.07328073680400848, 0.07855431735515594, 0.04789663851261139, 0.0559365451335907, 0.07124951481819153, 0.03568926453590393, 0.049560461193323135, 0.07637481391429901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2977541983127594, 0.05259548872709274, 0.04347937926650047, 0.058458633720874786, 0.04568732529878616, 0.052594032138586044, 0.0445619635283947, 0.0459747239947319, 0.06316150724887848, 0.07768755406141281, 0.05499148741364479, 0.034664712846279144, 0.05020102858543396, 0.05886140838265419, 0.01932654157280922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28853151202201843, 0.046169109642505646, 0.02823304384946823, 0.03824242576956749, 0.04330622777342796, 0.05174916237592697, 0.04318273440003395, 0.04393119364976883, 0.056163422763347626, 0.0677381381392479, 0.05490180850028992, 0.08139312267303467, 0.04325693100690842, 0.059048131108284, 0.03989902883768082, 0.014254054985940456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23721367120742798, 0.03161582350730896, 0.03324564918875694, 0.02923194319009781, 0.038618169724941254, 0.05549165979027748, 0.05966496095061302, 0.06321780383586884, 0.04073698818683624, 0.04752673953771591, 0.058378253132104874, 0.030399682000279427, 0.042871586978435516, 0.06284616887569427, 0.05321290343999863, 0.047368962317705154, 0.06835903227329254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2098696082830429, 0.02729126065969467, 0.03115660697221756, 0.026614999398589134, 0.03165116906166077, 0.05273225158452988, 0.0527450330555439, 0.05635902285575867, 0.04076547920703888, 0.04278235137462616, 0.056191280484199524, 0.030678270384669304, 0.0439896285533905, 0.060914747416973114, 0.050137005746364594, 0.041573163121938705, 0.06652862578630447, 0.07801952958106995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2385382503271103, 0.044145818799734116, 0.046435050666332245, 0.0345127172768116, 0.03572181984782219, 0.04369327798485756, 0.043049730360507965, 0.034988246858119965, 0.04371805489063263, 0.0395219624042511, 0.04457855224609375, 0.02459944598376751, 0.0625118762254715, 0.04753483459353447, 0.04375608637928963, 0.04995928332209587, 0.050908081233501434, 0.05266242474317551, 0.019164476543664932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17729146778583527, 0.042214617133140564, 0.030818702653050423, 0.030886109918355942, 0.033868517726659775, 0.045211855322122574, 0.042901020497083664, 0.03221559524536133, 0.04018864035606384, 0.04926897957921028, 0.048016250133514404, 0.03814244642853737, 0.0512651763856411, 0.05206843465566635, 0.04744115099310875, 0.03924531862139702, 0.05630476027727127, 0.05462939664721489, 0.05991863086819649, 0.02810296230018139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19048276543617249, 0.025203490629792213, 0.02678745612502098, 0.023672688752412796, 0.0311040710657835, 0.04345342889428139, 0.04649331048130989, 0.04820645600557327, 0.03323280066251755, 0.038927506655454636, 0.04549151286482811, 0.024442730471491814, 0.03570159897208214, 0.049077682197093964, 0.043035659939050674, 0.03905563801527023, 0.0537174753844738, 0.06658954918384552, 0.04320827126502991, 0.03176472336053848, 0.06035127118229866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1497536599636078, 0.02347457781434059, 0.02550838701426983, 0.02894243411719799, 0.03517160564661026, 0.0388018935918808, 0.04594280570745468, 0.03962727263569832, 0.03708778694272041, 0.03872300684452057, 0.041907213628292084, 0.021688053384423256, 0.04328259453177452, 0.04592539742588997, 0.03893951699137688, 0.040076084434986115, 0.050600238144397736, 0.0608304925262928, 0.04372159764170647, 0.03023523837327957, 0.05728614702820778, 0.062474045902490616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1751340627670288, 0.027519280090928078, 0.029514005407691002, 0.020715326070785522, 0.026873530820012093, 0.03454612195491791, 0.038530781865119934, 0.033037807792425156, 0.041815564036369324, 0.040100302547216415, 0.03696897253394127, 0.030468925833702087, 0.03995397686958313, 0.04023701697587967, 0.0448262058198452, 0.03708262741565704, 0.04420146346092224, 0.04931037500500679, 0.04125743359327316, 0.02861069329082966, 0.04997343569993973, 0.05269286409020424, 0.036629170179367065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13285988569259644, 0.04070804640650749, 0.041116777807474136, 0.03484427556395531, 0.04087607562541962, 0.027567220851778984, 0.028293684124946594, 0.022520430386066437, 0.03875420615077019, 0.04037803038954735, 0.0290894266217947, 0.02960921637713909, 0.056701187044382095, 0.031181856989860535, 0.03766117990016937, 0.05688636004924774, 0.03396708518266678, 0.03781304135918617, 0.049514103680849075, 0.03194558247923851, 0.03759903833270073, 0.043266378343105316, 0.04305671527981758, 0.03379024937748909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14709363877773285, 0.018218711018562317, 0.022143611684441566, 0.021621398627758026, 0.027072913944721222, 0.03385418280959129, 0.03787612169981003, 0.038019631057977676, 0.02793252095580101, 0.03090183436870575, 0.03606925904750824, 0.01902313157916069, 0.034658029675483704, 0.039169859141111374, 0.0337555892765522, 0.026136614382267, 0.042978327721357346, 0.05313740670681, 0.03463507443666458, 0.02014029584825039, 0.04878360405564308, 0.04990803450345993, 0.04624393582344055, 0.047156691551208496, 0.06346960365772247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17602786421775818, 0.014882151037454605, 0.026751166209578514, 0.024088067933917046, 0.035667534917593, 0.027094289660453796, 0.024984240531921387, 0.021471867337822914, 0.02635936439037323, 0.02384510263800621, 0.027567004784941673, 0.01686953753232956, 0.07777431607246399, 0.029109209775924683, 0.047996968030929565, 0.02900249883532524, 0.031323354691267014, 0.036155980080366135, 0.039595600217580795, 0.017008021473884583, 0.03483906760811806, 0.03443719819188118, 0.041492193937301636, 0.09124377369880676, 0.04052295908331871, 0.0038906047120690346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18501748144626617, 0.027786999940872192, 0.02509763464331627, 0.027019010856747627, 0.02919921837747097, 0.0303370151668787, 0.03222178295254707, 0.023015083745121956, 0.026792865246534348, 0.022793833166360855, 0.030674872919917107, 0.02122085727751255, 0.05388808622956276, 0.032593000680208206, 0.03073764219880104, 0.025725232437253, 0.034866053611040115, 0.03793580085039139, 0.028672028332948685, 0.026148967444896698, 0.03875335305929184, 0.04179505631327629, 0.038631584495306015, 0.05337152257561684, 0.03982068598270416, 0.02571161277592182, 0.010172730311751366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1244632825255394, 0.01676890254020691, 0.02010509744286537, 0.01926703006029129, 0.024457845836877823, 0.03020336665213108, 0.03127393126487732, 0.032546062022447586, 0.023186009377241135, 0.02350839413702488, 0.03173321858048439, 0.01708051562309265, 0.029082056134939194, 0.03428216278553009, 0.035791296511888504, 0.02582055889070034, 0.03753117844462395, 0.04618246853351593, 0.029500015079975128, 0.017913812771439552, 0.04274730384349823, 0.0424346998333931, 0.039002399891614914, 0.04141839221119881, 0.059494998306035995, 0.035957347601652145, 0.030984869226813316, 0.05726282671093941, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14491020143032074, 0.025843987241387367, 0.03117695264518261, 0.019462747499346733, 0.012575741857290268, 0.025274593383073807, 0.02202068828046322, 0.02126728929579258, 0.03165539354085922, 0.02766416035592556, 0.026251591742038727, 0.022091040387749672, 0.03851797431707382, 0.02826686017215252, 0.028877614066004753, 0.03686533495783806, 0.030699966475367546, 0.03204502910375595, 0.034116294234991074, 0.020355412736535072, 0.03446315973997116, 0.03542865812778473, 0.03072841465473175, 0.04441896826028824, 0.03793594241142273, 0.057348690927028656, 0.03889699652791023, 0.04111206904053688, 0.01972820796072483, 0.0, 0.0, 0.0, 0.0], [0.1316843181848526, 0.02546011097729206, 0.027962401509284973, 0.024109849706292152, 0.016868827864527702, 0.03140677139163017, 0.02324734814465046, 0.02207169681787491, 0.027362488210201263, 0.026370452716946602, 0.03204537183046341, 0.02877582609653473, 0.04614204913377762, 0.03455977886915207, 0.031321071088314056, 0.029437724500894547, 0.037490688264369965, 0.035974208265542984, 0.03067101538181305, 0.026778321713209152, 0.041662365198135376, 0.03274399787187576, 0.030348774045705795, 0.032651983201503754, 0.038056500256061554, 0.034575626254081726, 0.022936126217246056, 0.036903269588947296, 0.025966186076402664, 0.014414903707802296, 0.0, 0.0, 0.0], [0.16563695669174194, 0.022809254005551338, 0.029107755050063133, 0.024944668635725975, 0.024352887645363808, 0.025031816214323044, 0.01848665066063404, 0.018573684617877007, 0.028443647548556328, 0.029199903830885887, 0.025318238884210587, 0.0322050005197525, 0.025753289461135864, 0.026890495792031288, 0.03127396106719971, 0.0330515019595623, 0.028835482895374298, 0.029910417273640633, 0.027558812871575356, 0.02462468110024929, 0.0320536270737648, 0.02649376541376114, 0.021709619089961052, 0.03164015710353851, 0.037074748426675797, 0.047994695603847504, 0.027932148426771164, 0.034756120294332504, 0.03804945573210716, 0.021535690873861313, 0.00875084102153778, 0.0, 0.0], [0.1679421365261078, 0.02598348818719387, 0.03222334757447243, 0.019469384104013443, 0.023735303431749344, 0.023115726187825203, 0.019973624497652054, 0.016550229862332344, 0.029796777293086052, 0.028494669124484062, 0.02310885861515999, 0.022087080404162407, 0.042165569961071014, 0.024390170350670815, 0.020749147981405258, 0.038735855370759964, 0.026269836351275444, 0.027289096266031265, 0.01961737684905529, 0.02024286612868309, 0.02920321188867092, 0.030413372442126274, 0.02576262690126896, 0.040849801152944565, 0.033326636999845505, 0.021795310080051422, 0.02631053514778614, 0.031013479456305504, 0.036892615258693695, 0.01937718316912651, 0.043556053191423416, 0.009558654390275478, 0.0], [0.11396825313568115, 0.0177528727799654, 0.016061948612332344, 0.015585058368742466, 0.01839613914489746, 0.0243670791387558, 0.026053884997963905, 0.023999108001589775, 0.021919477730989456, 0.02625109814107418, 0.024730542674660683, 0.01532302051782608, 0.02561456710100174, 0.026337873190641403, 0.024982869625091553, 0.024642597883939743, 0.028590325266122818, 0.03295150026679039, 0.027568642050027847, 0.01848755031824112, 0.03220851719379425, 0.031914710998535156, 0.03630727529525757, 0.034154027700424194, 0.03678560256958008, 0.03297771140933037, 0.02627890184521675, 0.03809887915849686, 0.029801957309246063, 0.018183251842856407, 0.03632066771388054, 0.03568094223737717, 0.057703107595443726]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8058415055274963, 0.19415844976902008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6373866200447083, 0.09672049432992935, 0.265892893075943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5870267152786255, 0.09922724962234497, 0.07913826406002045, 0.23460783064365387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4194740355014801, 0.06312595307826996, 0.08123063296079636, 0.08381497859954834, 0.352354496717453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.530853271484375, 0.0959073081612587, 0.07779335975646973, 0.06661548465490341, 0.07293293625116348, 0.15589763224124908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3850307762622833, 0.0747809186577797, 0.06978143751621246, 0.047606535255908966, 0.05144914612174034, 0.08776704221963882, 0.2835841178894043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2962956726551056, 0.05328270420432091, 0.06944748014211655, 0.040975481271743774, 0.06660832464694977, 0.1021856963634491, 0.10869501531124115, 0.26250967383384705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30475011467933655, 0.06337985396385193, 0.05753422528505325, 0.04057719558477402, 0.07300138473510742, 0.07375828176736832, 0.07239887863397598, 0.056936051696538925, 0.2576640844345093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29880765080451965, 0.055528245866298676, 0.05443596467375755, 0.052853018045425415, 0.06568748503923416, 0.07554223388433456, 0.06968104094266891, 0.05411387234926224, 0.09120786190032959, 0.18214257061481476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2693301737308502, 0.06352430582046509, 0.059521205723285675, 0.05242469906806946, 0.06052158400416374, 0.12185832113027573, 0.07608653604984283, 0.09753072261810303, 0.042326074093580246, 0.050583261996507645, 0.10629310458898544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22074298560619354, 0.06960075348615646, 0.04872344434261322, 0.06675713509321213, 0.06954210251569748, 0.06483785808086395, 0.04652373120188713, 0.039300836622714996, 0.018016086891293526, 0.035806313157081604, 0.053022850304841995, 0.2671259045600891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15080073475837708, 0.04732475057244301, 0.12551113963127136, 0.062400832772254944, 0.053546320647001266, 0.0557839535176754, 0.04542611539363861, 0.03888600692152977, 0.0301998108625412, 0.03337055444717407, 0.04645954445004463, 0.023437924683094025, 0.2868523597717285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2044883370399475, 0.049720507115125656, 0.04838545247912407, 0.04385359212756157, 0.05115719884634018, 0.1007489413022995, 0.06420682370662689, 0.08302561938762665, 0.03880453109741211, 0.047957733273506165, 0.09582382440567017, 0.03239700570702553, 0.044411029666662216, 0.09501936286687851, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16236740350723267, 0.028519179672002792, 0.047843087464571, 0.041354816406965256, 0.040284883230924606, 0.052005354315042496, 0.04226505383849144, 0.03821168839931488, 0.05986882373690605, 0.06849396973848343, 0.04734281450510025, 0.019715163856744766, 0.06202229857444763, 0.04572192206978798, 0.24398353695869446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1312893033027649, 0.03962808847427368, 0.059519387781620026, 0.039663221687078476, 0.04406356438994408, 0.04348495230078697, 0.03726546838879585, 0.03240035101771355, 0.037205733358860016, 0.06481602042913437, 0.0404745377600193, 0.025914236903190613, 0.06507600098848343, 0.03922510892152786, 0.0774419754743576, 0.22253204882144928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1581333875656128, 0.03911251947283745, 0.03856494650244713, 0.03587969392538071, 0.04187794402241707, 0.08161000907421112, 0.05245805159211159, 0.0681268572807312, 0.03444807231426239, 0.04342750832438469, 0.08275996893644333, 0.029333394020795822, 0.04157378897070885, 0.08478686213493347, 0.048816002905368805, 0.032352838665246964, 0.08673812448978424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13890595734119415, 0.03169632703065872, 0.03251554071903229, 0.03538898378610611, 0.038000334054231644, 0.06974425911903381, 0.05942453071475029, 0.06768239289522171, 0.027843806892633438, 0.039054665714502335, 0.07273104041814804, 0.030109873041510582, 0.04163093492388725, 0.07565010339021683, 0.04018832743167877, 0.027483616024255753, 0.0779590755701065, 0.09399020671844482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09691290557384491, 0.03068731166422367, 0.030817952007055283, 0.044734325259923935, 0.04171941801905632, 0.036036767065525055, 0.04101702570915222, 0.03210476040840149, 0.04344063997268677, 0.04885551705956459, 0.03457902371883392, 0.016025099903345108, 0.04994165524840355, 0.0346352718770504, 0.06065686047077179, 0.034977883100509644, 0.03454343602061272, 0.03782794997096062, 0.25048619508743286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1205921471118927, 0.04121064394712448, 0.05098516866564751, 0.05289150029420853, 0.02886130101978779, 0.047061987221241, 0.029212836176156998, 0.038170017302036285, 0.021046487614512444, 0.02978781796991825, 0.04406721517443657, 0.02650335431098938, 0.04127003252506256, 0.044307366013526917, 0.03080156072974205, 0.04064901918172836, 0.044745106250047684, 0.042122457176446915, 0.028442280367016792, 0.1972716897726059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11388306319713593, 0.02825540117919445, 0.028351284563541412, 0.02695867046713829, 0.03131086379289627, 0.05977547913789749, 0.0391821451485157, 0.05072040110826492, 0.02768402174115181, 0.035564225167036057, 0.06452133506536484, 0.024267084896564484, 0.03616494685411453, 0.06838169693946838, 0.041393011808395386, 0.0290946364402771, 0.0723005011677742, 0.07349381595849991, 0.03700020909309387, 0.0352863147854805, 0.07641096413135529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08453851193189621, 0.017416611313819885, 0.018949132412672043, 0.016560642048716545, 0.022296126931905746, 0.041740596294403076, 0.05894863232970238, 0.038933612406253815, 0.030214648693799973, 0.03464233875274658, 0.048319004476070404, 0.01635843701660633, 0.02567455731332302, 0.053096748888492584, 0.020546521991491318, 0.02046983130276203, 0.05704640597105026, 0.06604909896850586, 0.03774646297097206, 0.02141387201845646, 0.06129930168390274, 0.20773889124393463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11248443275690079, 0.024394843727350235, 0.024523135274648666, 0.02748955972492695, 0.026104673743247986, 0.037315063178539276, 0.06748529523611069, 0.03890375792980194, 0.01798143796622753, 0.028454391285777092, 0.037565309554338455, 0.018326064571738243, 0.020088661462068558, 0.038651712238788605, 0.023285649716854095, 0.02422661893069744, 0.03960611671209335, 0.04833188280463219, 0.04500092566013336, 0.017362141981720924, 0.04009140282869339, 0.05208283290266991, 0.19024406373500824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08183359354734421, 0.019828449934720993, 0.0268733948469162, 0.029252558946609497, 0.02518443949520588, 0.031927723437547684, 0.029049787670373917, 0.024972515180706978, 0.03350626304745674, 0.040074292570352554, 0.033517323434352875, 0.01603599824011326, 0.03204454109072685, 0.03448064252734184, 0.02851710096001625, 0.03532731905579567, 0.03583228588104248, 0.040583960711956024, 0.029941115528345108, 0.02109791710972786, 0.03671329468488693, 0.03921257704496384, 0.03543240949511528, 0.23876051604747772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1014569103717804, 0.014237052761018276, 0.01698417402803898, 0.018636560067534447, 0.028536250814795494, 0.036538016051054, 0.029570508748292923, 0.04198319464921951, 0.014166050590574741, 0.030081404373049736, 0.04016640782356262, 0.020075039938092232, 0.03037012554705143, 0.04353441670536995, 0.03039301559329033, 0.02071734517812729, 0.04677112400531769, 0.054951030761003494, 0.028809187933802605, 0.020043691620230675, 0.05092542991042137, 0.040844667702913284, 0.04185802862048149, 0.03848978877067566, 0.15986062586307526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07937928289175034, 0.02067432925105095, 0.020799750462174416, 0.027988238260149956, 0.0456547737121582, 0.02656259760260582, 0.02539670467376709, 0.021243248134851456, 0.01776380091905594, 0.025200635194778442, 0.02757645957171917, 0.03060709498822689, 0.0343799963593483, 0.028568318113684654, 0.022726938128471375, 0.016051946207880974, 0.02971273846924305, 0.03276180475950241, 0.025702396407723427, 0.012878886424005032, 0.03062613122165203, 0.020369645208120346, 0.037413887679576874, 0.02785036899149418, 0.035718511790037155, 0.27639150619506836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09605437517166138, 0.023092901334166527, 0.024199649691581726, 0.02497413381934166, 0.036829665303230286, 0.030014390125870705, 0.02106921561062336, 0.018117520958185196, 0.022569265216588974, 0.02834322489798069, 0.03050513006746769, 0.021707683801651, 0.02821178361773491, 0.031639423221349716, 0.03916611522436142, 0.03627365455031395, 0.03311571106314659, 0.03514396771788597, 0.025745240971446037, 0.01588900201022625, 0.034675467759370804, 0.026770086959004402, 0.02714345045387745, 0.040450796484947205, 0.037603843957185745, 0.03232336416840553, 0.17837102711200714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07476936280727386, 0.011021515354514122, 0.010706553235650063, 0.015325449407100677, 0.01990356482565403, 0.03285866603255272, 0.02193606272339821, 0.029454153031110764, 0.01642150804400444, 0.022476568818092346, 0.037223439663648605, 0.017580240964889526, 0.021954137831926346, 0.040462128818035126, 0.0314154177904129, 0.010417778976261616, 0.044297389686107635, 0.05118127539753914, 0.02956555038690567, 0.015394327230751514, 0.0490642711520195, 0.032021936029195786, 0.030905112624168396, 0.04132053256034851, 0.06578275561332703, 0.039784036576747894, 0.020499693229794502, 0.1662566363811493, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05124204233288765, 0.011390029452741146, 0.020265797153115273, 0.02452964335680008, 0.1273244321346283, 0.02008390985429287, 0.01769273355603218, 0.020381979644298553, 0.01854861155152321, 0.023206062614917755, 0.02102605439722538, 0.020521238446235657, 0.025210730731487274, 0.021994249895215034, 0.017190469428896904, 0.020805906504392624, 0.023035310208797455, 0.026458051055669785, 0.031086131930351257, 0.011454473249614239, 0.024357983842492104, 0.022524939849972725, 0.02460077404975891, 0.024588003754615784, 0.028380829840898514, 0.046606115996837616, 0.0436270646750927, 0.020300474017858505, 0.2115660160779953, 0.0, 0.0, 0.0, 0.0], [0.07929296046495438, 0.023537393659353256, 0.022847279906272888, 0.01993604004383087, 0.015462889336049557, 0.025110291317105293, 0.021429041400551796, 0.015073486603796482, 0.009924097917973995, 0.015724750235676765, 0.027188710868358612, 0.020747274160385132, 0.034976352006196976, 0.029102327302098274, 0.021219026297330856, 0.01814761385321617, 0.031058205291628838, 0.033809494227170944, 0.020137561485171318, 0.01232312060892582, 0.0336926206946373, 0.024336127564311028, 0.031084518879652023, 0.03377700224518776, 0.04355441778898239, 0.032963529229164124, 0.03314928337931633, 0.02536490373313427, 0.02216367982327938, 0.22286593914031982, 0.0, 0.0, 0.0], [0.10059653967618942, 0.03096376173198223, 0.025578506290912628, 0.02022406831383705, 0.02713298238813877, 0.029490763321518898, 0.04074482247233391, 0.021403620019555092, 0.01639261096715927, 0.022520696744322777, 0.027555173262953758, 0.013599208556115627, 0.027306705713272095, 0.02780657820403576, 0.011214186437427998, 0.023586537688970566, 0.028399186208844185, 0.03066891059279442, 0.021664202213287354, 0.0170323196798563, 0.02905159257352352, 0.02654992789030075, 0.03297554329037666, 0.026790326461195946, 0.032060641795396805, 0.027298329398036003, 0.017307188361883163, 0.01876882277429104, 0.028226526454091072, 0.017085116356611252, 0.18000461161136627, 0.0, 0.0], [0.08361605554819107, 0.01658189296722412, 0.015823297202587128, 0.022005168721079826, 0.024062560871243477, 0.021028300747275352, 0.022811293601989746, 0.01441238820552826, 0.01557209063321352, 0.015104832127690315, 0.020917730405926704, 0.02179816924035549, 0.02598598599433899, 0.022013207897543907, 0.022025061771273613, 0.018091216683387756, 0.02311510220170021, 0.025451797991991043, 0.02594352513551712, 0.011241882108151913, 0.024466171860694885, 0.022869886830449104, 0.031613435596227646, 0.029542667791247368, 0.02381790429353714, 0.029349012300372124, 0.025922641158103943, 0.017268184572458267, 0.031844593584537506, 0.012037739157676697, 0.02752492018043995, 0.25614133477211, 0.0], [0.05258439853787422, 0.012508384883403778, 0.012737673707306385, 0.012144193984568119, 0.014467821456491947, 0.024812445044517517, 0.017109140753746033, 0.02516257017850876, 0.016298970207571983, 0.015160082839429379, 0.029820039868354797, 0.014290271326899529, 0.02409479022026062, 0.03374277800321579, 0.02163226343691349, 0.018924102187156677, 0.03819216787815094, 0.04115181788802147, 0.024165775626897812, 0.02063564397394657, 0.0441853329539299, 0.037937089800834656, 0.02963634952902794, 0.03152840584516525, 0.04542307183146477, 0.03596360608935356, 0.030482541769742966, 0.04609917104244232, 0.03206765279173851, 0.01766294613480568, 0.03169601783156395, 0.044629115611314774, 0.10305344313383102]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7707713842391968, 0.22922860085964203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7813623547554016, 0.10978527367115021, 0.1088523343205452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5350388884544373, 0.11194944381713867, 0.15013688802719116, 0.2028747797012329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4180358350276947, 0.16036385297775269, 0.10740306973457336, 0.10625777393579483, 0.2079394906759262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4349866509437561, 0.0957985520362854, 0.08251801878213882, 0.10028502345085144, 0.15332910418510437, 0.13308261334896088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44621357321739197, 0.056242119520902634, 0.05040299892425537, 0.0708429366350174, 0.09360905736684799, 0.11472617089748383, 0.16796310245990753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3609194755554199, 0.07294464856386185, 0.05191003903746605, 0.07159049808979034, 0.09321669489145279, 0.09543664008378983, 0.14539925754070282, 0.1085827425122261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31714069843292236, 0.07683128118515015, 0.0555228516459465, 0.06445363909006119, 0.08586593717336655, 0.10643254965543747, 0.1452113538980484, 0.09439334273338318, 0.054148342460393906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19288600981235504, 0.11343874782323837, 0.045305073261260986, 0.08361206203699112, 0.05763271823525429, 0.11914195120334625, 0.11441227048635483, 0.12364509701728821, 0.07640955597162247, 0.07351643592119217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25174087285995483, 0.060194142162799835, 0.049302127212285995, 0.0592232346534729, 0.08453334867954254, 0.07307681441307068, 0.12308555096387863, 0.08293969184160233, 0.06380269676446915, 0.07185833901166916, 0.08024313300848007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24793602526187897, 0.04855771362781525, 0.0617169588804245, 0.06616784632205963, 0.0878860205411911, 0.059203825891017914, 0.09128591418266296, 0.06866812705993652, 0.06062868982553482, 0.08399355411529541, 0.0656941831111908, 0.05826115608215332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15039603412151337, 0.07072301208972931, 0.0361880287528038, 0.038128845393657684, 0.0549657829105854, 0.09552796185016632, 0.1278020441532135, 0.09101752191781998, 0.04133947566151619, 0.06619425117969513, 0.11493083089590073, 0.0352681428194046, 0.07751806080341339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21730749309062958, 0.052248768508434296, 0.04279685020446777, 0.05130990967154503, 0.07021073251962662, 0.060848649591207504, 0.1009417176246643, 0.06729136407375336, 0.053472720086574554, 0.05803244560956955, 0.0638660341501236, 0.041436828672885895, 0.054298125207424164, 0.06593839824199677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14158986508846283, 0.08735616505146027, 0.041096288710832596, 0.07771318405866623, 0.0664159283041954, 0.06084612011909485, 0.07890867441892624, 0.0646718218922615, 0.04156755656003952, 0.05314024165272713, 0.06033195182681084, 0.04990345239639282, 0.061476901173591614, 0.06152055785059929, 0.05346130579710007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11277396976947784, 0.051402702927589417, 0.03480074182152748, 0.04410993680357933, 0.04927105829119682, 0.08066020160913467, 0.09371132403612137, 0.07634276896715164, 0.03460071608424187, 0.05556502193212509, 0.09000375121831894, 0.027950908988714218, 0.05808689445257187, 0.09759874641895294, 0.0585305280983448, 0.03459075838327408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19136783480644226, 0.0458880178630352, 0.03718419373035431, 0.044788483530282974, 0.05845540761947632, 0.05162312090396881, 0.08451797813177109, 0.05661727488040924, 0.04477924108505249, 0.046815864741802216, 0.051775235682725906, 0.03474309295415878, 0.04365592449903488, 0.05257754027843475, 0.04571913182735443, 0.05523937568068504, 0.0542522594332695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1780986338853836, 0.036513157188892365, 0.035378023982048035, 0.046600595116615295, 0.05606749653816223, 0.055425308644771576, 0.06580903381109238, 0.05869591236114502, 0.044602103531360626, 0.03845332935452461, 0.05522070452570915, 0.028129279613494873, 0.03887631371617317, 0.05635207146406174, 0.04307203367352486, 0.04859212040901184, 0.05801304802298546, 0.05610081925988197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11277122050523758, 0.04416342079639435, 0.016790850088000298, 0.03922899439930916, 0.030570238828659058, 0.08429381996393204, 0.05829834192991257, 0.07985574752092361, 0.0277402326464653, 0.024607928469777107, 0.08568025380373001, 0.012135534547269344, 0.02122361958026886, 0.08979950100183487, 0.024395618587732315, 0.018000077456235886, 0.09797869622707367, 0.08564860373735428, 0.046817269176244736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15648676455020905, 0.04359336569905281, 0.029469123110175133, 0.023382794111967087, 0.039893943816423416, 0.06601442396640778, 0.07239897549152374, 0.049598757177591324, 0.025720084086060524, 0.02872989885509014, 0.072687529027462, 0.02010437287390232, 0.03894995152950287, 0.07793485373258591, 0.0318501777946949, 0.029572593048214912, 0.08162933588027954, 0.04983031377196312, 0.04757082462310791, 0.014582015573978424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16675150394439697, 0.04021673649549484, 0.03194626793265343, 0.039155542850494385, 0.04867978021502495, 0.043519336730241776, 0.07027733325958252, 0.04676979035139084, 0.037370480597019196, 0.03785953298211098, 0.041853513568639755, 0.029438771307468414, 0.03496701642870903, 0.04187152534723282, 0.0366595983505249, 0.04418947920203209, 0.042447008192539215, 0.04308998957276344, 0.05540823936462402, 0.024029964581131935, 0.04349851235747337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2131170630455017, 0.03452149033546448, 0.026512041687965393, 0.03728464990854263, 0.04200230538845062, 0.053780727088451385, 0.06410718709230423, 0.040195904672145844, 0.029513956978917122, 0.030562086030840874, 0.04814052954316139, 0.019645746797323227, 0.023855995386838913, 0.04712359234690666, 0.027805248275399208, 0.02563280612230301, 0.04690323770046234, 0.042115021497011185, 0.04245338216423988, 0.016209963709115982, 0.047201577574014664, 0.04131557047367096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16099104285240173, 0.031492140144109726, 0.02550600655376911, 0.03203628957271576, 0.038119375705718994, 0.05386460945010185, 0.05289202556014061, 0.06297369301319122, 0.03872942551970482, 0.030703024938702583, 0.0486149825155735, 0.016964131966233253, 0.020984867587685585, 0.04743489250540733, 0.026178570464253426, 0.032817017287015915, 0.04874100908637047, 0.037023045122623444, 0.050284452736377716, 0.014425929635763168, 0.04926920682191849, 0.027485135942697525, 0.052469104528427124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13924194872379303, 0.04732195660471916, 0.022920064628124237, 0.03782675042748451, 0.03733158856630325, 0.056281961500644684, 0.06773106753826141, 0.06383748352527618, 0.028824562206864357, 0.028368622064590454, 0.05008406192064285, 0.014775182120501995, 0.021058904007077217, 0.04819711297750473, 0.017685120925307274, 0.015456218272447586, 0.04842803254723549, 0.03709951788187027, 0.04247325658798218, 0.018426815047860146, 0.04861331358551979, 0.022673944011330605, 0.05998959392309189, 0.025352949276566505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1956234872341156, 0.03233328461647034, 0.02287408895790577, 0.038390759378671646, 0.03449878841638565, 0.046169035136699677, 0.05553751066327095, 0.03960668295621872, 0.023098403587937355, 0.02424929477274418, 0.04043306037783623, 0.016078542917966843, 0.02162495255470276, 0.039030540734529495, 0.026520878076553345, 0.02811342291533947, 0.0382363460958004, 0.03542612865567207, 0.041745755821466446, 0.02109713852405548, 0.03767954558134079, 0.0372869148850441, 0.04423920810222626, 0.02292150817811489, 0.0371846966445446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0581965297460556, 0.038897402584552765, 0.026005247607827187, 0.023567883297801018, 0.022979989647865295, 0.053841497749090195, 0.058061063289642334, 0.06858772039413452, 0.03745982423424721, 0.029159117490053177, 0.05474672466516495, 0.013592935167253017, 0.027647055685520172, 0.05575402453541756, 0.030779872089624405, 0.016137350350618362, 0.05745430663228035, 0.039687298238277435, 0.03406552970409393, 0.013110971078276634, 0.059776563197374344, 0.016043761745095253, 0.0296992938965559, 0.020566528663039207, 0.08347287029027939, 0.03070860542356968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15561480820178986, 0.030323179438710213, 0.021067576482892036, 0.03860040754079819, 0.025089262053370476, 0.0471951961517334, 0.042556509375572205, 0.05166256055235863, 0.030368110164999962, 0.02013363502919674, 0.04255697503685951, 0.018511774018406868, 0.01867171935737133, 0.0414302758872509, 0.022022126242518425, 0.02106103114783764, 0.041666194796562195, 0.027249205857515335, 0.0404815711081028, 0.01553641352802515, 0.04219621419906616, 0.01700734533369541, 0.06220947578549385, 0.015703151002526283, 0.05443185567855835, 0.040924087166786194, 0.015729248523712158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1521887183189392, 0.032320473343133926, 0.02627762407064438, 0.03215135633945465, 0.037080563604831696, 0.03843332827091217, 0.0421852208673954, 0.034409213811159134, 0.02929617278277874, 0.02475227415561676, 0.03461233526468277, 0.021795077249407768, 0.023419689387083054, 0.033866435289382935, 0.028580613434314728, 0.034403249621391296, 0.03315696865320206, 0.02671039290726185, 0.04213566705584526, 0.019021358340978622, 0.0327858068048954, 0.026839980855584145, 0.033044565469026566, 0.023302629590034485, 0.03390035033226013, 0.039449259638786316, 0.02133425697684288, 0.042546432465314865, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10210391134023666, 0.04830533638596535, 0.027957912534475327, 0.02813485451042652, 0.04368894547224045, 0.037659596651792526, 0.04012181982398033, 0.03589580953121185, 0.024491775780916214, 0.019768046215176582, 0.03467409685254097, 0.01543145626783371, 0.032616570591926575, 0.03414337709546089, 0.02746138721704483, 0.020323215052485466, 0.034458424896001816, 0.015827570110559464, 0.030705854296684265, 0.020360929891467094, 0.035580456256866455, 0.0347902737557888, 0.03518150374293327, 0.028572576120495796, 0.04333386942744255, 0.03896387293934822, 0.017587702721357346, 0.045533761382102966, 0.04632510989904404, 0.0, 0.0, 0.0, 0.0], [0.1184174120426178, 0.026689790189266205, 0.02854764647781849, 0.03516456112265587, 0.03519095852971077, 0.030704857781529427, 0.04254690557718277, 0.023103507235646248, 0.025463111698627472, 0.029678557068109512, 0.028395213186740875, 0.019178256392478943, 0.02383357845246792, 0.027640020474791527, 0.033817537128925323, 0.03964013233780861, 0.027574429288506508, 0.021856164559721947, 0.03966764733195305, 0.03941831737756729, 0.027115626260638237, 0.030498048290610313, 0.03493284806609154, 0.0323205292224884, 0.027840537950396538, 0.03877580538392067, 0.021124791353940964, 0.038611434400081635, 0.032771822065114975, 0.019479986280202866, 0.0, 0.0, 0.0], [0.05433790758252144, 0.019247835502028465, 0.011686470359563828, 0.014118614606559277, 0.013909783214330673, 0.05736802518367767, 0.034546393901109695, 0.046650584787130356, 0.013026444241404533, 0.013271301984786987, 0.05952775850892067, 0.00906313955783844, 0.017364203929901123, 0.06135562062263489, 0.012634649872779846, 0.015145530924201012, 0.06425535678863525, 0.04627061262726784, 0.019556371495127678, 0.012543444521725178, 0.06913556903600693, 0.03482367470860481, 0.030005982145667076, 0.012261815369129181, 0.07985589653253555, 0.01899644173681736, 0.010722932405769825, 0.08654540032148361, 0.017174091190099716, 0.02214416302740574, 0.02245398424565792, 0.0, 0.0], [0.05849645659327507, 0.03437737002968788, 0.013603090308606625, 0.02417042851448059, 0.019005870446562767, 0.06546404957771301, 0.03062298148870468, 0.035732071846723557, 0.01885945536196232, 0.012241479009389877, 0.0628218948841095, 0.01183574739843607, 0.009552357718348503, 0.06431795656681061, 0.02158959023654461, 0.01091296412050724, 0.06665915250778198, 0.023997453972697258, 0.026596734300255775, 0.00615355372428894, 0.06984328478574753, 0.037238676100969315, 0.03004671446979046, 0.021686799824237823, 0.043640609830617905, 0.02120961807668209, 0.013490457087755203, 0.04632722958922386, 0.020434502512216568, 0.01336226798593998, 0.018568990752100945, 0.04714022949337959, 0.0], [0.1352868378162384, 0.02973336912691593, 0.02611132711172104, 0.03753575310111046, 0.0388815701007843, 0.033166784793138504, 0.048243921250104904, 0.030468309298157692, 0.02603822574019432, 0.02412371151149273, 0.02789275161921978, 0.022709941491484642, 0.0241852980107069, 0.026114553213119507, 0.023209670558571815, 0.02517528086900711, 0.02461479790508747, 0.02112315408885479, 0.02968505583703518, 0.018167467787861824, 0.02306438237428665, 0.02059805579483509, 0.034411415457725525, 0.021083395928144455, 0.02253883332014084, 0.032281555235385895, 0.013987252488732338, 0.024144919589161873, 0.027002308517694473, 0.012929446063935757, 0.03616539388895035, 0.026840241625905037, 0.03248501941561699]]], \"headLabels\": [\"L0H0\", \"L0H1\", \"L0H2\", \"L0H3\", \"L0H4\", \"L0H5\", \"L0H6\", \"L0H7\", \"L0H8\", \"L0H9\", \"L0H10\", \"L0H11\"]}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(type(gpt2_cache))\n",
        "attention_pattern = gpt2_cache[\"pattern\", 0]\n",
        "print(attention_pattern.shape)\n",
        "gpt2_str_tokens = gpt2_small.to_str_tokens(gpt2_text)\n",
        "\n",
        "print(\"Layer 0 Head Attention Patterns:\")\n",
        "display(\n",
        "    cv.attention.attention_patterns(\n",
        "        tokens=gpt2_str_tokens,\n",
        "        attention=attention_pattern,\n",
        "        attention_head_names=[f\"L0H{i}\" for i in range(12)],\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvF22eDkQGxh"
      },
      "source": [
        "Hover over heads to see the attention patterns; click on a head to lock it. Hover over each token to see which other tokens it attends to (or which other tokens attend to it - you can see this by changing the dropdown to `Destination <- Source`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYpnbhnlQGxi"
      },
      "source": [
        "<details>\n",
        "<summary>Other circuitsvis functions - neuron activations</summary>\n",
        "\n",
        "The `circuitsvis` library also has a number of cool visualisations for **neuron activations**. Here are some more of them (you don't have to understand them all now, but you can come back to them later).\n",
        "\n",
        "The function below visualises neuron activations. The example shows just one sequence, but it can also show multiple sequences (if `tokens` is a list of lists of strings, and `activations` is a list of tensors).\n",
        "\n",
        "```python\n",
        "neuron_activations_for_all_layers = t.stack([\n",
        "    gpt2_cache[\"post\", layer] for layer in range(gpt2_small.cfg.n_layers)\n",
        "], dim=1)\n",
        "# shape = (seq_pos, layers, neurons)\n",
        "\n",
        "cv.activations.text_neuron_activations(\n",
        "    tokens=gpt2_str_tokens,\n",
        "    activations=neuron_activations_for_all_layers\n",
        ")\n",
        "```\n",
        "\n",
        "The next function shows which words each of the neurons activates most / least on (note that it requires some weird indexing to work correctly).\n",
        "\n",
        "```python\n",
        "neuron_activations_for_all_layers_rearranged = utils.to_numpy(einops.rearrange(neuron_activations_for_all_layers, \"seq layers neurons -> 1 layers seq neurons\"))\n",
        "\n",
        "cv.topk_tokens.topk_tokens(\n",
        "    # Some weird indexing required here ¯\\_(ツ)_/¯\n",
        "    tokens=[gpt2_str_tokens],\n",
        "    activations=neuron_activations_for_all_layers_rearranged,\n",
        "    max_k=7,\n",
        "    first_dimension_name=\"Layer\",\n",
        "    third_dimension_name=\"Neuron\",\n",
        "    first_dimension_labels=list(range(12))\n",
        ")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzkx0tDDQGxi"
      },
      "source": [
        "# 2️⃣ Finding induction heads\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand what induction heads are, and the algorithm they are implementing\n",
        "> - Inspect activation patterns to identify basic attention head patterns, and write your own functions to detect attention heads for you\n",
        "> - Identify induction heads by looking at the attention patterns produced from a repeating random sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHHDtGsjQGxj"
      },
      "source": [
        "## Introducing Our Toy Attention-Only Model\n",
        "\n",
        "Here we introduce a toy 2L attention-only transformer trained specifically for today. Some changes to make them easier to interpret:\n",
        "- It has only attention blocks.\n",
        "- The positional embeddings are only added to the residual stream before calculating each key and query vector in the attention layers as opposed to the token embeddings - i.e. we compute queries as `Q = (resid + pos_embed) @ W_Q + b_Q` and same for keys, but values as `V = resid @ W_V + b_V`. This means that **the residual stream can't directly encode positional information**.\n",
        "    - This turns out to make it *way* easier for induction heads to form, it happens 2-3x times earlier - [see the comparison of two training runs](https://wandb.ai/mechanistic-interpretability/attn-only/reports/loss_ewma-22-08-24-11-08-83---VmlldzoyNTI0MDMz?accessToken=8ap8ir6y072uqa4f9uinotdtrwmoa8d8k2je4ec0lyasf1jcm3mtdh37ouijgdbm) here. (The bump in each curve is the formation of induction heads.)\n",
        "    - The argument that does this below is `positional_embedding_type=\"shortformer\"`.\n",
        "- It has no MLP layers, no LayerNorms, and no biases.\n",
        "- There are separate embed and unembed matrices (i.e. the weights are not tied).\n",
        "\n",
        "We now define our model with a `HookedTransformerConfig` object. This is similar to the `Config` object we used in the previous set of exercises, although it has a lot more features. You can look at the documentation page (Right-click, \"Go to Definition\" in VSCode) to seee what the different arguments do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_9yoGLfNQGxj"
      },
      "outputs": [],
      "source": [
        "cfg = HookedTransformerConfig(\n",
        "    d_model=768,\n",
        "    d_head=64,\n",
        "    n_heads=12,\n",
        "    n_layers=2,\n",
        "    n_ctx=2048,\n",
        "    d_vocab=50278,\n",
        "    attention_dir=\"causal\",\n",
        "    attn_only=True,  # defaults to False\n",
        "    tokenizer_name=\"EleutherAI/gpt-neox-20b\",\n",
        "    seed=398,\n",
        "    use_attn_result=True,\n",
        "    normalization_type=None,  # defaults to \"LN\", i.e. layernorm with weights & biases\n",
        "    positional_embedding_type=\"shortformer\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6zcfI0dQGxj"
      },
      "source": [
        "Note that in the last section we had to define a tokenizer explicitly, and passed it into our model. But here, we just pass a tokenizer name, and the model will automatically create a tokenizer for us (under the hood, it calls `AutoTokenizer.from_pretrained(tokenizer_name)`).\n",
        "\n",
        "Below, you'll load in your weights, with some boilerplate code to download your state dict from HuggingFace (you can do this for any model you've uploaded to HuggingFace yourself):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f664e47eec8b41b0ae2a14c93945bf9a",
            "bc4bbe816fc6472a849b8cae1b1151e8",
            "74beaf972a9341ae9becc7c6c06b00d1",
            "6f9844d3c95148de80fec60f35928148",
            "6bb66e06a110480db6449eab45c055c6",
            "633aa12e0ba34548a4b49117a28f7027",
            "0464cdf2b799410eb1a08bb52117792b",
            "501c2537b4614bf1ba7803f4720a4244",
            "b1935a0d49074f67b43089c490561bd4",
            "1d450b8542b74b7a883c22d9d4ecddb3",
            "d158ce376c34488bba9ecf5f302daca3"
          ]
        },
        "id": "TS9hkI1bQGxk",
        "outputId": "0231a752-b7e5-4e03-8427-f7b50f757e4c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "attn_only_2L_half.pth:   0%|          | 0.00/184M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f664e47eec8b41b0ae2a14c93945bf9a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "REPO_ID = \"callummcdougall/attn_only_2L_half\"\n",
        "FILENAME = \"attn_only_2L_half.pth\"\n",
        "\n",
        "weights_path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNi_Kla4QGxk"
      },
      "source": [
        "Finally, we'll create our model and load in the weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "89249b7c251e4c56827cd33c6aff2c2e",
            "29b5adf995d744b9975124e9a670d186",
            "4b0041ca10ab4ccd94d79f56b875cfca",
            "2653d7dd7509406797785faa25ed1631",
            "f0f9bf20533e40b999a4f7d0aaef16fb",
            "1e98e9311e6d423fb9b52dcaeede3cc2",
            "397645cfbde942e198a2f92d820640c5",
            "fe71550bf8de43f0ad581b319f741a3c",
            "0d4bdd208f8647ffb2c63bc1745a08b4",
            "6d1078b7b40248438dc3abb9e00324dd",
            "5b09a1bb20a047d2919093bdd217d203",
            "51b87bb187094498b9986dbb0b5d31e5",
            "32444aa7200645bd893c5e6e13d304b3",
            "72543015962e4a95b8e91e2c4461ff97",
            "9a1b40e2f08f4827a53f42c1fa4bcdf0",
            "5683e88ef9fd40baa382e619709faf15",
            "5de73fc84da642359b805744389b6d90",
            "0216077d09a24a4bb0a8abd3ee9127f6",
            "85834d46fa1841cb8a7bb9aba59b07d4",
            "69c80621e4724115bc4125c952d74279",
            "f4c4e38f95824cfe9b6c842a1879fbb5",
            "0e55fd8ef7574ad9a1af55457a278bab",
            "50de34c5d7ae4de190d619490be42512",
            "df2d943c66a04911bfab2355419cac17",
            "3bad63f31e414522ba2166b43392073d",
            "da8ebd42422b4040ad922b7450c78de7",
            "eba9112a84c14f62934293b2ff7978c1",
            "945a91da8b124b449a51f01d2533c200",
            "187a7574540c470086a8dc52121f6a9d",
            "83d0c0c5f2fa4c25bb783f0cc326d939",
            "723303fc94504efd9f06aa533e641eb1",
            "efe60bca2a47490eb73c2a2e79d2d002",
            "b496b881d9ff4107b32d67bc157946bc",
            "26011d39888d4dca862492ca4595de62",
            "60a0e5bd2bab41a693568b13904b53b6",
            "36dff6de227145bca4a9bea2e843d9f3",
            "1bc94989803540a79feb97a9ed976c06",
            "3193da9e981441d5904c0c8b3c7e7d15",
            "c5da7d32368543ea9a5959f167b9d895",
            "484adfa463b645ea902307aa2832cf89",
            "e45fca3153604a93a7ea955d0d46468f",
            "0dda3c1429714c848c5c345d7eeabc21",
            "7409c0db8d8f4f80ac02ffaa968efa17",
            "56ea7afa569f47499944bbc3397673b2",
            "22c22b56d541478fa4cdee721fdf0a80",
            "7579a364c10146538eb8a3a44d322b5b",
            "db26cd153b6b4957bb439a77b582c9f3",
            "d5034dab075d4a9cb9447ea953b2132f",
            "da86734aec2e4b43924cab031b2f22d3",
            "5518c7d9894d489c8bbf9c0b4008b89e",
            "d805c5d573164c22be7f312f2a382f5f",
            "a3fa600f457b442a8a033e4e25071814",
            "9f0b4081bb2a44618af4cdd259e08028",
            "668ed89f4e364d098d751336a7207bbf",
            "a9b0adaf198b4d9aafbfde630bbab8e1"
          ]
        },
        "id": "YNZ1RpXBQGxk",
        "outputId": "465adc70-65fb-4c0d-b808-ef67d393257f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89249b7c251e4c56827cd33c6aff2c2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51b87bb187094498b9986dbb0b5d31e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50de34c5d7ae4de190d619490be42512"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26011d39888d4dca862492ca4595de62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22c22b56d541478fa4cdee721fdf0a80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model = HookedTransformer(cfg)\n",
        "pretrained_weights = t.load(weights_path, map_location=device, weights_only=True)\n",
        "model.load_state_dict(pretrained_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCsI8-sUQGxk"
      },
      "source": [
        "Use the [diagram at this link](https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/small-merm.svg) to remind yourself of the relevant hook names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-Zgs511QGxl"
      },
      "source": [
        "### Exercise - visualise & inspect attention patterns\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        ">\n",
        "> It's important to be comfortable using circuitsvis, and the cache object.\n",
        "> ```\n",
        "\n",
        "*This exercise should be very quick - you can reuse code from the previous section. You should look at the solution if you're still stuck after 5-10 minutes.*\n",
        "\n",
        "Visualise the attention patterns for both layers of your model, on the following prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "x9KdK68WQGxl",
        "outputId": "860ad706-b955-4a61-a435-40ad66775d99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7e6c13ff3e10>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-295ca009-4ec5\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-295ca009-4ec5\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"<|endoftext|>\", \"We\", \" think\", \" that\", \" powerful\", \",\", \" significantly\", \" super\", \"human\", \" machine\", \" intelligence\", \" is\", \" more\", \" likely\", \" than\", \" not\", \" to\", \" be\", \" created\", \" this\", \" century\", \".\", \" If\", \" current\", \" machine\", \" learning\", \" techniques\", \" were\", \" scaled\", \" up\", \" to\", \" this\", \" level\", \",\", \" we\", \" think\", \" they\", \" would\", \" by\", \" default\", \" produce\", \" systems\", \" that\", \" are\", \" deceptive\", \" or\", \" manip\", \"ulative\", \",\", \" and\", \" that\", \" no\", \" solid\", \" plans\", \" are\", \" known\", \" for\", \" how\", \" to\", \" avoid\", \" this\", \".\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.911715030670166, 0.08828490972518921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7586267590522766, 0.1905537247657776, 0.050819505006074905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.45267751812934875, 0.02356713078916073, 0.51188063621521, 0.011874744668602943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7285254597663879, 0.12587599456310272, 0.03791874647140503, 0.06425879895687103, 0.04342092201113701, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23100148141384125, 0.20740002393722534, 0.1806115359067917, 0.02584725245833397, 0.3496801257133484, 0.005459538195282221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5995336771011353, 0.03500837832689285, 0.04405522346496582, 0.045588742941617966, 0.07754392176866531, 0.1194862499833107, 0.07878384739160538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.45623430609703064, 0.06956848502159119, 0.03143444284796715, 0.029351556673645973, 0.04350433871150017, 0.08336438983678818, 0.14937284588813782, 0.13716953992843628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5736039876937866, 0.03352554515004158, 0.014305063523352146, 0.04590103402733803, 0.02201821096241474, 0.09280773997306824, 0.049396876245737076, 0.10171309858560562, 0.06672846525907516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37267568707466125, 0.03348895162343979, 0.03849643096327782, 0.02252359315752983, 0.04794798046350479, 0.043860696256160736, 0.1772596389055252, 0.06309276074171066, 0.12463705241680145, 0.07601713389158249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.576324462890625, 0.012373088859021664, 0.013835322111845016, 0.024665752425789833, 0.027093255892395973, 0.036683090031147, 0.11631480604410172, 0.041630860418081284, 0.05044353008270264, 0.025202183052897453, 0.0754336565732956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33303117752075195, 0.04929724335670471, 0.019584568217396736, 0.1876918077468872, 0.013775168918073177, 0.20436470210552216, 0.03102118894457817, 0.012706907466053963, 0.017610730603337288, 0.013503064401447773, 0.04859960824251175, 0.06881380081176758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3963589072227478, 0.05455345660448074, 0.03737897425889969, 0.051253512501716614, 0.03155195713043213, 0.04770873486995697, 0.08573456853628159, 0.024092700332403183, 0.03386429324746132, 0.0416894368827343, 0.07806980609893799, 0.07713937014341354, 0.04060433804988861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39604416489601135, 0.016063056886196136, 0.014684741385281086, 0.022615596652030945, 0.039572589099407196, 0.04209722951054573, 0.1006195917725563, 0.019244754686951637, 0.033746425062417984, 0.03402508422732353, 0.06701559573411942, 0.06025390326976776, 0.053125523030757904, 0.10089182108640671, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3132553696632385, 0.037470363080501556, 0.0259820818901062, 0.039798345416784286, 0.027239063754677773, 0.04974314197897911, 0.02198387123644352, 0.01745515875518322, 0.02907319739460945, 0.036492783576250076, 0.04566141963005066, 0.06785815209150314, 0.061487939208745956, 0.14522701501846313, 0.08127205818891525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20642361044883728, 0.021272864192724228, 0.004047730006277561, 0.03683611750602722, 0.01605057343840599, 0.032187916338443756, 0.020205287262797356, 0.006327558774501085, 0.015434845350682735, 0.017792442813515663, 0.0289299339056015, 0.034878794103860855, 0.04064597934484482, 0.07039007544517517, 0.24768966436386108, 0.200886532664299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1521407812833786, 0.00919192936271429, 0.004513748921453953, 0.03166696056723595, 0.002445641439408064, 0.027421705424785614, 0.02151913195848465, 0.013300660066306591, 0.004710937850177288, 0.006210004910826683, 0.006869399454444647, 0.10991321504116058, 0.008775067515671253, 0.020539848133921623, 0.23338745534420013, 0.20802122354507446, 0.13937224447727203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08647950738668442, 0.007992416620254517, 0.002907593036070466, 0.04150892049074173, 0.0015596328303217888, 0.02856699377298355, 0.008329269476234913, 0.0030508008785545826, 0.0021661289501935244, 0.0015149383107200265, 0.005371870938688517, 0.03523837402462959, 0.0062901354394853115, 0.029986072331666946, 0.22317880392074585, 0.26638785004615784, 0.20146572589874268, 0.04800496622920036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2629539966583252, 0.009550852701067924, 0.007052391767501831, 0.01635989174246788, 0.006230763625353575, 0.020883634686470032, 0.015984635800123215, 0.004678795579820871, 0.0055497572757303715, 0.003985475283116102, 0.010810021311044693, 0.02518223039805889, 0.021963326260447502, 0.062266793102025986, 0.14940162003040314, 0.12864604592323303, 0.14171592891216278, 0.08605799823999405, 0.020725838840007782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1888464093208313, 0.017786148935556412, 0.018755324184894562, 0.022665588185191154, 0.00512212747707963, 0.02263793721795082, 0.015232070349156857, 0.006826380733400583, 0.003695101011544466, 0.00608748709782958, 0.010226698592305183, 0.05636347830295563, 0.009769092313945293, 0.04994489252567291, 0.17304939031600952, 0.06328552216291428, 0.1041327714920044, 0.09260356426239014, 0.0498698353767395, 0.08310022205114365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38214486837387085, 0.007263469975441694, 0.008141894824802876, 0.005458578001707792, 0.012512588873505592, 0.007048595231026411, 0.03821443021297455, 0.005482864566147327, 0.01697148010134697, 0.013889061287045479, 0.021215179935097694, 0.011355581693351269, 0.01610131748020649, 0.03020278550684452, 0.020502422004938126, 0.022151201963424683, 0.016941936686635017, 0.0530521422624588, 0.051383428275585175, 0.0797496885061264, 0.18021650612354279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11538945883512497, 0.00984716322273016, 0.028505560010671616, 0.004711788147687912, 0.017698796465992928, 0.004212573636323214, 0.042653750628232956, 0.005836242809891701, 0.02237747237086296, 0.031705256551504135, 0.022136030718684196, 0.02814832143485546, 0.01166743878275156, 0.01824467070400715, 0.0036953880917280912, 0.007935866713523865, 0.003936294466257095, 0.060416869819164276, 0.1703682690858841, 0.007349317893385887, 0.3583068251609802, 0.02485663630068302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08728720247745514, 0.007458625826984644, 0.003126033814623952, 0.006943827960640192, 0.004823082592338324, 0.01711665652692318, 0.0077100349590182304, 0.006648678332567215, 0.0030999828595668077, 0.006129730027168989, 0.0055062053725123405, 0.02925906702876091, 0.008518017828464508, 0.028879687190055847, 0.03342519700527191, 0.054244548082351685, 0.06315907090902328, 0.041417766362428665, 0.01939743012189865, 0.03188536316156387, 0.02769801951944828, 0.36842116713523865, 0.13784457743167877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15758801996707916, 0.009554026648402214, 0.005608857609331608, 0.006548126228153706, 0.005784330889582634, 0.014086030423641205, 0.01766606979072094, 0.015034150332212448, 0.006961270235478878, 0.0069831861183047295, 0.00887947529554367, 0.01354773435741663, 0.006114291027188301, 0.029761003330349922, 0.05135614052414894, 0.026400530710816383, 0.031319666653871536, 0.03081214427947998, 0.026938259601593018, 0.04443782940506935, 0.053520578891038895, 0.19637168943881989, 0.13856613636016846, 0.09616044163703918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17605793476104736, 0.009363764896988869, 0.007607475854456425, 0.004179368261247873, 0.007107473444193602, 0.006449236534535885, 0.024895330891013145, 0.008266473188996315, 0.016104765236377716, 0.010187891311943531, 0.018399763852357864, 0.014533814042806625, 0.011523955501616001, 0.022696204483509064, 0.015676047652959824, 0.021776845678687096, 0.024399403482675552, 0.03694448992609978, 0.031159818172454834, 0.06589246541261673, 0.13820277154445648, 0.05696190521121025, 0.0756443440914154, 0.12287753820419312, 0.07309095561504364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22713424265384674, 0.005752272438257933, 0.008293872699141502, 0.008422859013080597, 0.005686682648956776, 0.008340392261743546, 0.02148156613111496, 0.008186839520931244, 0.007411699276417494, 0.0038647078908979893, 0.01073922123759985, 0.025259891524910927, 0.010649065487086773, 0.026196161285042763, 0.036999065428972244, 0.04467380419373512, 0.06182258576154709, 0.06199280545115471, 0.01318033691495657, 0.03371265158057213, 0.053898099809885025, 0.038140133023262024, 0.11617377400398254, 0.08080213516950607, 0.03133572265505791, 0.04984944686293602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19434401392936707, 0.005195816047489643, 0.006905107293277979, 0.005479445680975914, 0.004751965869218111, 0.0049647619016468525, 0.01470539066940546, 0.0035068215802311897, 0.007717388682067394, 0.0031823483295738697, 0.013900748454034328, 0.018893137574195862, 0.018832892179489136, 0.027548011392354965, 0.01969580538570881, 0.02633223496377468, 0.027938472107052803, 0.04074789211153984, 0.012234198860824108, 0.09363996237516403, 0.08937045186758041, 0.020047815516591072, 0.05115436017513275, 0.06127135828137398, 0.025029508396983147, 0.04386410489678383, 0.15874600410461426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.042178377509117126, 0.0010927069233730435, 0.0007364588091149926, 0.008647679351270199, 0.0002836654894053936, 0.0041752890683710575, 0.0004922773223370314, 0.00027396800578571856, 0.00027053974918089807, 0.0001578613300807774, 0.0006033533136360347, 0.0016463559586554766, 0.0011537300888448954, 0.005080456379801035, 0.030463414266705513, 0.020955855026841164, 0.005829201079905033, 0.005168416537344456, 0.0009890272049233317, 0.017376063391566277, 0.005794863682240248, 0.09350349009037018, 0.6471176147460938, 0.005945555400103331, 0.002238089684396982, 0.013854937627911568, 0.023856978863477707, 0.0601138137280941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20671913027763367, 0.0028698286041617393, 0.002518764929845929, 0.007592111825942993, 0.0018985421629622579, 0.00918636005371809, 0.004352222662419081, 0.0028565882239490747, 0.0025609368458390236, 0.0015658932970836759, 0.004934682510793209, 0.010131696239113808, 0.005282975267618895, 0.01502868440002203, 0.04558604955673218, 0.03753494843840599, 0.04037171229720116, 0.016340794041752815, 0.00528289470821619, 0.02897266484797001, 0.017072107642889023, 0.0756334587931633, 0.14748366177082062, 0.021958889439702034, 0.010597370564937592, 0.03603691607713699, 0.05504944548010826, 0.1296401470899582, 0.05494048446416855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.216547429561615, 0.0025218725204467773, 0.003085269359871745, 0.006915247533470392, 0.002763384487479925, 0.007463088724762201, 0.008760577999055386, 0.0034327111206948757, 0.00419753510504961, 0.0027453412767499685, 0.006942041218280792, 0.01103974785655737, 0.006764461752027273, 0.011336230672895908, 0.04008046165108681, 0.03823855146765709, 0.02476523257791996, 0.019550373777747154, 0.0070084757171571255, 0.024590114131569862, 0.028455771505832672, 0.0843571126461029, 0.10425975918769836, 0.01818087510764599, 0.014997884631156921, 0.04003198444843292, 0.04581625387072563, 0.09738841652870178, 0.10043703764677048, 0.017326802015304565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0866457149386406, 0.0016765885520726442, 0.0010866925586014986, 0.007995398715138435, 0.00044537760550156236, 0.005560839548707008, 0.004875618498772383, 0.002805894473567605, 0.0009040447184816003, 0.0009796443628147244, 0.001099332352168858, 0.020190075039863586, 0.0014827229315415025, 0.0029041713569313288, 0.026868995279073715, 0.022354215383529663, 0.0163999255746603, 0.021683689206838608, 0.0037834139075130224, 0.011789149604737759, 0.023777928203344345, 0.05487016960978508, 0.10548177361488342, 0.006931937765330076, 0.00659286230802536, 0.015025898814201355, 0.009535479359328747, 0.2461860626935959, 0.08534682542085648, 0.04028777405619621, 0.16443173587322235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12249067425727844, 0.0041866060346364975, 0.0060414960607886314, 0.007522364147007465, 0.0017414481844753027, 0.005908133927732706, 0.005960255395621061, 0.0023728751111775637, 0.0014468965819105506, 0.0018981171306222677, 0.003677473869174719, 0.01737913489341736, 0.0032565637957304716, 0.01340783853083849, 0.03519350662827492, 0.011407552286982536, 0.014586529694497585, 0.014929876662790775, 0.008234656415879726, 0.015166232362389565, 0.012153019197285175, 0.026872240006923676, 0.06556759774684906, 0.006963275372982025, 0.007954198867082596, 0.025812139734625816, 0.03479905053973198, 0.13639940321445465, 0.10709931701421738, 0.035243045538663864, 0.1445426493883133, 0.09978575259447098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21824344992637634, 0.002284733112901449, 0.003727009752765298, 0.004525001626461744, 0.004835248924791813, 0.006937736179679632, 0.012990379706025124, 0.006317321211099625, 0.0073597305454313755, 0.004232000093907118, 0.00926411896944046, 0.006202250253409147, 0.006109174340963364, 0.01223920751363039, 0.016905592754483223, 0.010803235694766045, 0.008198557421565056, 0.008591515012085438, 0.006883477792143822, 0.0157622080296278, 0.017626779153943062, 0.026211325079202652, 0.022171135991811752, 0.021653329953551292, 0.012397611513733864, 0.022114921361207962, 0.04363048076629639, 0.037861693650484085, 0.07418780028820038, 0.01242502499371767, 0.06996913254261017, 0.1137634739279747, 0.15357540547847748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030602948740124702, 0.006844185758382082, 0.006438034120947123, 0.001285466947592795, 0.012234614230692387, 0.00021611560077872127, 0.02659733034670353, 0.0007970464648678899, 0.0058015319518744946, 0.006102270912379026, 0.00990968756377697, 0.004358369391411543, 0.008389094844460487, 0.008896228857338428, 0.0003970193210989237, 0.0017182364827021956, 0.0008686812943778932, 0.0031240915413945913, 0.026926511898636818, 0.0020134826190769672, 0.0770135447382927, 0.0016478733159601688, 0.008553821593523026, 0.013761782087385654, 0.021447530016303062, 0.052376873791217804, 0.1982041597366333, 0.013552768155932426, 0.11828191578388214, 0.06927429139614105, 0.008073748089373112, 0.016317633911967278, 0.23195452988147736, 0.006018525455147028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06864485889673233, 0.004128239117562771, 0.005856263916939497, 0.009820087812840939, 0.0027098737191408873, 0.008258916437625885, 0.007060769945383072, 0.0010457003954797983, 0.001311469473876059, 0.0017728179227560759, 0.003562384517863393, 0.016753798350691795, 0.002268230076879263, 0.011227959766983986, 0.03280966728925705, 0.014600232243537903, 0.005363488104194403, 0.012888728640973568, 0.004386126529425383, 0.00890160072594881, 0.0054060909897089005, 0.028603974729776382, 0.047012556344270706, 0.005505996756255627, 0.0063932836055755615, 0.01301039569079876, 0.02383248694241047, 0.1758418083190918, 0.07596112042665482, 0.009596806019544601, 0.05351162329316139, 0.07903966307640076, 0.030892278999090195, 0.16281422972679138, 0.05920644477009773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09877974539995193, 0.004930652678012848, 0.0028951498679816723, 0.012160230427980423, 0.003887985134497285, 0.01062470581382513, 0.005537114106118679, 0.0029327122028917074, 0.0017457898939028382, 0.0015680246287956834, 0.0024684988893568516, 0.014958408661186695, 0.003358330111950636, 0.006581125780940056, 0.009168061427772045, 0.012906630523502827, 0.013587715104222298, 0.011946680024266243, 0.0036190340761095285, 0.00439506396651268, 0.003527039662003517, 0.023050371557474136, 0.0416257381439209, 0.013514917343854904, 0.004686608444899321, 0.011011792346835136, 0.01391656044870615, 0.08395881950855255, 0.03588616102933884, 0.014936840161681175, 0.11237342655658722, 0.03663700819015503, 0.04551173746585846, 0.17132744193077087, 0.08818919956684113, 0.07179474830627441, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07516030222177505, 0.002341081155464053, 0.006599970627576113, 0.007894431240856647, 0.0035288373474031687, 0.005035743582993746, 0.012087472714483738, 0.0011560845887288451, 0.0013705414021387696, 0.0018592847045511007, 0.003720266744494438, 0.012669447809457779, 0.0027124949265271425, 0.010935484431684017, 0.019188454374670982, 0.01317505817860365, 0.005482432432472706, 0.009609084576368332, 0.004326950758695602, 0.005424717906862497, 0.004758406896144152, 0.015103636309504509, 0.0419766791164875, 0.005946545861661434, 0.006801343988627195, 0.017032193019986153, 0.031397730112075806, 0.13114717602729797, 0.06590112298727036, 0.00868408102542162, 0.048659540712833405, 0.043659500777721405, 0.037009403109550476, 0.08427804708480835, 0.04270791634917259, 0.16885945200920105, 0.041799113154411316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14534948766231537, 0.001988892676308751, 0.0019805021584033966, 0.009684436954557896, 0.0016289039049297571, 0.010277429595589638, 0.0022120517678558826, 0.0008637704886496067, 0.0010332055389881134, 0.0009277373901568353, 0.001937912660650909, 0.005717786028981209, 0.0022851990070194006, 0.004320652689784765, 0.02023424580693245, 0.009181492030620575, 0.002336057834327221, 0.005245349369943142, 0.002065586391836405, 0.01331975869834423, 0.005108735058456659, 0.02900487743318081, 0.04917735978960991, 0.004448334686458111, 0.002859360771253705, 0.009110466577112675, 0.012684749439358711, 0.06532074511051178, 0.02090613916516304, 0.0033783167600631714, 0.01915765553712845, 0.09801758080720901, 0.01586802303791046, 0.14676649868488312, 0.045800670981407166, 0.07841548323631287, 0.05229458585381508, 0.09908987581729889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0806637853384018, 0.0012531994143500924, 0.005770404357463121, 0.008098239079117775, 0.002086480613797903, 0.0038889285642653704, 0.003823790466412902, 0.0005984392482787371, 0.0009939391165971756, 0.0008553970837965608, 0.0018110378878191113, 0.004031293094158173, 0.0009504116605967283, 0.004214236047118902, 0.005510134622454643, 0.004769511055201292, 0.0015999632887542248, 0.007323073223233223, 0.010749069042503834, 0.005941710434854031, 0.006759198848158121, 0.005954326130449772, 0.04006092622876167, 0.00427655316889286, 0.002996714087203145, 0.01253054291009903, 0.01950656622648239, 0.040324680507183075, 0.09273061901330948, 0.013094316236674786, 0.01545737311244011, 0.05455059930682182, 0.011793985962867737, 0.07011834532022476, 0.029408903792500496, 0.1970335841178894, 0.03804982081055641, 0.11431902647018433, 0.07610084116458893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08517356216907501, 0.002637572819367051, 0.001298102200962603, 0.0018448272021487355, 0.0021107180509716272, 0.0031215313356369734, 0.0046858396381139755, 0.0025547754485160112, 0.003063380951061845, 0.002590983873233199, 0.004891936667263508, 0.005932971369475126, 0.0029349029064178467, 0.004925557877868414, 0.003636470763012767, 0.004894942045211792, 0.006336525548249483, 0.0038280540611594915, 0.002402948448434472, 0.0032117338851094246, 0.00541257718577981, 0.009499133564531803, 0.01240579318255186, 0.010964489541947842, 0.006118099670857191, 0.012900955975055695, 0.029771165922284126, 0.02211783640086651, 0.020456798374652863, 0.007778613828122616, 0.03922183811664581, 0.02691143937408924, 0.05653403699398041, 0.051354747265577316, 0.07429005205631256, 0.05637825280427933, 0.08226262032985687, 0.04657282307744026, 0.15538397431373596, 0.12158745527267456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04661743715405464, 0.0004265870666131377, 0.0009562959312461317, 0.002893696539103985, 0.0006741285906173289, 0.0019268105970695615, 0.0028601037338376045, 0.0006800193223170936, 0.0005611548549495637, 0.000536497391294688, 0.0014286567457020283, 0.004128680098801851, 0.0012240394717082381, 0.003195460420101881, 0.005989717319607735, 0.011254791170358658, 0.01329092402011156, 0.008211581036448479, 0.0011440988164395094, 0.0030292263254523277, 0.00407900707796216, 0.0070976512506604195, 0.03078334406018257, 0.003094182349741459, 0.00200275587849319, 0.00501785334199667, 0.00912241730839014, 0.0357334204018116, 0.01573541760444641, 0.0035466181579977274, 0.08533471077680588, 0.02323218807578087, 0.011408796533942223, 0.04023141786456108, 0.013290188275277615, 0.04670964553952217, 0.018496384844183922, 0.15488649904727936, 0.22387383878231049, 0.04977923631668091, 0.10551463067531586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07645215094089508, 0.000782136688940227, 0.0015878702979534864, 0.0010778539581224322, 0.0013382957549765706, 0.0011144713498651981, 0.005518519785255194, 0.0007938407943584025, 0.002680731238797307, 0.0010653708595782518, 0.005178462713956833, 0.004242521710693836, 0.003094868268817663, 0.004229356534779072, 0.0033992130775004625, 0.003726397641003132, 0.003378174966201186, 0.005436529405415058, 0.0019953427836298943, 0.008745179511606693, 0.016143105924129486, 0.0023136581294238567, 0.005289267748594284, 0.006739029660820961, 0.0034945658408105373, 0.00652019027620554, 0.032631807029247284, 0.04252639040350914, 0.02686006762087345, 0.00263421144336462, 0.01802806183695793, 0.04265592247247696, 0.035597216337919235, 0.015081724151968956, 0.027818109840154648, 0.05485926568508148, 0.050886742770671844, 0.02959141880273819, 0.06148465350270271, 0.11465679109096527, 0.1603536158800125, 0.10799695551395416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019308369606733322, 5.266430525807664e-05, 0.0021506387274712324, 6.364194268826395e-05, 0.0007047972176223993, 0.0005727147217839956, 0.002881610533222556, 0.00022246972366701812, 0.00017485645366832614, 0.001138327643275261, 0.0017031899187713861, 0.0017896814970299602, 0.0005702219204977155, 0.0030453756917268038, 0.0014430033043026924, 0.0022946130484342575, 0.0026606861501932144, 0.0021673040464520454, 0.0017630141228437424, 0.00022434419952332973, 0.0028208803851157427, 0.0042943814769387245, 0.034372929483652115, 0.0018535812851041555, 0.005927026271820068, 0.013047213666141033, 0.03924695774912834, 0.014352237805724144, 0.010372092016041279, 0.0010793855180963874, 0.01691965013742447, 0.0010453884024173021, 0.017827101051807404, 0.012011361308395863, 0.0038496535271406174, 0.11353365331888199, 0.0031148309353739023, 0.05707845464348793, 0.08150365203619003, 0.08818279206752777, 0.09126906096935272, 0.33101946115493774, 0.010346710681915283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021830730140209198, 0.00024860340636223555, 0.0001736409030854702, 0.0021242217626422644, 0.0001071559454430826, 0.0014140006387606263, 0.00021883715817239136, 7.938480121083558e-05, 7.649710460100323e-05, 5.22532282047905e-05, 0.00016858286107890308, 0.000488396268337965, 0.00027551501989364624, 0.0008998261764645576, 0.005609557963907719, 0.00277383322827518, 0.001113965641707182, 0.0011900949757546186, 0.00036137105780653656, 0.005013785324990749, 0.001582105178385973, 0.010203033685684204, 0.044801440089941025, 0.0006838684203103185, 0.00031368565396405756, 0.001528948894701898, 0.003335043787956238, 0.012562352232635021, 0.0042130970396101475, 0.0007036206661723554, 0.007488186005502939, 0.02332148142158985, 0.0022137672640383244, 0.032228145748376846, 0.008552959188818932, 0.012992484495043755, 0.013195916078984737, 0.02921600453555584, 0.055183444172143936, 0.014771227724850178, 0.032461561262607574, 0.013628087937831879, 0.5618531703948975, 0.0687461644411087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11321716755628586, 0.0005039677489548922, 0.0006362983258441091, 0.0014595144893974066, 0.0011325690429657698, 0.001782523817382753, 0.003580327145755291, 0.0008588655618950725, 0.0009641789365559816, 0.0006049314979463816, 0.0014976552920415998, 0.0026767936069518328, 0.0017817250918596983, 0.0024069612845778465, 0.006140104960650206, 0.004576134495437145, 0.006105531472712755, 0.005427555646747351, 0.001633721636608243, 0.005704778246581554, 0.007156056817620993, 0.013273293152451515, 0.014164709486067295, 0.00341107533313334, 0.002130041364580393, 0.004138903226703405, 0.008362632244825363, 0.016997497528791428, 0.00806085392832756, 0.0015835025114938617, 0.027693284675478935, 0.01476852037012577, 0.01011552382260561, 0.017681589350104332, 0.00859412457793951, 0.015915067866444588, 0.01394263282418251, 0.024053679779171944, 0.13616496324539185, 0.035544101148843765, 0.06783775240182877, 0.05286762863397598, 0.11693795770406723, 0.12218314409255981, 0.09373009204864502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009232274256646633, 9.454303653910756e-05, 0.00022156811610329896, 0.00014103107969276607, 0.0003037426504306495, 0.00016323798627126962, 0.0005375314503908157, 0.00015507385251112282, 0.0003329394094180316, 0.00022264925064519048, 0.00020470685558393598, 7.372433901764452e-05, 0.00016848428640514612, 0.0004611072945408523, 0.0001432626595487818, 0.00016489147674292326, 0.00010702651343308389, 0.00023753521963953972, 0.0033758904319256544, 0.00020126043818891048, 0.006275267340242863, 0.0014913768973201513, 0.005046841222792864, 0.005563822109252214, 0.001521096215583384, 0.016209669411182404, 0.003844828112050891, 0.0008298087050206959, 0.023297710344195366, 0.011450132355093956, 0.000961668265517801, 0.0009971369290724397, 0.006937799509614706, 0.005280366167426109, 0.0022404666524380445, 0.016017979010939598, 0.000993118854239583, 0.0021430079359561205, 0.003287689993157983, 0.03930890932679176, 0.10259442776441574, 0.02296273224055767, 0.04796655476093292, 0.011747806333005428, 0.6339104771614075, 0.010576803237199783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02952934429049492, 0.0003614058659877628, 0.0004064352542627603, 0.000482574658235535, 0.0005114411469548941, 0.0004679772537201643, 0.0017806671094149351, 0.0006882547168061137, 0.000936407595872879, 0.0004014688020106405, 0.0012166185770183802, 0.0007558473153039813, 0.0008363116648979485, 0.001135213184170425, 0.001371885184198618, 0.0017974884249269962, 0.003114299848675728, 0.0019627243746072054, 0.0013160003582015634, 0.006115404888987541, 0.005670709535479546, 0.0030306957196444273, 0.00590647105127573, 0.0033566616475582123, 0.0017393019516021013, 0.004329851362854242, 0.007338289637118578, 0.004682355560362339, 0.006626969203352928, 0.0019099069759249687, 0.01592862606048584, 0.017672354355454445, 0.012532801367342472, 0.007067799102514982, 0.00729305949062109, 0.011906540021300316, 0.010362640954554081, 0.008739310316741467, 0.0331987701356411, 0.025383522734045982, 0.056023355573415756, 0.038068678230047226, 0.05824907124042511, 0.056584764271974564, 0.22481361031532288, 0.1352325826883316, 0.18116356432437897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06995043158531189, 0.0005032544140703976, 0.00027259759372100234, 0.0007659295224584639, 0.0004848333483096212, 0.001150525757111609, 0.0011885800631716847, 0.0008271032711490989, 0.000647148524876684, 0.000381084275431931, 0.0006620701751671731, 0.0008719662437215447, 0.0004671792557928711, 0.0009520499734207988, 0.001745167886838317, 0.002493128180503845, 0.0030239555053412914, 0.0023419500794261694, 0.0010443506762385368, 0.0023851001169532537, 0.0054557486437261105, 0.014413283206522465, 0.011737914755940437, 0.005756426602602005, 0.0019948449917137623, 0.004921559244394302, 0.0044508399441838264, 0.006327113602310419, 0.005828682333230972, 0.0011569602647796273, 0.010918695479631424, 0.006522189360111952, 0.00783404242247343, 0.01478535495698452, 0.008139243349432945, 0.008461237885057926, 0.00892480555921793, 0.008079207502305508, 0.05498525872826576, 0.020024416968226433, 0.045950405299663544, 0.01698465086519718, 0.06633765995502472, 0.0374576598405838, 0.13610000908374786, 0.12597094476222992, 0.12671798467636108, 0.14160437881946564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010885187424719334, 0.0008781618671491742, 0.0008644746849313378, 0.00014318792091216892, 0.001921683200635016, 3.2899912184802815e-05, 0.004653319716453552, 0.00012026097101625055, 0.0010465362574905157, 0.0010651133488863707, 0.001794692361727357, 0.0005752100259996951, 0.00111029960680753, 0.0012381999986246228, 9.271394810639322e-05, 0.0004330474475864321, 0.00027721698279492557, 0.0012206134852021933, 0.008839144371449947, 0.0007770353695377707, 0.0304496418684721, 0.0005800167564302683, 0.0034875927958637476, 0.005164916627109051, 0.008258198387920856, 0.014052466489374638, 0.04814450442790985, 0.002345942659303546, 0.015241955406963825, 0.006543335504829884, 0.0008598865824751556, 0.0017451995518058538, 0.023132039234042168, 0.0007687359466217458, 0.03285897895693779, 0.03661830350756645, 0.020087575539946556, 0.008796097710728645, 0.0034315516240894794, 0.08192968368530273, 0.08710023015737534, 0.120961993932724, 0.018364857882261276, 0.027412114664912224, 0.15205101668834686, 0.013846601359546185, 0.07170794159173965, 0.11678943037986755, 0.009300158359110355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006732376292347908, 0.0001116560451919213, 0.00031455326825380325, 0.00010916798055404797, 0.0006795446388423443, 0.00022137835912872106, 0.0005953845102339983, 5.237827281234786e-05, 0.00016507328837178648, 0.00020784835214726627, 0.000293566903565079, 0.00013738276902586222, 0.0001253303635166958, 0.00029489246662706137, 6.63252139929682e-05, 0.00025100866332650185, 5.009575033909641e-05, 0.0007075532921589911, 0.007564665749669075, 0.00020205692271701992, 0.008214657194912434, 0.0018483990570530295, 0.0041449605487287045, 0.007773164659738541, 0.002597538521513343, 0.020568737760186195, 0.009130612947046757, 0.002566336188465357, 0.02200789377093315, 0.008061242289841175, 0.000206578872166574, 0.000433633744250983, 0.004580288659781218, 0.005882474593818188, 0.003960697446018457, 0.017844900488853455, 0.0011043528793379664, 0.0019905194640159607, 0.0011303089559078217, 0.032769594341516495, 0.10391367971897125, 0.024056674912571907, 0.024601856246590614, 0.011921063996851444, 0.3428773880004883, 0.007494353223592043, 0.04206022247672081, 0.1333678960800171, 0.1300783008337021, 0.003929440397769213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.017271023243665695, 6.503049371531233e-05, 0.0019271287601441145, 5.901283657294698e-05, 0.0005330035928636789, 0.0005196956917643547, 0.0019270736956968904, 0.00019451917614787817, 0.00011404327960917726, 0.0007504901732318103, 0.0007594968192279339, 0.0009864302119240165, 0.00039450376061722636, 0.0024382248520851135, 0.0012315453495830297, 0.002067921683192253, 0.002721172757446766, 0.002549702301621437, 0.002653413452208042, 0.0003626701363828033, 0.004308697767555714, 0.007291214540600777, 0.05745265260338783, 0.0030638445168733597, 0.007844331674277782, 0.014077913947403431, 0.03023216873407364, 0.009738930501043797, 0.004599647596478462, 0.00047239026753231883, 0.007137286476790905, 0.0004755421250592917, 0.009486719034612179, 0.0065393876284360886, 0.002011561533436179, 0.051358867436647415, 0.001332174288108945, 0.02109227515757084, 0.029120195657014847, 0.0303500909358263, 0.02956625074148178, 0.11214791983366013, 0.00501979747787118, 0.03598660230636597, 0.07905671745538712, 0.04471324011683464, 0.02283593825995922, 0.10247807204723358, 0.10117902606725693, 0.11118023842573166, 0.01832418702542782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03010854683816433, 0.00043287264998070896, 0.0002509859041310847, 0.0007506766123697162, 0.00028534457669593394, 0.0007479768246412277, 0.0005552785587497056, 0.00020145544840488583, 0.00019394021364860237, 0.00023160039563663304, 0.0002572154044173658, 0.0007884824881330132, 0.0004971455200575292, 0.0013164536794647574, 0.00370076484978199, 0.0020909758750349283, 0.0016822931356728077, 0.0026705656200647354, 0.0013493442675098777, 0.0034487221855670214, 0.002408144995570183, 0.019007757306098938, 0.023338349536061287, 0.003364507807418704, 0.0024206594098359346, 0.005163649562746286, 0.003873049281537533, 0.006731207948178053, 0.006255797576159239, 0.0007836876320652664, 0.005536951124668121, 0.004375504795461893, 0.003147955983877182, 0.010316623374819756, 0.005354542285203934, 0.008784552104771137, 0.00667924527078867, 0.018490558490157127, 0.04228416085243225, 0.01149181742221117, 0.01853197254240513, 0.014210582710802555, 0.061108846217393875, 0.023384511470794678, 0.034014176577329636, 0.03639036789536476, 0.02949436381459236, 0.0419095940887928, 0.11360576748847961, 0.10679259151220322, 0.2650631368160248, 0.014124746434390545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.060919709503650665, 0.00039216456934809685, 0.0003859229909721762, 0.0002935113152489066, 0.00043421369628049433, 0.0007292246446013451, 0.0011713566491380334, 0.0007107537821866572, 0.000922860752325505, 0.0008948478498496115, 0.0007361014140769839, 0.0006036180420778692, 0.0005299387266859412, 0.0009407153120264411, 0.0014550976920872927, 0.0013775366824120283, 0.001331457868218422, 0.0023503378033638, 0.0023971591144800186, 0.00324026751331985, 0.00786535069346428, 0.008383452892303467, 0.005569839850068092, 0.008689896203577518, 0.008699207566678524, 0.0076959142461419106, 0.00719273928552866, 0.004668134730309248, 0.00684541929513216, 0.0009601094061508775, 0.0032924290280789137, 0.003804323961958289, 0.008110853843390942, 0.007528112735599279, 0.003069002879783511, 0.0070946370251476765, 0.005224855616688728, 0.004507976584136486, 0.015204914845526218, 0.024387631565332413, 0.018518881872296333, 0.03400089219212532, 0.01519428938627243, 0.015866223722696304, 0.04899253323674202, 0.02933848462998867, 0.08842235803604126, 0.12804853916168213, 0.09364881366491318, 0.08213203400373459, 0.06003466248512268, 0.023539908230304718, 0.13165083527565002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030743282288312912, 0.00024352058244403452, 0.0001965188275789842, 0.0003399289562366903, 0.0001661518181208521, 0.0002898115199059248, 0.0005137406988069415, 0.00014693055709358305, 0.0002192767133237794, 0.00010287903569405898, 0.0003581791534088552, 0.0008863759576343, 0.0008138475241139531, 0.0012126881629228592, 0.0015917805721983314, 0.002641902770847082, 0.002032325603067875, 0.003001953475177288, 0.0005344254313968122, 0.005979761481285095, 0.0037243622355163097, 0.0036956185940653086, 0.006149160675704479, 0.0028129855636507273, 0.0012940121814608574, 0.001958345528692007, 0.006467864848673344, 0.021230705082416534, 0.005306005943566561, 0.0003558231401257217, 0.009941553696990013, 0.012819411233067513, 0.004332378972321749, 0.00633650179952383, 0.0038144101854413748, 0.006368361413478851, 0.008203171193599701, 0.01415680069476366, 0.01759175956249237, 0.012317412532866001, 0.016049254685640335, 0.012461085803806782, 0.031720660626888275, 0.05477139353752136, 0.04002413526177406, 0.0590241476893425, 0.025175277143716812, 0.06104337051510811, 0.06416109204292297, 0.13194739818572998, 0.12533429265022278, 0.03900736942887306, 0.06223197281360626, 0.07615657150745392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0048988922499120235, 0.00013888912508264184, 6.16886536590755e-05, 0.0006643429514952004, 2.8894064598716795e-05, 0.00034326183958910406, 4.274768434697762e-05, 2.091122769343201e-05, 2.023066372203175e-05, 1.4576437024516053e-05, 4.235232700011693e-05, 0.00016733011580072343, 0.00014197533892001957, 0.0005844830302521586, 0.003535960568115115, 0.002018851460888982, 0.0006547291413880885, 0.0007906418759375811, 0.00021020649001002312, 0.0027088511269539595, 0.0008199067087844014, 0.00794790405780077, 0.03976021707057953, 0.0005481323460116982, 0.0002411880122963339, 0.0009328412706963718, 0.0016648768214508891, 0.006232143379747868, 0.0016137524507939816, 0.00020663495524786413, 0.002701150719076395, 0.0073424470610916615, 0.0006280821398831904, 0.01013354305177927, 0.001925304881297052, 0.002762020332738757, 0.0029501121025532484, 0.007026767358183861, 0.010379661805927753, 0.0026727996300905943, 0.0042128353379666805, 0.0018736966885626316, 0.08592008054256439, 0.011690296232700348, 0.012094927951693535, 0.04196985438466072, 0.005343430209904909, 0.007493435405194759, 0.09288421273231506, 0.09720508009195328, 0.38099563121795654, 0.010388465598225594, 0.006911537144333124, 0.037675753235816956, 0.07776139676570892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03406171500682831, 0.0002791550359688699, 0.00026197716942988336, 0.00044945988338440657, 0.000235167404753156, 0.0004888267139904201, 0.00047847218229435384, 0.000124471727758646, 0.00018911772349383682, 0.00013336673146113753, 0.0002734478039201349, 0.0009273833711631596, 0.0010136475320905447, 0.001955650048330426, 0.00518493028357625, 0.0036851083859801292, 0.0032691904343664646, 0.00386685854755342, 0.0009712778264656663, 0.00245372555218637, 0.004269842524081469, 0.008690265007317066, 0.019559895619750023, 0.003005340928211808, 0.0016323667950928211, 0.002781190909445286, 0.0037980021443217993, 0.011300234124064445, 0.00449584424495697, 0.0003839351993519813, 0.01026452798396349, 0.005301184486597776, 0.002751902909949422, 0.009263849817216396, 0.002352985320612788, 0.005981379188597202, 0.003046357538551092, 0.008392617106437683, 0.03713595122098923, 0.00981594156473875, 0.011384529992938042, 0.006219982169568539, 0.02046220749616623, 0.01969181001186371, 0.020730052143335342, 0.03523191064596176, 0.010297363623976707, 0.05298725515604019, 0.05286148190498352, 0.08172278106212616, 0.08112328499555588, 0.01629791595041752, 0.05701702460646629, 0.06967830657958984, 0.1278185099363327, 0.12194898724555969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008628574199974537, 0.00023206656624097377, 8.08901822892949e-05, 0.0010687407338991761, 2.5858938897727057e-05, 0.0005439039668999612, 6.893691897857934e-05, 9.36145952437073e-05, 2.53695689025335e-05, 2.3770036932546645e-05, 3.178326733177528e-05, 0.0013881976483389735, 0.00015152922424022108, 0.00035617913817986846, 0.002485577017068863, 0.003031483618542552, 0.0030413263011723757, 0.0026902828831225634, 0.0001939857902470976, 0.0015677728224545717, 0.000295757781714201, 0.005335475318133831, 0.01281946524977684, 0.0005704398499801755, 0.0002542503352742642, 0.0003469123912509531, 0.0003345540026202798, 0.010372000746428967, 0.0014769481495022774, 0.000335908931447193, 0.010308356024324894, 0.004357724450528622, 0.000575946643948555, 0.010344133712351322, 0.0012423695297911763, 0.001642956747673452, 0.0016563923563808203, 0.013248555362224579, 0.01768512651324272, 0.0016260488191619515, 0.0036079464480280876, 0.0006868361379019916, 0.04532194137573242, 0.019148478284478188, 0.0033346640411764383, 0.03468634933233261, 0.006431283429265022, 0.010400854051113129, 0.06392945349216461, 0.06548423320055008, 0.17069904506206512, 0.00354380183853209, 0.007141615729779005, 0.00914042629301548, 0.16347406804561615, 0.023318514227867126, 0.2490912675857544, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016153566539287567, 0.0004021422064397484, 0.000246586772846058, 0.00039211916737258434, 0.00018189277034252882, 0.00039071639184840024, 0.0005752493743784726, 9.152058919426054e-05, 9.60329343797639e-05, 0.00012264140241313726, 0.0002302330976817757, 0.001438319100998342, 0.00031989553826861084, 0.0010187872685492039, 0.0015366397565230727, 0.0019254471408203244, 0.002684464678168297, 0.0022728785406798124, 0.0008004519040696323, 0.0008759743650443852, 0.0012959637679159641, 0.007869317196309566, 0.01133735105395317, 0.0012400822015479207, 0.001319501781836152, 0.002767141442745924, 0.0036764261312782764, 0.009341240860521793, 0.0035532661713659763, 0.00048329372657462955, 0.008969875052571297, 0.002273108111694455, 0.0037790287751704454, 0.007406194228678942, 0.0041168914176523685, 0.004985773470252752, 0.0030146976932883263, 0.008566251024603844, 0.01619226671755314, 0.00480499304831028, 0.010929685086011887, 0.0058549498207867146, 0.010936463251709938, 0.013803365640342236, 0.012050042860209942, 0.016321254894137383, 0.0062164985574781895, 0.019415196031332016, 0.03135434165596962, 0.03323917090892792, 0.044482532888650894, 0.008716248907148838, 0.018590638414025307, 0.059227801859378815, 0.11304578930139542, 0.09565772861242294, 0.24990805983543396, 0.11150193214416504, 0.0, 0.0, 0.0, 0.0], [0.006278130691498518, 0.0001543619582662359, 7.79202237026766e-05, 0.0005160702276043594, 2.6819430786417797e-05, 0.0002867778530344367, 0.0001801592588890344, 9.690524166217074e-05, 2.7968497306574136e-05, 3.304142228444107e-05, 2.826516720233485e-05, 0.0005949745536781847, 5.436337232822552e-05, 0.00011272111441940069, 0.0012499677250161767, 0.001144079607911408, 0.0007359753362834454, 0.0012076919665560126, 0.00023368744587060064, 0.0005954155931249261, 0.0009510694653727114, 0.0025261433329433203, 0.005666487850248814, 0.00039810946327634156, 0.00041349840466864407, 0.0006085932836867869, 0.0003132710116915405, 0.00602399418130517, 0.0013407920487225056, 0.0005851986934430897, 0.002751467516645789, 0.0015333981718868017, 0.0010374551638960838, 0.005661388393491507, 0.000981137971393764, 0.0016814492410048842, 0.0006805094890296459, 0.0020702918991446495, 0.007359153125435114, 0.001541171339340508, 0.0022502357605844736, 0.0004793816478922963, 0.015700649470090866, 0.009454496204853058, 0.003965394571423531, 0.013713194988667965, 0.0034235219936817884, 0.006578715518116951, 0.032385990023612976, 0.030150175094604492, 0.08218380808830261, 0.005803714506328106, 0.017297664657235146, 0.009115481749176979, 0.09831172227859497, 0.031372666358947754, 0.27828314900398254, 0.19111260771751404, 0.11065760254859924, 0.0, 0.0, 0.0], [0.013316591270267963, 0.00031249341554939747, 0.00015127546794246882, 0.00145147112198174, 8.981907012639567e-05, 0.00043376730172894895, 0.00017704861238598824, 0.00010736902913777158, 4.8325047828257084e-05, 4.47078600700479e-05, 6.200344796525314e-05, 0.0006730035529471934, 0.00019114950555376709, 0.00039492285577580333, 0.0015261549269780517, 0.0023305006325244904, 0.0020735186990350485, 0.001998892053961754, 0.00023725118080619723, 0.0015921107260510325, 0.000423832650994882, 0.0025543004740029573, 0.006690943613648415, 0.0006707071443088353, 0.0004636898229364306, 0.0006993018905632198, 0.000607309746555984, 0.0064599099569022655, 0.0016444107750430703, 0.000308566028252244, 0.00785495713353157, 0.003991121891885996, 0.0007929987623356283, 0.006883804686367512, 0.002027760725468397, 0.0026984645519405603, 0.0023960047401487827, 0.016279809176921844, 0.014527514576911926, 0.0018537557916715741, 0.003002369776368141, 0.0008231300162151456, 0.024074764922261238, 0.008524617180228233, 0.0031836917623877525, 0.0144401416182518, 0.004719048272818327, 0.006330228876322508, 0.023246727883815765, 0.0317913182079792, 0.11369495838880539, 0.004065956454724073, 0.00832656491547823, 0.009734034538269043, 0.07312892377376556, 0.02171534299850464, 0.14243750274181366, 0.08462197333574295, 0.24511747062206268, 0.06997959315776825, 0.0, 0.0], [0.010528289712965488, 0.00037980033084750175, 0.0005506193265318871, 0.0005607525818049908, 0.0001016763417283073, 0.00034819814027287066, 0.00024170074902940542, 0.00010227852908428758, 5.683273047907278e-05, 8.40440479805693e-05, 0.00013424157805275172, 0.00077499367762357, 0.0001529195433249697, 0.0006704986444674432, 0.0016317734261974692, 0.0006615975289605558, 0.0007492965087294579, 0.0007669302867725492, 0.00043435118277557194, 0.0006939009763300419, 0.0004938431666232646, 0.0009582574712112546, 0.0031987596303224564, 0.00043466323404572904, 0.0005568718770518899, 0.0014355827588588, 0.0016573057509958744, 0.005336902569979429, 0.0021627559326589108, 0.0006322027184069157, 0.002721918746829033, 0.001956154126673937, 0.0009990386897698045, 0.00400032801553607, 0.0029190953355282545, 0.008057248778641224, 0.0024373759515583515, 0.004227451980113983, 0.016248762607574463, 0.0026167964097112417, 0.005188777577131987, 0.0020125946030020714, 0.008081802166998386, 0.00672124233096838, 0.005564559251070023, 0.008767799474298954, 0.0031580456998199224, 0.005180622451007366, 0.012555963359773159, 0.018783407285809517, 0.02591870166361332, 0.0016317624831572175, 0.0070224953815341, 0.01822519302368164, 0.05232982710003853, 0.04309384897351265, 0.19310642778873444, 0.22627876698970795, 0.07211221754550934, 0.1354614496231079, 0.06612852215766907, 0.0], [0.02012799307703972, 0.0007763780886307359, 0.003086308017373085, 0.0004464056983124465, 0.0013612806797027588, 0.0002319967607036233, 0.0024010760243982077, 0.0002689790562726557, 0.0012039203429594636, 0.001514637260697782, 0.0012098074657842517, 0.0015229759737849236, 0.0006705703563056886, 0.0008577927947044373, 0.00015773650375194848, 0.00033824806450866163, 0.0001076312837540172, 0.001710972166620195, 0.004556654486805201, 0.0001775332202669233, 0.008213168010115623, 0.0005010403692722321, 0.0022639683447778225, 0.0037343797739595175, 0.00842569675296545, 0.005878419615328312, 0.02433820255100727, 0.005577642936259508, 0.01791756972670555, 0.004827611148357391, 0.0004031555145047605, 0.0004668041074182838, 0.008638747967779636, 0.0024270080029964447, 0.011311531998217106, 0.03164820745587349, 0.017115190625190735, 0.004648583009839058, 0.001365027274005115, 0.040150776505470276, 0.012669113464653492, 0.0270103570073843, 0.003379593137651682, 0.004780960734933615, 0.0033947236370295286, 0.0015225352253764868, 0.005077104549854994, 0.010767020285129547, 0.0048566157929599285, 0.0024253176525235176, 0.009792350232601166, 0.06370354443788528, 0.010726762004196644, 0.14562930166721344, 0.02503286860883236, 0.0705365315079689, 0.013153782114386559, 0.12172118574380875, 0.006824889685958624, 0.1781042069196701, 0.008621242828667164, 0.027688372880220413]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9507848024368286, 0.04921519383788109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8253860473632812, 0.11625620722770691, 0.05835782736539841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7130882740020752, 0.1435311883687973, 0.07766081392765045, 0.06571970134973526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7373332381248474, 0.09197795391082764, 0.06147481128573418, 0.045911479741334915, 0.06330247223377228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6348984837532043, 0.026265038177371025, 0.07419194281101227, 0.10832624137401581, 0.025537677109241486, 0.13078071177005768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4449959397315979, 0.12301786988973618, 0.1002483069896698, 0.08696195483207703, 0.11523083597421646, 0.05067902430891991, 0.07886600494384766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6408796906471252, 0.05841835215687752, 0.02383996546268463, 0.02175375260412693, 0.05597667023539543, 0.03971228748559952, 0.05293777957558632, 0.10648157447576523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6170547008514404, 0.042758576571941376, 0.023711375892162323, 0.01437905803322792, 0.02773732878267765, 0.03535905480384827, 0.05396566167473793, 0.14108899235725403, 0.043945252895355225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5905019640922546, 0.07982834428548813, 0.05129684880375862, 0.045745089650154114, 0.03145846351981163, 0.05054415762424469, 0.06739436089992523, 0.027319887652993202, 0.011440482921898365, 0.04447033256292343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5453328490257263, 0.0699911117553711, 0.030395489186048508, 0.026853667572140694, 0.038123611360788345, 0.04408705234527588, 0.059596218168735504, 0.027538632974028587, 0.016968389973044395, 0.07225584983825684, 0.0688571184873581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4641231894493103, 0.08181463181972504, 0.11783846467733383, 0.0942227691411972, 0.03679685667157173, 0.020510617643594742, 0.06593655794858932, 0.01462290994822979, 0.008178463205695152, 0.019398996606469154, 0.03409721702337265, 0.04245932400226593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49445003271102905, 0.04163888841867447, 0.01786048151552677, 0.01866147853434086, 0.03984879329800606, 0.01001692097634077, 0.07093874365091324, 0.026560772210359573, 0.0137861967086792, 0.09657979011535645, 0.059383392333984375, 0.06595253944396973, 0.04432191699743271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49404147267341614, 0.056259870529174805, 0.03094601258635521, 0.028298361226916313, 0.026828913018107414, 0.016907667741179466, 0.03656737133860588, 0.02033071033656597, 0.012362862005829811, 0.044710781425237656, 0.03759600222110748, 0.08526800572872162, 0.01669475995004177, 0.09318722784519196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49575161933898926, 0.028285449370741844, 0.02327943779528141, 0.02746102772653103, 0.02090129256248474, 0.01652824506163597, 0.025175755843520164, 0.031220953911542892, 0.02497600018978119, 0.041769009083509445, 0.05609873682260513, 0.03599484637379646, 0.02953142486512661, 0.061594314873218536, 0.08143191039562225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30587923526763916, 0.0459950715303421, 0.043365444988012314, 0.05721193552017212, 0.019570734351873398, 0.009910741820931435, 0.03293938562273979, 0.014868083409965038, 0.00643053837120533, 0.015735112130641937, 0.029859542846679688, 0.05618481710553169, 0.01886737532913685, 0.1675570160150528, 0.08005938678979874, 0.095565564930439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4614524245262146, 0.010533899068832397, 0.01651586964726448, 0.011949307285249233, 0.017032373696565628, 0.009341244585812092, 0.024768609553575516, 0.018259797245264053, 0.010727708227932453, 0.033238042145967484, 0.056810442358255386, 0.03467854484915733, 0.015813738107681274, 0.10864794254302979, 0.05827602744102478, 0.06426914781332016, 0.047684818506240845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14033254981040955, 0.009064720012247562, 0.0343872494995594, 0.012739589437842369, 0.018473785370588303, 0.0031071635894477367, 0.013254620134830475, 0.01378442533314228, 0.0031097426544874907, 0.009245418943464756, 0.023284535855054855, 0.021664468571543694, 0.0062688966281712055, 0.4351518154144287, 0.035733453929424286, 0.06388769298791885, 0.13816282153129578, 0.018347054719924927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4196637272834778, 0.033093880861997604, 0.017530277371406555, 0.01294742152094841, 0.01541176252067089, 0.019787508994340897, 0.021864397451281548, 0.011675388552248478, 0.0050476654432713985, 0.02169097773730755, 0.025399718433618546, 0.023925676941871643, 0.015358604490756989, 0.04242078587412834, 0.03927305340766907, 0.05130155012011528, 0.032234445214271545, 0.030271699652075768, 0.1611015349626541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31659120321273804, 0.029168585315346718, 0.009115557186305523, 0.007782870903611183, 0.010859092697501183, 0.007592401001602411, 0.02198927477002144, 0.013511678203940392, 0.0061140963807702065, 0.03156207874417305, 0.024546392261981964, 0.03407454863190651, 0.016527263447642326, 0.0340418703854084, 0.029096294194459915, 0.05052059516310692, 0.008671893738210201, 0.06499431282281876, 0.14716534316539764, 0.1360747367143631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3676280677318573, 0.04198157787322998, 0.009963181801140308, 0.008036897517740726, 0.00905166007578373, 0.010576107539236546, 0.021969277411699295, 0.003404289484024048, 0.0016113162273541093, 0.013040969148278236, 0.011943715624511242, 0.03639070317149162, 0.008059333078563213, 0.0216619111597538, 0.022638682276010513, 0.05729353800415993, 0.0037831738591194153, 0.06161525100469589, 0.11807714402675629, 0.08533342182636261, 0.08593973517417908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2956782281398773, 0.007869427092373371, 0.0017699601594358683, 0.007118838373571634, 0.0009686860721558332, 0.004663348663598299, 0.005260568577796221, 0.0016217287629842758, 0.0011571882059797645, 0.0017591549549251795, 0.0030998012516647577, 0.042521074414253235, 0.008157594129443169, 0.004252235405147076, 0.025584828108549118, 0.03159163147211075, 0.017299462109804153, 0.04692934453487396, 0.02274821698665619, 0.1200905442237854, 0.01946697197854519, 0.3303912580013275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15079818665981293, 0.007394575048238039, 0.002088217530399561, 0.0020593865774571896, 0.002487403806298971, 0.002987020183354616, 0.0041235266253352165, 0.00382738234475255, 0.002889354480430484, 0.0058800275437533855, 0.004844211041927338, 0.009254703298211098, 0.004027226008474827, 0.00475612748414278, 0.01031524408608675, 0.014445683918893337, 0.018886543810367584, 0.017585670575499535, 0.032492656260728836, 0.04739910736680031, 0.04558953270316124, 0.37352821230888367, 0.23233993351459503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11895493417978287, 0.007065926678478718, 0.002462315373122692, 0.001940009999088943, 0.0034216914791613817, 0.003249150002375245, 0.005628469865769148, 0.004121907986700535, 0.0017049146117642522, 0.007482248358428478, 0.005866093561053276, 0.005036463029682636, 0.0036618304438889027, 0.006692373659461737, 0.006843719631433487, 0.01128788385540247, 0.00323475175537169, 0.011721747927367687, 0.04231521859765053, 0.03666860982775688, 0.05338870361447334, 0.4291132688522339, 0.16608478128910065, 0.06205306202173233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1293080896139145, 0.007517507765442133, 0.004074631724506617, 0.003072272054851055, 0.0023324782960116863, 0.0036216271109879017, 0.004990477114915848, 0.0017231878591701388, 0.000690532149747014, 0.002946465741842985, 0.00383196584880352, 0.00698902877047658, 0.0013627444859594107, 0.005977155175060034, 0.0064272331073880196, 0.012016484513878822, 0.002319375751540065, 0.010235429741442204, 0.030783386901021004, 0.02644497901201248, 0.025523366406559944, 0.43709999322891235, 0.2032880187034607, 0.034208379685878754, 0.03321514278650284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1486750692129135, 0.011767015792429447, 0.002427652245387435, 0.0021869810298085213, 0.0033012067433446646, 0.0046805511228740215, 0.00501583656296134, 0.0026063716504722834, 0.0011123487493023276, 0.005132531281560659, 0.0041526551358401775, 0.005836912430822849, 0.003851100569590926, 0.004752586130052805, 0.005937997251749039, 0.01187813002616167, 0.0022888348903506994, 0.012333433143794537, 0.030128533020615578, 0.03243668004870415, 0.03175543621182442, 0.3750951290130615, 0.12494147568941116, 0.049011800438165665, 0.047095004469156265, 0.07159870862960815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11110895127058029, 0.016045093536376953, 0.0031673735938966274, 0.0024529846850782633, 0.002544017508625984, 0.0041451300494372845, 0.004705377854406834, 0.0010122586973011494, 0.0005364516982808709, 0.0024681342765688896, 0.002069692360237241, 0.00686207739636302, 0.001974098850041628, 0.0040881698951125145, 0.004670408554375172, 0.01285045500844717, 0.0018206379609182477, 0.010412104427814484, 0.01590484194457531, 0.018033446744084358, 0.020836753770709038, 0.4041283130645752, 0.19998696446418762, 0.02464224211871624, 0.027145477011799812, 0.034603700041770935, 0.06178485229611397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15250493586063385, 0.004860042594373226, 0.0065876818262040615, 0.002969530411064625, 0.002562963403761387, 0.001153596444055438, 0.004546673037111759, 0.0009880849393084645, 0.0004983540857210755, 0.0017118373652920127, 0.002686705207452178, 0.00347260688431561, 0.001398291322402656, 0.015389986336231232, 0.0042520253919065, 0.01102544367313385, 0.00584067776799202, 0.00430999044328928, 0.02564103901386261, 0.009602834470570087, 0.023868778720498085, 0.2032465636730194, 0.2971981167793274, 0.02141759730875492, 0.021787554025650024, 0.04366065561771393, 0.06164854019880295, 0.06516893953084946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10709892958402634, 0.002602207474410534, 0.0021190345287323, 0.0011307985987514257, 0.0017659126315265894, 0.002046411158517003, 0.0023193785455077887, 0.0016567000420764089, 0.0007963357493281364, 0.0030886598397046328, 0.0030438906978815794, 0.00257477187551558, 0.0009683076641522348, 0.004449281841516495, 0.0038526486605405807, 0.004754537250846624, 0.0035937766078859568, 0.0035855809692293406, 0.02327154390513897, 0.010464487597346306, 0.024923566728830338, 0.2680410146713257, 0.1280278116464615, 0.03474050015211105, 0.04348430410027504, 0.07200177013874054, 0.10676097869873047, 0.043773312121629715, 0.09306354075670242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13694798946380615, 0.003415616462007165, 0.002684519626200199, 0.0016103254165500402, 0.0018092949176207185, 0.002175354864448309, 0.0031748118344694376, 0.0016018353635445237, 0.0009396583191119134, 0.0036782200913876295, 0.0036690093111246824, 0.0035479485522955656, 0.0012516231508925557, 0.0037973865400999784, 0.0030449836049228907, 0.004697700031101704, 0.002007598290219903, 0.004753569606691599, 0.018853770568966866, 0.011919069103896618, 0.019450677558779716, 0.19665218889713287, 0.12466663122177124, 0.0332837849855423, 0.04261476546525955, 0.08314478397369385, 0.12211716175079346, 0.05197146162390709, 0.09241432696580887, 0.018103918060660362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15853111445903778, 0.0010178311495110393, 0.0018803945276886225, 0.0010018504690378904, 0.0015635591698810458, 0.0008988103363662958, 0.002477802336215973, 0.001621524104848504, 0.0009046684135682881, 0.0027294375468045473, 0.004036487080156803, 0.0023034990299493074, 0.0007688812329433858, 0.005685609765350819, 0.0028803981840610504, 0.003722261870279908, 0.002732088789343834, 0.002834400860592723, 0.026751438155770302, 0.008815658278763294, 0.020371848717331886, 0.13322047889232635, 0.09341132640838623, 0.03315063565969467, 0.03175739571452141, 0.10055337101221085, 0.12078055739402771, 0.04204271361231804, 0.13426533341407776, 0.028387630358338356, 0.02890101820230484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1362103670835495, 0.004338766448199749, 0.001712488243356347, 0.0011967254104092717, 0.0016946495743468404, 0.001255979179404676, 0.0046587251126766205, 0.0023808579426258802, 0.0010549467988312244, 0.004525521770119667, 0.0035553458146750927, 0.004353862255811691, 0.0016976131591945887, 0.003220050595700741, 0.002224068157374859, 0.004187384154647589, 0.0006551325786858797, 0.006654122844338417, 0.016760513186454773, 0.015205257572233677, 0.024541784077882767, 0.10131025314331055, 0.08443067967891693, 0.029074717313051224, 0.04023384675383568, 0.07159268856048584, 0.11321533471345901, 0.06619233638048172, 0.1081211194396019, 0.015822988003492355, 0.00764720793813467, 0.1202746033668518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1873355358839035, 0.005997521337121725, 0.002568773925304413, 0.0016919367481023073, 0.0020438453648239374, 0.00191947678104043, 0.0049299271777272224, 0.0014454522170126438, 0.0004500063369050622, 0.0022439886815845966, 0.0019520148634910583, 0.004333163145929575, 0.000890544499270618, 0.0025129851419478655, 0.0022236695513129234, 0.00437321700155735, 0.0009242146043106914, 0.004263405222445726, 0.014568370766937733, 0.009179888293147087, 0.01117609441280365, 0.1636558324098587, 0.0882190465927124, 0.015530445612967014, 0.020207419991493225, 0.03708368167281151, 0.07278755307197571, 0.07402423769235611, 0.08429528027772903, 0.01603933610022068, 0.012837979942560196, 0.08896473050117493, 0.05933046713471413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11882876604795456, 0.0008760913624428213, 0.002239841967821121, 0.0024505862966179848, 0.0006728086736984551, 0.004453102592378855, 0.001245036837644875, 0.0004328702634666115, 0.00032733959960751235, 0.0005436912761069834, 0.0010141906095668674, 0.003320668125525117, 0.00029612178332172334, 0.001416738610714674, 0.00537419319152832, 0.004106109030544758, 0.009821799583733082, 0.0020476938225328922, 0.0065700216218829155, 0.003346099518239498, 0.00511009618639946, 0.12845107913017273, 0.11634030938148499, 0.01000810693949461, 0.00438015628606081, 0.013905857689678669, 0.017939314246177673, 0.026542846113443375, 0.02550768107175827, 0.02605191059410572, 0.1558937281370163, 0.03798292577266693, 0.024837767705321312, 0.23766444623470306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14467613399028778, 0.006374509539455175, 0.0045099216513335705, 0.002331397496163845, 0.002288348041474819, 0.001346921781077981, 0.0040205176919698715, 0.002570771612226963, 0.0010988266440108418, 0.002546189120039344, 0.002458150265738368, 0.00533693190664053, 0.0012402012944221497, 0.006290500517934561, 0.0020215294789522886, 0.003611169522628188, 0.0020787296816706657, 0.003968905191868544, 0.011766265146434307, 0.008202755823731422, 0.009589077904820442, 0.058957699686288834, 0.09392597526311874, 0.014395061880350113, 0.013755658641457558, 0.0229931753128767, 0.02909197099506855, 0.040532436221838, 0.08101166039705276, 0.02340688556432724, 0.02858944796025753, 0.08803877234458923, 0.030612997710704803, 0.05091237649321556, 0.1954481452703476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12368541210889816, 0.004667370580136776, 0.002206171629950404, 0.001960703870281577, 0.002144171856343746, 0.0012812804197892547, 0.002779831411316991, 0.0017812616424635053, 0.001412081765010953, 0.0030021793209016323, 0.002208672696724534, 0.0024385000579059124, 0.000665457162540406, 0.002163813915103674, 0.001955695217475295, 0.0022683562710881233, 0.003358409972861409, 0.00235090684145689, 0.007597604300826788, 0.004865838680416346, 0.005163456778973341, 0.06952495872974396, 0.08904384821653366, 0.012483887374401093, 0.016832085326313972, 0.02377082034945488, 0.027420753613114357, 0.018423018977046013, 0.03851976990699768, 0.011576944030821323, 0.04413067549467087, 0.05355968698859215, 0.037567220628261566, 0.041303813457489014, 0.16947050392627716, 0.16641484200954437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1306557059288025, 0.00406297342851758, 0.002998755779117346, 0.0018537131836637855, 0.0018622095230966806, 0.0011134585365653038, 0.0028715389780700207, 0.001558855758048594, 0.0006875721155665815, 0.002033400582149625, 0.0019482278730720282, 0.003764813533052802, 0.0008931256015785038, 0.004003925248980522, 0.0017579501727595925, 0.002568337135016918, 0.0012502091703936458, 0.002597923157736659, 0.009500415995717049, 0.004609267693012953, 0.006218124646693468, 0.04891782999038696, 0.06186258792877197, 0.009626971557736397, 0.010098326951265335, 0.01846480183303356, 0.029006967321038246, 0.027124682441353798, 0.05140271782875061, 0.012047265656292439, 0.015330458991229534, 0.04966605082154274, 0.023743147030472755, 0.037512894719839096, 0.13787496089935303, 0.2123720645904541, 0.06613786518573761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12756317853927612, 0.004984545987099409, 0.004401443526148796, 0.002799689769744873, 0.0013080424396321177, 0.0009885740000754595, 0.0031962848734110594, 0.0008824312244541943, 0.00039709178963676095, 0.0010369764640927315, 0.0011988731566816568, 0.0024603386409580708, 0.000526286952663213, 0.00362949981354177, 0.001170864561572671, 0.002116188406944275, 0.0009132714476436377, 0.0014077925588935614, 0.0038388390094041824, 0.003214580472558737, 0.002671487396582961, 0.047257788479328156, 0.06928633898496628, 0.0044526937417685986, 0.00491659389808774, 0.009336117655038834, 0.014221169985830784, 0.017240682616829872, 0.018586821854114532, 0.009851007722318172, 0.011260916478931904, 0.03312540054321289, 0.013024491257965565, 0.032968670129776, 0.14117708802223206, 0.3102737069129944, 0.05950404331088066, 0.03281018137931824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1947619616985321, 0.0018174691358581185, 0.0012482983293011785, 0.0006819904665462673, 0.0013240048428997397, 0.0010296677937731147, 0.0025293342769145966, 0.001218475983478129, 0.0007344170589931309, 0.0024152137339115143, 0.0020575993694365025, 0.0021027170587331057, 0.0007263664156198502, 0.0020786793902516365, 0.001567394589073956, 0.0024857097305357456, 0.0007351220119744539, 0.0020301705226302147, 0.007606974802911282, 0.004031074699014425, 0.009393476881086826, 0.058806512504816055, 0.033818792551755905, 0.011009152047336102, 0.013490160927176476, 0.02351783774793148, 0.03888078033924103, 0.024782951921224594, 0.0454259030520916, 0.008610917255282402, 0.009014745242893696, 0.043295666575431824, 0.04648745059967041, 0.040863726288080215, 0.06507096439599991, 0.13273084163665771, 0.04390263557434082, 0.03807508945465088, 0.07963982969522476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14357836544513702, 0.0021401734557002783, 0.00075404072413221, 0.0006914183031767607, 0.0007910302374511957, 0.0013060515047982335, 0.0020061437971889973, 0.0010821003234013915, 0.0003850881475955248, 0.0019213467603549361, 0.0009759957320056856, 0.001853780820965767, 0.0005947627942077816, 0.0008495876099914312, 0.0013064452214166522, 0.0019759759306907654, 0.00039438006933778524, 0.0020503501873463392, 0.0034686338622123003, 0.003663911484181881, 0.0046637216582894325, 0.05078897252678871, 0.024868186563253403, 0.007281201891601086, 0.01023804396390915, 0.012901728972792625, 0.025830086320638657, 0.019736867398023605, 0.021892083808779716, 0.004535195883363485, 0.004485754296183586, 0.0393027663230896, 0.03677667677402496, 0.052929531782865524, 0.0920989066362381, 0.08269336819648743, 0.06872334331274033, 0.01337774284183979, 0.06823299825191498, 0.18685315549373627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07567711174488068, 0.0010357594583183527, 0.0008841941016726196, 0.0005654477863572538, 0.0007825446664355695, 0.0006473932298831642, 0.0011369041167199612, 0.000604754954110831, 0.0002729720144998282, 0.0010619348613545299, 0.0010389400413259864, 0.0005873197806067765, 0.000301355350529775, 0.0012760438257828355, 0.0007937142509035766, 0.0012134537100791931, 0.0007295592804439366, 0.0007256609969772398, 0.004296335391700268, 0.0023469009902328253, 0.004075287375599146, 0.048997119069099426, 0.029762187972664833, 0.005238584242761135, 0.007268200628459454, 0.012240486219525337, 0.023308491334319115, 0.010155735537409782, 0.02297278679907322, 0.005486796610057354, 0.007689799647778273, 0.02334357239305973, 0.021488603204488754, 0.03251459449529648, 0.060302842408418655, 0.12238548696041107, 0.03302095830440521, 0.037471212446689606, 0.1000513955950737, 0.1487504243850708, 0.1474970132112503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08507728576660156, 0.0028133222367614508, 0.0008844317635521293, 0.0007174569764174521, 0.0006478705327026546, 0.0013153147883713245, 0.001424577902071178, 0.00031259492971003056, 0.00014917613589204848, 0.0006686222623102367, 0.0006154270377010107, 0.001624477212317288, 0.0003267059219069779, 0.0006645417306572199, 0.0008406212436966598, 0.0019742650911211967, 0.00023949274327605963, 0.0016832358669489622, 0.0023509550374001265, 0.002505322452634573, 0.00258960435166955, 0.06234052777290344, 0.026378069072961807, 0.0035027991980314255, 0.003941192291676998, 0.006520541850477457, 0.01547905895859003, 0.02126518450677395, 0.007759280502796173, 0.003580159042030573, 0.0024249949492514133, 0.02552187070250511, 0.01446379255503416, 0.05869557335972786, 0.12770876288414001, 0.09154296666383743, 0.0500502809882164, 0.008356268517673016, 0.058890972286462784, 0.1201457753777504, 0.08974099904298782, 0.09226561337709427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07089580595493317, 0.0009932932443916798, 0.0005573395756073296, 0.0003760607505682856, 0.00043043229379691184, 0.0003241784288547933, 0.000757467292714864, 0.0006408347398974001, 0.0002947431057691574, 0.0009360628901049495, 0.0006179550546221435, 0.0009665829711593688, 0.0002485991280991584, 0.0007628463208675385, 0.0006782378768548369, 0.0010355878621339798, 0.0005974724190309644, 0.0013043502112850547, 0.0033761714585125446, 0.002698182361200452, 0.003419127082452178, 0.024765903130173683, 0.027962859719991684, 0.004134777467697859, 0.006954030133783817, 0.007273305207490921, 0.01016231533139944, 0.011468691751360893, 0.021518588066101074, 0.005358720198273659, 0.005941769573837519, 0.022785170003771782, 0.013210431672632694, 0.015662558376789093, 0.05609333515167236, 0.0786207988858223, 0.03975642845034599, 0.026685502380132675, 0.07693014293909073, 0.12746016681194305, 0.12762297689914703, 0.07834308594465256, 0.11937716603279114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.047990500926971436, 0.000911170442122966, 0.001240551588125527, 0.0008534801308996975, 0.00040270050521939993, 0.00020527189190033823, 0.0007123209070414305, 0.00013436496374197304, 5.312359644449316e-05, 0.00015474430983886123, 0.0002577396226115525, 0.00033406156580895185, 0.00017386957188136876, 0.0014516511000692844, 0.000398945645429194, 0.0009837839752435684, 0.0007807088550180197, 0.00044465294922702014, 0.002054999815300107, 0.0012318615335971117, 0.0013156564673408866, 0.020121483132243156, 0.041340697556734085, 0.001335450098849833, 0.0012588658137246966, 0.0027469529304653406, 0.0054255286231637, 0.006577485706657171, 0.0075072129257023335, 0.0032160126138478518, 0.007060416042804718, 0.009280741214752197, 0.003555889241397381, 0.010518533177673817, 0.043834540992975235, 0.1625252068042755, 0.016531744971871376, 0.0259567704051733, 0.08039555698633194, 0.047093842178583145, 0.0691865012049675, 0.02867603860795498, 0.29715073108673096, 0.04661763831973076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07087338715791702, 0.0008310890407301486, 0.00031010661041364074, 0.0003504113119561225, 0.0005770290736109018, 0.0004831614496652037, 0.000712667650077492, 0.0005212267278693616, 0.00022907101083546877, 0.0010557867353782058, 0.0006138126482255757, 0.0004513259627856314, 0.00044017404434271157, 0.0003953378472942859, 0.0006278722430579364, 0.0007351624662987888, 0.00041429270640946925, 0.001111270859837532, 0.003788392525166273, 0.0027532505337148905, 0.0030020771082490683, 0.026387182995676994, 0.013674698770046234, 0.004019813612103462, 0.0066138762049376965, 0.00909096747636795, 0.015836084261536598, 0.004982778802514076, 0.010059156455099583, 0.0014100864063948393, 0.002505037235096097, 0.012124093249440193, 0.012630179524421692, 0.012765028513967991, 0.03440167382359505, 0.026034511625766754, 0.02673506923019886, 0.007024667225778103, 0.03610527142882347, 0.086495041847229, 0.13832461833953857, 0.12942315638065338, 0.08343864977359772, 0.05181559920310974, 0.15782584249973297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04075988754630089, 0.00022467067174147815, 0.00020346646488178521, 0.00026895967312157154, 0.0002524053561501205, 0.00019774772226810455, 0.00028641370590776205, 0.00047203447320498526, 0.00021384705905802548, 0.00033363167312927544, 0.0003449702344369143, 0.00020673050312325358, 0.00016159072401933372, 0.0003148688701912761, 0.000687983469106257, 0.0004977686330676079, 0.0032998649403452873, 0.0006042654276825488, 0.0026288428343832493, 0.0016509469132870436, 0.003186848247423768, 0.033670566976070404, 0.022177044302225113, 0.004114545416086912, 0.003396189073100686, 0.005440931301563978, 0.007289184257388115, 0.003203907050192356, 0.009918613359332085, 0.00322000402957201, 0.027649808675050735, 0.008833187632262707, 0.007757772225886583, 0.007916757836937904, 0.016778357326984406, 0.026932934299111366, 0.015301700681447983, 0.021686382591724396, 0.05171337351202965, 0.045164477080106735, 0.09169068187475204, 0.06531717628240585, 0.11084642261266708, 0.04256102442741394, 0.12407972663640976, 0.18654145300388336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03399789705872536, 0.00028308702167123556, 0.00020229678193572909, 0.00019712006906047463, 0.00021733911125920713, 0.0003661288064904511, 0.00028044614009559155, 0.0003182626678608358, 0.00017078203381970525, 0.00039660706534050405, 0.0002583113091532141, 0.0003804755979217589, 0.00011195555998710915, 0.00018352142069488764, 0.0005412519676610827, 0.0006062022875994444, 0.0005564294406212866, 0.0009122149203903973, 0.0017139316769316792, 0.0013853578129783273, 0.0019835857674479485, 0.013203679583966732, 0.008775994181632996, 0.0026367029640823603, 0.0034376729745417833, 0.004166238475590944, 0.0039877742528915405, 0.00332132657058537, 0.0055410610511898994, 0.0021721054799854755, 0.003545599291101098, 0.006012992467731237, 0.0054770177230238914, 0.013288512825965881, 0.023923851549625397, 0.019889047369360924, 0.02307506464421749, 0.012114453129470348, 0.02677900716662407, 0.048152342438697815, 0.0762212797999382, 0.05939367413520813, 0.07610826194286346, 0.06523053348064423, 0.15761449933052063, 0.06835661083459854, 0.22251152992248535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03478885442018509, 0.00020694774866569787, 0.0002368932473473251, 0.00010869350808206946, 0.0002491283812560141, 0.00019831242389045656, 0.00032125742291100323, 0.0002798094064928591, 8.969639748102054e-05, 0.0004262143047526479, 0.0003321142867207527, 0.00017592041695024818, 4.944231113768183e-05, 0.0003186628455296159, 0.000314398726914078, 0.0004279840795788914, 0.0002690285036806017, 0.0003886937047354877, 0.003238692646846175, 0.0011493363417685032, 0.0028281400445848703, 0.028522372245788574, 0.011353467591106892, 0.0030953167006373405, 0.0050038439221680164, 0.006229243706911802, 0.008313633501529694, 0.002624013926833868, 0.00968972872942686, 0.0020938769448548555, 0.0017132021021097898, 0.004869207739830017, 0.008717833086848259, 0.008694054558873177, 0.015855662524700165, 0.03444676846265793, 0.009451843798160553, 0.013842776417732239, 0.03181954845786095, 0.08346550911664963, 0.08894030004739761, 0.07237459719181061, 0.05303741618990898, 0.03268051519989967, 0.1738131195306778, 0.054917991161346436, 0.07198848575353622, 0.11604748666286469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.031032303348183632, 9.32696639210917e-05, 0.00022819850710220635, 0.00028736176318489015, 9.038109419634566e-05, 0.0005373716121539474, 0.000135055321152322, 4.675923628383316e-05, 3.546645893948153e-05, 6.774500798201188e-05, 0.00011813035234808922, 0.00033231641282327473, 3.863728488795459e-05, 0.0002049573085969314, 0.000978349708020687, 0.0008757601026445627, 0.0021954418625682592, 0.00047127524157986045, 0.001571468892507255, 0.0009295225609093904, 0.0013776839477941394, 0.030791660770773888, 0.02684229239821434, 0.0018505060579627752, 0.0008725970983505249, 0.0020619919523596764, 0.0025387355126440525, 0.002873120130971074, 0.0020271586254239082, 0.002054742770269513, 0.01139441505074501, 0.003265551058575511, 0.0020158844999969006, 0.0212762039154768, 0.008596707135438919, 0.022929362952709198, 0.0049181352369487286, 0.007604053243994713, 0.043929655104875565, 0.02015654928982258, 0.03660514950752258, 0.013418233953416348, 0.1039750948548317, 0.04376731812953949, 0.047491852194070816, 0.14202551543712616, 0.018748804926872253, 0.051303066313266754, 0.28301823139190674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03184065967798233, 0.00026643832097761333, 0.0001827980886446312, 0.0002630468225106597, 0.00017991499044001102, 0.00011090098996646702, 0.00017019006190821528, 0.00019206760043743998, 8.559790876461193e-05, 0.00017234472034033388, 0.00017894509073812515, 0.00015057383279781789, 7.808673399267718e-05, 0.0003553485148586333, 0.0005686646327376366, 0.0004343278706073761, 0.0031769212801009417, 0.0005130724748596549, 0.00263070035725832, 0.0013994239270687103, 0.0019091045251116157, 0.0331575833261013, 0.029113464057445526, 0.0030504639726132154, 0.0022951874416321516, 0.003228224581107497, 0.0045546372421085835, 0.002036742400377989, 0.005138694308698177, 0.0016041139606386423, 0.014088384807109833, 0.00416528107598424, 0.00258041569031775, 0.0035118325613439083, 0.011525271460413933, 0.016168609261512756, 0.0071243965066969395, 0.012977923266589642, 0.029855873435735703, 0.023213734850287437, 0.04400523379445076, 0.023631524294614792, 0.08302248269319534, 0.02337617613375187, 0.07269150763750076, 0.14842918515205383, 0.021052176132798195, 0.09760846942663193, 0.05418391525745392, 0.17774933576583862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.039354197680950165, 0.0006506305071525276, 0.00026500949752517045, 0.0001892854052130133, 0.0002337978221476078, 0.00016342323215212673, 0.00034044223139062524, 0.0002895369252655655, 0.00011951796477660537, 0.00040212407475337386, 0.0002462858974467963, 0.0004823897033929825, 0.0001427309907739982, 0.00046008662320673466, 0.00046952758566476405, 0.0007860768819227815, 0.0005033237976022065, 0.0012375513324514031, 0.003360944567248225, 0.0027912200894206762, 0.0033081597648561, 0.021222831681370735, 0.023914756253361702, 0.003266333369538188, 0.005274811293929815, 0.0043678246438503265, 0.004902968183159828, 0.005213531665503979, 0.007003380451351404, 0.0016010005492717028, 0.0017720040632411838, 0.00607455987483263, 0.0033631923142820597, 0.00405981857329607, 0.014382727444171906, 0.017402006313204765, 0.009855415672063828, 0.007109794765710831, 0.019860850647091866, 0.03357703983783722, 0.038588304072618484, 0.02453605830669403, 0.045319389551877975, 0.04085242375731468, 0.0811825543642044, 0.08311907947063446, 0.023443639278411865, 0.08277346938848495, 0.06789547204971313, 0.13692359626293182, 0.12534494698047638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02842983976006508, 0.000602168554905802, 0.00023647851776331663, 0.00026672868989408016, 0.0002300250926055014, 0.00012355725630186498, 0.0003318660019431263, 0.00019159620569553226, 9.439391578780487e-05, 0.000305429712170735, 0.0002066181623376906, 0.00028924536309204996, 0.0001749851944623515, 0.0004721789446193725, 0.0004018793406430632, 0.0006673526950180531, 0.0005851599271409214, 0.0008121801656670868, 0.002286589005962014, 0.0020686076022684574, 0.0023680024314671755, 0.020843658596277237, 0.02971615083515644, 0.002990094246342778, 0.003933750092983246, 0.004608639050275087, 0.0057469382882118225, 0.0034512437414377928, 0.004356727469712496, 0.0008773289737291634, 0.0020866638515144587, 0.004048812668770552, 0.00249903229996562, 0.002751689637079835, 0.012647745199501514, 0.014816566370427608, 0.008817911148071289, 0.0063162208534777164, 0.01381224486976862, 0.021728571504354477, 0.03201352432370186, 0.024435285478830338, 0.054970767349004745, 0.027428172528743744, 0.06367656588554382, 0.059650637209415436, 0.025457331910729408, 0.07680471986532211, 0.045799799263477325, 0.10279994457960129, 0.1774851381778717, 0.10228326916694641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046545907855033875, 0.00037066408549435437, 0.00010029135592048988, 6.60158766550012e-05, 0.00021849750191904604, 0.00019264803268015385, 0.0003476535785011947, 0.0002848924195859581, 0.00011157515837112442, 0.0007335727568715811, 0.0002896317164413631, 0.00037187428097240627, 0.00024910044157877564, 0.0003144033835269511, 0.00036157661816105247, 0.0006033485406078398, 0.00013651076005771756, 0.0011422507232055068, 0.0030830358155071735, 0.002341147046536207, 0.0053146700374782085, 0.015280178748071194, 0.008063038811087608, 0.0037071711849421263, 0.008492065593600273, 0.006795608904212713, 0.010988123714923859, 0.004681416787207127, 0.008230485953390598, 0.00047047078260220587, 0.00042458646930754185, 0.004110310692340136, 0.00620432710275054, 0.003877972951158881, 0.005763726774603128, 0.005869410000741482, 0.00555898854508996, 0.0017285920912399888, 0.008092609234154224, 0.03999049589037895, 0.03736359253525734, 0.048009902238845825, 0.011589357629418373, 0.023815711960196495, 0.06389649212360382, 0.04393376410007477, 0.02801634930074215, 0.07038310170173645, 0.06465668231248856, 0.06988077610731125, 0.04385918751358986, 0.15587380528450012, 0.12721246480941772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.017199154943227768, 0.0005979815614409745, 0.0001087469354388304, 6.305072020040825e-05, 0.00010312777158105746, 0.00015843000437598675, 0.00023612599761690944, 5.79627558181528e-05, 2.2879055904923007e-05, 0.0001377903245156631, 0.00010523181117605418, 0.0003458908468019217, 6.255623884499073e-05, 0.00016802978643681854, 0.00015174929285421968, 0.0005260381731204689, 4.339728184277192e-05, 0.0009329669992439449, 0.0015432984801009297, 0.0013346992200240493, 0.0018091334495693445, 0.021874811500310898, 0.009757574647665024, 0.002323669148609042, 0.00269331899471581, 0.003325989004224539, 0.006097353063523769, 0.005855480208992958, 0.0027852028142660856, 0.0004696731921285391, 0.0002240141766378656, 0.003434811718761921, 0.0030379975214600563, 0.006010234821587801, 0.013695253990590572, 0.009681520983576775, 0.005329101346433163, 0.0012033832026645541, 0.005190983880311251, 0.026760410517454147, 0.019698703661561012, 0.024675874039530754, 0.019636863842606544, 0.034044258296489716, 0.027445301413536072, 0.02451220713555813, 0.01736343279480934, 0.046507611870765686, 0.11568101495504379, 0.04278373718261719, 0.08922374993562698, 0.17476876080036163, 0.07048875838518143, 0.13771066069602966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011759546585381031, 0.00038567036972381175, 0.00035667046904563904, 0.0002428690786473453, 0.00011835320037789643, 5.812637755298056e-05, 0.00020576325186993927, 4.018616527901031e-05, 1.512282142357435e-05, 4.53398133686278e-05, 8.460685785394162e-05, 0.00013371290697250515, 9.272636816604063e-05, 0.0008785266545601189, 0.00022752926452085376, 0.0006313907215371728, 0.0004858639440499246, 0.0002750521816778928, 0.0013847576919943094, 0.000935916556045413, 0.0010052570141851902, 0.014187656342983246, 0.02851380966603756, 0.0010791459353640676, 0.0008209967636503279, 0.00170320481993258, 0.0027473485097289085, 0.0032017857301980257, 0.002557264408096671, 0.0009559955215081573, 0.002086282940581441, 0.0023410627618432045, 0.0008028055890463293, 0.002192320767790079, 0.008257257752120495, 0.028177890926599503, 0.0033232872374355793, 0.005172382108867168, 0.014263818971812725, 0.008217052556574345, 0.012273195199668407, 0.005322766490280628, 0.06404954195022583, 0.011082579381763935, 0.01904246211051941, 0.030888019129633904, 0.0036851130425930023, 0.01868797466158867, 0.0337771475315094, 0.06997828930616379, 0.2782343327999115, 0.11767842620611191, 0.033478111028671265, 0.0922050029039383, 0.05965267866849899, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014287869445979595, 0.00037118379259482026, 7.505333633162081e-05, 5.2518440497806296e-05, 0.00010475722228875384, 0.00010541113442741334, 0.0002060777769656852, 7.586761057609692e-05, 3.475629637250677e-05, 0.00020064522686880082, 0.00015453246305696666, 0.00018709506548475474, 0.00015725517005193979, 0.00023510772734880447, 0.00018028121849056333, 0.0004830063262488693, 7.605625432915986e-05, 0.0006299950182437897, 0.0015390071785077453, 0.001476290519349277, 0.002164907054975629, 0.020464222878217697, 0.009612064808607101, 0.0029551403131335974, 0.003404915565624833, 0.004737917799502611, 0.010334036312997341, 0.0044775852002203465, 0.003870536107569933, 0.0003731010074261576, 0.0003841743164230138, 0.004514502827078104, 0.004927693400532007, 0.003931424580514431, 0.006110569462180138, 0.006565832532942295, 0.003561708377674222, 0.0008151109213940799, 0.004803555551916361, 0.023987380787730217, 0.018455998972058296, 0.02789282612502575, 0.012909799814224243, 0.014029367826879025, 0.01980402320623398, 0.026921888813376427, 0.011545988731086254, 0.03579423576593399, 0.0498272068798542, 0.03267514333128929, 0.054039694368839264, 0.12537416815757751, 0.07106351852416992, 0.15243156254291534, 0.08764622360467911, 0.11695924401283264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012858104892075062, 0.00012082941975677386, 5.806228728033602e-05, 3.53788782376796e-05, 9.260938531951979e-05, 4.798361987923272e-05, 0.00011300142068648711, 5.737008177675307e-05, 3.758276216103695e-05, 0.00014241952158045024, 0.00015953225374687463, 9.462624439038336e-05, 8.232545224018395e-05, 0.0002366936969337985, 0.00017243990441784263, 0.00029948208248242736, 0.00017823588859755546, 0.0002328685950487852, 0.0019146729027852416, 0.0009743556729517877, 0.0016631096368655562, 0.01155280414968729, 0.00627201609313488, 0.0025950674898922443, 0.002421185839921236, 0.005284157115966082, 0.007303223013877869, 0.002038205275312066, 0.0032110330648720264, 0.0004924391396343708, 0.0008904692367650568, 0.00318675278685987, 0.003277036128565669, 0.0019106199033558369, 0.0032062719110399485, 0.005733939819037914, 0.0024755671620368958, 0.003183554159477353, 0.0062495069578289986, 0.014308988116681576, 0.020285552367568016, 0.01850542239844799, 0.008681721054017544, 0.007240627892315388, 0.027320202440023422, 0.026211390271782875, 0.007961531169712543, 0.03530675172805786, 0.02336071990430355, 0.03387920930981636, 0.036438051611185074, 0.033820055425167084, 0.04845226928591728, 0.21808449923992157, 0.05258006975054741, 0.251299113035202, 0.045408304780721664, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014682917855679989, 0.00026191884535364807, 9.428098564967513e-05, 5.4260621254798025e-05, 9.4090290076565e-05, 5.6233355280710384e-05, 0.00010924954403890297, 0.0001479275815654546, 5.5742450058460236e-05, 0.0001780524180503562, 0.00016273772052954882, 0.0001599345705471933, 5.733529542339966e-05, 0.0002325576642761007, 0.00018703863315749913, 0.0002703683858271688, 0.00020471557218115777, 0.0003198101185262203, 0.001637619105167687, 0.0009933722903952003, 0.0010929888812825084, 0.014638302847743034, 0.008666169829666615, 0.002377111231908202, 0.0025993473827838898, 0.0033804543782025576, 0.003510737791657448, 0.0018754082266241312, 0.003542557591572404, 0.0008229269296862185, 0.0010775737464427948, 0.0033010912593454123, 0.0017976637464016676, 0.002084069885313511, 0.008751703426241875, 0.008290968835353851, 0.004217600449919701, 0.004356287885457277, 0.007761065382510424, 0.013257329352200031, 0.01335231401026249, 0.008318709209561348, 0.00993829034268856, 0.007173839490860701, 0.0226842500269413, 0.017890211194753647, 0.011393029242753983, 0.03055262193083763, 0.019824134185910225, 0.027078991755843163, 0.04185333847999573, 0.031100284308195114, 0.03962322697043419, 0.11039517819881439, 0.05174976587295532, 0.1783764511346817, 0.05432431399822235, 0.20700952410697937, 0.0, 0.0, 0.0, 0.0], [0.009568708948791027, 4.450808046385646e-05, 6.702233804389834e-05, 3.607775579439476e-05, 5.6649365433258936e-05, 2.8944152290932834e-05, 7.232447387650609e-05, 4.3499283492565155e-05, 2.190590021200478e-05, 8.001489914022386e-05, 0.00010414137796033174, 7.629260653629899e-05, 2.946308086393401e-05, 0.00027150314417667687, 0.00013998406939208508, 0.00017674123228061944, 0.0001235788658959791, 0.00013265665620565414, 0.0012529968516901135, 0.00039291000575758517, 0.0008198567666113377, 0.004875518847256899, 0.0036583011969923973, 0.0011598310666158795, 0.0011762601789087057, 0.002563048154115677, 0.0030375795904546976, 0.001091286656446755, 0.002550398698076606, 0.0005493989447131753, 0.0006661009974777699, 0.0014321579365059733, 0.0016672237543389201, 0.0011677745496854186, 0.00169480184558779, 0.006084030959755182, 0.0011064230930060148, 0.004065672867000103, 0.0038631181232631207, 0.008334308862686157, 0.009887264110147953, 0.006846772041171789, 0.006443218793720007, 0.0035509145818650723, 0.01438063196837902, 0.01264546811580658, 0.0045808469876646996, 0.015037952922284603, 0.012010902166366577, 0.018895313143730164, 0.029467925429344177, 0.01246055867522955, 0.02671819180250168, 0.13112597167491913, 0.032876573503017426, 0.18817996978759766, 0.05956398323178291, 0.3092172145843506, 0.041827380657196045, 0.0, 0.0, 0.0], [0.019205084070563316, 0.00028727418975904584, 0.0001298292336286977, 6.863242015242577e-05, 0.00012723205145448446, 7.441869092872366e-05, 0.0001889411360025406, 9.035320545081049e-05, 4.574602280627005e-05, 0.00017829606076702476, 0.0001281152799492702, 0.00011041469406336546, 7.08125953678973e-05, 0.0002376296033617109, 0.0001528471620986238, 0.0002840928209479898, 0.0001421443303115666, 0.00021149488748051226, 0.0009980079485103488, 0.000641393125988543, 0.0011731706326827407, 0.008896471001207829, 0.006524611264467239, 0.0013610887108370662, 0.0022624337580055, 0.002479258691892028, 0.0034326554741710424, 0.0017546096350997686, 0.0031187692657113075, 0.0004785038763657212, 0.000842243549413979, 0.0027161636389791965, 0.002854568650946021, 0.00260634976439178, 0.005579957738518715, 0.009121774695813656, 0.0034849350340664387, 0.002166077494621277, 0.006538130808621645, 0.01198355108499527, 0.010362361557781696, 0.008167833089828491, 0.007037070579826832, 0.004702365957200527, 0.01726698875427246, 0.016379298642277718, 0.005407537333667278, 0.019789772108197212, 0.01665429212152958, 0.025724880397319794, 0.03118889592587948, 0.04253312945365906, 0.035977885127067566, 0.07316716015338898, 0.04093020781874657, 0.10639133304357529, 0.05458693951368332, 0.15829473733901978, 0.04231707751750946, 0.18037214875221252, 0.0, 0.0], [0.014692679978907108, 0.0003339496033731848, 0.00010777758143376559, 7.450285920640454e-05, 0.00010363840556237847, 7.355107663897797e-05, 0.00021725190163124353, 0.00011256454308750108, 4.622362757800147e-05, 0.00025849518715403974, 0.00016128677816595882, 0.00024620775366201997, 0.00010457464668434113, 0.000254268292337656, 0.00016452529234811664, 0.0002959521079901606, 4.130640809307806e-05, 0.00042651177500374615, 0.0011186908232048154, 0.0009362097480334342, 0.001420262735337019, 0.005796479992568493, 0.005087833385914564, 0.0015987749211490154, 0.0024831718765199184, 0.002982959384098649, 0.004805542528629303, 0.0026908472646027803, 0.003179522231221199, 0.0004195614892523736, 0.00022699357941746712, 0.0038493252359330654, 0.0030810756143182516, 0.002226378535851836, 0.005885151214897633, 0.007109721191227436, 0.003611126448959112, 0.0014413592871278524, 0.003305968828499317, 0.014041992835700512, 0.009967053309082985, 0.010716686025261879, 0.006810852326452732, 0.006637428421527147, 0.011835102923214436, 0.009626413695514202, 0.005718253552913666, 0.015125717036426067, 0.013878186233341694, 0.018163951113820076, 0.02860156260430813, 0.04133063554763794, 0.03558661416172981, 0.0762685090303421, 0.05599059909582138, 0.07029171288013458, 0.024250471964478493, 0.06090736761689186, 0.011321812868118286, 0.21248042583465576, 0.17947636544704437, 0.0], [0.011266042478382587, 8.001583773875609e-05, 1.9974315364379436e-05, 6.457917334046215e-05, 9.130094440479297e-06, 4.3626838305499405e-05, 5.043783312430605e-05, 1.2254991816007532e-05, 7.976924280228559e-06, 1.354063624603441e-05, 1.928344863699749e-05, 0.0003020749718416482, 4.698194970842451e-05, 3.0001590857864358e-05, 0.0001326064666500315, 0.0001603850832907483, 7.043052755761892e-05, 0.00024346292775589973, 0.0001308667124249041, 0.0005663733463734388, 0.00011765953240683302, 0.001951848971657455, 0.0028286385349929333, 0.000577655853703618, 0.00012286266428418458, 0.00034636963391676545, 0.0007941344520077109, 0.0018206823151558638, 0.00017950803157873452, 0.00016405702626798302, 0.0004951490554958582, 0.0028835346456617117, 0.00028927490347996354, 0.0015636308817192912, 0.0035585444420576096, 0.001724448287859559, 0.002315567107871175, 0.00020668873912654817, 0.004211461171507835, 0.0028286492452025414, 0.0024748388677835464, 0.001135934260673821, 0.007362679112702608, 0.007655354216694832, 0.0018031264189630747, 0.01057012751698494, 0.0017215301049873233, 0.0032007344998419285, 0.009831970557570457, 0.022931506857275963, 0.0323852077126503, 0.016705011948943138, 0.021975502371788025, 0.008786295540630817, 0.05824236199259758, 0.00437773996964097, 0.031569093465805054, 0.06186917424201965, 0.028092771768569946, 0.06627467274665833, 0.16017727553844452, 0.39860671758651733]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9748935699462891, 0.02510647289454937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9375593662261963, 0.029095854610204697, 0.033344775438308716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8151788711547852, 0.05286300927400589, 0.11625124514102936, 0.01570684090256691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8972122669219971, 0.02099972404539585, 0.03337117284536362, 0.03375580906867981, 0.014661065302789211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.661294162273407, 0.05436446890234947, 0.09762963652610779, 0.08005142211914062, 0.10111597180366516, 0.00554434210062027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7680426836013794, 0.02941710501909256, 0.0152047760784626, 0.0697350949048996, 0.02049539051949978, 0.09158490598201752, 0.00552006671205163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7376888394355774, 0.01726387068629265, 0.028870372101664543, 0.03234289214015007, 0.032025255262851715, 0.06660796701908112, 0.019038258120417595, 0.0661625862121582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.822395384311676, 0.010085398331284523, 0.01199088990688324, 0.03276045620441437, 0.01004923228174448, 0.0396868996322155, 0.0056815072894096375, 0.044692449271678925, 0.02265789359807968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7194886803627014, 0.025224147364497185, 0.011629246175289154, 0.09923703223466873, 0.011933784931898117, 0.06904225796461105, 0.008016320876777172, 0.02770085074007511, 0.019188879057765007, 0.00853878352791071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7772552967071533, 0.01299375481903553, 0.005039674695581198, 0.061522725969552994, 0.00357622466981411, 0.10706210136413574, 0.0013423984637483954, 0.014984273351728916, 0.005249571055173874, 0.0029818988405168056, 0.007992023602128029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29682207107543945, 0.021393440663814545, 0.06385233253240585, 0.010416610166430473, 0.07655388116836548, 0.0029128037858754396, 0.16534258425235748, 0.03510933741927147, 0.08411327749490738, 0.08748877048492432, 0.13645227253437042, 0.019542669877409935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2898499071598053, 0.016143180429935455, 0.03955192491412163, 0.018205789849162102, 0.0707600861787796, 0.011945492587983608, 0.0698670819401741, 0.07645519822835922, 0.08348814398050308, 0.0780949518084526, 0.17858998477458954, 0.01060289517045021, 0.05644537881016731, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5707874894142151, 0.025526490062475204, 0.027529357001185417, 0.0432543009519577, 0.025613190606236458, 0.01777847670018673, 0.027173103764653206, 0.032519590109586716, 0.02608996070921421, 0.01923440396785736, 0.05404254049062729, 0.0618947297334671, 0.014209391549229622, 0.0543469600379467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11094137281179428, 0.011568980291485786, 0.03978976979851723, 0.004057224374264479, 0.06590628623962402, 0.0010816967114806175, 0.23178118467330933, 0.031578149646520615, 0.07574131339788437, 0.04004913941025734, 0.1538712978363037, 0.005255353637039661, 0.09987924247980118, 0.12578488886356354, 0.002714048372581601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22433048486709595, 0.020093556493520737, 0.03973958641290665, 0.022637730464339256, 0.06780469417572021, 0.006939453538507223, 0.09101992100477219, 0.032604798674583435, 0.06170662119984627, 0.05187810957431793, 0.13196471333503723, 0.0352630689740181, 0.030538052320480347, 0.13259257376194, 0.019150836393237114, 0.03173581138253212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1624956578016281, 0.02045603282749653, 0.03831563517451286, 0.012362606823444366, 0.07122331857681274, 0.00341851357370615, 0.10863102227449417, 0.03431713581085205, 0.1070912778377533, 0.07663839310407639, 0.17336183786392212, 0.007679650094360113, 0.02349691465497017, 0.14054232835769653, 0.006212471518665552, 0.008808658458292484, 0.004948575980961323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36289942264556885, 0.014566613361239433, 0.03263060748577118, 0.011451504193246365, 0.0463736429810524, 0.0066520897671580315, 0.05412008985877037, 0.031646523624658585, 0.07188345491886139, 0.05084230750799179, 0.1267835646867752, 0.018608734011650085, 0.013176591135561466, 0.11023186147212982, 0.01827012188732624, 0.01132428739219904, 0.011016417294740677, 0.007522193714976311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2924647331237793, 0.027575725689530373, 0.00895586609840393, 0.07514776289463043, 0.015145568177103996, 0.01535476092249155, 0.009475477039813995, 0.017311204224824905, 0.012317088432610035, 0.007875760085880756, 0.028262339532375336, 0.14114536345005035, 0.005567743442952633, 0.028573786839842796, 0.020093819126486778, 0.012971417047083378, 0.03390549123287201, 0.22479525208473206, 0.02306080237030983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18114323914051056, 0.013290907256305218, 0.04544598236680031, 0.006001980043947697, 0.05499182268977165, 0.0033015338703989983, 0.10316180437803268, 0.03244152292609215, 0.07502924650907516, 0.0673336610198021, 0.13053208589553833, 0.00616768142208457, 0.030358392745256424, 0.1101999506354332, 0.010667589493095875, 0.021226849406957626, 0.00758579233661294, 0.003630438121035695, 0.08182979375123978, 0.01565972901880741, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4430793523788452, 0.017495807260274887, 0.003947802819311619, 0.10138052701950073, 0.005393701605498791, 0.04695768281817436, 0.002538299886509776, 0.016274014487862587, 0.006683283485472202, 0.004588865675032139, 0.009956277906894684, 0.047621481120586395, 0.0011226885253563523, 0.016258224844932556, 0.06594881415367126, 0.004584010224789381, 0.08083245903253555, 0.06229092553257942, 0.014961103908717632, 0.028061460703611374, 0.02002326026558876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10584570467472076, 0.020390834659337997, 0.019462861120700836, 0.011822937987744808, 0.03183110058307648, 0.0018693194724619389, 0.1419091671705246, 0.012696481309831142, 0.042971063405275345, 0.02299860492348671, 0.05612356215715408, 0.004635884892195463, 0.015743792057037354, 0.0868682786822319, 0.0028612767346203327, 0.0687294751405716, 0.00680107856169343, 0.0065894047729671, 0.11737652122974396, 0.04347888007760048, 0.17590726912021637, 0.003086448647081852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15678422152996063, 0.02116173319518566, 0.031652066856622696, 0.0046965633518993855, 0.03966299444437027, 0.0014666657662019134, 0.07246518135070801, 0.01853795535862446, 0.053202252835035324, 0.04484094679355621, 0.09326973557472229, 0.005292195826768875, 0.031978119164705276, 0.07614034414291382, 0.0037103912327438593, 0.020567812025547028, 0.0037547575775533915, 0.004682355094701052, 0.06964249908924103, 0.029897887259721756, 0.18174786865711212, 0.004157288931310177, 0.030688082799315453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26233816146850586, 0.008227932266891003, 0.015287302434444427, 0.016232158988714218, 0.017782151699066162, 0.007712926249951124, 0.0160441342741251, 0.01878875307738781, 0.026183750480413437, 0.019025210291147232, 0.04529402777552605, 0.005276639945805073, 0.0043593705631792545, 0.03153983876109123, 0.013673476874828339, 0.004314577206969261, 0.014935137704014778, 0.004225468263030052, 0.036821167916059494, 0.02081858552992344, 0.1484082043170929, 0.04969686642289162, 0.17944468557834625, 0.033569466322660446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2403797060251236, 0.008537013083696365, 0.003193649696186185, 0.03345038369297981, 0.004137728828936815, 0.01864251308143139, 0.002475425135344267, 0.008983493782579899, 0.006069430150091648, 0.0022825966589152813, 0.008007179945707321, 0.009668935090303421, 0.0012965780915692449, 0.009556032717227936, 0.022472823038697243, 0.0024797776713967323, 0.03348479047417641, 0.012423365376889706, 0.011250817216932774, 0.019746439531445503, 0.034392811357975006, 0.17187979817390442, 0.3159867227077484, 0.011787696741521358, 0.0074143060483038425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2053709477186203, 0.008431779220700264, 0.001645341282710433, 0.01932300254702568, 0.0020224228501319885, 0.019280608743429184, 0.0006163073121570051, 0.005787846632301807, 0.0026178061962127686, 0.0015303977997973561, 0.003219643607735634, 0.004784366115927696, 0.0005168524803593755, 0.005801596213132143, 0.017944684252142906, 0.0019148901337757707, 0.023506371304392815, 0.006940225604921579, 0.007423390634357929, 0.012244146317243576, 0.017855985090136528, 0.399737149477005, 0.2060273289680481, 0.008006622083485126, 0.004723357502371073, 0.01272689551115036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13627751171588898, 0.005563747603446245, 0.0006454444373957813, 0.020349303260445595, 0.0010130491573363543, 0.018246306106448174, 0.00016858280287124217, 0.0035553823690861464, 0.0009493609541095793, 0.0004201926349196583, 0.0015070138033479452, 0.010052436962723732, 0.00032602649298496544, 0.0021971508394926786, 0.022026758641004562, 0.0011245259083807468, 0.032981615513563156, 0.012944851070642471, 0.002722771605476737, 0.007052519358694553, 0.006153147201985121, 0.38022783398628235, 0.3153690695762634, 0.004114694427698851, 0.0014660933520644903, 0.006898917723447084, 0.0056456211023032665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06594748795032501, 0.00781299825757742, 0.0199162308126688, 0.0032303223852068186, 0.03019612841308117, 0.0008715580333955586, 0.04844076931476593, 0.0062029436230659485, 0.029216211289167404, 0.02033831924200058, 0.035897642374038696, 0.013184340670704842, 0.010507604107260704, 0.05679325386881828, 0.0020306012593209743, 0.020280620083212852, 0.0012335090432316065, 0.008957612328231335, 0.03826121240854263, 0.006458504591137171, 0.11437341570854187, 0.0027336168568581343, 0.029459118843078613, 0.02268415503203869, 0.04530004784464836, 0.1715889573097229, 0.17118629813194275, 0.016896497458219528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19471392035484314, 0.008082333020865917, 0.0053503243252635, 0.021282639354467392, 0.006304475478827953, 0.008196194656193256, 0.002663293620571494, 0.007244630716741085, 0.007806719746440649, 0.004907711874693632, 0.012411507777869701, 0.03518809750676155, 0.0018798481905832887, 0.012045040726661682, 0.010065476410090923, 0.004462125711143017, 0.015960542485117912, 0.05789906904101372, 0.013220451772212982, 0.013629073277115822, 0.031229499727487564, 0.06339665502309799, 0.15046755969524384, 0.02245158702135086, 0.017137963324785233, 0.07578285783529282, 0.04817547649145126, 0.11832566559314728, 0.029719308018684387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15329177677631378, 0.011903694830834866, 0.007259206380695105, 0.0233050137758255, 0.0107850581407547, 0.009203165769577026, 0.007174681406468153, 0.01380532793700695, 0.018055511638522148, 0.007194099016487598, 0.0179650466889143, 0.01149924099445343, 0.0033970526419579983, 0.01994973234832287, 0.010740377940237522, 0.004900735337287188, 0.01803097315132618, 0.01250135712325573, 0.02148224227130413, 0.02739039435982704, 0.06134422868490219, 0.05982184037566185, 0.1371563971042633, 0.027439258992671967, 0.023444360122084618, 0.07477587461471558, 0.0834522619843483, 0.04226211458444595, 0.06891798228025436, 0.01155095361173153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06276267021894455, 0.005249538458883762, 0.01031812746077776, 0.0035940189845860004, 0.020475108176469803, 0.0009247570997104049, 0.02719857171177864, 0.008819496259093285, 0.02688480168581009, 0.016136502847075462, 0.038538988679647446, 0.001550421817228198, 0.004786163568496704, 0.030001146718859673, 0.0013805237831547856, 0.001904663280583918, 0.001239267410710454, 0.0012709032744169235, 0.024534396827220917, 0.016615310683846474, 0.12306483089923859, 0.0019385837949812412, 0.030683442950248718, 0.023548124358057976, 0.04547715559601784, 0.10337294638156891, 0.15630538761615753, 0.002718123607337475, 0.19655877351760864, 0.009490694850683212, 0.0026565920561552048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09187550097703934, 0.004833724815398455, 0.018197257071733475, 0.0023454250767827034, 0.022938568145036697, 0.0011651794193312526, 0.04147540405392647, 0.01282540988177061, 0.028863586485385895, 0.020901676267385483, 0.04434419423341751, 0.0018311860039830208, 0.009039944969117641, 0.032104481011629105, 0.003028185572475195, 0.0068099619820714, 0.002490722807124257, 0.001228931825608015, 0.03142604976892471, 0.005684276111423969, 0.10819260776042938, 0.003203449072316289, 0.02482709288597107, 0.023164890706539154, 0.04356896132230759, 0.08060884475708008, 0.1377425640821457, 0.00530468113720417, 0.14859628677368164, 0.025949768722057343, 0.005527364555746317, 0.00990383978933096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1768004149198532, 0.005610228981822729, 0.002386117121204734, 0.024313317611813545, 0.0036495146341621876, 0.014261512085795403, 0.0011250213719904423, 0.00711181852966547, 0.0033048370387405157, 0.001879067742265761, 0.005500809755176306, 0.006164411548525095, 0.000632413022685796, 0.005218328442424536, 0.014963849447667599, 0.0012646481627598405, 0.0236675925552845, 0.005661277566105127, 0.00781591609120369, 0.015708789229393005, 0.015825895592570305, 0.12786589562892914, 0.29528385400772095, 0.00952624436467886, 0.005877070594578981, 0.02295307256281376, 0.023098284378647804, 0.03406599164009094, 0.01918911375105381, 0.006808807607740164, 0.06621459871530533, 0.03683503717184067, 0.009416176937520504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12205418199300766, 0.007957998663187027, 0.011194100603461266, 0.013491489924490452, 0.01676337607204914, 0.0006686499109491706, 0.056445274502038956, 0.008560963906347752, 0.023448821157217026, 0.008405369706451893, 0.026629747822880745, 0.007030353881418705, 0.013153044506907463, 0.03499970585107803, 0.0020092150662094355, 0.012023979797959328, 0.0016010015970095992, 0.004080646671354771, 0.03170127049088478, 0.015537349507212639, 0.06673503667116165, 0.0008796583279035985, 0.051481325179338455, 0.015716196969151497, 0.021672246977686882, 0.08464272320270538, 0.10499455779790878, 0.014534843154251575, 0.10043676197528839, 0.012203969061374664, 0.004469698294997215, 0.03577134758234024, 0.06533998996019363, 0.0033652062993496656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.054029133170843124, 0.005275334231555462, 0.02488788031041622, 0.0015851258067414165, 0.025419043377041817, 0.0006318503874354064, 0.06652785837650299, 0.007249967660754919, 0.025184866040945053, 0.020868830382823944, 0.029813088476657867, 0.0026471675373613834, 0.008763180114328861, 0.03797600418329239, 0.0010909694246947765, 0.015498909167945385, 0.0008501101401634514, 0.0017061018152162433, 0.035218965262174606, 0.004833173472434282, 0.10639116913080215, 0.0017292569391429424, 0.012542170472443104, 0.018476612865924835, 0.03722565621137619, 0.0833568423986435, 0.1197817474603653, 0.005356627982109785, 0.14360907673835754, 0.022836050018668175, 0.0020064294803887606, 0.008445252664387226, 0.04684010520577431, 0.0017663618782535195, 0.019579118117690086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30222606658935547, 0.010634436272084713, 0.008507889695465565, 0.007192532531917095, 0.006075266283005476, 0.0038731370586901903, 0.008467143401503563, 0.009655437432229519, 0.008895489387214184, 0.005297147668898106, 0.010766725987195969, 0.004287114832550287, 0.00357596343383193, 0.014908170327544212, 0.004102435894310474, 0.01161719486117363, 0.005373268388211727, 0.005231610499322414, 0.017832571640610695, 0.01439007930457592, 0.04524784907698631, 0.019311869516968727, 0.04803372174501419, 0.019252363592386246, 0.012624853290617466, 0.0380534827709198, 0.04104657098650932, 0.011951534077525139, 0.03963470086455345, 0.015606993809342384, 0.015370936132967472, 0.03175976872444153, 0.033120959997177124, 0.01871568150818348, 0.08501612395048141, 0.062342897057533264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09868745505809784, 0.0034807620104402304, 0.018998319283127785, 0.00260434509254992, 0.020850274711847305, 0.0020339793991297483, 0.03171437978744507, 0.01032781321555376, 0.0139363594353199, 0.013838863000273705, 0.026072675362229347, 0.004565814509987831, 0.007233519572764635, 0.025272276252508163, 0.002809803932905197, 0.0119426054880023, 0.0019409481901675463, 0.002752360887825489, 0.02628987468779087, 0.004152031149715185, 0.0890716165304184, 0.005077800713479519, 0.034616004675626755, 0.016869833692908287, 0.025374092161655426, 0.07097068428993225, 0.09414631873369217, 0.010019897483289242, 0.1063995212316513, 0.018027089536190033, 0.005353156942874193, 0.00887207593768835, 0.036703046411275864, 0.0074300640262663364, 0.013054272159934044, 0.0942935049533844, 0.03421653062105179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08045803755521774, 0.011795301921665668, 0.013716420158743858, 0.004602053202688694, 0.019381577149033546, 0.0007994111510924995, 0.015483599156141281, 0.005068894010037184, 0.011691580526530743, 0.010671773925423622, 0.016128404065966606, 0.009038150310516357, 0.004965114872902632, 0.02199474349617958, 0.001635477296076715, 0.010738552547991276, 0.001070213969796896, 0.005636746529489756, 0.025342198088765144, 0.007391966413706541, 0.03850293159484863, 0.0025239665992558002, 0.04212319850921631, 0.01604660600423813, 0.021925967186689377, 0.07149138301610947, 0.07229944318532944, 0.019561542198061943, 0.07601825147867203, 0.02114834636449814, 0.003131845500320196, 0.016883088275790215, 0.03396810591220856, 0.003468447597697377, 0.05641885846853256, 0.08218028396368027, 0.10624472796916962, 0.03845277056097984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03353549912571907, 0.0017957782838493586, 0.008729364722967148, 0.001285539590753615, 0.01770709827542305, 0.0003193159936927259, 0.05065998435020447, 0.005580536089837551, 0.022538375109434128, 0.014625083655118942, 0.027119027450680733, 0.0005503727006725967, 0.004376680124551058, 0.022371554747223854, 0.00042111260700039566, 0.0018408973701298237, 0.00035198565456084907, 0.00038869408308528364, 0.020558064803481102, 0.006465039681643248, 0.08485160768032074, 0.0005561120342463255, 0.006544429808855057, 0.012590283527970314, 0.03494487330317497, 0.07451885938644409, 0.13629178702831268, 0.0008981868159025908, 0.19029363989830017, 0.00443987874314189, 0.000985480728559196, 0.014198340475559235, 0.0607452429831028, 0.001213728217408061, 0.017796136438846588, 0.05616484582424164, 0.05205695703625679, 0.007306480780243874, 0.002383120823651552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19355182349681854, 0.004547407850623131, 0.004322690889239311, 0.012570447288453579, 0.004602086264640093, 0.00806169118732214, 0.0029350779950618744, 0.007468263618648052, 0.00829760730266571, 0.0031578647904098034, 0.010832197964191437, 0.0036754945758730173, 0.0009276882628910244, 0.006606186740100384, 0.00648629991337657, 0.0013774943072348833, 0.010905085131525993, 0.004351229406893253, 0.008434056304395199, 0.009856735356152058, 0.026081819087266922, 0.027937710285186768, 0.09998688846826553, 0.013378849253058434, 0.009067235514521599, 0.0351245142519474, 0.033510006964206696, 0.014150637201964855, 0.03476569429039955, 0.008278661407530308, 0.03290463984012604, 0.023452213034033775, 0.0322633758187294, 0.0432928167283535, 0.027054177597165108, 0.03468535467982292, 0.04995967820286751, 0.027168458327651024, 0.06380902975797653, 0.05016080662608147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20328012108802795, 0.005315303802490234, 0.004890746437013149, 0.009786847978830338, 0.006867770571261644, 0.004150227177888155, 0.005542110651731491, 0.008939136750996113, 0.010223198682069778, 0.0049708206206560135, 0.014231945388019085, 0.0040147011168301105, 0.0022280849516391754, 0.01055573858320713, 0.004031206015497446, 0.001354216830804944, 0.005441378336399794, 0.00431663217023015, 0.008699768222868443, 0.01293045375496149, 0.038051482290029526, 0.022700093686580658, 0.0593668557703495, 0.010847107507288456, 0.011416424065828323, 0.031063497066497803, 0.0409075990319252, 0.010091706179082394, 0.04489460587501526, 0.005132648162543774, 0.014487305656075478, 0.029119295999407768, 0.026944482699036598, 0.01919381506741047, 0.044292401522397995, 0.034859757870435715, 0.07901044189929962, 0.02726655639708042, 0.033285897225141525, 0.03608835116028786, 0.04920922964811325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12200266867876053, 0.002277866704389453, 0.0003816249663941562, 0.01419193297624588, 0.0007050717249512672, 0.0125206233933568, 0.0001320391020271927, 0.0021461155265569687, 0.0006291974568739533, 0.00022140410146676004, 0.0010997210629284382, 0.005594690330326557, 0.00015305734996218234, 0.0011497818632051349, 0.01145292166620493, 0.0004285563773009926, 0.01665567234158516, 0.006307333242148161, 0.0011796315666288137, 0.0027402262203395367, 0.003088812343776226, 0.14327454566955566, 0.1699552685022354, 0.0016562622040510178, 0.0006397546967491508, 0.004062441177666187, 0.0038401500787585974, 0.040197499096393585, 0.0028281325940042734, 0.0017295529833063483, 0.056038565933704376, 0.008237036876380444, 0.0020960511174052954, 0.10218767076730728, 0.012800854630768299, 0.004619091749191284, 0.03868481144309044, 0.05603637173771858, 0.1258615106344223, 0.002814209321513772, 0.009909910149872303, 0.007471330929547548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08011537790298462, 0.003565652295947075, 0.006613415665924549, 0.0013192452024668455, 0.010997721925377846, 0.0007356387213803828, 0.013091729022562504, 0.00881341751664877, 0.016374055296182632, 0.010220460593700409, 0.03002023510634899, 0.0008328401600010693, 0.005383458454161882, 0.014822496101260185, 0.0015287124551832676, 0.0014337442116811872, 0.0017548843752592802, 0.0005799198406748474, 0.012304073199629784, 0.003783118911087513, 0.05286615714430809, 0.0019609935116022825, 0.013782891444861889, 0.008637082763016224, 0.017773831263184547, 0.03386996313929558, 0.06910058110952377, 0.0023853005841374397, 0.06148666515946388, 0.008719640783965588, 0.003716997802257538, 0.007742695044726133, 0.03234907612204552, 0.002579785417765379, 0.02435978315770626, 0.0371786393225193, 0.10565908253192902, 0.014345481060445309, 0.011389396153390408, 0.08558163046836853, 0.052932094782590866, 0.11813019961118698, 0.00916183553636074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08379995077848434, 0.0034277592785656452, 0.008740315213799477, 0.001661767135374248, 0.012553339824080467, 0.0006342111155390739, 0.0185227133333683, 0.003942748531699181, 0.011266286484897137, 0.007675188593566418, 0.016470687463879585, 0.002971983514726162, 0.005002234131097794, 0.02033006027340889, 0.0014213257236406207, 0.00617582444101572, 0.0008276699227280915, 0.0020591106731444597, 0.01667802780866623, 0.004451494198292494, 0.041997406631708145, 0.001758707920089364, 0.016533780843019485, 0.010067575611174107, 0.015504751354455948, 0.048324499279260635, 0.07494169473648071, 0.005339798983186483, 0.06646983325481415, 0.009405788034200668, 0.001822820631787181, 0.008057083003222942, 0.034230489283800125, 0.0022563354577869177, 0.01521225180476904, 0.04692896828055382, 0.042189132422208786, 0.016115248203277588, 0.007122842129319906, 0.08833964169025421, 0.055507149547338486, 0.12836666405200958, 0.013109222054481506, 0.021785693243145943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2719852030277252, 0.0029805200174450874, 0.002823862014338374, 0.008807757869362831, 0.0020010911393910646, 0.007930434308946133, 0.001293014851398766, 0.00566133251413703, 0.0027074762620031834, 0.0016018671449273825, 0.004217151086777449, 0.004369659814983606, 0.000698830233886838, 0.0037309867329895496, 0.006742800585925579, 0.0016081291250884533, 0.009116572327911854, 0.006589481607079506, 0.0045104315504431725, 0.0054623037576675415, 0.017769573256373405, 0.059612248092889786, 0.06616316735744476, 0.006556209176778793, 0.004207935184240341, 0.012791560962796211, 0.011294187046587467, 0.011194994673132896, 0.011715181171894073, 0.003541892860084772, 0.022125793620944023, 0.009869612753391266, 0.009661166928708553, 0.036225009709596634, 0.014798152260482311, 0.019075244665145874, 0.021600328385829926, 0.018723465502262115, 0.038774970918893814, 0.014845079742372036, 0.021245095878839493, 0.028980256989598274, 0.10240717232227325, 0.04769209399819374, 0.034290771931409836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.040626417845487595, 0.002808121731504798, 0.004002096131443977, 0.0012201106874272227, 0.007179740816354752, 0.0006888026255182922, 0.012084996327757835, 0.006936249323189259, 0.009360281750559807, 0.004584239795804024, 0.014336624182760715, 0.001917196554131806, 0.0038355616852641106, 0.010191971436142921, 0.0008264346979558468, 0.003807677188888192, 0.0013311136281117797, 0.00158800114877522, 0.010868072509765625, 0.005969916936010122, 0.037057649344205856, 0.0012914114631712437, 0.00847359374165535, 0.01327334064990282, 0.011112874373793602, 0.04766133055090904, 0.05515842139720917, 0.0033884046133607626, 0.0393669568002224, 0.0046226452104747295, 0.003013425040990114, 0.011331710033118725, 0.023802001029253006, 0.003114809049293399, 0.017264168709516525, 0.031126830726861954, 0.04729574918746948, 0.018836941570043564, 0.0064963591285049915, 0.0975327417254448, 0.050055649131536484, 0.10714368522167206, 0.01398357655853033, 0.016219625249505043, 0.18017001450061798, 0.007042429875582457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09750205278396606, 0.0014468143926933408, 0.0015269111609086394, 0.009085837751626968, 0.0020785306114703417, 0.01008669100701809, 0.001320329145528376, 0.0061265164986252785, 0.0031593649182468653, 0.0012981075560674071, 0.004385942127555609, 0.0019116154871881008, 0.0006892291130498052, 0.0025436857249587774, 0.009728280827403069, 0.00042382595711387694, 0.013414289802312851, 0.002123436890542507, 0.003196213161572814, 0.005010885652154684, 0.014654062688350677, 0.04975835233926773, 0.06098521128296852, 0.004956958349794149, 0.003401121823117137, 0.00864039920270443, 0.0117524778470397, 0.006850578356534243, 0.012895525433123112, 0.0025873135309666395, 0.03412351757287979, 0.009589786641299725, 0.010643786750733852, 0.05275334045290947, 0.006774615496397018, 0.01284925639629364, 0.018044721335172653, 0.019314201548695564, 0.05963345244526863, 0.011921021156013012, 0.02532016672194004, 0.035626064985990524, 0.14878763258457184, 0.027272401377558708, 0.06524629145860672, 0.053898975253105164, 0.05466024577617645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2174314707517624, 0.001595750916749239, 0.0020877879578620195, 0.006259145215153694, 0.002418093616142869, 0.004001484718173742, 0.001517538446933031, 0.004886901006102562, 0.003316828515380621, 0.0016114015597850084, 0.005424463655799627, 0.0029177654068917036, 0.0005714551662094891, 0.0037420643493533134, 0.003979404456913471, 0.0008463297854177654, 0.005802946165204048, 0.004250829108059406, 0.004065406043082476, 0.003694311948493123, 0.018520861864089966, 0.02187483385205269, 0.0420159250497818, 0.006370870862156153, 0.004890137352049351, 0.02018801122903824, 0.016136614605784416, 0.009381432086229324, 0.014139100909233093, 0.003398435888811946, 0.015390543267130852, 0.007109795697033405, 0.015306569635868073, 0.02073707990348339, 0.008645572699606419, 0.017094450071454048, 0.02241932787001133, 0.014445040374994278, 0.03306363895535469, 0.019998325034976006, 0.03116803802549839, 0.0507369264960289, 0.09653212130069733, 0.03774340823292732, 0.06247417628765106, 0.023632965981960297, 0.04981260374188423, 0.036351799964904785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.052530303597450256, 0.0029992940835654736, 0.0041608368046581745, 0.00534889055415988, 0.006426949519664049, 0.0002787007251754403, 0.021060580387711525, 0.002877729944884777, 0.007303762715309858, 0.003069790545850992, 0.008898759260773659, 0.002370011294260621, 0.005059187766164541, 0.012501158751547337, 0.0008295975276269019, 0.00469815731048584, 0.000638842408079654, 0.0016703379806131124, 0.013124699704349041, 0.00660794647410512, 0.02654728665947914, 0.00035815208684653044, 0.021688183769583702, 0.005130700301378965, 0.008068723604083061, 0.02611580304801464, 0.03277686610817909, 0.0042288112454116344, 0.028871217742562294, 0.003409742144867778, 0.001248717657290399, 0.010767447762191296, 0.018494484946131706, 0.0011393040185794234, 0.023914385586977005, 0.027049066498875618, 0.06367576867341995, 0.016470856964588165, 0.004999441094696522, 0.06633446365594864, 0.04857950657606125, 0.08229096978902817, 0.062282394617795944, 0.02726132981479168, 0.0786295235157013, 0.010259722359478474, 0.0958719328045845, 0.03690299764275551, 0.004176671151071787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03327583521604538, 0.002129122382029891, 0.0028189371805638075, 0.0007099812501110137, 0.0066504087299108505, 0.00021286237461026758, 0.012607458047568798, 0.005072577856481075, 0.008023629896342754, 0.00264060590416193, 0.01156605500727892, 0.0016750909853726625, 0.008671757765114307, 0.012067821808159351, 0.0004502731026150286, 0.005813681520521641, 0.0006486975471489131, 0.0014312624698504806, 0.011204978451132774, 0.0059124017134308815, 0.042662154883146286, 0.0006603479851037264, 0.007200784515589476, 0.010971970856189728, 0.007244329899549484, 0.03773801028728485, 0.05210140720009804, 0.0029804310761392117, 0.03053431212902069, 0.0028018243610858917, 0.0012044659815728664, 0.009180180728435516, 0.01653394103050232, 0.0009094057604670525, 0.011478728614747524, 0.019773200154304504, 0.03419684246182442, 0.02192015014588833, 0.0028035936411470175, 0.07058899104595184, 0.03160260617733002, 0.08270605653524399, 0.00823360588401556, 0.013560494408011436, 0.1583949774503708, 0.0033564195036888123, 0.13243499398231506, 0.04367123916745186, 0.00375663535669446, 0.0052144527435302734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0649355873465538, 0.003362838877364993, 0.005079854279756546, 0.001226769294589758, 0.009227901697158813, 0.0006781049305573106, 0.01028815284371376, 0.007423940114676952, 0.012791765853762627, 0.008621243759989738, 0.022287866100668907, 0.0006867691990919411, 0.004564134404063225, 0.013089981861412525, 0.001608718535862863, 0.0011974425287917256, 0.001805775798857212, 0.0005204082117415965, 0.012653092853724957, 0.003881556447595358, 0.05019424855709076, 0.0020846507977694273, 0.013762789778411388, 0.007648313418030739, 0.016487380489706993, 0.026483263820409775, 0.05180460214614868, 0.0017684204503893852, 0.04167850688099861, 0.0054333205334842205, 0.0025874576531350613, 0.0049997298046946526, 0.020327195525169373, 0.0017401197692379355, 0.014904758892953396, 0.019849203526973724, 0.06611015647649765, 0.008928720839321613, 0.007488177623599768, 0.05299098417162895, 0.035076335072517395, 0.07819952815771103, 0.007165515795350075, 0.005554446950554848, 0.10786318778991699, 0.009380417875945568, 0.097220778465271, 0.030015967786312103, 0.00504477322101593, 0.011660733260214329, 0.009614391252398491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0605032853782177, 0.0036038372199982405, 0.010622366331517696, 0.0019439755706116557, 0.010133705101907253, 0.0006502467440441251, 0.011932237073779106, 0.004540584981441498, 0.00862879678606987, 0.009134714491665363, 0.013786708004772663, 0.0007617917726747692, 0.0025916886515915394, 0.011763148009777069, 0.001070463447831571, 0.0030559857841581106, 0.0008914031786844134, 0.0006184505182318389, 0.01972847245633602, 0.004848133306950331, 0.0585329644382, 0.0012858123518526554, 0.023615367710590363, 0.011354083195328712, 0.021385082975029945, 0.036025941371917725, 0.04545465484261513, 0.0015579176833853126, 0.04312270134687424, 0.007610705215483904, 0.001270460314117372, 0.0051884837448596954, 0.017052527517080307, 0.0016061883652582765, 0.009948117658495903, 0.036526236683130264, 0.02328001894056797, 0.005909767933189869, 0.00434822216629982, 0.10772749036550522, 0.03260093554854393, 0.06417915970087051, 0.010474899783730507, 0.005609256215393543, 0.07174425572156906, 0.0056176697835326195, 0.08860449492931366, 0.04176117479801178, 0.00486142560839653, 0.0065372418612241745, 0.015033591538667679, 0.00936315767467022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11149515211582184, 0.0031100765336304903, 0.003507490735501051, 0.009186651557683945, 0.00478952843695879, 0.004298938903957605, 0.00282872561365366, 0.006277876440435648, 0.005487928166985512, 0.0034244495909661055, 0.009305375628173351, 0.0032710374798625708, 0.0009408933110535145, 0.005522803403437138, 0.004370357841253281, 0.0008088081376627088, 0.005692823324352503, 0.0035650571808218956, 0.006073346361517906, 0.005824151914566755, 0.027027837932109833, 0.01963741146028042, 0.06250862032175064, 0.007661856710910797, 0.008192921057343483, 0.02395230159163475, 0.019857468083500862, 0.008328287862241268, 0.01741010509431362, 0.002652703318744898, 0.008558523841202259, 0.006507003214210272, 0.008783741854131222, 0.011226153932511806, 0.00755223399028182, 0.011871568858623505, 0.013429074548184872, 0.008411336690187454, 0.01594376191496849, 0.015094783157110214, 0.019996071234345436, 0.035537756979465485, 0.05484514683485031, 0.01672966405749321, 0.06361596286296844, 0.01402236521244049, 0.04648919776082039, 0.028121287003159523, 0.03945556655526161, 0.03658958896994591, 0.10190602391958237, 0.006791787687689066, 0.03151050955057144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.058799128979444504, 0.0020209418144077063, 0.0002536314423196018, 0.005254015326499939, 0.00039261559140868485, 0.004145797807723284, 0.00010609253513393924, 0.00116963020991534, 0.0003037476562894881, 0.0001466073445044458, 0.0005623958422802389, 0.0021942241583019495, 9.19409139896743e-05, 0.0007848931709304452, 0.0032303486950695515, 0.0003328858292661607, 0.005706955678761005, 0.0038431831635534763, 0.0011352997971698642, 0.0018783735577017069, 0.00278287916444242, 0.06618944555521011, 0.10026068240404129, 0.0012324103154242039, 0.0005413616891019046, 0.0027440725825726986, 0.0023311551194638014, 0.01632845774292946, 0.0012641942594200373, 0.0007548704743385315, 0.0117268655449152, 0.00320476689375937, 0.0007070715073496103, 0.023103253915905952, 0.007416878826916218, 0.0018740094965323806, 0.018427496775984764, 0.022360049188137054, 0.027082690969109535, 0.001655189786106348, 0.004213940352201462, 0.0033846693113446236, 0.09066760540008545, 0.05513225868344307, 0.01571880653500557, 0.014294144697487354, 0.005546811502426863, 0.0036064099986106157, 0.1043718084692955, 0.06822112947702408, 0.1846628040075302, 0.004541913513094187, 0.007962584495544434, 0.03333462029695511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05053098127245903, 0.002618232276290655, 0.005277227610349655, 0.0010463314829394221, 0.007603778038173914, 0.00041705454350449145, 0.01078717689961195, 0.002540526445955038, 0.007086588069796562, 0.005006583407521248, 0.009753193706274033, 0.0020083654671907425, 0.0034410874359309673, 0.014953598380088806, 0.0012171510607004166, 0.004550779704004526, 0.0006740468088537455, 0.0014659978915005922, 0.013698807917535305, 0.003591713961213827, 0.03266100585460663, 0.0015485684853047132, 0.013959749601781368, 0.00820998102426529, 0.012057739309966564, 0.03319232165813446, 0.04684000462293625, 0.0033732294104993343, 0.03677036240696907, 0.0049934396520257, 0.0010078855557367206, 0.003866261336952448, 0.016186699271202087, 0.001125091454014182, 0.006956386845558882, 0.01939205639064312, 0.01927536353468895, 0.007184928748756647, 0.0033094764221459627, 0.039180781692266464, 0.023946426808834076, 0.056926265358924866, 0.006351119838654995, 0.010670081712305546, 0.07858825474977493, 0.004728173371404409, 0.0431043915450573, 0.04479038715362549, 0.003813427407294512, 0.006832930259406567, 0.01093912310898304, 0.01681802049279213, 0.02799908071756363, 0.18427065014839172, 0.020861072465777397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10693037509918213, 0.0022478876635432243, 0.0010327830677852035, 0.006038899067789316, 0.000931316229980439, 0.0020725978538393974, 0.0005974919185973704, 0.0017273937119171023, 0.0009979137685149908, 0.0006144040962681174, 0.0013585002161562443, 0.002448987914249301, 0.000282995228189975, 0.0022676752414554358, 0.0026657411362975836, 0.0014112337958067656, 0.004566140007227659, 0.004671236965805292, 0.0037121432833373547, 0.004712522961199284, 0.007640052121132612, 0.031001966446638107, 0.06404426693916321, 0.004515422973781824, 0.0023255799897015095, 0.007367833983153105, 0.0052080159075558186, 0.00838172622025013, 0.005158663261681795, 0.001705744070932269, 0.008762429468333721, 0.006242209114134312, 0.0031756912358105183, 0.00968876201659441, 0.008869734592735767, 0.006692724768072367, 0.010970348492264748, 0.011884999461472034, 0.015352165326476097, 0.007416554726660252, 0.008618809282779694, 0.009227666072547436, 0.07626385241746902, 0.029874583706259727, 0.01594814471900463, 0.010412362404167652, 0.01132747158408165, 0.014864640310406685, 0.04128558561205864, 0.03722858801484108, 0.1658805012702942, 0.008838922716677189, 0.014607872813940048, 0.07525303214788437, 0.07455405592918396, 0.02812080830335617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018330812454223633, 0.0015166840748861432, 0.002003258792683482, 0.0005511872586794198, 0.004189928062260151, 4.790481034433469e-05, 0.012417001649737358, 0.0010494427988305688, 0.005627757403999567, 0.003392246551811695, 0.0072508277371525764, 0.00030348380096256733, 0.0014027677243575454, 0.008749517612159252, 0.00014173977251630276, 0.00042948004556819797, 8.671794057590887e-05, 0.00033370073651894927, 0.004381974693387747, 0.0018795538926497102, 0.02137802354991436, 0.00017624162137508392, 0.0032781846821308136, 0.0034930321853607893, 0.009603459388017654, 0.01924177259206772, 0.03603965416550636, 0.0008192515233531594, 0.03145230561494827, 0.0022278805263340473, 0.00015627116954419762, 0.0022309592459350824, 0.01099882461130619, 0.00016158194921445101, 0.010537991300225258, 0.010084650479257107, 0.024028705433011055, 0.0011053384514525533, 0.0005441374960355461, 0.029869575053453445, 0.019435269758105278, 0.058015115559101105, 0.004255183041095734, 0.002591657917946577, 0.05833395570516586, 0.0014664989430457354, 0.05025704577565193, 0.023521479219198227, 0.0006178045878186822, 0.00354217691347003, 0.008201929740607738, 0.015735521912574768, 0.022038962692022324, 0.1610986292362213, 0.006575180683284998, 0.2718317210674286, 0.0009680569055490196, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1100514829158783, 0.004237769637256861, 0.0031567905098199844, 0.0014876765199005604, 0.004718614276498556, 0.0012293908512219787, 0.002464202931150794, 0.0071530952118337154, 0.007073606830090284, 0.005243212915956974, 0.011570186354219913, 0.0004803691408596933, 0.0017755271401256323, 0.007907922379672527, 0.002739791525527835, 0.000694328045938164, 0.0027392597403377295, 0.00036807742435485125, 0.009921007789671421, 0.0045853559859097, 0.03897228091955185, 0.010893180966377258, 0.02571074292063713, 0.008116418495774269, 0.011980745941400528, 0.01582181826233864, 0.029778137803077698, 0.001881290809251368, 0.02555013634264469, 0.005552021320909262, 0.004290641751140356, 0.005647159647196531, 0.012524093501269817, 0.0036719688214361668, 0.012790325097739697, 0.013160050846636295, 0.05105592682957649, 0.007431295700371265, 0.010476784780621529, 0.030708907172083855, 0.01637032814323902, 0.033773478120565414, 0.008806743659079075, 0.0038285916671156883, 0.049612049013376236, 0.010433172807097435, 0.04430073872208595, 0.020637575536966324, 0.010275810025632381, 0.016733409836888313, 0.015921035781502724, 0.012810882180929184, 0.024666212499141693, 0.12539607286453247, 0.008505908772349358, 0.0342402383685112, 0.027426060289144516, 0.020650051534175873, 0.0, 0.0, 0.0, 0.0], [0.024522649124264717, 0.001507997396402061, 0.002615656703710556, 0.0009097714792005718, 0.005324209574609995, 0.0002682652557268739, 0.00638851523399353, 0.0023018415085971355, 0.006600250490009785, 0.004178603645414114, 0.008905576542019844, 0.0003710851597134024, 0.0013400425668805838, 0.008527684956789017, 0.00043523695785552263, 0.0004848511016461998, 0.0003092152182944119, 0.0002989272470586002, 0.0073614404536783695, 0.004567499738186598, 0.033301837742328644, 0.0005376525223255157, 0.00854109413921833, 0.006149074528366327, 0.01156552042812109, 0.02191554196178913, 0.03457536920905113, 0.0005766002577729523, 0.04064483568072319, 0.001937777386046946, 0.0005623899050988257, 0.006432336755096912, 0.017161332070827484, 0.0009341606055386364, 0.008879845961928368, 0.013995641842484474, 0.027323707938194275, 0.0030580328311771154, 0.0015586733352392912, 0.031411312520504, 0.020376622676849365, 0.048339977860450745, 0.007002908270806074, 0.0022459281608462334, 0.08032749593257904, 0.0028670683968812227, 0.08296312391757965, 0.023601187393069267, 0.0033543554600328207, 0.006594663020223379, 0.014691581018269062, 0.016405517235398293, 0.07214174419641495, 0.15651081502437592, 0.0061841984279453754, 0.0646522119641304, 0.005592778790742159, 0.02426774799823761, 0.0035980441607534885, 0.0, 0.0, 0.0], [0.06460406631231308, 0.00220228498801589, 0.0022579599171876907, 0.002774808555841446, 0.0028800866566598415, 0.0013330955989658833, 0.0027764257974922657, 0.003089566482231021, 0.0030437244568020105, 0.0025347359478473663, 0.005234239157289267, 0.001671572681516409, 0.0010399133898317814, 0.004692970775067806, 0.0013644812861457467, 0.0007849221001379192, 0.0015363881830126047, 0.0019647274166345596, 0.00490295235067606, 0.0055366335436701775, 0.013609145767986774, 0.006024201866239309, 0.02267473191022873, 0.005939255468547344, 0.006345185451209545, 0.014473549090325832, 0.01596740260720253, 0.0037785612512379885, 0.013137998059391975, 0.002559331012889743, 0.0031431338284164667, 0.008892115205526352, 0.007662288844585419, 0.005306563340127468, 0.010655015707015991, 0.011598251760005951, 0.01760532334446907, 0.008510244078934193, 0.005863327533006668, 0.016007089987397194, 0.01458592526614666, 0.025886306539177895, 0.019900599494576454, 0.011420936323702335, 0.04597644880414009, 0.007211342453956604, 0.0414869524538517, 0.017994999885559082, 0.015338592231273651, 0.01801205612719059, 0.03964385390281677, 0.020689954981207848, 0.02589644119143486, 0.10429088026285172, 0.029417462646961212, 0.08108630031347275, 0.01940302364528179, 0.06211045756936073, 0.022019218653440475, 0.06164991855621338, 0.0, 0.0], [0.046683575958013535, 0.0020585251040756702, 0.0065439133904874325, 0.0008544400334358215, 0.00829838402569294, 0.00044778911978937685, 0.013182294555008411, 0.004153180401772261, 0.008936096914112568, 0.007086604367941618, 0.01370403915643692, 0.0006796258967369795, 0.0034679435193538666, 0.012833455577492714, 0.0011959163239225745, 0.0024995331186801195, 0.0007402485935017467, 0.00045027738087810576, 0.01144921500235796, 0.0018529384396970272, 0.035873472690582275, 0.0010567742865532637, 0.009765198454260826, 0.007399761117994785, 0.013365664519369602, 0.02225370518863201, 0.03701215982437134, 0.0016089859418570995, 0.0358051173388958, 0.0065752980299293995, 0.0013025362277403474, 0.002546916017308831, 0.01680467650294304, 0.0012354424688965082, 0.005168549250811338, 0.024493355304002762, 0.01827399618923664, 0.007151757832616568, 0.00315516022965312, 0.05754552409052849, 0.020311051979660988, 0.03930196911096573, 0.003823827486485243, 0.0035449869465082884, 0.04652724787592888, 0.004917393904179335, 0.04728684946894646, 0.029593786224722862, 0.0028585607651621103, 0.0055860113352537155, 0.006636349018663168, 0.010512038134038448, 0.027765044942498207, 0.13546940684318542, 0.009120487608015537, 0.03711222857236862, 0.008393964730203152, 0.008490185253322124, 0.006098440382629633, 0.07744933664798737, 0.013688815757632256, 0.0], [0.02014796808362007, 0.002820352790877223, 0.002330965595319867, 0.0014975696103647351, 0.003857285948470235, 0.00023951426555868238, 0.01452222652733326, 0.001404623151756823, 0.004158226307481527, 0.00195452943444252, 0.0046783010475337505, 0.00045414039050228894, 0.001467653433792293, 0.0077758608385920525, 0.0002750775602180511, 0.006307216826826334, 0.0005446343566291034, 0.0006863969611003995, 0.011906986124813557, 0.003901522606611252, 0.016732141375541687, 0.00027051963843405247, 0.007505164016038179, 0.004632549826055765, 0.005766467656940222, 0.01906447298824787, 0.018322771415114403, 0.001267911633476615, 0.019068801775574684, 0.003445193637162447, 0.0011660470627248287, 0.007052177097648382, 0.014410738833248615, 0.0009271109593100846, 0.028510797768831253, 0.014217443764209747, 0.047829385846853256, 0.008848381228744984, 0.00239137327298522, 0.057940464466810226, 0.02203688770532608, 0.02657969854772091, 0.012574262917041779, 0.0047140358947217464, 0.016986439004540443, 0.0031755564268678427, 0.03260204941034317, 0.016226179897785187, 0.002974117873236537, 0.006665981374680996, 0.025199268013238907, 0.015260693617165089, 0.051197346299886703, 0.08094542473554611, 0.015647707507014275, 0.040494680404663086, 0.008028211072087288, 0.04951268807053566, 0.008723804727196693, 0.13203780353069305, 0.0543944276869297, 0.003721712389960885]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9973666071891785, 0.0026333967689424753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9894182085990906, 0.0025154517497867346, 0.008066308684647083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859943389892578, 0.0015265560941770673, 0.0057945046573877335, 0.0066846078261733055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891934990882874, 0.0012269628932699561, 0.0043141962960362434, 0.0032654094975441694, 0.0020000236108899117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9434327483177185, 0.002444160170853138, 0.007474003825336695, 0.006221005227416754, 0.004280664958059788, 0.03614738583564758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9657812714576721, 0.003441035049036145, 0.006938825361430645, 0.005929748527705669, 0.003234539180994034, 0.010471944697201252, 0.00420265831053257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9708122611045837, 0.0021068959031254053, 0.006619448307901621, 0.0036918804980814457, 0.0034690690226852894, 0.006174566689878702, 0.003836036892607808, 0.0032898515928536654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9678450226783752, 0.0012552454136312008, 0.004922770895063877, 0.003995061386376619, 0.002692759968340397, 0.010262269526720047, 0.002659570425748825, 0.002985124010592699, 0.0033822241239249706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9694236516952515, 0.001507952343672514, 0.004122478887438774, 0.003402364207431674, 0.0020375470630824566, 0.007918530143797398, 0.00207798951305449, 0.0029443884268403053, 0.002655714051797986, 0.003909440245479345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9645799994468689, 0.0017632948001846671, 0.0037354128435254097, 0.0032683531753718853, 0.0015957987634465098, 0.008139306679368019, 0.0019664193969219923, 0.0028079310432076454, 0.0025083899963647127, 0.0049059391021728516, 0.004729111213237047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9445419311523438, 0.0036534385289996862, 0.005546467378735542, 0.0058945403434336185, 0.0030396755319088697, 0.008151787333190441, 0.003655301406979561, 0.005318051669746637, 0.0035907463170588017, 0.006736079230904579, 0.00737584987655282, 0.0024961470626294613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9089175462722778, 0.004224114585667849, 0.009782315231859684, 0.005848946515470743, 0.004479007795453072, 0.012888222932815552, 0.004264138173311949, 0.007470741868019104, 0.005514988210052252, 0.012687822803854942, 0.011117714457213879, 0.004081731662154198, 0.00872277095913887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9299942851066589, 0.0025570488069206476, 0.0068308282643556595, 0.005235025659203529, 0.003422969253733754, 0.009752866812050343, 0.004360483027994633, 0.004930965602397919, 0.0036808180157095194, 0.005779470782727003, 0.0070427474565804005, 0.002722844248637557, 0.006823038216680288, 0.006866578012704849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9106050729751587, 0.00288446806371212, 0.007578087970614433, 0.005513567943125963, 0.004729752894490957, 0.012404102832078934, 0.003716715844348073, 0.005222344305366278, 0.004645779728889465, 0.009001746773719788, 0.009083646349608898, 0.004205169156193733, 0.005368838552385569, 0.007286393083631992, 0.007754250429570675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9133710265159607, 0.004963260143995285, 0.007568703964352608, 0.006276231724768877, 0.0034942820202559233, 0.011124961078166962, 0.0041209119372069836, 0.006862068083137274, 0.003599063493311405, 0.005602643825113773, 0.007628131192177534, 0.0031649477314203978, 0.004296396858990192, 0.0064614079892635345, 0.008034591563045979, 0.003431356279179454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9023541212081909, 0.002774403663352132, 0.0059594628401100636, 0.005749890580773354, 0.0035123699344694614, 0.009411578066647053, 0.0035622469149529934, 0.005325016565620899, 0.004004005808383226, 0.006367608904838562, 0.007105762138962746, 0.0026634898968040943, 0.004923499189317226, 0.006724829785525799, 0.00804243702441454, 0.002614011522382498, 0.01890529692173004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9021815657615662, 0.004108758177608252, 0.0046679009683430195, 0.00440262584015727, 0.0025138799101114273, 0.0073426938615739346, 0.0025638039223849773, 0.00482396874576807, 0.003215109696611762, 0.005494024138897657, 0.006317696999758482, 0.0027228211984038353, 0.0025732286740094423, 0.00468482356518507, 0.008690578863024712, 0.0016468308167532086, 0.025588735938072205, 0.006460868287831545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9273940324783325, 0.002319156192243099, 0.003710618009790778, 0.0034876582212746143, 0.002059926511719823, 0.006637147162109613, 0.002412214642390609, 0.003481853986158967, 0.002562158042564988, 0.003636041423305869, 0.0046658809296786785, 0.0016670047771185637, 0.003339562565088272, 0.00438343221321702, 0.00518814567476511, 0.0014821946388110518, 0.012288417667150497, 0.004576167091727257, 0.004708502907305956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9042530059814453, 0.00197052164003253, 0.005534423515200615, 0.005320058669894934, 0.0032378605101257563, 0.007616283372044563, 0.0028704353608191013, 0.0036137206479907036, 0.003000785131007433, 0.006753978785127401, 0.005734764039516449, 0.00230981083586812, 0.004577499348670244, 0.005614872556179762, 0.005271677393466234, 0.0020316734444350004, 0.008113556541502476, 0.004862045869231224, 0.006205212790518999, 0.011107729747891426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9389152526855469, 0.0009971677791327238, 0.0030268689151853323, 0.0025953231379389763, 0.001755883451551199, 0.005942136514931917, 0.002124103484675288, 0.001498196623288095, 0.0019416887080296874, 0.003343974705785513, 0.0032593279611319304, 0.0012939013540744781, 0.0031285921577364206, 0.002865872345864773, 0.0026159542612731457, 0.0015041357837617397, 0.004409773740917444, 0.004027944523841143, 0.0031148262787610292, 0.006275175139307976, 0.005363752134144306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9114602208137512, 0.0012208460830152035, 0.003338881302624941, 0.003585485275834799, 0.0029695264529436827, 0.0056115505285561085, 0.00465152645483613, 0.0021342982072383165, 0.0025086894165724516, 0.002826330717653036, 0.0036054980009794235, 0.001636431785300374, 0.005203955806791782, 0.005555289331823587, 0.002871357835829258, 0.0022466385271400213, 0.005613578949123621, 0.0030945255421102047, 0.0037378272973001003, 0.009082773700356483, 0.011188358068466187, 0.0058564855717122555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8322315216064453, 0.00326149957254529, 0.008755479007959366, 0.0048073576763272285, 0.005345870275050402, 0.011943367309868336, 0.004704218357801437, 0.004140008240938187, 0.005079105030745268, 0.006170329637825489, 0.007607617415487766, 0.003445104695856571, 0.0052243126556277275, 0.007984333671629429, 0.007348571438342333, 0.0028771699871867895, 0.0079909423366189, 0.0070792753249406815, 0.007891983725130558, 0.01190968882292509, 0.0142888855189085, 0.017778299748897552, 0.012135063298046589, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9065037369728088, 0.0014513508649542928, 0.005324473138898611, 0.0020510805770754814, 0.0026784036308526993, 0.005901548080146313, 0.0024976278655231, 0.0023324228823184967, 0.0025682479608803988, 0.0046138153411448, 0.004990082699805498, 0.002039834624156356, 0.00357447424903512, 0.0036385944113135338, 0.002400845754891634, 0.001016335911117494, 0.002683194587007165, 0.005367584992200136, 0.004410084802657366, 0.0072469268925487995, 0.009229290299117565, 0.007812854833900928, 0.003750499337911606, 0.005916645284742117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8755037188529968, 0.0018202342325821519, 0.004392610862851143, 0.0034661893732845783, 0.0022421858739107847, 0.00812460295855999, 0.002307527232915163, 0.0030229471158236265, 0.0027815885841846466, 0.003942511975765228, 0.004725001752376556, 0.0016997097991406918, 0.0027420837432146072, 0.004561250098049641, 0.006497568916529417, 0.0015727198915556073, 0.014634707942605019, 0.0041579557582736015, 0.005130330100655556, 0.006807955447584391, 0.007853209041059017, 0.014723916538059711, 0.009849430061876774, 0.003329878207296133, 0.00411007646471262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8744680881500244, 0.001705908216536045, 0.0025319610722362995, 0.0024669948033988476, 0.00159766327124089, 0.006996021140366793, 0.0013014253927394748, 0.002761788899078965, 0.002374366857111454, 0.004689353518188, 0.004308826755732298, 0.0017866481794044375, 0.0019255854422226548, 0.003158477833494544, 0.007463980466127396, 0.0013092238223180175, 0.019761983305215836, 0.004647866822779179, 0.004622167441993952, 0.005101269111037254, 0.005235037300735712, 0.017598452046513557, 0.009166112169623375, 0.0034435486886650324, 0.005376703571528196, 0.004200465511530638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8600145578384399, 0.0024106274358928204, 0.0030401733238250017, 0.003259894670918584, 0.0015205803792923689, 0.00746047543361783, 0.0014558614930137992, 0.003122519701719284, 0.002282562432810664, 0.004049976356327534, 0.004599051550030708, 0.0017368289409205317, 0.0018779911333695054, 0.003714639227837324, 0.008024025708436966, 0.001268909778445959, 0.027962518855929375, 0.004188832826912403, 0.004743810743093491, 0.005247973836958408, 0.005434536375105381, 0.016931649297475815, 0.011265255510807037, 0.002667397726327181, 0.004527037963271141, 0.004525129683315754, 0.002667168853804469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.832127571105957, 0.0034859704319387674, 0.0049433959648013115, 0.004407557658851147, 0.0025932511780411005, 0.0062290821224451065, 0.002986564999446273, 0.004429142456501722, 0.0029754803981631994, 0.005584141705185175, 0.005343386437743902, 0.0024591449182480574, 0.002939289901405573, 0.0049523948691785336, 0.007155073806643486, 0.0021164510399103165, 0.017735250294208527, 0.00506584532558918, 0.006246794946491718, 0.0070641785860061646, 0.00883593037724495, 0.018858544528484344, 0.013684280216693878, 0.0040169390849769115, 0.006094539072364569, 0.007086502853780985, 0.004594844300299883, 0.005988370161503553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8402149677276611, 0.0025432384572923183, 0.0053672511130571365, 0.0033252304419875145, 0.0025901589542627335, 0.00904354453086853, 0.0027662382926791906, 0.003657049033790827, 0.0031181275844573975, 0.004484873730689287, 0.005822096951305866, 0.0022595259360969067, 0.00323777599260211, 0.005009292624890804, 0.005706515163183212, 0.0016111615113914013, 0.008766214363276958, 0.005692611448466778, 0.005661820527166128, 0.009207113645970821, 0.009846771135926247, 0.014993199147284031, 0.008700782433152199, 0.004933352116495371, 0.004694996401667595, 0.009377754293382168, 0.004502804949879646, 0.005328434519469738, 0.007537080440670252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8099767565727234, 0.002884039655327797, 0.006916594225913286, 0.0032117487862706184, 0.002903362736105919, 0.008534813299775124, 0.0031867686193436384, 0.0046889097429811954, 0.003277169307693839, 0.004979304503649473, 0.005728903692215681, 0.0028150395955890417, 0.004147541243582964, 0.004805692471563816, 0.006334313191473484, 0.001778545556589961, 0.017111221328377724, 0.00653963815420866, 0.0068403310142457485, 0.007677570916712284, 0.012542448937892914, 0.01816502958536148, 0.0103430962190032, 0.005043034441769123, 0.005216178949922323, 0.007850316353142262, 0.004951196257025003, 0.007812927477061749, 0.008759298361837864, 0.00497819809243083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8144234418869019, 0.0024813709314912558, 0.004943566396832466, 0.004412280861288309, 0.0028584981337189674, 0.007030004169791937, 0.0029101248364895582, 0.004203738644719124, 0.0031456078868359327, 0.00495269987732172, 0.005781135521829128, 0.0022404890041798353, 0.003735309699550271, 0.005266683641821146, 0.0059146881103515625, 0.0019441669574007392, 0.01432698406279087, 0.005250072572380304, 0.005902384407818317, 0.008140036836266518, 0.010495414026081562, 0.013574914075434208, 0.011270851828157902, 0.0044966503046453, 0.005152916070073843, 0.007490701973438263, 0.00424582976847887, 0.005401147063821554, 0.007587797474116087, 0.0034951865673065186, 0.01692531257867813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8267797827720642, 0.0017052805051207542, 0.004864788148552179, 0.004741846118122339, 0.003009272739291191, 0.006478952709585428, 0.0026514590717852116, 0.003231625072658062, 0.0027473748195916414, 0.006160551682114601, 0.005152330733835697, 0.0020972397178411484, 0.004268817603588104, 0.0050050667487084866, 0.004514093976467848, 0.0017881619278341532, 0.006746634375303984, 0.004213740583509207, 0.005513621028512716, 0.010452551767230034, 0.008669338189065456, 0.011603893712162971, 0.008011850528419018, 0.005314223002642393, 0.006679321173578501, 0.008646314032375813, 0.004274268168956041, 0.0048014516942203045, 0.0074241687543690205, 0.0026406256947666407, 0.007561185397207737, 0.012250106781721115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8088124394416809, 0.0025960616767406464, 0.0035516764037311077, 0.0027002922724932432, 0.0020166656468063593, 0.006641461048275232, 0.0018484181491658092, 0.0033754585310816765, 0.002543393522500992, 0.005753929726779461, 0.005089261569082737, 0.002146670129150152, 0.0025103914085775614, 0.003501150757074356, 0.006566417403519154, 0.0011523711727932096, 0.018407931551337242, 0.004472229164093733, 0.005720810499042273, 0.0056523815728724, 0.007404782809317112, 0.016796747222542763, 0.010093830525875092, 0.004214202053844929, 0.006554767489433289, 0.006165129132568836, 0.0042794132605195045, 0.004880798980593681, 0.00663576228544116, 0.0030209277756512165, 0.0225834958255291, 0.007248702924698591, 0.00506203155964613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7306621670722961, 0.0021939887665212154, 0.005337754730135202, 0.004430422093719244, 0.003172335447743535, 0.02520778402686119, 0.002839141758158803, 0.003550024004653096, 0.0042471615597605705, 0.0050717927515506744, 0.007918071001768112, 0.0031001046299934387, 0.0038178893737494946, 0.006119654979556799, 0.006653147749602795, 0.0022978370543569326, 0.020114293321967125, 0.006597278639674187, 0.006545282434672117, 0.006520358845591545, 0.011323846876621246, 0.012850888073444366, 0.01177010964602232, 0.004773370455950499, 0.005226407665759325, 0.006665849592536688, 0.00451305229216814, 0.005760988686233759, 0.008343130350112915, 0.004823269322514534, 0.02374635823071003, 0.00816982239484787, 0.00497418874874711, 0.03066219948232174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8135018944740295, 0.0019939809571951628, 0.005408898461610079, 0.0044659581035375595, 0.002718302421271801, 0.008330103009939194, 0.0021374591160565615, 0.0029215768445283175, 0.0023408259730786085, 0.005026697181165218, 0.005190200638025999, 0.0022532520815730095, 0.002775324508547783, 0.005612560082226992, 0.004323678091168404, 0.001710647251456976, 0.005430412478744984, 0.003880223026499152, 0.005508115515112877, 0.007499606814235449, 0.0063594672828912735, 0.011990510858595371, 0.008480817079544067, 0.004219289403408766, 0.00520326429978013, 0.00664220517501235, 0.003116280073300004, 0.0036904485896229744, 0.006126107648015022, 0.0028672770131379366, 0.00627185357734561, 0.009213710203766823, 0.006464719772338867, 0.010275078006088734, 0.01604916714131832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7804050445556641, 0.0023300177417695522, 0.0048388149589300156, 0.003716117702424526, 0.002585719572380185, 0.007885513827204704, 0.002471877494826913, 0.0033308013807982206, 0.0029966365545988083, 0.0034549476113170385, 0.004372422583401203, 0.0023002494126558304, 0.0029644176829606295, 0.00541192339733243, 0.0070467619225382805, 0.0020887318532913923, 0.013460682705044746, 0.004773719236254692, 0.0048519521951675415, 0.00751044787466526, 0.008605710230767727, 0.017953457310795784, 0.010919828899204731, 0.0033611920662224293, 0.0036987927742302418, 0.00508158840239048, 0.003516816534101963, 0.005728862248361111, 0.005899680778384209, 0.003065371885895729, 0.016914622858166695, 0.009676038287580013, 0.0037486725486814976, 0.010840659029781818, 0.013886799104511738, 0.008305130526423454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7508344650268555, 0.00296442536637187, 0.00739671615883708, 0.005121945403516293, 0.003904681885614991, 0.008413005620241165, 0.0038984958082437515, 0.0035519320517778397, 0.003197159618139267, 0.00510765565559268, 0.00609572371467948, 0.002853984013199806, 0.003998727537691593, 0.007569889072328806, 0.004143643658608198, 0.0021498885471373796, 0.0043258764781057835, 0.00461502093821764, 0.006219301372766495, 0.009702088311314583, 0.009320953860878944, 0.01182976271957159, 0.008549586869776249, 0.004964277148246765, 0.005098076071590185, 0.009590007364749908, 0.004618646577000618, 0.005464369896799326, 0.007307784166187048, 0.0034845503978431225, 0.004856376443058252, 0.011458540335297585, 0.0070553133264184, 0.009543749503791332, 0.02168387733399868, 0.011267716065049171, 0.017841706052422523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7513970136642456, 0.0038721614982932806, 0.005980572197586298, 0.005033767316490412, 0.0025412740651518106, 0.005978083238005638, 0.0036074742674827576, 0.004166534636169672, 0.002659902209416032, 0.004240579903125763, 0.005110020283609629, 0.0021894369274377823, 0.003258831100538373, 0.004611416719853878, 0.004888332914561033, 0.0022789721842855215, 0.010912630707025528, 0.004250850062817335, 0.005428832024335861, 0.007698925212025642, 0.00836227834224701, 0.015811065211892128, 0.01274695061147213, 0.0036822264082729816, 0.004379500634968281, 0.0073603554628789425, 0.004057864658534527, 0.004861600697040558, 0.006053995806723833, 0.0031710248440504074, 0.013505238108336926, 0.009571589529514313, 0.005961078219115734, 0.007277546916157007, 0.02283443883061409, 0.009645556099712849, 0.015644894912838936, 0.00496720289811492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7454784512519836, 0.0019278228282928467, 0.004611908923834562, 0.0038949833251535892, 0.0030921536963433027, 0.007725678384304047, 0.002661324106156826, 0.0036903293803334236, 0.003123044967651367, 0.005083587486296892, 0.005904884077608585, 0.0021008923649787903, 0.0039417436346411705, 0.005177387967705727, 0.004629337228834629, 0.0017227972857654095, 0.007994254119694233, 0.0046922932378947735, 0.005655399989336729, 0.009227754548192024, 0.010900185443460941, 0.012066083960235119, 0.008771242573857307, 0.005212294869124889, 0.005288467276841402, 0.008721662685275078, 0.0044136615470051765, 0.004755205940455198, 0.0074115595780313015, 0.003364768112078309, 0.009234352968633175, 0.01173621229827404, 0.006078252103179693, 0.010140709578990936, 0.016437048092484474, 0.008033998310565948, 0.013073637150228024, 0.0036094938404858112, 0.01841508224606514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7508793473243713, 0.001853910624049604, 0.00470891734585166, 0.0027244226075708866, 0.0025591629091650248, 0.007369253318756819, 0.0023602894507348537, 0.002985491417348385, 0.002792934887111187, 0.004392659291625023, 0.005039607640355825, 0.002121151192113757, 0.0029228648636490107, 0.0047814007848501205, 0.0061240228824317455, 0.0015255126636475325, 0.009307332336902618, 0.0045847767032682896, 0.005577925126999617, 0.007240885868668556, 0.008383960463106632, 0.014269215986132622, 0.008811014704406261, 0.003882840508595109, 0.004708742722868919, 0.006925453897565603, 0.004313462879508734, 0.0054455045610666275, 0.0074337017722427845, 0.003324043471366167, 0.010976669378578663, 0.009220633655786514, 0.0054584224708378315, 0.009987163357436657, 0.014603523537516594, 0.008062022738158703, 0.01180076040327549, 0.00337903737090528, 0.020493535324931145, 0.006668320391327143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7107994556427002, 0.0020385573152452707, 0.0037758550606667995, 0.0037430748343467712, 0.001990590011700988, 0.007980609312653542, 0.001680270186625421, 0.0036101348232477903, 0.002707031788304448, 0.003977136220782995, 0.005060739815235138, 0.0019451957195997238, 0.002303970977663994, 0.004686882719397545, 0.008601292967796326, 0.001361591275781393, 0.016649816185235977, 0.004411219619214535, 0.005081293173134327, 0.007737834472209215, 0.007106319535523653, 0.01625506579875946, 0.011619134806096554, 0.003452148288488388, 0.004327239468693733, 0.006690613925457001, 0.0034822348970919847, 0.0043541137129068375, 0.006181436590850353, 0.0024315572809427977, 0.02020438015460968, 0.010081649757921696, 0.005014886613935232, 0.011003990657627583, 0.017088275402784348, 0.006534912623465061, 0.0150190070271492, 0.0033772580791264772, 0.0367683507502079, 0.00508674792945385, 0.00377812422811985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7787640690803528, 0.0018686343682929873, 0.0032357664313167334, 0.0031801259610801935, 0.001623462070710957, 0.006471135187894106, 0.0018855294911190867, 0.0026758683379739523, 0.0021340087987482548, 0.0034850877709686756, 0.004217913374304771, 0.0015277705388143659, 0.0024913735687732697, 0.0034838696010410786, 0.00438762828707695, 0.001263921265490353, 0.01218617707490921, 0.00438063545152545, 0.00406529288738966, 0.006200480740517378, 0.006312116514891386, 0.012302686460316181, 0.0068810381926596165, 0.002841375069692731, 0.0037459859158843756, 0.005485607776790857, 0.002738697687163949, 0.0035701149608939886, 0.004335758276283741, 0.0021217111498117447, 0.014324742369353771, 0.0076629421673715115, 0.0038149997126311064, 0.008572656661272049, 0.013300547376275063, 0.005689484998583794, 0.011013079434633255, 0.0024947484489530325, 0.02339247241616249, 0.0043863458558917046, 0.0027946610935032368, 0.002689480083063245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.758579432964325, 0.001641062437556684, 0.004213033709675074, 0.00523004587739706, 0.0024294897448271513, 0.00604318268597126, 0.0029794832225888968, 0.002962337573990226, 0.0023817664477974176, 0.004129295237362385, 0.004586957395076752, 0.0018035582033917308, 0.004105930682271719, 0.004966468550264835, 0.0032459062058478594, 0.0017156805843114853, 0.0058905896730721, 0.003871709108352661, 0.004343726206570864, 0.01094136107712984, 0.009046776220202446, 0.009797816164791584, 0.007023327052593231, 0.0039695389568805695, 0.004376842640340328, 0.008634820580482483, 0.004138054791837931, 0.0051794154569506645, 0.005167825613170862, 0.002294495003297925, 0.006951950490474701, 0.013438750058412552, 0.004797731060534716, 0.008015947416424751, 0.015400085598230362, 0.00803188793361187, 0.013167024590075016, 0.002896640682592988, 0.01075225044041872, 0.006899484898895025, 0.0030392888002097607, 0.00338475639000535, 0.007534358650445938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7260456681251526, 0.0026574619114398956, 0.0038920447696000338, 0.0035861574579030275, 0.0022123774979263544, 0.006177054718136787, 0.002110264264047146, 0.003340726951137185, 0.0026490194723010063, 0.0044591352343559265, 0.004918734543025494, 0.0018893684027716517, 0.0022684999275952578, 0.004193632397800684, 0.005995826330035925, 0.001388246426358819, 0.01338705513626337, 0.0043881237506866455, 0.0050391643308103085, 0.006590043194591999, 0.008151251822710037, 0.016548676416277885, 0.010580319911241531, 0.0035650685895234346, 0.004846971947699785, 0.006556270178407431, 0.0035096267238259315, 0.0043884082697331905, 0.0058204978704452515, 0.0025320802815258503, 0.01604437083005905, 0.008255441673099995, 0.004671725444495678, 0.008374780416488647, 0.015722164884209633, 0.00676531158387661, 0.013267760165035725, 0.0031274922657757998, 0.028322819620370865, 0.005575166083872318, 0.0035987566225230694, 0.00375176128000021, 0.0050686998292803764, 0.0037660717498511076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7351841926574707, 0.0017057236982509494, 0.005190884228795767, 0.0036837588995695114, 0.002290953416377306, 0.007393514737486839, 0.003055931767448783, 0.0026737446896731853, 0.0030190765392035246, 0.005712835118174553, 0.0050799669697880745, 0.001938028377480805, 0.0036061578430235386, 0.004695103969424963, 0.0040372880175709724, 0.0013066406827419996, 0.005402642767876387, 0.004621308296918869, 0.0054614972323179245, 0.009448579512536526, 0.009231860749423504, 0.011804407462477684, 0.006323311943560839, 0.0047761257737874985, 0.0059865256771445274, 0.008225822821259499, 0.004080723971128464, 0.005688848439604044, 0.008490088395774364, 0.003013313515111804, 0.006203655153512955, 0.011445720680058002, 0.0064075361005961895, 0.009659758768975735, 0.01220723707228899, 0.008887562900781631, 0.0122520225122571, 0.002828975673764944, 0.011430438607931137, 0.008069484494626522, 0.004306972026824951, 0.003593414556235075, 0.00508217653259635, 0.00297547341324389, 0.011520802974700928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7499460577964783, 0.0019080229103565216, 0.005042970180511475, 0.00244902353733778, 0.00239128852263093, 0.006084596272557974, 0.0021251316647976637, 0.003363874042406678, 0.0023131431080400944, 0.003449356649070978, 0.00513430405408144, 0.0025177726056426764, 0.0025403937324881554, 0.004034862853586674, 0.0035108791198581457, 0.0012495095143094659, 0.008919152431190014, 0.0056887418031692505, 0.0047497255727648735, 0.0047961995005607605, 0.010016846470534801, 0.01010683923959732, 0.007154704071581364, 0.003657910507172346, 0.003346614073961973, 0.0059207710437476635, 0.0028479781467467546, 0.005074887070804834, 0.0061519150622189045, 0.003552926704287529, 0.010085382498800755, 0.006284621544182301, 0.005038768518716097, 0.007044012192636728, 0.013731622137129307, 0.007314551621675491, 0.009793521836400032, 0.00303052831441164, 0.018776465207338333, 0.005243844352662563, 0.003753366880118847, 0.0026591799687594175, 0.002871519885957241, 0.004107688087970018, 0.009865458123385906, 0.010353020392358303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6422825455665588, 0.0027042534202337265, 0.0051707676611840725, 0.0037249200977385044, 0.002191143110394478, 0.009089574217796326, 0.002068151254206896, 0.0037820241414010525, 0.00304387416690588, 0.00627999659627676, 0.006154743488878012, 0.0030017129611223936, 0.0024596620351076126, 0.0039888103492558, 0.008931750431656837, 0.001895659719593823, 0.01947771944105625, 0.007766425609588623, 0.005987650249153376, 0.005394826643168926, 0.006364436354488134, 0.018325285986065865, 0.011535171419382095, 0.004306540824472904, 0.006855516228824854, 0.006287493743002415, 0.003422197187319398, 0.005690448917448521, 0.008161108940839767, 0.004214435815811157, 0.02389482781291008, 0.00648316228762269, 0.007038828916847706, 0.012152280658483505, 0.015339224599301815, 0.007656054105609655, 0.013401441276073456, 0.004190357401967049, 0.03614803031086922, 0.005927364807575941, 0.004994681570678949, 0.00412793830037117, 0.005281491205096245, 0.0053717708215117455, 0.011800935491919518, 0.009068680927157402, 0.006564039271324873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7684469819068909, 0.0019372524693608284, 0.004155109636485577, 0.002459825249388814, 0.0022870078682899475, 0.006543186027556658, 0.0025275873485952616, 0.0021658623591065407, 0.0026768932584673166, 0.003917308058589697, 0.0041566276922822, 0.0017174722161144018, 0.002354052383452654, 0.004012736491858959, 0.003344126045703888, 0.0010180558310821652, 0.004512030631303787, 0.0035191562492400408, 0.004289563279598951, 0.006859470158815384, 0.009527204558253288, 0.010602605529129505, 0.005857336800545454, 0.0037410061340779066, 0.004006712231785059, 0.006123736500740051, 0.0032879156060516834, 0.004974440671503544, 0.006271013990044594, 0.002412959933280945, 0.005173512734472752, 0.008253254927694798, 0.0036298467312008142, 0.008306056261062622, 0.010897383093833923, 0.006713727954775095, 0.009535199962556362, 0.002390296896919608, 0.011286554858088493, 0.005857448559254408, 0.0031796202529221773, 0.0032882008235901594, 0.0030682480428367853, 0.002839081222191453, 0.008807582780718803, 0.009051927365362644, 0.0037649611476808786, 0.004251642152667046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6207239627838135, 0.0019301658030599356, 0.004452905151993036, 0.003916025627404451, 0.002635756740346551, 0.021364431828260422, 0.0024806528817862272, 0.002947703003883362, 0.003578617237508297, 0.004179910756647587, 0.006644126493483782, 0.0025925717782229185, 0.0030843871645629406, 0.00515962578356266, 0.005535557400435209, 0.0019363116007298231, 0.01702835038304329, 0.00540555827319622, 0.005594838410615921, 0.0057749152183532715, 0.010003292933106422, 0.01106790080666542, 0.010358721949160099, 0.004030987154692411, 0.004379876423627138, 0.0056288596242666245, 0.003822954837232828, 0.0049783638678491116, 0.006902480032294989, 0.003906955011188984, 0.01985182613134384, 0.007100398652255535, 0.004046188667416573, 0.026192080229520798, 0.01063976064324379, 0.00671171210706234, 0.009075946174561977, 0.00445330236107111, 0.03505397588014603, 0.005528248380869627, 0.004773369058966637, 0.004066356457769871, 0.005388038232922554, 0.004567233845591545, 0.011072123423218727, 0.007667443249374628, 0.0041422974318265915, 0.006139710545539856, 0.0314832367002964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7170909643173218, 0.0018801905680447817, 0.004652001429349184, 0.0026529759634286165, 0.0026302023325115442, 0.005195446778088808, 0.0022402103058993816, 0.0032620399724692106, 0.002384823514148593, 0.00375976599752903, 0.005170176737010479, 0.0023952010087668896, 0.002532358979806304, 0.003951769322156906, 0.00404878705739975, 0.0013442998751997948, 0.01177947223186493, 0.005484989378601313, 0.004747240804135799, 0.004619077313691378, 0.01022990420460701, 0.010328542441129684, 0.007750596385449171, 0.0036433744244277477, 0.0037435905542224646, 0.0061557600274682045, 0.0029913587495684624, 0.005139253102242947, 0.005865515675395727, 0.003215380245819688, 0.0134112648665905, 0.005939489230513573, 0.005007543135434389, 0.006289911922067404, 0.012656761333346367, 0.006968023255467415, 0.009223206900060177, 0.002891757758334279, 0.02291211672127247, 0.005315587390214205, 0.003405614523217082, 0.00300232763402164, 0.0031698259990662336, 0.004463530145585537, 0.008701697923243046, 0.00888027809560299, 0.003196491627022624, 0.003727829549461603, 0.007330105174332857, 0.012621413916349411, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7155146598815918, 0.0018297478090971708, 0.004286212846636772, 0.005202405154705048, 0.0024836985394358635, 0.00570648442953825, 0.0030068408232182264, 0.0029190154746174812, 0.0023567641619592905, 0.003960352391004562, 0.0044261091388762, 0.0018333983607590199, 0.003885152516886592, 0.005018450785428286, 0.0031838715076446533, 0.0017034237971529365, 0.005858430173248053, 0.003665454452857375, 0.004299838561564684, 0.009942627511918545, 0.008510326966643333, 0.009169760160148144, 0.00698794424533844, 0.003694942919537425, 0.004103075247257948, 0.008011075668036938, 0.0038606885354965925, 0.004959695506840944, 0.004866703413426876, 0.002187908161431551, 0.006785910576581955, 0.012028400786221027, 0.0045826067216694355, 0.007214432582259178, 0.014376656152307987, 0.007574708200991154, 0.011970655992627144, 0.002818828681483865, 0.010175284929573536, 0.0063693830743432045, 0.0028419599402695894, 0.0032225053291767836, 0.0069749378599226475, 0.003220953745767474, 0.008969797752797604, 0.008333752863109112, 0.0035962569527328014, 0.0036743860691785812, 0.007963491603732109, 0.012808318249881268, 0.007061684038490057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6824939846992493, 0.0023301299661397934, 0.006706184707581997, 0.002965121529996395, 0.0037743286229670048, 0.008789191022515297, 0.0031794810201972723, 0.0036701993085443974, 0.0029419627971947193, 0.004652808886021376, 0.005843096878379583, 0.0024334618356078863, 0.003333097090944648, 0.006212667096406221, 0.003082426032051444, 0.001890860847197473, 0.004288706928491592, 0.00391201488673687, 0.00579817546531558, 0.006789319217205048, 0.012246417813003063, 0.011970793828368187, 0.008186452090740204, 0.003768474794924259, 0.0045012133195996284, 0.007099843584001064, 0.0045007928274571896, 0.005101705901324749, 0.006923107896000147, 0.004490029998123646, 0.004629628732800484, 0.008408167399466038, 0.005324085243046284, 0.009850353002548218, 0.014694069512188435, 0.009639528580009937, 0.010555638000369072, 0.003533428767696023, 0.008363625966012478, 0.006757792551070452, 0.00402423832565546, 0.0038813676219433546, 0.0034995710011571646, 0.003678204258903861, 0.01866488717496395, 0.011453901417553425, 0.004922602791339159, 0.0041313162073493, 0.011456659063696861, 0.010133817791938782, 0.0035575521178543568, 0.00496345479041338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6915627121925354, 0.002082636347040534, 0.005226495210081339, 0.00380336819216609, 0.003393649123609066, 0.007426782511174679, 0.0031070394907146692, 0.0028542596846818924, 0.003156578168272972, 0.0051079485565423965, 0.005194652825593948, 0.0023303464986383915, 0.0040021371096372604, 0.0046200877986848354, 0.003746847389265895, 0.001737875398248434, 0.004766894970089197, 0.004588406998664141, 0.004976628348231316, 0.009164496324956417, 0.009793662466108799, 0.01024666242301464, 0.006695431657135487, 0.005254071671515703, 0.005090410355478525, 0.008418411947786808, 0.003739663166925311, 0.005123042967170477, 0.00699375057592988, 0.002802816918119788, 0.005325864534825087, 0.01073868665844202, 0.005363938864320517, 0.008689514361321926, 0.012937833555042744, 0.007884505204856396, 0.009600929915904999, 0.0029726300854235888, 0.009757173247635365, 0.008073567412793636, 0.003588269231840968, 0.003575040027499199, 0.004582584369927645, 0.0035939146764576435, 0.008406982757151127, 0.009334213100373745, 0.0037140180356800556, 0.0046915458515286446, 0.009792196564376354, 0.012900091707706451, 0.004522464703768492, 0.003326835809275508, 0.00961947999894619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.754885733127594, 0.001982711488381028, 0.0025315217208117247, 0.002557475585490465, 0.001332457410171628, 0.004743257071822882, 0.0016111339209601283, 0.002195919631049037, 0.0018157141748815775, 0.0033825046848505735, 0.003123814007267356, 0.001211469410918653, 0.0014925641007721424, 0.0027167941443622112, 0.0046607679687440395, 0.0009578412864357233, 0.01254219375550747, 0.00222612707875669, 0.003815225325524807, 0.0044273072853684425, 0.005384644493460655, 0.01015677023679018, 0.009015192277729511, 0.002302527194842696, 0.003765077330172062, 0.004029375500977039, 0.0024869022890925407, 0.002974580740556121, 0.004477229434996843, 0.001641184207983315, 0.014551911503076553, 0.005275452509522438, 0.0028897833544760942, 0.00648125447332859, 0.008627476170659065, 0.00425832299515605, 0.007609032094478607, 0.0022856437135487795, 0.025301611050963402, 0.003514203941449523, 0.002597901038825512, 0.002844033297151327, 0.0034940612968057394, 0.002289482392370701, 0.006950815208256245, 0.005785602610558271, 0.003491521580144763, 0.0030778618529438972, 0.007108832243829966, 0.008177979849278927, 0.0035494891926646233, 0.002057319739833474, 0.003053469816222787, 0.004281031433492899, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6790143251419067, 0.0027427251916378736, 0.0038747796788811684, 0.003546306863427162, 0.0023276754654943943, 0.005779630038887262, 0.002261150162667036, 0.0032272636890411377, 0.0026891480665653944, 0.00440211733803153, 0.004622358828783035, 0.00197271048091352, 0.0023440918885171413, 0.004241419956088066, 0.005448197480291128, 0.0014358276966959238, 0.011007603257894516, 0.004122082144021988, 0.004932512529194355, 0.0063727842643857, 0.007736319676041603, 0.014171076938509941, 0.00964448694139719, 0.003608266357332468, 0.004679350648075342, 0.006120145320892334, 0.003262557089328766, 0.004298996180295944, 0.005639397539198399, 0.002482326701283455, 0.012838451191782951, 0.007798409555107355, 0.004478356335312128, 0.007531425449997187, 0.01402510330080986, 0.006319974549114704, 0.011906768195331097, 0.003038558876141906, 0.022364677861332893, 0.005401712376624346, 0.0034022293984889984, 0.003510065609589219, 0.004670251626521349, 0.0035561569966375828, 0.008481253869831562, 0.009326386265456676, 0.0038092099130153656, 0.0042466712184250355, 0.008337073028087616, 0.013613780029118061, 0.00467597646638751, 0.002904619090259075, 0.005187555681914091, 0.0069784256629645824, 0.0035893055610358715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7925981283187866, 0.0012567793019115925, 0.0022428904194384813, 0.002511889673769474, 0.0013330891961231828, 0.004666131921112537, 0.0013503000373020768, 0.001714165904559195, 0.0015682991361245513, 0.0029937124345451593, 0.0030371583998203278, 0.0010133060859516263, 0.002197894500568509, 0.0028205488342791796, 0.0024355335626751184, 0.0007851572008803487, 0.0045894659124314785, 0.002703265752643347, 0.0029945604037493467, 0.0063850455917418, 0.004750500433146954, 0.009183344431221485, 0.004295609425753355, 0.002730955369770527, 0.0031889881938695908, 0.00463528698310256, 0.0020380911882966757, 0.0023198570124804974, 0.0032356553710997105, 0.00127730134408921, 0.005329708103090525, 0.008052263408899307, 0.003209166694432497, 0.006165879312902689, 0.009972571395337582, 0.004259190056473017, 0.008574627339839935, 0.0015664621023461223, 0.010314974933862686, 0.004100427962839603, 0.001984409289434552, 0.0019927688408643007, 0.0035877744667232037, 0.001775162760168314, 0.005384557414799929, 0.006308653857558966, 0.0021048637572675943, 0.002640186343342066, 0.007062399294227362, 0.009192313067615032, 0.0034918494056910276, 0.002000583568587899, 0.004377013072371483, 0.005272409413009882, 0.0017836509505286813, 0.0006433880771510303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.698692262172699, 0.001918025896884501, 0.0043091136030852795, 0.0035302024334669113, 0.0025991767179220915, 0.006228314246982336, 0.0020697745494544506, 0.0028622455429285765, 0.002551811980083585, 0.004158210940659046, 0.004455968271940947, 0.0019606081768870354, 0.002786422846838832, 0.004499615170061588, 0.004187646321952343, 0.0012244994286447763, 0.00534422043710947, 0.00347314914688468, 0.004807267338037491, 0.007991024293005466, 0.008196714334189892, 0.009054157882928848, 0.007551289163529873, 0.004396882839500904, 0.00420586671680212, 0.006869304459542036, 0.0028883032500743866, 0.004056257661432028, 0.00655245129019022, 0.0024212796706706285, 0.0060361940413713455, 0.009817042388021946, 0.004913820885121822, 0.007700993213802576, 0.013435657136142254, 0.006753399036824703, 0.010980817489326, 0.0028140167705714703, 0.012505494989454746, 0.006364082917571068, 0.003183202352374792, 0.0027275101747363806, 0.004283796064555645, 0.002839295892044902, 0.009166338481009007, 0.00955656822770834, 0.003717332147061825, 0.0037298621609807014, 0.008486609905958176, 0.01339718233793974, 0.00424785353243351, 0.002741146832704544, 0.006883521564304829, 0.007502345368266106, 0.0029539410024881363, 0.0013259347761049867, 0.006094055715948343, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6655088663101196, 0.0018439703853800893, 0.0047733536921441555, 0.0034364473540335894, 0.002503633266314864, 0.007244185544550419, 0.0021361829712986946, 0.002604659181088209, 0.002685314742848277, 0.003894008696079254, 0.004466934595257044, 0.0018306294223293662, 0.0024169113021343946, 0.004383348859846592, 0.0048258379101753235, 0.001060320297256112, 0.007360019255429506, 0.003638406051322818, 0.004663581494241953, 0.008177448064088821, 0.010050863027572632, 0.015198210254311562, 0.00796661339700222, 0.003841293742880225, 0.003934004344046116, 0.007157408632338047, 0.0034089130349457264, 0.004842968191951513, 0.006154483649879694, 0.0021102610044181347, 0.008635002188384533, 0.010668633505702019, 0.0046234470792114735, 0.009311863221228123, 0.01183820329606533, 0.007928036153316498, 0.009803896769881248, 0.002531260484829545, 0.017135795205831528, 0.006513533648103476, 0.0033139169681817293, 0.0031475620344281197, 0.004235117696225643, 0.003194302087649703, 0.008876764215528965, 0.010133378207683563, 0.003091396065428853, 0.0043603344820439816, 0.00998916570097208, 0.016123482957482338, 0.004214804153889418, 0.00221744691953063, 0.005797124933451414, 0.007257666438817978, 0.0033774320036172867, 0.0016981424996629357, 0.007950510829687119, 0.00791271310299635, 0.0, 0.0, 0.0, 0.0], [0.6549370288848877, 0.002244319999590516, 0.003973026294261217, 0.003972870763391256, 0.002434179652482271, 0.005553503055125475, 0.0025262993294745684, 0.0031472474802285433, 0.002515405183658004, 0.0040495870634913445, 0.004473748616874218, 0.001924925483763218, 0.0028840322047472, 0.004267861135303974, 0.004545316100120544, 0.0015967220533639193, 0.010376873426139355, 0.003954715095460415, 0.004731576424092054, 0.006679595448076725, 0.008338321931660175, 0.010456105694174767, 0.009233951568603516, 0.0035470055881887674, 0.004152881447225809, 0.005764517467468977, 0.0033140394371002913, 0.004486286547034979, 0.005919368471950293, 0.0026011685840785503, 0.01224302127957344, 0.008452428504824638, 0.004489556420594454, 0.007072898093611002, 0.013017535209655762, 0.00638682721182704, 0.010784346610307693, 0.0033069185446947813, 0.020038167014718056, 0.005326690152287483, 0.003459770930930972, 0.0034483177587389946, 0.005069355946034193, 0.00347986351698637, 0.00879425834864378, 0.008618928492069244, 0.003916234243661165, 0.0041113607585430145, 0.007797115948051214, 0.011576344259083271, 0.005162773188203573, 0.0032163579016923904, 0.005995269864797592, 0.0073106298223137856, 0.0036242948845028877, 0.001448331749998033, 0.010422475636005402, 0.007734737824648619, 0.015092690475285053, 0.0, 0.0, 0.0], [0.6181995272636414, 0.0025393464602530003, 0.005476771388202906, 0.0034503096248954535, 0.0027236975729465485, 0.0070496778935194016, 0.002444548299536109, 0.003244757652282715, 0.002782854251563549, 0.003733578370884061, 0.004640820436179638, 0.0023576843086630106, 0.002397975418716669, 0.0046174488961696625, 0.006172551307827234, 0.0015141996555030346, 0.010224089957773685, 0.00395227549597621, 0.004937238525599241, 0.007066034246236086, 0.009352822788059711, 0.015664808452129364, 0.011073099449276924, 0.0036299191415309906, 0.0037698529195040464, 0.006422029342502356, 0.0035608543548732996, 0.005625982768833637, 0.006497915834188461, 0.0027082215528935194, 0.011934288777410984, 0.008950838819146156, 0.004789718426764011, 0.00860871747136116, 0.013857814483344555, 0.0081753795966506, 0.010052287951111794, 0.0034788898192346096, 0.0206303671002388, 0.005821748171001673, 0.0035799681209027767, 0.0034770008642226458, 0.004066250752657652, 0.004065892193466425, 0.010177228599786758, 0.011226443573832512, 0.003773237345740199, 0.004506452940404415, 0.009324128739535809, 0.015705956146121025, 0.004095491953194141, 0.002749734092503786, 0.006288960110396147, 0.007044143974781036, 0.004333373159170151, 0.001825526007451117, 0.010855560190975666, 0.008298111148178577, 0.014939626678824425, 0.005535852164030075, 0.0, 0.0], [0.6996461749076843, 0.0015996412839740515, 0.004003928974270821, 0.004117444157600403, 0.002608469221740961, 0.00503572029992938, 0.0023987300228327513, 0.0024196573067456484, 0.002196537796407938, 0.004930692724883556, 0.003917303867638111, 0.0017785864183679223, 0.0032224860042333603, 0.0041521345265209675, 0.003418956184759736, 0.0014783729566261172, 0.004758970346301794, 0.002955736592411995, 0.0045066759921610355, 0.008196426555514336, 0.007003767881542444, 0.008601084351539612, 0.00679315160959959, 0.004091346170753241, 0.005231673829257488, 0.006489047314971685, 0.0033557736314833164, 0.003910590894520283, 0.005930917803198099, 0.0019978638738393784, 0.005280833225697279, 0.009490473195910454, 0.004576037637889385, 0.006179898511618376, 0.009140901267528534, 0.006433791946619749, 0.008277839981019497, 0.002364899031817913, 0.008113685064017773, 0.007218521554023027, 0.00286603020504117, 0.0032633694354444742, 0.00526095787063241, 0.0026452671736478806, 0.00866131391376257, 0.006903425324708223, 0.003486473811790347, 0.003636997891589999, 0.006793306674808264, 0.010084290988743305, 0.005168967414647341, 0.0031185189727693796, 0.006312998943030834, 0.007423895876854658, 0.002664047060534358, 0.0011854490730911493, 0.0045279860496521, 0.005444912239909172, 0.006584597285836935, 0.00427080225199461, 0.01187154557555914, 0.0], [0.7406506538391113, 0.0009827669709920883, 0.002481555100530386, 0.003017698647454381, 0.002469846745952964, 0.003925081808120012, 0.0041053202003240585, 0.0015533528057858348, 0.0018973415717482567, 0.0020940378308296204, 0.0025587633717805147, 0.0013148693833500147, 0.004122463520616293, 0.0044217961840331554, 0.0019267959287390113, 0.0018036332912743092, 0.003403176786378026, 0.002037360332906246, 0.0028038830496370792, 0.007349316496402025, 0.009065359830856323, 0.0038074792828410864, 0.004681629128754139, 0.0027957819402217865, 0.0022236709482967854, 0.004228673409670591, 0.002934674732387066, 0.005113436374813318, 0.0041300030425190926, 0.0017403929959982634, 0.004155406262725592, 0.009244761429727077, 0.0019802008755505085, 0.005501041188836098, 0.009680382907390594, 0.00550718791782856, 0.008542895317077637, 0.0027243245858699083, 0.006156677380204201, 0.006277155131101608, 0.0016918618930503726, 0.0023683160543441772, 0.004624109249562025, 0.002238040091469884, 0.004510694183409214, 0.006031283177435398, 0.0023950107861310244, 0.0026329823303967714, 0.006164029706269503, 0.013333446346223354, 0.0048155407421290874, 0.003762237960472703, 0.006598901469260454, 0.00593617744743824, 0.0023482032120227814, 0.0013600821839645505, 0.003290710272267461, 0.004092871677130461, 0.005373071413487196, 0.003822766011580825, 0.012013161554932594, 0.005185586865991354]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630289077758789, 0.03697109594941139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6484466195106506, 0.26222658157348633, 0.08932667225599289, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.48596739768981934, 0.26091909408569336, 0.14470313489437103, 0.10841032862663269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25202134251594543, 0.19155336916446686, 0.291084885597229, 0.18232762813568115, 0.08301281929016113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22716791927814484, 0.0878002867102623, 0.1403079330921173, 0.23840153217315674, 0.25331786274909973, 0.0530044324696064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15647414326667786, 0.02638215199112892, 0.07721028476953506, 0.17041711509227753, 0.37536412477493286, 0.1279291957616806, 0.06622299551963806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22356371581554413, 0.016243185847997665, 0.029892053455114365, 0.061249006539583206, 0.18187125027179718, 0.18408724665641785, 0.1915130466222763, 0.11158054322004318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10669614374637604, 0.005925686098635197, 0.011317705735564232, 0.021654309704899788, 0.07326848059892654, 0.11282385885715485, 0.2974182963371277, 0.3007798492908478, 0.07011564821004868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15362027287483215, 0.004785284399986267, 0.005597691051661968, 0.007312814239412546, 0.02864680252969265, 0.0530642606317997, 0.15412653982639313, 0.31170350313186646, 0.19018597900867462, 0.09095677733421326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12682780623435974, 0.0022533931769430637, 0.001351956627331674, 0.0031752551440149546, 0.009603430517017841, 0.015738805755972862, 0.058046068996191025, 0.17092101275920868, 0.2533193528652191, 0.2684042155742645, 0.09035864472389221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15279580652713776, 0.002299722284078598, 0.0010013434803113341, 0.00036632776027545333, 0.00521021569147706, 0.009152665734291077, 0.016933312639594078, 0.033053841441869736, 0.13871751725673676, 0.3204987049102783, 0.26627373695373535, 0.053696829825639725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14279291033744812, 0.005270672030746937, 0.0017375380266457796, 0.0007363432087004185, 0.0031150009017437696, 0.004059419501572847, 0.009129960089921951, 0.020338160917162895, 0.04678439721465111, 0.17844417691230774, 0.40441450476646423, 0.1537831574678421, 0.029393741860985756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0938665121793747, 0.010687812231481075, 0.005217972211539745, 0.0017573151271790266, 0.002107772743329406, 0.002691013738512993, 0.006660624407231808, 0.013352862559258938, 0.01669679582118988, 0.05865020677447319, 0.2505703568458557, 0.4097483456134796, 0.0729101374745369, 0.05508223921060562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11395492404699326, 0.010473332367837429, 0.004927823320031166, 0.0022587592247873545, 0.002246341435238719, 0.0011279996251687407, 0.003117808373644948, 0.013650084845721722, 0.012686051428318024, 0.0295646283775568, 0.11971687525510788, 0.24043679237365723, 0.12600065767765045, 0.2357165664434433, 0.08412132412195206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13812871277332306, 0.014267588965594769, 0.004612781573086977, 0.0027705486863851547, 0.002928124973550439, 0.0008828555000945926, 0.0013943389058113098, 0.008660240098834038, 0.01509132981300354, 0.02292807027697563, 0.04161147400736809, 0.029862787574529648, 0.09508778899908066, 0.3480881154537201, 0.23401622474193573, 0.03966900706291199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13450999557971954, 0.008774783462285995, 0.002588980831205845, 0.002442363416776061, 0.003923582844436169, 0.0013999748043715954, 0.0010607579024508595, 0.0038814458530396223, 0.00831384863704443, 0.02129637636244297, 0.03681298345327377, 0.025085236877202988, 0.030589012429118156, 0.20278328657150269, 0.33164262771606445, 0.12442708015441895, 0.0604676716029644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17554160952568054, 0.011392027139663696, 0.00428979704156518, 0.0006763187702745199, 0.005164982285350561, 0.00145289720967412, 0.0008428345900028944, 0.001601500902324915, 0.0060132695361971855, 0.021186744794249535, 0.04968727380037308, 0.015421557240188122, 0.03517654165625572, 0.07387852668762207, 0.3274729251861572, 0.15719449520111084, 0.08656870573759079, 0.026438096538186073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11316271126270294, 0.016760636121034622, 0.004126289859414101, 0.0012999101309105754, 0.004438408184796572, 0.002318969462066889, 0.0017247949726879597, 0.0019663870334625244, 0.006339320447295904, 0.0196041502058506, 0.025257423520088196, 0.022328756749629974, 0.010294787585735321, 0.030607759952545166, 0.12315436452627182, 0.08820157498121262, 0.1530279666185379, 0.22598479688167572, 0.14940106868743896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10660461336374283, 0.014832403510808945, 0.006914160680025816, 0.004290629643946886, 0.0048501272685825825, 0.006166853941977024, 0.004036233760416508, 0.0036177996080368757, 0.00326498132199049, 0.00714684696868062, 0.013005423359572887, 0.009438971988856792, 0.005822496023029089, 0.01177673228085041, 0.052576374262571335, 0.04913344234228134, 0.09349056333303452, 0.1860869973897934, 0.3409808874130249, 0.07596343010663986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06683407723903656, 0.010644346475601196, 0.007929209619760513, 0.00466588931158185, 0.0054689268581569195, 0.0059764692559838295, 0.004748292732983828, 0.0024338176008313894, 0.0015651659341529012, 0.003697375999763608, 0.004591153468936682, 0.009870178066194057, 0.0026820036582648754, 0.003332046326249838, 0.003746950998902321, 0.009282716549932957, 0.031112026423215866, 0.15310609340667725, 0.3687170147895813, 0.19851116836071014, 0.10108505934476852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07005743682384491, 0.006617405451834202, 0.0022492483258247375, 0.0013649356551468372, 0.002912640105932951, 0.004045308567583561, 0.004535121377557516, 0.008530108258128166, 0.0037315923254936934, 0.0029997085221111774, 0.002906421897932887, 0.004566712770611048, 0.0034618552308529615, 0.00276511674746871, 0.003475388279184699, 0.002744872821494937, 0.007680652663111687, 0.035287950187921524, 0.166892871260643, 0.26588836312294006, 0.3286125957965851, 0.06867367029190063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12540894746780396, 0.008102706633508205, 0.0016390003729611635, 0.0021636735182255507, 0.0016277157701551914, 0.0012936029816046357, 0.0036480440758168697, 0.008025594055652618, 0.004420657176524401, 0.0032485572155565023, 0.0018727525603026152, 0.0018852477660402656, 0.002397674135863781, 0.0030596957076340914, 0.002692975103855133, 0.0009979986352846026, 0.0027962124440819025, 0.010749436914920807, 0.04414946213364601, 0.11363735049962997, 0.3343348801136017, 0.2223278433084488, 0.09951987117528915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0823986828327179, 0.004373936913907528, 0.0011622554156929255, 0.0006886600749567151, 0.0009628941188566387, 0.0011385466204956174, 0.001937967143021524, 0.005959632340818644, 0.005422220099717379, 0.003599752439185977, 0.0015381018165498972, 0.0013112053275108337, 0.0012151175178587437, 0.002741207368671894, 0.005545698571950197, 0.0014398933853954077, 0.003708135336637497, 0.006518166977912188, 0.02568909153342247, 0.04309011250734329, 0.25695058703422546, 0.22214803099632263, 0.24633967876434326, 0.07412046194076538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07645153254270554, 0.0028822128660976887, 0.0008426313870586455, 0.00027326797135174274, 0.0005339429480955005, 0.0007941392250359058, 0.00075613206718117, 0.0015206891112029552, 0.002204728778451681, 0.002635809825733304, 0.0012135094730183482, 0.0007001099293120205, 0.00036476633977144957, 0.0009113945998251438, 0.003169170580804348, 0.0024040392599999905, 0.004809337668120861, 0.006893008016049862, 0.010905256494879723, 0.009112890809774399, 0.07175274193286896, 0.09200727194547653, 0.46523991227149963, 0.17186304926872253, 0.06975847482681274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06391625106334686, 0.002448000945150852, 0.0007065602694638073, 0.00024162190675269812, 0.0004380192549433559, 0.0007627565646544099, 0.0011034593917429447, 0.0014307197416201234, 0.001860171789303422, 0.003175474237650633, 0.0018453386146575212, 0.0005971036734990776, 0.00017780557391233742, 0.0002515080850571394, 0.0011229569790884852, 0.0014416207559406757, 0.0030026391614228487, 0.00391788687556982, 0.01530043687671423, 0.0069978563115000725, 0.036119554191827774, 0.037024591118097305, 0.2525322437286377, 0.24499079585075378, 0.22538776695728302, 0.09320687502622604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06818991899490356, 0.0024787720758467913, 0.0011678602313622832, 0.0005412424798123538, 0.00024399245739914477, 0.0005612460663542151, 0.0005177294369786978, 0.0004573750775307417, 0.00036578980507329106, 0.0008970628841780126, 0.0010554109467193484, 0.0009428909397684038, 0.00017497291264589876, 0.00018685049144551158, 0.0003796668315771967, 0.0009007215849123895, 0.0016698348335921764, 0.004003285430371761, 0.011590887792408466, 0.005937633570283651, 0.014263414777815342, 0.015733912587165833, 0.13617190718650818, 0.10411563515663147, 0.2931372821331024, 0.25062096118927, 0.08369378000497818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1527165323495865, 0.001389242592267692, 0.0009041542652994394, 9.739206143422052e-05, 0.00020572969515342265, 0.0002349843125557527, 0.0006410047644749284, 0.0006549053941853344, 0.0005822113598696887, 0.0012615423183888197, 0.0029423043597489595, 0.002734727691859007, 0.001169014722108841, 0.0004989187000319362, 0.0010870477417483926, 0.0005205135094001889, 0.0006295634666457772, 0.0011608381755650043, 0.006447000429034233, 0.0036930113565176725, 0.010357849299907684, 0.008789598941802979, 0.05109397694468498, 0.036149535328149796, 0.14568521082401276, 0.22385045886039734, 0.29519519209861755, 0.04930747672915459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05755018815398216, 0.000961571407970041, 0.00032497974461875856, 7.484223897336051e-05, 9.200275962939486e-05, 6.341985135804862e-05, 0.00029810244450345635, 0.00046725597348995507, 0.0006149144028313458, 0.0014473451301455498, 0.004843817092478275, 0.0054591200314462185, 0.00139367685187608, 0.0011041832622140646, 0.0008308214019052684, 0.0005785026587545872, 0.0007126780692487955, 0.001449710107408464, 0.002835094230249524, 0.002383885206654668, 0.0062438612803816795, 0.0026098904199898243, 0.008055067621171474, 0.017129119485616684, 0.07277585566043854, 0.2092934548854828, 0.3674122989177704, 0.17867761850357056, 0.0543166920542717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05508726090192795, 0.0008460559183731675, 0.00025174644542858005, 0.00010345279588364065, 0.00011812719458248466, 0.00010944397217826918, 0.0003702868998516351, 0.0009240753133781254, 0.000890744908247143, 0.0022566502448171377, 0.007673189043998718, 0.01053022500127554, 0.004071095958352089, 0.002563607646152377, 0.0015951568493619561, 0.0008864864357747138, 0.0016041576163843274, 0.0020557951647788286, 0.0035151916090399027, 0.003386764321476221, 0.007029864005744457, 0.004572818987071514, 0.0059618111699819565, 0.00785250123590231, 0.025560958310961723, 0.11208906024694443, 0.23435987532138824, 0.25542062520980835, 0.19340278208255768, 0.05491013452410698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11570952087640762, 0.0016107147093862295, 0.0006207459955476224, 0.0003122714988421649, 0.000441347568994388, 0.0002591531665530056, 0.0006676541524939239, 0.002129903994500637, 0.001562196295708418, 0.0026479163207113743, 0.006952413357794285, 0.00935971550643444, 0.007897306233644485, 0.010322852991521358, 0.004288951400667429, 0.001077754539437592, 0.0016888807294890285, 0.001658232999034226, 0.003831977490335703, 0.006111983209848404, 0.011137139983475208, 0.0038596128579229116, 0.0038937737699598074, 0.0021838301327079535, 0.005910032894462347, 0.03752599656581879, 0.08526711910963058, 0.1451009064912796, 0.341056764125824, 0.13830330967903137, 0.04661006107926369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06405766308307648, 0.0016102558001875877, 0.0011208587093278766, 0.001214600750245154, 0.00048103093286044896, 0.00036694962182082236, 0.0007263164152391255, 0.002768303267657757, 0.0013133804313838482, 0.0011612946400418878, 0.0016142610693350434, 0.0022741947323083878, 0.004682544153183699, 0.009261911734938622, 0.008166378363966942, 0.0004281480214558542, 0.00041775123099796474, 0.00044145630090497434, 0.0026148550678044558, 0.0036266467068344355, 0.014628829434514046, 0.007740041706711054, 0.005378597415983677, 0.0015317224897444248, 0.0013124588876962662, 0.010662886314094067, 0.028834611177444458, 0.03667855262756348, 0.31715652346611023, 0.3469618558883667, 0.07839913666248322, 0.0423659048974514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03587769716978073, 0.0018152729608118534, 0.001576214679516852, 0.0015984534984454513, 0.0010199639946222305, 0.00027872459031641483, 0.00020997803949285299, 0.000888648210093379, 0.000783619936555624, 0.0008165768231265247, 0.0012970807729288936, 0.0018972151447087526, 0.003584324149414897, 0.013095716945827007, 0.014844812452793121, 0.0016279187984764576, 0.0010654526995494962, 0.0007733302772976458, 0.0018040119903162122, 0.0016321268631145358, 0.0049317325465381145, 0.004748289939016104, 0.008461732417345047, 0.0008855501073412597, 0.0006282090325839818, 0.0029494476038962603, 0.008311919867992401, 0.02312912791967392, 0.15432778000831604, 0.24915270507335663, 0.18598635494709015, 0.16877803206443787, 0.10122192651033401, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07296939194202423, 0.006299134809523821, 0.004831929691135883, 0.007494852878153324, 0.009773229248821735, 0.001904912176541984, 0.0014444743283092976, 0.004060008563101292, 0.0028266063891351223, 0.0027988036163151264, 0.0022888046223670244, 0.0010738896671682596, 0.002845452632755041, 0.011062760837376118, 0.014124463312327862, 0.0036444494035094976, 0.0014759886544197798, 0.0012053357204422355, 0.0036297219339758158, 0.0034873755648732185, 0.016036801040172577, 0.0060894382186234, 0.007291468326002359, 0.0016827489016577601, 0.0011131098726764321, 0.0014258999144658446, 0.003184705041348934, 0.002576535101979971, 0.026379253715276718, 0.06172816455364227, 0.08193644881248474, 0.27410680055618286, 0.29599738121032715, 0.06120963394641876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08549552410840988, 0.006954933982342482, 0.00657925009727478, 0.0042000156827270985, 0.008320879191160202, 0.002881372580304742, 0.0018464011372998357, 0.001978765707463026, 0.002397295320406556, 0.0020080129615962505, 0.0009269973379559815, 0.0006106701912358403, 0.00144780776463449, 0.004661153070628643, 0.017373114824295044, 0.0013459218898788095, 0.0008591969963163137, 0.0008322541834786534, 0.002565966686233878, 0.0025222105905413628, 0.008357079699635506, 0.00796899851411581, 0.03997184336185455, 0.003030777210369706, 0.0014187461929395795, 0.0012390395859256387, 0.001734372926875949, 0.0017606087494641542, 0.006089038215577602, 0.017119525000452995, 0.025636062026023865, 0.14369122684001923, 0.35044339299201965, 0.15203358232975006, 0.08369792997837067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.054537128657102585, 0.003574230009689927, 0.0040962654165923595, 0.005074010696262121, 0.008004158735275269, 0.0033120252192020416, 0.0017932637128978968, 0.0011702020419761539, 0.0011557727120816708, 0.0016036983579397202, 0.001226126099936664, 0.0007169638411141932, 0.00025914632715284824, 0.0004977344069629908, 0.0033058871049433947, 0.002143408404663205, 0.001026822137646377, 0.0010508548002690077, 0.0014557192334905267, 0.0009156823507510126, 0.0014436417259275913, 0.0024054558016359806, 0.017249276861548424, 0.005077036563307047, 0.004893740173429251, 0.002165551297366619, 0.0027968301437795162, 0.0017791218124330044, 0.0012196233728900552, 0.002017992315813899, 0.006815304979681969, 0.050331421196460724, 0.17950740456581116, 0.2508406639099121, 0.28108417987823486, 0.09345360100269318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09991040080785751, 0.0026532721240073442, 0.006426513195037842, 0.004406806547194719, 0.0065905372612178326, 0.006254072766751051, 0.004330602008849382, 0.0021933659445494413, 0.0010732177179306746, 0.0009498692816123366, 0.000656390271615237, 0.00033707162947393954, 0.00023894483456388116, 0.0002756392932496965, 0.001432456774637103, 0.0003235091280657798, 0.00017440431111026555, 0.00018281074881087989, 0.001006370410323143, 0.0008422255632467568, 0.001720996806398034, 0.0009468375938013196, 0.007875032722949982, 0.0024479315616190434, 0.003333322936668992, 0.0030734760221093893, 0.0032853896263986826, 0.000773769395891577, 0.0009119387832470238, 0.0013030595146119595, 0.0014125461457297206, 0.00980734545737505, 0.06402447819709778, 0.15749682486057281, 0.29886698722839355, 0.2547900974750519, 0.047671493142843246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15940754115581512, 0.0011479894164949656, 0.0031842603348195553, 0.0018739467486739159, 0.002983217826113105, 0.0019937113393098116, 0.0028902690391987562, 0.0023044596891850233, 0.0009441708098165691, 0.0006861407309770584, 0.0006029547657817602, 0.00045350074651651084, 0.00023061558022163808, 0.00024475331883877516, 0.0006630785646848381, 9.66343650361523e-05, 5.1146129408152774e-05, 5.9531070291996e-05, 0.0004344320623204112, 0.000504586729221046, 0.0016836633440107107, 0.000880498846527189, 0.003422419773414731, 0.0012401685817167163, 0.0024323423858731985, 0.005758194252848625, 0.011425427161157131, 0.0028403003234416246, 0.0022133237216621637, 0.002282878616824746, 0.0019097181502729654, 0.004076208453625441, 0.018350891768932343, 0.04364417865872383, 0.1315506398677826, 0.4249356687068939, 0.10762882977724075, 0.05296775698661804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1503731608390808, 0.0009959578746929765, 0.00110089301597327, 0.002724581863731146, 0.0018398278625681996, 0.0011507092276588082, 0.0015930539229884744, 0.0024784260895103216, 0.0012964269844815135, 0.0016616680659353733, 0.0013343972386792302, 0.0008634756086394191, 0.0006573444115929306, 0.0011495448416098952, 0.0014135531382635236, 0.00032082348479889333, 0.00010730628127930686, 5.300401971908286e-05, 0.00019450002582743764, 0.00029970414470881224, 0.001118152285926044, 0.0005295203300192952, 0.0018235952593386173, 0.0008790433057583869, 0.001729857292957604, 0.0037336188834160566, 0.009449741803109646, 0.00526818260550499, 0.006035011727362871, 0.0047156354412436485, 0.005250251851975918, 0.011291024275124073, 0.014074904844164848, 0.021738270297646523, 0.08200597763061523, 0.18399949371814728, 0.2551276981830597, 0.13606876134872437, 0.08355291187763214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02712048590183258, 0.0001829506945796311, 0.00028041659970767796, 0.0003435718244872987, 0.0005508536705747247, 0.0003718147345352918, 0.0005273421411402524, 0.0007938555208966136, 0.0009189220727421343, 0.0013802259927615523, 0.0019973195157945156, 0.001061872229911387, 0.00034543988294899464, 0.0007973597967065871, 0.0020017558708786964, 0.0007900565396994352, 0.00026423807139508426, 0.00011184746108483523, 0.00012266621342860162, 5.937577225267887e-05, 0.00033665879163891077, 0.00030507228802889585, 0.0014178177807480097, 0.0010861785849556327, 0.0011330535635352135, 0.0021919659338891506, 0.008301488123834133, 0.004931528586894274, 0.00597646739333868, 0.00354191055521369, 0.00375902047380805, 0.008239693939685822, 0.011048302054405212, 0.01286973524838686, 0.03521775081753731, 0.1172766461968422, 0.1556670218706131, 0.24625073373317719, 0.2457922399044037, 0.09463430941104889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.036786433309316635, 0.00010443175415275618, 7.87560420576483e-05, 5.61120941711124e-05, 0.00023268244694918394, 0.000272939883871004, 0.00043686915887519717, 0.0006855598767288029, 0.0015721844974905252, 0.004010282922536135, 0.004615151323378086, 0.001060906914062798, 0.0004894777084700763, 0.0009393329964950681, 0.0035723953042179346, 0.0009756578947417438, 0.0005989047349430621, 0.00020053527259733528, 0.0001888857368612662, 7.808006193954498e-05, 0.000500842637848109, 0.0007421868504025042, 0.004283470567315817, 0.0022548914421349764, 0.0023401109501719475, 0.0019848353695124388, 0.0072953966446220875, 0.003909384831786156, 0.004831851460039616, 0.002668861299753189, 0.0016400071326643229, 0.004236031789332628, 0.006112923379987478, 0.006118017714470625, 0.01471138745546341, 0.03748075291514397, 0.049238551408052444, 0.09146003425121307, 0.26171451807022095, 0.2750433385372162, 0.16447709500789642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021221308037638664, 9.742628026288003e-05, 9.323257836513221e-05, 9.498425788478926e-05, 0.00017791891878005117, 0.0003719894157256931, 0.00040918757440522313, 0.0004045500245410949, 0.0005565895116887987, 0.0018941286252811551, 0.0034595623146742582, 0.0018187746172770858, 0.00038504961412400007, 0.00034628945286385715, 0.0011295025469735265, 0.0008942917338572443, 0.0009475756669417024, 0.0007795448182150722, 0.0004492929729167372, 0.0001486520195612684, 0.00037150373100303113, 0.0003209678689017892, 0.002077218610793352, 0.001576768234372139, 0.0038281246088445187, 0.0035588336177170277, 0.007399162743240595, 0.006749268621206284, 0.004578243475407362, 0.001856057671830058, 0.00070768321165815, 0.0010891800047829747, 0.0016322245355695486, 0.0033754485193639994, 0.006844307761639357, 0.01948726922273636, 0.017018994316458702, 0.043191660195589066, 0.16013644635677338, 0.2693564295768738, 0.32889074087142944, 0.08027371764183044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028055906295776367, 7.780436862958595e-05, 6.334221689030528e-05, 0.00011413055472075939, 8.412803435930982e-05, 0.000124010955914855, 0.00046092490083537996, 0.00043478456791490316, 0.0002045146975433454, 0.0006304231355898082, 0.001326570869423449, 0.0006668887799605727, 0.00021867462783120573, 0.00018346587603446096, 0.0006030008080415428, 0.00019474202417768538, 0.0002941713319160044, 0.00021833441860508174, 0.0005702877533622086, 0.00040303776040673256, 0.0005651545361615717, 0.00015803368296474218, 0.0006032141973264515, 0.000501589325722307, 0.0016921724891290069, 0.003408043645322323, 0.008880109526216984, 0.005074917804449797, 0.006041604094207287, 0.002308348659425974, 0.00035583070712164044, 0.0004660540434997529, 0.00041995939682237804, 0.0003650196304079145, 0.0020610280334949493, 0.007939043454825878, 0.007496834732592106, 0.01548553816974163, 0.03862159326672554, 0.1454220712184906, 0.41101425886154175, 0.20855872333049774, 0.0976317748427391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03136174753308296, 7.939780334709212e-05, 0.00013679439143743366, 5.7587065384723246e-05, 0.00035625341115519404, 0.0002603814355097711, 0.0007513320306316018, 0.0007445958908647299, 0.0005474740173667669, 0.0006762523553334177, 0.001314334338530898, 0.0008936872472986579, 0.0008629949879832566, 0.00039232938433997333, 0.0006379224359989166, 8.180863369489089e-05, 0.0001412072597304359, 0.00019088284170720726, 0.0007442295318469405, 0.0006394942756742239, 0.0014165168395265937, 0.00023607566254213452, 0.0002766341785900295, 0.0001329363731201738, 0.00050193234346807, 0.0018297373317182064, 0.008790740743279457, 0.006370868068188429, 0.01020143087953329, 0.004789040423929691, 0.0006298710941337049, 0.0004782723553944379, 0.0003481352759990841, 0.00024838096578605473, 0.0009207799448631704, 0.0067147561348974705, 0.0064399102702736855, 0.011310206726193428, 0.02468467503786087, 0.06520062685012817, 0.2565825581550598, 0.42518898844718933, 0.07289067655801773, 0.05294550582766533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009172121994197369, 4.788478690898046e-05, 4.97692271892447e-05, 5.98159822402522e-05, 0.00013302307343110442, 0.00011664196063065901, 0.0004920237697660923, 0.0007641269476152956, 0.00044140152749605477, 0.0005489822360686958, 0.000513230508659035, 0.00047923048259690404, 0.00015670809079892933, 0.0003665525873657316, 0.00026038195937871933, 5.287483872962184e-05, 0.00013272413343656808, 0.00015958688163664192, 0.0006411791546270251, 0.0006492527318187058, 0.001963572110980749, 0.00039578787982463837, 0.0002464221906848252, 0.0001461737701902166, 0.00021607326925732195, 0.0015854670200496912, 0.003793303621932864, 0.005316456779837608, 0.011553873308002949, 0.007341465912759304, 0.0019097609911113977, 0.0007789349765516818, 0.0006288046133704484, 0.00018036577966995537, 0.0005870641325600445, 0.002911978168413043, 0.0066041792742908, 0.006739057134836912, 0.016245566308498383, 0.029575107619166374, 0.21230261027812958, 0.2725925147533417, 0.19207815825939178, 0.1482921838760376, 0.0607777014374733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016415711492300034, 5.3423769713845104e-05, 2.2911983251105994e-05, 1.4939413631509524e-05, 0.00016971725563053042, 6.163152283988893e-05, 0.00024355963978450745, 0.0009831455536186695, 0.0008046223083510995, 0.0007831475231796503, 0.0005981047870591283, 0.00013058047625236213, 0.0002456174115650356, 0.00034093481372110546, 0.00031277970992960036, 5.5393647926393896e-05, 7.532450399594381e-05, 8.077525853877887e-05, 0.0002484759606886655, 0.00045183583279140294, 0.004857076797634363, 0.0011276323348283768, 0.00056355947162956, 0.0002911298652179539, 0.0002428749285172671, 0.0007814710843376815, 0.002248166361823678, 0.0012993247946724296, 0.007718059699982405, 0.010137209668755531, 0.003187847090885043, 0.003153488039970398, 0.0027726253028959036, 0.0005194759578444064, 0.0008261626353487372, 0.001552980742417276, 0.004381099715828896, 0.004846892785280943, 0.0070608011446893215, 0.02071547694504261, 0.03799375146627426, 0.1526755690574646, 0.04887230321764946, 0.14899711310863495, 0.4666624367237091, 0.04442288354039192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011031534522771835, 4.544903276837431e-05, 2.7625867005554028e-05, 3.747841765289195e-05, 0.00012979355233255774, 0.00010294400271959603, 0.00020658002176787704, 0.0005636319401673973, 0.0005776450270786881, 0.0006011303048580885, 0.0002030534524237737, 7.886165258241817e-05, 5.7754612498683855e-05, 0.0002316487516509369, 0.00034034837153740227, 7.495344470953569e-05, 0.00016587635036557913, 0.0001473529264330864, 0.0003814790106844157, 0.00038384197978302836, 0.004133992828428745, 0.001300024800002575, 0.0011590172071009874, 0.00051925890147686, 0.00021635055600199848, 0.0004868324031122029, 0.0007063773227855563, 0.0006948213558644056, 0.002557808067649603, 0.0054270862601697445, 0.0026395427994430065, 0.003129582619294524, 0.006118701305240393, 0.0012733854819089174, 0.001116821775212884, 0.001835801056586206, 0.0029240825679153204, 0.0023327430244535208, 0.008070055395364761, 0.012141170911490917, 0.026324467733502388, 0.03741149231791496, 0.05481135472655296, 0.13161972165107727, 0.5147477984428406, 0.05850738659501076, 0.10240539163351059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015597253106534481, 6.939751619938761e-05, 3.171709613525309e-05, 4.93484731123317e-05, 0.00013827627117279917, 0.00014820793876424432, 0.0001955046900548041, 0.00036432925844565034, 0.00044502323726192117, 0.0005708193057216704, 0.00019970966968685389, 0.00010997075878549367, 3.883988756570034e-05, 0.0001515995099907741, 0.0005485470173880458, 0.0002792541345115751, 0.0005146855837665498, 0.0005569150089286268, 0.0004256082756910473, 0.0005325576057657599, 0.003786165965721011, 0.0048827906139194965, 0.010506671853363514, 0.0030051462817937136, 0.0009756701183505356, 0.0008210897794924676, 0.0011331167770549655, 0.00134952156804502, 0.000948533124756068, 0.0014246734790503979, 0.0026041227392852306, 0.00386716122739017, 0.007356892339885235, 0.00553382420912385, 0.0042272391729056835, 0.004221220500767231, 0.005391274578869343, 0.008091293275356293, 0.012285055592656136, 0.01096681971102953, 0.01232801005244255, 0.013310308568179607, 0.0253929253667593, 0.13379989564418793, 0.2602042555809021, 0.2378917783498764, 0.13857200741767883, 0.0641549825668335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023063164204359055, 0.00016682308341842145, 3.409318742342293e-05, 3.0215984224923886e-05, 0.00014189181092660874, 0.00024018836847972125, 0.00026566380984149873, 0.0005548194167204201, 0.000727653328794986, 0.0016611163737252355, 0.0007309173233807087, 0.00015238251944538206, 7.894991722423583e-05, 0.00023243072791956365, 0.0007879176991991699, 0.001326887053437531, 0.00180719792842865, 0.0015312934992834926, 0.0021294746547937393, 0.0013556279009208083, 0.012783680111169815, 0.008235648274421692, 0.015168708749115467, 0.011731483973562717, 0.005801862105727196, 0.002268656389787793, 0.0016562220407649875, 0.0005906461738049984, 0.0006698241923004389, 0.0008135167299769819, 0.0004485747485887259, 0.0012373503996059299, 0.0037577443290501833, 0.0027101158630102873, 0.0026422925293445587, 0.0012766452273353934, 0.0013732371153309941, 0.0013153098989278078, 0.005365998484194279, 0.02304985001683235, 0.013310340233147144, 0.013175968080759048, 0.008509003557264805, 0.019059501588344574, 0.13072660565376282, 0.11203071475028992, 0.3161192238330841, 0.17557013034820557, 0.07158244401216507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03406638652086258, 0.00014116024249233305, 5.44179420103319e-05, 2.8365244361339137e-05, 0.0002983518352266401, 0.00023592976504005492, 0.00053282460430637, 0.00047426208038814366, 0.0004200467374175787, 0.001044420525431633, 0.000857784878462553, 0.00011009875015588477, 3.513586852932349e-05, 4.8307632823707536e-05, 0.00013131657033227384, 0.0004434686852619052, 0.0010601789690554142, 0.002106189029291272, 0.00449353689327836, 0.0024190701078623533, 0.011249485425651073, 0.0023643060121685266, 0.005724641494452953, 0.0163884274661541, 0.017700446769595146, 0.009327773936092854, 0.0049850232899188995, 0.0004707630432676524, 0.0005246134824119508, 0.0002836399944499135, 9.198195766657591e-05, 0.00038722544559277594, 0.0016519767232239246, 0.001414550351910293, 0.003332505002617836, 0.0019108190899714828, 0.0010723323794081807, 0.0010509589919820428, 0.0029581855051219463, 0.021271713078022003, 0.02173011377453804, 0.019574148580431938, 0.0027501548174768686, 0.004918701946735382, 0.06345663219690323, 0.04315231740474701, 0.2355736643075943, 0.3192586600780487, 0.11029938608407974, 0.02612362802028656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0665668398141861, 0.00031550414860248566, 0.00019603740656748414, 0.00033240625634789467, 0.0002970762434415519, 0.0006126610678620636, 0.0013971042353659868, 0.0007520470535382628, 0.00022778981656301767, 0.0003659739450085908, 0.00021489706705324352, 8.466797589790076e-05, 2.769129969237838e-05, 3.1106297683436424e-05, 0.00017708612722344697, 0.00012671499280259013, 0.0005917460657656193, 0.0012943524634465575, 0.008292166516184807, 0.009341742843389511, 0.014686179347336292, 0.002404852770268917, 0.008054295554757118, 0.0056887478567659855, 0.00952195469290018, 0.009104575030505657, 0.004491678439080715, 0.0007463753572665155, 0.0004455950402189046, 0.00034103950019925833, 6.788138853153214e-05, 0.0001902511139633134, 0.0007127919234335423, 0.001113681122660637, 0.0036029713228344917, 0.004248239565640688, 0.001024571480229497, 0.0007663560681976378, 0.001701861503534019, 0.006945759989321232, 0.021824030205607414, 0.01659507490694523, 0.016078440472483635, 0.003903307020664215, 0.012962182983756065, 0.02188708260655403, 0.08489201217889786, 0.11329545080661774, 0.2176593691110611, 0.15915139019489288, 0.16464634239673615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03008858673274517, 0.00017509052122477442, 0.00012574702850542963, 7.377271685982123e-05, 0.00016225209401454777, 0.00026067867293022573, 0.0009172267746180296, 0.0007121650269255042, 0.0002967941400129348, 0.0003186922112945467, 0.000158867915160954, 0.00014882486721035093, 4.801467002835125e-05, 5.384905671235174e-05, 4.4113963667768985e-05, 4.3444004404591396e-05, 0.00011970099149039015, 0.0005535270902328193, 0.00541686499491334, 0.007280312944203615, 0.019666362553834915, 0.00347722414880991, 0.003016254398971796, 0.004860511515289545, 0.007469881791621447, 0.022731050848960876, 0.007742679677903652, 0.003511076793074608, 0.001388763077557087, 0.0007757707498967648, 9.524991037324071e-05, 0.00012430764036253095, 0.0004194987122900784, 0.0005626344354823232, 0.0012625203235074878, 0.004326869733631611, 0.0009329860913567245, 0.0009803995490074158, 0.0019102084916085005, 0.00348732341080904, 0.019018547609448433, 0.018063830211758614, 0.009819349274039268, 0.013183780945837498, 0.019324293360114098, 0.008393705822527409, 0.05618917942047119, 0.06353123486042023, 0.12814012169837952, 0.23218800127506256, 0.197123721241951, 0.09928414970636368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013779735192656517, 0.00010559861402725801, 4.6856777771608904e-05, 2.05565411306452e-05, 3.104510687990114e-05, 4.3477379222167656e-05, 0.00016954312741290778, 0.00029653962701559067, 0.00015793809143360704, 0.0001713617966743186, 0.00011062165867770091, 0.00010007854871219024, 3.7793874071212485e-05, 5.350446735974401e-05, 3.222711166017689e-05, 2.988604137499351e-05, 9.811374911805615e-05, 0.0002544896269682795, 0.0011644092155620456, 0.0018354812636971474, 0.00852922908961773, 0.0042140670120716095, 0.00355563429184258, 0.004606487695127726, 0.005022245459258556, 0.019272353500127792, 0.008348463103175163, 0.0029494145419448614, 0.001184951514005661, 0.0006776123773306608, 0.00016819831216707826, 7.996805652510375e-05, 0.0002010802272707224, 0.0002574512909632176, 0.000917473342269659, 0.003569063963368535, 0.0017929478781297803, 0.0012148909736424685, 0.0019708748441189528, 0.0029491388704627752, 0.012494131922721863, 0.011725621297955513, 0.00877426564693451, 0.00984214898198843, 0.018395161256194115, 0.009134442545473576, 0.029614651575684547, 0.04730154946446419, 0.06845969706773758, 0.11395266652107239, 0.35131245851516724, 0.12764643132686615, 0.10132598876953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01465389784425497, 0.0001397683226969093, 4.965579864801839e-05, 1.601097574166488e-05, 5.995218998577911e-06, 6.704050520056626e-06, 1.187542420666432e-05, 3.452386590652168e-05, 2.118980592058506e-05, 3.594251029426232e-05, 5.263573257252574e-05, 0.00011021191312465817, 7.093768363120034e-05, 7.967359852045774e-05, 6.928383663762361e-05, 2.5428204025956802e-05, 3.917267167707905e-05, 9.069018415175378e-05, 0.00044330302625894547, 0.0004952860181219876, 0.001776074175722897, 0.001520434976555407, 0.006482674740254879, 0.001433037337847054, 0.004294461105018854, 0.016295941546559334, 0.01885208860039711, 0.009450563229620457, 0.004724853206425905, 0.0019340848084539175, 0.00038613472133874893, 0.00017333759751636535, 0.00027639264590106905, 0.00039675741572864354, 0.0010804554913192987, 0.00541509035974741, 0.0031896033324301243, 0.0015607242239639163, 0.0031495706643909216, 0.004677810240536928, 0.018542103469371796, 0.012793686240911484, 0.009263125248253345, 0.005732504650950432, 0.005598923657089472, 0.002805099356919527, 0.007806216366589069, 0.014038377441465855, 0.04009074717760086, 0.0387113131582737, 0.29508885741233826, 0.12899784743785858, 0.20729319751262665, 0.10971564054489136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012177551165223122, 0.0003440394648350775, 0.00014693876437377185, 2.2274743969319388e-05, 3.318367453175597e-05, 9.053164831129834e-06, 1.3965645848657005e-05, 4.4250824430491775e-05, 5.627811697195284e-05, 7.888743130024523e-05, 0.00014755979645997286, 0.0002295566810062155, 0.0009211926953867078, 0.0016015601577237248, 0.002108906628564, 0.0002581762964837253, 0.00025164379621855915, 0.0002373807510593906, 0.000835410610307008, 0.000781195645686239, 0.0028866874054074287, 0.0034244318958371878, 0.008746127597987652, 0.0015465536853298545, 0.0022919729817658663, 0.004667035304009914, 0.012791544198989868, 0.008769312873482704, 0.01063520647585392, 0.005477735307067633, 0.002063056919723749, 0.0010138638317584991, 0.0006898631691001356, 0.00034595729084685445, 0.00045880521065555513, 0.0015638835029676557, 0.0012608268298208714, 0.002100171986967325, 0.002409797627478838, 0.003478201339021325, 0.005697453860193491, 0.00787358544766903, 0.0035632236395031214, 0.0059495107270777225, 0.010645739734172821, 0.004051354248076677, 0.006601561326533556, 0.004663831554353237, 0.007191264536231756, 0.017075108364224434, 0.04355233162641525, 0.1023704931139946, 0.26958993077278137, 0.34803101420402527, 0.06622353196144104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0045068226754665375, 0.0006301513640210032, 0.0001353489060420543, 6.283663242356852e-05, 4.136124698561616e-05, 1.7232825484825298e-05, 1.1315345545881428e-05, 2.973796654259786e-05, 5.216558201937005e-05, 0.00012584969226736575, 0.0001528459251858294, 0.00029143961728550494, 0.00026571255875751376, 0.001307457103393972, 0.001796351745724678, 0.0009050460066646338, 0.0007473985897377133, 0.0006563810748048127, 0.0008902199333533645, 0.0007011968991719186, 0.0016103805974125862, 0.004468700382858515, 0.012386215850710869, 0.0029330062679946423, 0.002447941806167364, 0.003159538609907031, 0.0034483163617551327, 0.005831283051520586, 0.004402096848934889, 0.0033913003280758858, 0.0031900028698146343, 0.0039360676892101765, 0.0030492027290165424, 0.00143534189555794, 0.0012194897281005979, 0.001004510559141636, 0.0012076081475242972, 0.0012816527159884572, 0.002628709888085723, 0.002430053660646081, 0.002902257489040494, 0.0016139468643814325, 0.0018901737639680505, 0.005636159330606461, 0.007025865372270346, 0.0059271384961903095, 0.0073724365793168545, 0.005250833462923765, 0.0039865137077867985, 0.0034789445344358683, 0.021550564095377922, 0.02441881224513054, 0.13946393132209778, 0.36383292078971863, 0.2619532346725464, 0.06490804255008698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01494812872260809, 0.00300946575589478, 0.0005226925131864846, 0.0002759798080660403, 0.00011797719344031066, 4.164347774349153e-05, 1.7746613593772054e-05, 4.6853449021000415e-05, 6.011462755850516e-05, 0.00016617693472653627, 0.0004013909201603383, 0.0004213164793327451, 0.0012203212827444077, 0.003574129194021225, 0.007221135776489973, 0.004712716210633516, 0.0037368815392255783, 0.003164904424920678, 0.0036603601183742285, 0.0022964959498494864, 0.002814588835462928, 0.003777440171688795, 0.02199942246079445, 0.00756312720477581, 0.009013944305479527, 0.005189667921513319, 0.004891448654234409, 0.003928204532712698, 0.005124417599290609, 0.0020571027416735888, 0.0020138334948569536, 0.004490859340876341, 0.002822418697178364, 0.002065777312964201, 0.0012118470622226596, 0.0005660405731759965, 0.00041295774281024933, 0.0006328410818241537, 0.0011294034775346518, 0.0034466928336769342, 0.0021467364858835936, 0.0012755092466250062, 0.0012439900310710073, 0.0009438297129236162, 0.0027550344821065664, 0.00297545432113111, 0.009878825396299362, 0.007588640321046114, 0.008521512150764465, 0.003814637428149581, 0.013419867493212223, 0.015423398464918137, 0.054861318320035934, 0.24742388725280762, 0.2323160469532013, 0.16701041162014008, 0.0936325192451477, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027103273198008537, 0.008105883374810219, 0.0026407260447740555, 0.00404528621584177, 0.0008833640022203326, 0.00033584286575205624, 8.527261525159702e-05, 0.00013850341201759875, 7.876296149333939e-05, 0.00017965695587918162, 0.0003363212454132736, 0.0002734673907980323, 0.0003658631758298725, 0.0013694895897060633, 0.003874274669215083, 0.00471362704411149, 0.0037131367716938257, 0.004431059118360281, 0.013990625739097595, 0.004354977514594793, 0.0034332405775785446, 0.002771299798041582, 0.011369655840098858, 0.006391456350684166, 0.009841789491474628, 0.005398632027208805, 0.002927511464804411, 0.0013305569300428033, 0.0018764217384159565, 0.0008518130634911358, 0.0009896490955725312, 0.004961294587701559, 0.007335633505135775, 0.0069646285846829414, 0.005467681679874659, 0.0013056605821475387, 0.0006142293568700552, 0.00038951210444793105, 0.0005804020911455154, 0.001268307096324861, 0.0011294330470263958, 0.0005009312881156802, 0.0006452731904573739, 0.00025951131829060614, 0.001069467980414629, 0.0011810108553618193, 0.0056564901024103165, 0.004744520410895348, 0.006692924071103334, 0.0023124623112380505, 0.006015220191329718, 0.0016080697532743216, 0.010496117174625397, 0.09211967140436172, 0.11863426119089127, 0.2887740135192871, 0.20750369131565094, 0.09356812387704849, 0.0, 0.0, 0.0, 0.0], [0.016270291060209274, 0.003212032373994589, 0.001767591922543943, 0.0010782004101201892, 0.0006670334842056036, 0.00021701656805817038, 7.102834206307307e-05, 5.636187415802851e-05, 2.7216041416977532e-05, 4.1079129005083814e-05, 5.240428799879737e-05, 6.783248682040721e-05, 4.46605117758736e-05, 0.0001489366841269657, 0.00027975341072306037, 0.0005429624579846859, 0.0008510879706591368, 0.001352599821984768, 0.004548129625618458, 0.0031786870677024126, 0.0022494203876703978, 0.0007244323496706784, 0.004463420249521732, 0.003377595217898488, 0.005821413826197386, 0.0038903621025383472, 0.0012972308322787285, 0.0003681032976601273, 0.00023311249969992787, 0.00013606424909085035, 0.00025805833865888417, 0.0010571898892521858, 0.0032375226728618145, 0.004336700774729252, 0.004883974324911833, 0.0013393574627116323, 0.0003082965558860451, 0.00011122802970930934, 0.0001299779978580773, 0.00020416665938682854, 0.00019632212934084237, 0.00013059776392765343, 5.582255107583478e-05, 9.082124597625807e-05, 0.00037366835749708116, 0.0007212798809632659, 0.0020218100398778915, 0.0026608335319906473, 0.004272038117051125, 0.0026393590960651636, 0.0017841525841504335, 0.001656797481700778, 0.0034576330799609423, 0.016956685110926628, 0.041546713560819626, 0.10461635142564774, 0.36744096875190735, 0.3385624885559082, 0.03791314363479614, 0.0, 0.0, 0.0], [0.00982022937387228, 0.0009120897157117724, 0.0006350247422233224, 0.00022093260486144572, 0.00017131374625023454, 0.00010965725959977135, 4.9666810809867457e-05, 3.272413960075937e-05, 1.7345995729556307e-05, 2.3816015527700074e-05, 2.4563159968238324e-05, 2.45228784478968e-05, 9.843463885772508e-06, 1.5449859347427264e-05, 3.4384793252684176e-05, 7.485074456781149e-05, 9.610448614694178e-05, 0.0002488895843271166, 0.001409099088050425, 0.0007465708767995238, 0.0009521842584945261, 0.0005700288456864655, 0.004519968759268522, 0.0042022597044706345, 0.009016888216137886, 0.006189224775880575, 0.001880766125395894, 0.0002304011140950024, 6.787566962884739e-05, 3.38954123435542e-05, 3.29709546349477e-05, 0.00014761324564460665, 0.001033640350215137, 0.0038882920052856207, 0.009577679447829723, 0.005109279416501522, 0.0006459233700297773, 0.00020973460050299764, 0.00014936842489987612, 0.0001313843094976619, 0.00017566750466357917, 6.119933823356405e-05, 2.0418492567841895e-05, 3.5321969335200265e-05, 0.00018268403073307127, 0.00042180289165116847, 0.0017091002082452178, 0.004646425601094961, 0.006271836813539267, 0.0026466846466064453, 0.002746637910604477, 0.0034585162065923214, 0.003716743318364024, 0.010083933360874653, 0.02510753646492958, 0.0984998494386673, 0.1454746425151825, 0.4327016770839691, 0.09708648175001144, 0.10168637335300446, 0.0, 0.0], [0.008352887816727161, 0.0006420369609259069, 0.0006678223144263029, 0.0003974934807047248, 8.569011697545648e-05, 9.896158735500649e-05, 8.344193338416517e-05, 7.174364873208106e-05, 2.051324918284081e-05, 2.668444903974887e-05, 5.611581218545325e-05, 7.730751531198621e-05, 3.812759314314462e-05, 4.4242620788281783e-05, 9.777256491361186e-05, 7.34557252144441e-05, 5.371276711230166e-05, 0.00010684116568882018, 0.0008605631301179528, 0.00040695659117773175, 0.0005268594832159579, 0.00028808158822357655, 0.0017000698717311025, 0.002278353553265333, 0.006423615850508213, 0.011430177837610245, 0.007228556554764509, 0.0007289726054295897, 0.0005058922106400132, 0.00012933232937939465, 4.7434903535759076e-05, 0.00010452597052790225, 0.0003731980104930699, 0.0019301939755678177, 0.007123748306185007, 0.009717090986669064, 0.0027075838297605515, 0.0008296045707538724, 0.0004561924433801323, 0.0008601869340054691, 0.0010871125850826502, 0.0003423347952775657, 0.00012568752572406083, 2.8542799554998055e-05, 0.00011031932808691636, 0.00017235973791684955, 0.0004439452604856342, 0.0015363905113190413, 0.005107712931931019, 0.004057344049215317, 0.005230249837040901, 0.0027523422613739967, 0.003951548598706722, 0.0056131016463041306, 0.004207218065857887, 0.04305867850780487, 0.05078046768903732, 0.24676354229450226, 0.12420923262834549, 0.3801772892475128, 0.052592579275369644, 0.0], [0.002833892125636339, 0.000338861282216385, 0.00019914530275855213, 9.149551624432206e-05, 2.780369140964467e-05, 1.7697624571155757e-05, 1.4929637472960167e-05, 3.0359662559931166e-05, 9.437229891773313e-06, 1.2254894500074442e-05, 3.4600736398715526e-05, 0.00010408517846371979, 6.908314389875159e-05, 5.418236833065748e-05, 4.777470530825667e-05, 4.8888065066421404e-05, 1.8779775928123854e-05, 3.209770511602983e-05, 0.00019074002921115607, 0.00020458151993807405, 0.00017736513109412044, 0.0001307368220295757, 0.0003533988492563367, 0.0004966274718753994, 0.002266520168632269, 0.004587754141539335, 0.006011147517710924, 0.0022162427194416523, 0.0009266599081456661, 0.0002570826618466526, 0.00011603502935031429, 0.00012860895367339253, 0.00017813201702665538, 0.0005511966301128268, 0.00268086651340127, 0.004333773162215948, 0.0033273142762482166, 0.001169989351183176, 0.0005136928521096706, 0.0006772877532057464, 0.0008895230130292475, 0.0005630312371067703, 0.00014762874343432486, 6.570694677066058e-05, 5.405328920460306e-05, 0.00010629426833475009, 0.000115840659418609, 0.0003956901782657951, 0.0018002040451392531, 0.003022590419277549, 0.0027316061314195395, 0.0040872953832149506, 0.005551693961024284, 0.00550302118062973, 0.0034883390180766582, 0.009846220724284649, 0.028516417369246483, 0.10566439479589462, 0.09947802871465683, 0.4035807251930237, 0.19454485177993774, 0.09436570107936859]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.726279616355896, 0.2737203538417816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6243199110031128, 0.03774431347846985, 0.33793574571609497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7881168723106384, 0.18725468218326569, 0.000503558199852705, 0.024124860763549805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3439514636993408, 0.008476469665765762, 0.5517817139625549, 0.02786164917051792, 0.06792871654033661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5007545948028564, 0.43827158212661743, 0.0010861775372177362, 0.04854315519332886, 0.011293873190879822, 5.066089579486288e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4467826187610626, 0.08610506355762482, 0.13386182487010956, 0.07884252816438675, 0.09555311501026154, 0.029473988339304924, 0.12938092648983002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5964309573173523, 0.09791555255651474, 0.060900937765836716, 0.08292083442211151, 0.060177046805620193, 0.0028137515764683485, 0.052157893776893616, 0.04668301343917847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2414315789937973, 0.1028098538517952, 0.06954184174537659, 0.19907893240451813, 0.08703877031803131, 0.0004203447315376252, 0.08685475587844849, 0.11072808504104614, 0.10209576785564423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06005648523569107, 0.0723152905702591, 0.12193846702575684, 0.06697913259267807, 0.20428544282913208, 0.00031633180333301425, 0.17139007151126862, 0.0631677582859993, 0.18389074504375458, 0.05566030368208885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05738425254821777, 0.04283629730343819, 0.11781302094459534, 0.0504164844751358, 0.1427917331457138, 0.00015210156561806798, 0.18529252707958221, 0.051876578480005264, 0.1470184624195099, 0.040418244898319244, 0.16400031745433807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3462902307510376, 0.1851508766412735, 0.046662233769893646, 0.10192833840847015, 0.08512590825557709, 0.004370743874460459, 0.04227111488580704, 0.048995617777109146, 0.03528638184070587, 0.013812600634992123, 0.03292762115597725, 0.057178251445293427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47429773211479187, 0.10327186435461044, 0.028608260676264763, 0.0362413227558136, 0.03884071856737137, 0.023103171959519386, 0.04176326468586922, 0.03561662882566452, 0.03369070589542389, 0.022586943581700325, 0.03470554202795029, 0.07261257618665695, 0.05466132238507271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05332346260547638, 0.00371685647405684, 0.041283342987298965, 0.007212244439870119, 0.007693323772400618, 0.773786723613739, 0.008713879622519016, 0.004678071476519108, 0.010056843981146812, 0.00948818027973175, 0.014593864791095257, 0.030348598957061768, 0.003993208520114422, 0.031111406162381172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5500724911689758, 0.271014004945755, 0.0009471020312048495, 0.014281591400504112, 0.004426614847034216, 0.0004887725808657706, 0.003589037572965026, 0.0113689498975873, 0.001486414228565991, 0.00045989867066964507, 0.0010320903966203332, 0.01733051985502243, 0.10636872798204422, 0.009525655768811703, 0.007608005777001381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4676109850406647, 0.19005849957466125, 0.0041809421963989735, 0.028465401381254196, 0.015551559627056122, 0.0008451499743387103, 0.015834424644708633, 0.027468740940093994, 0.007830681279301643, 0.004195736721158028, 0.006356307305395603, 0.025767656043171883, 0.064275823533535, 0.039340101182460785, 0.013193592429161072, 0.08902444690465927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5127249956130981, 0.29900407791137695, 0.0006209489074535668, 0.017206760123372078, 0.0026358396280556917, 3.496326826279983e-05, 0.0015966743230819702, 0.008279231376945972, 0.0016239044489338994, 0.0006617194158025086, 0.0011935954680666327, 0.007453927770256996, 0.03293329477310181, 0.007693702820688486, 0.0033982209861278534, 0.02959042601287365, 0.07334762811660767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19186712801456451, 0.12053592503070831, 0.0233153123408556, 0.04854979366064072, 0.04465426504611969, 0.0014008585130795836, 0.01793058030307293, 0.0245523639023304, 0.02217232808470726, 0.009059363044798374, 0.0223099235445261, 0.03807160630822182, 0.02408372424542904, 0.09685390442609787, 0.04526214301586151, 0.05868113785982132, 0.12018067389726639, 0.09051897376775742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001136675477027893, 4.472723594517447e-05, 0.0050143892876803875, 8.518634422216564e-05, 0.0007514912285842001, 0.9609103202819824, 0.00031538837356492877, 5.460240208776668e-05, 0.0007500931969843805, 0.0005347569822333753, 0.001325970166362822, 0.0008721620542928576, 6.47322231088765e-05, 0.0017828886630013585, 0.014786990359425545, 0.00042574244434945285, 0.0001065057804225944, 5.198727376409806e-05, 0.01098531112074852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5348114371299744, 0.11527957022190094, 0.0025817384012043476, 0.018661823123693466, 0.008799530565738678, 0.00015596312005072832, 0.007991650141775608, 0.012300867587327957, 0.004634749609977007, 0.0024634860455989838, 0.004414128605276346, 0.011383268982172012, 0.027068788185715675, 0.014778886921703815, 0.006095605436712503, 0.03743286430835724, 0.06169026345014572, 0.04008542373776436, 0.005960570648312569, 0.08340930938720703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02924676612019539, 0.011049235239624977, 0.09568186849355698, 0.008235719986259937, 0.036768388003110886, 0.00864804070442915, 0.033680450171232224, 0.005687203258275986, 0.023678993806242943, 0.007852030918002129, 0.029831912368535995, 0.06622059643268585, 0.0032309326343238354, 0.11209346354007721, 0.050110410898923874, 0.04894993081688881, 0.018687108531594276, 0.015352549962699413, 0.10679958760738373, 0.010465656407177448, 0.2777291536331177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1322774887084961, 0.5847139358520508, 0.0001626320881769061, 0.007737824227660894, 0.0032700577285140753, 1.6947209360296256e-06, 0.0013337369309738278, 0.006487657781690359, 0.0006067996146157384, 0.0002619285078253597, 0.0005489987670443952, 0.004697629250586033, 0.037810590118169785, 0.0028160721994936466, 0.000940488709602505, 0.021408729255199432, 0.04704589769244194, 0.0625576376914978, 0.0002495906956028193, 0.08251600712537766, 0.0025387818459421396, 1.5740211892989464e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22157377004623413, 0.3477570116519928, 0.001981361536309123, 0.01979045756161213, 0.008805091492831707, 5.381810842663981e-05, 0.003146412083879113, 0.011557292193174362, 0.0037623124662786722, 0.001839791308157146, 0.0036521339789032936, 0.01690129190683365, 0.030341532081365585, 0.012017658911645412, 0.008380234241485596, 0.0378812775015831, 0.07685651630163193, 0.07320570945739746, 0.00263211433775723, 0.10012149065732956, 0.008961830288171768, 0.00048201059689745307, 0.008298829197883606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10249683260917664, 0.022133752703666687, 0.02465967647731304, 0.022031297907233238, 0.03789547085762024, 0.001789628411643207, 0.02333732694387436, 0.016442926600575447, 0.03565637767314911, 0.015265481546521187, 0.03922508284449577, 0.024356268346309662, 0.015069513581693172, 0.062044307589530945, 0.021686973050236702, 0.021785790100693703, 0.04438028484582901, 0.04066145047545433, 0.06485219299793243, 0.06456159800291061, 0.14242570102214813, 0.01358590368181467, 0.07064731419086456, 0.07300890237092972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01785343885421753, 0.019543645903468132, 0.03287525475025177, 0.011478996835649014, 0.04901038855314255, 0.00013030064292252064, 0.03935335949063301, 0.011866556480526924, 0.03755918890237808, 0.010735354386270046, 0.03782861679792404, 0.040637895464897156, 0.00567195750772953, 0.09588642418384552, 0.008264046162366867, 0.019349031150341034, 0.02118002064526081, 0.036204639822244644, 0.04617009311914444, 0.01803082600235939, 0.29964208602905273, 0.0014787566615268588, 0.06022484973073006, 0.05125641077756882, 0.02776782587170601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00993178691715002, 0.006194743327796459, 0.032747041434049606, 0.004200368653982878, 0.0379432812333107, 8.225326018873602e-05, 0.04544846713542938, 0.005332096014171839, 0.027604693546891212, 0.006731818430125713, 0.031153835356235504, 0.01833944022655487, 0.001684304908849299, 0.07693321257829666, 0.003586531849578023, 0.009044538252055645, 0.006801149342209101, 0.009251996874809265, 0.046750590205192566, 0.005068931262940168, 0.39827653765678406, 0.0009611306013539433, 0.052437882870435715, 0.028977984562516212, 0.020572349429130554, 0.11394307017326355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009499029256403446, 0.01005025114864111, 0.04056946560740471, 0.0028496598824858665, 0.02404773235321045, 0.00026145970332436264, 0.02985553815960884, 0.00299138599075377, 0.017199305817484856, 0.0036434289067983627, 0.01993710733950138, 0.03576301410794258, 0.0015932468231767416, 0.07788790762424469, 0.0051769595593214035, 0.017598195001482964, 0.004229967948049307, 0.010009807534515858, 0.04453470930457115, 0.004442727658897638, 0.2702672779560089, 0.002799557289108634, 0.0971423089504242, 0.015932917594909668, 0.013021591119468212, 0.07250341773033142, 0.1661919355392456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20153038203716278, 0.05343054607510567, 0.014870216138660908, 0.023146383464336395, 0.022001396864652634, 0.0014112343778833747, 0.01200170535594225, 0.013142683543264866, 0.007570391055196524, 0.003159533953294158, 0.006704200524836779, 0.01577090471982956, 0.0126035800203681, 0.03201913833618164, 0.022157911211252213, 0.07325362414121628, 0.06117971986532211, 0.030507631599903107, 0.01268981397151947, 0.06599535048007965, 0.04339897260069847, 0.01140107586979866, 0.04687681421637535, 0.043447963893413544, 0.009337591007351875, 0.07021484524011612, 0.03652876988053322, 0.053647592663764954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00016194033378269523, 5.095404503663303e-06, 0.0013184472918510437, 1.8025331883109175e-05, 0.0001228795008501038, 0.32972612977027893, 7.925029785837978e-05, 1.3391573702392634e-05, 0.00018173163698520511, 0.0001538628275739029, 0.0003092458937317133, 0.00018040509894490242, 1.0368585208198056e-05, 0.00029192602960392833, 0.0028713003266602755, 9.09630543901585e-05, 2.2825022824690677e-05, 1.210174013976939e-05, 0.002572242869064212, 3.146766539430246e-05, 0.0006452574743889272, 0.6509683728218079, 0.006820023991167545, 6.86539351590909e-05, 0.0004046829417347908, 0.00019465875811874866, 0.0016513582086190581, 0.0003605149395298213, 0.0007129069417715073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008440074510872364, 0.0002670430112630129, 0.009946554899215698, 0.0004293571109883487, 0.0021159853786230087, 0.14127764105796814, 0.002074937801808119, 0.0003662772651296109, 0.0019688517786562443, 0.0011648940853774548, 0.002791034523397684, 0.0025521903298795223, 0.00031258922535926104, 0.0063377004116773605, 0.013114538975059986, 0.0030102997552603483, 0.0007077983464114368, 0.0005017955554649234, 0.020510902628302574, 0.0012316424399614334, 0.014073162339627743, 0.5997605323791504, 0.05741066485643387, 0.001980223460122943, 0.003920427989214659, 0.006470742169767618, 0.026340553537011147, 0.012310503050684929, 0.02148008905351162, 0.03713090345263481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.42849141359329224, 0.17088203132152557, 0.000390356668503955, 0.008465621620416641, 0.0016480993945151567, 2.0232799215591513e-05, 0.0011175797553732991, 0.004497039597481489, 0.0009590011322870851, 0.00031784476595930755, 0.0006210464052855968, 0.004015450365841389, 0.015895459800958633, 0.004209436476230621, 0.0014167644549161196, 0.014659583568572998, 0.032305892556905746, 0.039748068898916245, 0.0007499548955820501, 0.0957762748003006, 0.0023527604062110186, 0.00012304291885811836, 0.002138401847332716, 0.009121798910200596, 0.000709814834408462, 0.012446612119674683, 0.001478685881011188, 0.04389337822794914, 0.010206280276179314, 0.0009256477933377028, 0.09041637927293777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5157032012939453, 0.05598190799355507, 0.0014907665317878127, 0.008461149409413338, 0.005098880734294653, 7.935009489301592e-05, 0.005108347162604332, 0.006588242948055267, 0.002527539851143956, 0.0011470112949609756, 0.002186202211305499, 0.0061461906880140305, 0.013029739260673523, 0.008066988550126553, 0.002317780163139105, 0.01696617901325226, 0.022353235632181168, 0.018663492053747177, 0.002835489809513092, 0.03937575966119766, 0.01050011720508337, 0.00039295852184295654, 0.0052767000161111355, 0.014299046248197556, 0.0023275797720998526, 0.026797957718372345, 0.008494346402585506, 0.036191582679748535, 0.015374704264104366, 0.002457272494211793, 0.06173368915915489, 0.08202654123306274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007869443856179714, 0.003271630499511957, 0.02077748067677021, 0.0022801856976002455, 0.01812470518052578, 0.0002325951209058985, 0.02478875406086445, 0.003248297842219472, 0.013053515926003456, 0.003619068767875433, 0.01588389277458191, 0.02306501939892769, 0.001854158123023808, 0.05518786981701851, 0.0036340164951980114, 0.01167785283178091, 0.003154402133077383, 0.007794201374053955, 0.02471199631690979, 0.0036792769096791744, 0.1462598741054535, 0.0020237192511558533, 0.03980886936187744, 0.012340059503912926, 0.009151333943009377, 0.05071210488677025, 0.11900224536657333, 0.15142379701137543, 0.10703825950622559, 0.03108355589210987, 0.011038362979888916, 0.009309286251664162, 0.0629001259803772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18857072293758392, 0.1295877993106842, 0.00026835763128474355, 0.006765197962522507, 0.0028995205648243427, 1.0398292033642065e-05, 0.0021249549463391304, 0.0073807863518595695, 0.0005669526872225106, 0.00021501744049601257, 0.0003527474473230541, 0.007555290590971708, 0.05242711305618286, 0.004239504225552082, 0.000812627375125885, 0.06679278612136841, 0.027881452813744545, 0.07960037142038345, 0.00027819006936624646, 0.0593520887196064, 0.002521762391552329, 4.913298107567243e-05, 0.0015889093047007918, 0.010795333422720432, 0.00043645984260365367, 0.010294536128640175, 0.0019289972260594368, 0.042536161839962006, 0.008683870546519756, 0.00016243127174675465, 0.11977337300777435, 0.16248418390750885, 0.0009993448620662093, 6.361542909871787e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.132991224527359, 0.1022520661354065, 1.7709355233819224e-05, 0.0009297440992668271, 0.00019224781135562807, 1.1339965055867651e-07, 4.950321454089135e-05, 0.00044092119787819684, 4.9650348955765367e-05, 1.7236803614650853e-05, 2.980366480187513e-05, 0.00039683381328359246, 0.0011286785593256354, 0.00027706133550964296, 9.882375888992101e-05, 0.0010636395309120417, 0.003187270835042, 0.003323701210319996, 1.9066415916313417e-05, 0.010351911187171936, 0.00013543271052185446, 1.3498693078872748e-06, 8.978770347312093e-05, 0.0005772257572971284, 2.9723620173172094e-05, 0.0013772764941677451, 5.093229265185073e-05, 0.003551688976585865, 0.0006601152708753943, 1.821774640120566e-05, 0.011923660524189472, 0.024295033887028694, 2.5046654627658427e-05, 6.445171720770304e-07, 0.7004467248916626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0048549361526966095, 0.00036079593701288104, 0.004249717108905315, 0.00016918407345656306, 0.0010210293112322688, 0.06359322369098663, 0.0003463946341071278, 9.580205369275063e-05, 0.0006039049476385117, 0.00038997913361527026, 0.0008752670837566257, 0.0012403555447235703, 6.750172178726643e-05, 0.0018138013547286391, 0.009131197817623615, 0.00045500052510760725, 0.00017925708380062133, 0.0001023145014187321, 0.005187309812754393, 0.0003696782805491239, 0.003498086705803871, 0.3561004102230072, 0.026112377643585205, 0.00033351703314110637, 0.0009108310332521796, 0.001689431257545948, 0.005277854390442371, 0.004200526978820562, 0.004683223087340593, 0.010899344459176064, 0.0005014362977817655, 0.0009349150350317359, 0.005218266509473324, 0.4291604161262512, 0.0059445640072226524, 0.049428194761276245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1982400119304657, 0.10903377085924149, 5.209575829212554e-05, 0.0020097093656659126, 0.00027431416674517095, 3.777157928652741e-07, 0.00011433758481871337, 0.0009379714610986412, 0.0001264238526346162, 4.788624937646091e-05, 6.50821384624578e-05, 0.0008791675791144371, 0.0018897880800068378, 0.0004901192733086646, 0.00014931443729437888, 0.0021372789051383734, 0.0049026962369680405, 0.006466068793088198, 4.9533417040947825e-05, 0.012711193412542343, 0.00022246736625675112, 2.531520749471383e-06, 0.00015107222134247422, 0.0010089024435728788, 7.605477730976418e-05, 0.0017032952746376395, 9.473712998442352e-05, 0.006065284367650747, 0.0009491673554293811, 6.562937778653577e-05, 0.017891038209199905, 0.03019271045923233, 6.495688285212964e-05, 1.909715138026513e-06, 0.5693546533584595, 0.00032993758213706315, 0.03124859184026718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06308405101299286, 0.012752720154821873, 0.019761614501476288, 0.005882023833692074, 0.008279957808554173, 0.001419349224306643, 0.005971114616841078, 0.0027902398724108934, 0.005515372846275568, 0.0016436545411124825, 0.004724883008748293, 0.013501077890396118, 0.0014765921514481306, 0.018800802528858185, 0.009529846720397472, 0.01274123229086399, 0.00870811939239502, 0.005648304242640734, 0.012905395589768887, 0.0075336042791605, 0.028761345893144608, 0.00765659986063838, 0.042183246463537216, 0.007271889131516218, 0.003841801080852747, 0.01996028609573841, 0.02498605102300644, 0.06220264360308647, 0.038669049739837646, 0.021563472226262093, 0.026578012853860855, 0.016487309709191322, 0.014491839334368706, 0.0073372176848351955, 0.126032754778862, 0.1403469741344452, 0.10377661883831024, 0.08518300950527191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1494465321302414, 0.07497281581163406, 0.00011598454875638708, 0.003165553556755185, 0.0006617268081754446, 1.061050807038555e-05, 0.0003040683805011213, 0.0016650969628244638, 0.00028086244128644466, 0.00010435408330522478, 0.00017767860845196992, 0.0012629091506823897, 0.008600625209510326, 0.0009392960928380489, 0.00046405321336351335, 0.004780048504471779, 0.007594203110784292, 0.011442732065916061, 0.00013375315757002681, 0.029122989624738693, 0.00038513579056598246, 4.145178900216706e-05, 0.0005004088161513209, 0.002307845978066325, 0.0001691172510618344, 0.002542773960158229, 0.00028596087940968573, 0.008631850592792034, 0.0018990361131727695, 0.00016795484407339245, 0.025952890515327454, 0.06913065910339355, 0.00021670851856470108, 4.966649066773243e-05, 0.4741755723953247, 0.0007884812657721341, 0.05033385753631592, 0.0018680579960346222, 0.06530672311782837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.017252638936042786, 0.0035717475693672895, 0.012776399962604046, 0.002293832367286086, 0.013111242093145847, 0.0001686729083303362, 0.011799583211541176, 0.0024811136536300182, 0.008137470111250877, 0.0027750213630497456, 0.009405743330717087, 0.008157050237059593, 0.0009159221081063151, 0.025578582659363747, 0.003258045529946685, 0.0047615645453333855, 0.0029315068386495113, 0.0031512025743722916, 0.014001305215060711, 0.0030559340957552195, 0.07314278930425644, 0.0015472002560272813, 0.021394239738583565, 0.009397046640515327, 0.006843097507953644, 0.03872891888022423, 0.056749485433101654, 0.04762330278754234, 0.059288449585437775, 0.019487926736474037, 0.010001949965953827, 0.007911643013358116, 0.028820933774113655, 0.0011024005943909287, 0.06011921912431717, 0.13011647760868073, 0.09462808817625046, 0.08379299193620682, 0.02596375159919262, 0.07375555485486984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.058444079011678696, 0.006339859217405319, 0.01057041808962822, 0.0028370916843414307, 0.005790719762444496, 0.005325444974005222, 0.002834478858858347, 0.0015672764275223017, 0.0045491429045796394, 0.001551521592773497, 0.004259360954165459, 0.007993211969733238, 0.0014636736596003175, 0.012450804933905602, 0.011015075258910656, 0.00590667175129056, 0.0036702926736325026, 0.0033798457589000463, 0.011951061896979809, 0.007420554757118225, 0.016926359385252, 0.028115684166550636, 0.034163326025009155, 0.005129534751176834, 0.0037369229830801487, 0.01495251152664423, 0.01673230528831482, 0.047373123466968536, 0.033811453729867935, 0.028793245553970337, 0.011406035162508488, 0.01849975436925888, 0.013261386193335056, 0.03218958526849747, 0.10482259094715118, 0.10501199960708618, 0.10752289742231369, 0.07614258676767349, 0.04572421312332153, 0.02674870565533638, 0.059615228325128555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004711156245321035, 0.002936585573479533, 0.01403653435409069, 0.0010639190440997481, 0.007755917962640524, 9.182060603052378e-05, 0.00868895836174488, 0.0009582711500115693, 0.0057768439874053, 0.001106964540667832, 0.0066930684261024, 0.012305178679525852, 0.00045154758845455945, 0.022236838936805725, 0.0017696412978693843, 0.004667299799621105, 0.0012011174112558365, 0.0022973460145294666, 0.010798661038279533, 0.001120951259508729, 0.060967039316892624, 0.000689530570525676, 0.024049120023846626, 0.0038285688497126102, 0.0029571857303380966, 0.01996501162648201, 0.05100967735052109, 0.08489059656858444, 0.039075132459402084, 0.014536896720528603, 0.0038460176438093185, 0.0027111286763101816, 0.018046261742711067, 0.0005272615235298872, 0.06254708021879196, 0.13126525282859802, 0.08843571692705154, 0.10484528541564941, 0.01158692967146635, 0.041830603033304214, 0.06934358924627304, 0.05237749591469765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2210250347852707, 0.035983651876449585, 0.00013931824651081115, 0.0027449147310107946, 0.0004456356109585613, 1.0314483915863093e-05, 0.0004071671864949167, 0.0012195968301966786, 0.000264988950220868, 8.37329716887325e-05, 0.00013243983266875148, 0.0018129079835489392, 0.0034747484605759382, 0.0013701366260647774, 0.0005663922056555748, 0.004727141000330448, 0.011828174814581871, 0.011470909230411053, 0.00029930431628599763, 0.03316012769937515, 0.0008818319183774292, 4.844576687901281e-05, 0.0009534949786029756, 0.0021757364738732576, 0.00019349601643625647, 0.0032977291848510504, 0.0005586213665083051, 0.022714370861649513, 0.0030816642101854086, 0.00030431358027271926, 0.03805088251829147, 0.08017969131469727, 0.0002927339228335768, 6.517711153719574e-05, 0.29802262783050537, 0.0014578882837668061, 0.05827225372195244, 0.004703868646174669, 0.10847288370132446, 0.0019949101842939854, 0.004038339480757713, 0.003601707285270095, 0.035470668226480484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06975667178630829, 0.016121089458465576, 0.004883023910224438, 0.004924312699586153, 0.007354241330176592, 0.00037276395596563816, 0.003837099764496088, 0.002704011742025614, 0.0025689066387712955, 0.0008808386046439409, 0.0024186372756958008, 0.004515352658927441, 0.002453416818752885, 0.010258314199745655, 0.00448971800506115, 0.009107295423746109, 0.008444602601230145, 0.005926455836743116, 0.0049852533265948296, 0.014655101113021374, 0.01536801178008318, 0.0025909144897013903, 0.012442036531865597, 0.007939857430756092, 0.0022686999291181564, 0.018759628757834435, 0.012752198614180088, 0.024321582168340683, 0.02766413427889347, 0.005386536009609699, 0.02264978550374508, 0.02956363372504711, 0.005541497841477394, 0.0017982478020712733, 0.15334200859069824, 0.03991568088531494, 0.12251739948987961, 0.03108357824385166, 0.07948802411556244, 0.021631773561239243, 0.03928631544113159, 0.02788076363503933, 0.062146853655576706, 0.05300373584032059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00989264715462923, 0.000264208996668458, 0.010757763870060444, 0.0008752942085266113, 0.0035804470535367727, 0.04488441348075867, 0.002828785916790366, 0.0007572906324639916, 0.003478314960375428, 0.0023991218768060207, 0.004108564928174019, 0.0027486307080835104, 0.00031006967765279114, 0.0060703628696501255, 0.010416173376142979, 0.00159457977861166, 0.0011177239939570427, 0.0006546317017637193, 0.01901901327073574, 0.001361086848191917, 0.015866098925471306, 0.12341870367527008, 0.025234825909137726, 0.002315784804522991, 0.004993292037397623, 0.006395071744918823, 0.01899658888578415, 0.008066457696259022, 0.01717199943959713, 0.03764340281486511, 0.002515218686312437, 0.0026957180816680193, 0.022340895608067513, 0.22032657265663147, 0.004011635202914476, 0.09975036233663559, 0.01198605541139841, 0.04366820678114891, 0.008823364041745663, 0.028283705934882164, 0.056785281747579575, 0.02392934076488018, 0.01403156016021967, 0.011996107175946236, 0.06163466349244118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14401046931743622, 0.018198683857917786, 8.133050141623244e-05, 0.0018546254141256213, 0.0004240656562615186, 1.330391205556225e-05, 0.0006451692315749824, 0.0016556812915951014, 0.00015683443052694201, 4.827274096896872e-05, 6.765362195437774e-05, 0.0007500069332309067, 0.0036463169381022453, 0.0008433294715359807, 0.00030168244848027825, 0.00751881580799818, 0.024119136855006218, 0.010017341002821922, 0.0001588951563462615, 0.01801435463130474, 0.0008257996523752809, 2.607578062452376e-05, 0.0005631506792269647, 0.00241935346275568, 0.00011136318789795041, 0.002424853155389428, 0.000599043327383697, 0.008121006190776825, 0.002731048734858632, 7.859372271923348e-05, 0.06904949247837067, 0.033966660499572754, 0.00025737323448993266, 7.050539716146886e-05, 0.12572045624256134, 0.000839652435388416, 0.02026192471385002, 0.002165970392525196, 0.18188491463661194, 0.0016580356750637293, 0.0029392819851636887, 0.004872387740761042, 0.031009571626782417, 0.1018362045288086, 0.003834508126601577, 0.16920684278011322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0875796228647232, 0.0054402220994234085, 0.0012138070305809379, 0.004864251706749201, 0.0027853932697325945, 4.891320349997841e-05, 0.003825995372608304, 0.004791913088411093, 0.002218550071120262, 0.0010018803877756, 0.0014512398047372699, 0.0032156044617295265, 0.004229860845953226, 0.005391984712332487, 0.0009767137235030532, 0.00837594736367464, 0.014014944434165955, 0.015907704830169678, 0.0024932913947850466, 0.017502382397651672, 0.008266814053058624, 0.00016447360394522548, 0.002391533460468054, 0.010920940898358822, 0.0020869115833193064, 0.013115756213665009, 0.004606382455676794, 0.02052871696650982, 0.014577030204236507, 0.002973653143271804, 0.03720245882868767, 0.0317826122045517, 0.004330949392169714, 0.00022978246852289885, 0.05260235071182251, 0.009739238768815994, 0.049813997000455856, 0.017695510759949684, 0.07588928192853928, 0.01708672009408474, 0.023129157721996307, 0.029460791498422623, 0.06779718399047852, 0.11463525146245956, 0.049538299441337585, 0.0857330933213234, 0.06637091934680939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01118831429630518, 0.001487228088080883, 0.015071970410645008, 0.0016958117485046387, 0.007891558110713959, 0.0017214873805642128, 0.006620220374315977, 0.0013413261622190475, 0.005733772646635771, 0.0018523578764870763, 0.006291698198765516, 0.00553892320021987, 0.0005992440273985267, 0.012973746284842491, 0.005090024787932634, 0.003747079521417618, 0.002607618924230337, 0.0018713586032390594, 0.01679830811917782, 0.0019071763381361961, 0.04280632361769676, 0.008196777664124966, 0.030234098434448242, 0.004974509589374065, 0.0045332531444728374, 0.014434071257710457, 0.03611108660697937, 0.023145390674471855, 0.02585931308567524, 0.021439922973513603, 0.005772694945335388, 0.0032530799508094788, 0.020744070410728455, 0.007519986480474472, 0.016824552789330482, 0.10771138966083527, 0.03825715184211731, 0.06269405037164688, 0.013965999707579613, 0.037416450679302216, 0.06906930357217789, 0.047378506511449814, 0.022927414625883102, 0.032490696758031845, 0.10399843752384186, 0.01253723818808794, 0.0169858206063509, 0.05668923631310463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07504942268133163, 0.04218173772096634, 8.395662007387727e-05, 0.0020148244220763445, 0.0008396147168241441, 3.77664105144504e-06, 0.0005846293061040342, 0.0020101070404052734, 0.00015278188220690936, 5.877976946067065e-05, 9.080317249754444e-05, 0.0019185185665264726, 0.012847097590565681, 0.0009561142069287598, 0.0002398659271420911, 0.021243730559945107, 0.009065184742212296, 0.02463134005665779, 9.64064965955913e-05, 0.01949899271130562, 0.0008084636065177619, 1.684181006567087e-05, 0.0005437010549940169, 0.003239688463509083, 0.00013742300507146865, 0.0028418104629963636, 0.0004812901315744966, 0.0099767642095685, 0.0017870506271719933, 3.6058638215763494e-05, 0.02441936731338501, 0.03312493488192558, 0.00021857753745280206, 1.7226246200152673e-05, 0.23465955257415771, 0.0005569630302488804, 0.024988731369376183, 0.0018155527068302035, 0.07105875015258789, 0.0013815263519063592, 0.001691566314548254, 0.0037629639264196157, 0.021238647401332855, 0.12889724969863892, 0.002875989070162177, 0.20674337446689606, 0.006588687654584646, 0.0024510230869054794, 7.253405783558264e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13843509554862976, 0.027117395773530006, 4.058048580191098e-05, 0.000952942471485585, 0.0002770122664514929, 4.068742327945074e-06, 0.0004297108098398894, 0.0009920567972585559, 0.00010259400005452335, 2.643832704052329e-05, 4.5334829337662086e-05, 0.0005972388316877186, 0.004051996860653162, 0.0006208950071595609, 0.0001174396529677324, 0.00806475430727005, 0.011617399752140045, 0.009506863541901112, 0.00010797607683343813, 0.016204632818698883, 0.0006492778775282204, 9.189570846501738e-06, 0.00040298819658346474, 0.001932858838699758, 7.595602801302448e-05, 0.002121672732755542, 0.00038532621692866087, 0.009363999590277672, 0.0016167823923751712, 3.289650339866057e-05, 0.026991821825504303, 0.02491198480129242, 0.00015446075121872127, 2.1786559955216944e-05, 0.2225082665681839, 0.0004182844131719321, 0.020373933017253876, 0.0013666916638612747, 0.08808395266532898, 0.0009432065999135375, 0.0013492756988853216, 0.002970996778458357, 0.01377327460795641, 0.11662585288286209, 0.002757377689704299, 0.16100293397903442, 0.00518395658582449, 0.0016545583494007587, 0.00011024210834875703, 0.07289376854896545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1995508074760437, 0.0331091582775116, 0.00011092008207924664, 0.0021166803780943155, 0.0003450235817581415, 8.414050171268173e-06, 0.0002832511090673506, 0.0008771744323894382, 0.00017412292072549462, 5.937927926424891e-05, 8.158417767845094e-05, 0.0011706679360941052, 0.0024002569261938334, 0.0009115944267250597, 0.0004263557493686676, 0.0036756566260010004, 0.009934557601809502, 0.00950749684125185, 0.00027544167824089527, 0.028854232281446457, 0.000758553680498153, 4.4436059397412464e-05, 0.0008294599247165024, 0.0016297581605613232, 0.0001565305719850585, 0.002135590184479952, 0.000328675436321646, 0.012337442487478256, 0.0015855442034080625, 0.00016009778482839465, 0.01950659230351448, 0.04077085480093956, 0.000159876246470958, 3.71390487998724e-05, 0.1571277230978012, 0.0007220768020488322, 0.027448510751128197, 0.0022280828561633825, 0.049460165202617645, 0.0009995211148634553, 0.001955370418727398, 0.00187205511610955, 0.02013610675930977, 0.07804430276155472, 0.003919804934412241, 0.11581210047006607, 0.005968604236841202, 0.0019207806326448917, 0.00013987421698402613, 0.12101279944181442, 0.036918818950653076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19574546813964844, 0.03499729931354523, 0.0005661770701408386, 0.003049731021746993, 0.0017160562565550208, 0.00016707825125195086, 0.0012383179273456335, 0.002367024077102542, 0.0009227055707015097, 0.00046600046334788203, 0.0006967073422856629, 0.001689048600383103, 0.0071742236614227295, 0.0019788756035268307, 0.0009486195631325245, 0.006468736566603184, 0.006875572260469198, 0.010202269069850445, 0.0014448383590206504, 0.025175802409648895, 0.002675445284694433, 0.0005284557701088488, 0.00234165508300066, 0.005141777917742729, 0.0010462177451699972, 0.00636195857077837, 0.0014761831844225526, 0.011117484420537949, 0.0035965126007795334, 0.0008100921404547989, 0.010285007767379284, 0.0279033575206995, 0.0013515468453988433, 0.0004974292241968215, 0.1523667871952057, 0.002768883714452386, 0.0362694226205349, 0.004389962647110224, 0.03121880628168583, 0.003818899393081665, 0.0053872885182499886, 0.0073205274529755116, 0.02110508643090725, 0.05526142939925194, 0.011910706758499146, 0.08282051235437393, 0.018736885860562325, 0.007924985140562057, 0.0018636747263371944, 0.04074384272098541, 0.034338101744651794, 0.10273049026727676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015770943835377693, 0.0010557862697169185, 0.0043658060021698475, 0.0013709767954424024, 0.0033437043894082308, 0.014747611247003078, 0.003979212138801813, 0.0014616006519645452, 0.002237739972770214, 0.0016249256441369653, 0.0024919244460761547, 0.0031549325212836266, 0.0015306031564250588, 0.005647376179695129, 0.006209042854607105, 0.006085965316742659, 0.003106547286733985, 0.002673303009942174, 0.01032139454036951, 0.004630536772310734, 0.012806182727217674, 0.034129105508327484, 0.01762770675122738, 0.004530303180217743, 0.003959710709750652, 0.007313999813050032, 0.014077926985919476, 0.009851960465312004, 0.011042959988117218, 0.006836812477558851, 0.004841705318540335, 0.006288497243076563, 0.012275740504264832, 0.06237281113862991, 0.010846473276615143, 0.03334401547908783, 0.012901779264211655, 0.0233903955668211, 0.015170223079621792, 0.01800663024187088, 0.028667721897363663, 0.02295747958123684, 0.016863135620951653, 0.026696955785155296, 0.032450735569000244, 0.022598769515752792, 0.014177074655890465, 0.04022596403956413, 0.258211612701416, 0.016491370275616646, 0.027112672105431557, 0.03431612253189087, 0.041805557906627655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01580730266869068, 0.0020097976084798574, 0.011794665828347206, 0.0007055665482766926, 0.004396257922053337, 0.0005003698170185089, 0.0037357553374022245, 0.0005571625661104918, 0.0031828880310058594, 0.0009169261902570724, 0.0036335063632577658, 0.006415676325559616, 0.0002881988475564867, 0.013243190012872219, 0.0027283867821097374, 0.003425347153097391, 0.0009849995840340853, 0.0013405028730630875, 0.0155254565179348, 0.001322658616118133, 0.04110477492213249, 0.004523912910372019, 0.029642002657055855, 0.002715697744861245, 0.0032089902088046074, 0.012670239433646202, 0.026364067569375038, 0.04050229489803314, 0.023694884032011032, 0.015239403583109379, 0.0019380179001018405, 0.0019821724854409695, 0.011791684664785862, 0.0025629233568906784, 0.02762269228696823, 0.09288590401411057, 0.037201639264822006, 0.05579352006316185, 0.007105726283043623, 0.023881930857896805, 0.0436735562980175, 0.023981714621186256, 0.009219940751791, 0.03486195579171181, 0.08608929067850113, 0.00863860547542572, 0.011437507346272469, 0.033949803560972214, 0.01050889678299427, 0.00713984714820981, 0.016619984060525894, 0.011414972133934498, 0.04289926216006279, 0.10461754351854324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06556236743927002, 0.015437926165759563, 0.004083666019141674, 0.003871462307870388, 0.005359524395316839, 0.0003799672704190016, 0.0024657375179231167, 0.002032562857493758, 0.0018134816782549024, 0.0006886594346724451, 0.0017230358207598329, 0.0035902622621506453, 0.002346494933590293, 0.00890500470995903, 0.004556136671453714, 0.010113852098584175, 0.008818581700325012, 0.00541659165173769, 0.004958480130881071, 0.013575416058301926, 0.013126861304044724, 0.003350145649164915, 0.012845054268836975, 0.007345329038798809, 0.002150793792679906, 0.013912266120314598, 0.008571400307118893, 0.015937110409140587, 0.01777450181543827, 0.0037582984659820795, 0.015628604218363762, 0.018509458750486374, 0.003480973420664668, 0.001500332378782332, 0.07693901658058167, 0.02108100801706314, 0.05856830254197121, 0.015662087127566338, 0.042310792952775955, 0.01117481105029583, 0.018981967121362686, 0.013252370059490204, 0.03436682000756264, 0.028652267530560493, 0.04175269976258278, 0.0406150259077549, 0.01855381764471531, 0.023558802902698517, 0.006061159539967775, 0.04162559658288956, 0.06339764595031738, 0.01737486571073532, 0.04042775556445122, 0.024697110056877136, 0.057355787605047226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00015310615708585829, 2.57112196777598e-06, 0.00011312845890643075, 3.183270564477425e-06, 1.3003749700146727e-05, 0.04289190471172333, 4.3343370634829625e-06, 1.4025605423739762e-06, 1.0626973562466446e-05, 8.643335604574531e-06, 1.7329546608380042e-05, 1.9449304090812802e-05, 2.1379050849645864e-06, 2.68611383944517e-05, 0.0005377266788855195, 1.717785380606074e-05, 5.137844709679484e-06, 1.6637245607853401e-06, 0.00023265043273568153, 9.419054549653083e-06, 4.848946264246479e-05, 0.1317135989665985, 0.001086177653633058, 6.990694146224996e-06, 2.526380558265373e-05, 1.9678605895023793e-05, 8.704545325599611e-05, 4.026547685498372e-05, 5.3299205319490284e-05, 0.0003754692734219134, 6.558893346664263e-06, 1.2654335478146095e-05, 9.637194307288155e-05, 0.18902312219142914, 2.0861045413766988e-05, 0.0008166724583134055, 3.921975803677924e-05, 0.00020959826360922307, 3.128145181108266e-05, 5.64256843063049e-05, 0.00018951161473523825, 3.795397424255498e-05, 4.223332507535815e-05, 3.308264786028303e-05, 0.0001473552401876077, 3.256244963267818e-05, 1.5713363609393127e-05, 0.00020095467334613204, 0.6298817992210388, 1.6224921637331136e-05, 6.313298945315182e-05, 1.0456562449689955e-05, 0.00015083528705872595, 0.0002125837781932205, 6.312359619187191e-05, 0.001061989227309823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23992910981178284, 0.07745853811502457, 0.00013883100473321974, 0.0018242961959913373, 0.0002914142969530076, 3.8899244827916846e-05, 9.7549484053161e-05, 0.0006602514768019319, 0.00013721435971092433, 5.5644606618443504e-05, 9.340258111478761e-05, 0.0011877728393301368, 0.00405521783977747, 0.0006869595963507891, 0.0009504439076408744, 0.006449760403484106, 0.006630109157413244, 0.006814334541559219, 0.0001609908795217052, 0.017643900588154793, 0.00023583517759107053, 0.0002086088788928464, 0.0008912752964533865, 0.0011394955217838287, 0.00012066253111697733, 0.0012351424666121602, 0.00015455656102858484, 0.005543238949030638, 0.0010488007683306932, 0.00018624597578309476, 0.01281774416565895, 0.02503282204270363, 0.00010141229722648859, 0.00014780838682781905, 0.2487114667892456, 0.0006088383379392326, 0.020935971289873123, 0.0011570878559723496, 0.03428040072321892, 0.00044878924381919205, 0.0009251548908650875, 0.0006860672729089856, 0.011119593866169453, 0.02296113781630993, 0.0015835181111469865, 0.05196727067232132, 0.0038152250926941633, 0.0009171073324978352, 0.0004084211541339755, 0.056257229298353195, 0.022002041339874268, 0.020658638328313828, 0.0030893629882484674, 0.0008861426613293588, 0.04154498502612114, 0.0013871778501197696, 0.039480097591876984, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1834769994020462, 0.057562414556741714, 0.0004410381952766329, 0.002674704184755683, 0.0006888455827720463, 1.1947993698413484e-05, 0.000367784290574491, 0.0009337099618278444, 0.0004935103934258223, 0.00013711479550693184, 0.00032220856519415975, 0.002409433014690876, 0.0022790133953094482, 0.002109247026965022, 0.0011115565430372953, 0.005181849934160709, 0.009757746011018753, 0.005929846316576004, 0.0006043935427442193, 0.013123196549713612, 0.001353513216599822, 7.609661406604573e-05, 0.0017978791147470474, 0.001601126859895885, 0.0002824488910846412, 0.0028461681213229895, 0.000678868149407208, 0.013390607200562954, 0.002064749365672469, 0.0005106130847707391, 0.017556658014655113, 0.018453562632203102, 0.0002918815007433295, 4.413687202031724e-05, 0.18003611266613007, 0.0018104289192706347, 0.031119801104068756, 0.003212633775547147, 0.023032035678625107, 0.0013093877350911498, 0.0023851783480495214, 0.001996139995753765, 0.013519384898245335, 0.03201909735798836, 0.004281607922166586, 0.037126846611499786, 0.004637670237571001, 0.0019908281974494457, 0.0001111003803089261, 0.06556956470012665, 0.028685079887509346, 0.007799369283020496, 0.004847384057939053, 0.004318675491958857, 0.0730084776878357, 0.004123505670577288, 0.06181623414158821, 0.06067858636379242, 0.0, 0.0, 0.0, 0.0], [0.1666886955499649, 0.06059230864048004, 8.374131721211597e-05, 0.0017889816081151366, 0.0003193189622834325, 3.6005578749609413e-06, 0.0001768333895597607, 0.0008210246451199055, 0.00014625609037466347, 5.424496703199111e-05, 8.605317998444661e-05, 0.0007093879394233227, 0.003275031689554453, 0.0007889191037975252, 0.0002633518597576767, 0.0035135922953486443, 0.006421893835067749, 0.007619456388056278, 0.00015683777746744454, 0.0202189814299345, 0.0004368961963336915, 2.4054488676483743e-05, 0.0004451233253348619, 0.001663249684497714, 0.00013433865387924016, 0.001781439408659935, 0.00018992471450474113, 0.005777106620371342, 0.0012027996126562357, 0.00011366367107257247, 0.013096066191792488, 0.028851792216300964, 0.00011634037946350873, 1.4793474292673636e-05, 0.19879232347011566, 0.00037740901461802423, 0.02458731085062027, 0.0009084413759410381, 0.025782262906432152, 0.000502455048263073, 0.0007569543085992336, 0.000861739506945014, 0.008937736973166466, 0.021984312683343887, 0.002020064275711775, 0.04971754178404808, 0.005096844397485256, 0.0009672696469351649, 4.101698868907988e-05, 0.0414852537214756, 0.022077063098549843, 0.02621280960738659, 0.0030392417684197426, 0.0011170097859576344, 0.05393199250102043, 0.0013855776051059365, 0.06257219612598419, 0.03923622891306877, 0.0800328180193901, 0.0, 0.0, 0.0], [0.06472421437501907, 0.00430729053914547, 0.0037133335135877132, 0.001554512302391231, 0.0016083641676232219, 0.014888664707541466, 0.0006868256023153663, 0.0007250816561281681, 0.001195206306874752, 0.0006855523679405451, 0.0010830708779394627, 0.002699807519093156, 0.00114825286436826, 0.003494012402370572, 0.008801253512501717, 0.004145409911870956, 0.002671804279088974, 0.001839980250224471, 0.005429742857813835, 0.005660247523337603, 0.003412596881389618, 0.053881216794252396, 0.01650405116379261, 0.00221014185808599, 0.0017298356397077441, 0.00357062928378582, 0.0031770593486726284, 0.009427838958799839, 0.006512921769171953, 0.00818377360701561, 0.005050837527960539, 0.008948606438934803, 0.003571456065401435, 0.07074939459562302, 0.029912853613495827, 0.021245639771223068, 0.017181463539600372, 0.012633165344595909, 0.014337876811623573, 0.004243709146976471, 0.00926064420491457, 0.0035322264302521944, 0.009775319136679173, 0.01305901538580656, 0.01364632323384285, 0.015919044613838196, 0.006650583352893591, 0.010861281305551529, 0.16180419921875, 0.010943618603050709, 0.021444939076900482, 0.012734746560454369, 0.015870166942477226, 0.014066183939576149, 0.03361811116337776, 0.04043325036764145, 0.02850426733493805, 0.09505949169397354, 0.027332406491041183, 0.027936428785324097, 0.0, 0.0], [0.26483994722366333, 0.03062695637345314, 0.0005420676316134632, 0.0028796561527997255, 0.001463783672079444, 2.7848684112541378e-05, 0.0013027731329202652, 0.0018881013384088874, 0.0006172702996991575, 0.00032419836497865617, 0.0005146008916199207, 0.00167416303884238, 0.004036905709654093, 0.002030838280916214, 0.0006693546310998499, 0.006344437133520842, 0.006153726950287819, 0.004728198517113924, 0.0008424991392530501, 0.01160923670977354, 0.00250990386120975, 0.00012333859922364354, 0.0016805570339784026, 0.003818811848759651, 0.0006988974055275321, 0.005767884198576212, 0.0017112581990659237, 0.006801036186516285, 0.002482669660821557, 0.00042326931725256145, 0.011820976622402668, 0.016785340383648872, 0.0008057020604610443, 9.922688332153484e-05, 0.06438940763473511, 0.0022123921662569046, 0.019555047154426575, 0.002859198022633791, 0.01656945049762726, 0.0025942486245185137, 0.002804283984005451, 0.003891395404934883, 0.010048136115074158, 0.018859293311834335, 0.00406985217705369, 0.024771958589553833, 0.0070899720303714275, 0.0037562022916972637, 0.00021186252706684172, 0.02938189171254635, 0.021904082968831062, 0.009703225456178188, 0.006934079807251692, 0.005660726688802242, 0.05128788203001022, 0.005429355427622795, 0.05503396689891815, 0.03564535081386566, 0.07820829749107361, 0.018189523369073868, 0.10029347985982895, 0.0], [0.05409429967403412, 0.13270330429077148, 2.981280158564914e-05, 0.0009748058510012925, 0.0004530882288236171, 2.558386142936797e-07, 0.00018340563110541552, 0.0008224594639614224, 6.950245006009936e-05, 2.88940154860029e-05, 5.445537681225687e-05, 0.0006103961495682597, 0.0047368742525577545, 0.00034882797626778483, 8.71769298100844e-05, 0.0031803022138774395, 0.003627397818490863, 0.0054789576679468155, 2.768843296507839e-05, 0.008107303641736507, 0.0002869873133022338, 1.924336856973241e-06, 0.00015604702639393508, 0.001061582355760038, 5.621281161438674e-05, 0.0015182830393314362, 0.00015150048420764506, 0.003078550100326538, 0.00042437075171619654, 6.7062264861306176e-06, 0.007767217233777046, 0.0122481444850564, 4.6930756070651114e-05, 8.727899398763839e-07, 0.30984747409820557, 0.0001232499780599028, 0.011105618439614773, 0.00026042424724437296, 0.016271496191620827, 0.00031618529465049505, 0.0002604617620818317, 0.0006696101045235991, 0.0030574779957532883, 0.013755851425230503, 0.00039160018786787987, 0.046682439744472504, 0.0010928786359727383, 0.0003543063357938081, 2.164514626201708e-06, 0.09293868392705917, 0.00761492270976305, 0.01800219900906086, 0.0020463629625737667, 0.00032408745028078556, 0.03674140200018883, 0.00029367508250288665, 0.030090561136603355, 0.015061021782457829, 0.06216106191277504, 0.004070206079632044, 0.08402037620544434, 1.965779665624723e-05]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6306540369987488, 0.36934593319892883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8540881872177124, 0.0920879915356636, 0.05382382869720459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8603088855743408, 0.04775992035865784, 0.05647234991192818, 0.03545879200100899, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.832524299621582, 0.028114788234233856, 0.02703282982110977, 0.01567378081381321, 0.09665422886610031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8019688129425049, 0.010280164889991283, 0.030390214174985886, 0.029632752761244774, 0.10340499877929688, 0.024323096498847008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7744812965393066, 0.04780302569270134, 0.03863868862390518, 0.031203364953398705, 0.02141769789159298, 0.0366208516061306, 0.04983500391244888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8699086308479309, 0.02560955099761486, 0.013338228687644005, 0.01309638936072588, 0.00639557559043169, 0.032683297991752625, 0.004355486948043108, 0.03461286053061485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7326204776763916, 0.010952708311378956, 0.01380202081054449, 0.00920427031815052, 0.031435590237379074, 0.031539835035800934, 0.02083556167781353, 0.013682140037417412, 0.13592742383480072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6469839811325073, 0.011533213779330254, 0.011730492115020752, 0.016059700399637222, 0.02891778200864792, 0.03115108236670494, 0.025515174493193626, 0.009233827702701092, 0.020365919917821884, 0.19850876927375793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5850639939308167, 0.019476622343063354, 0.01211734302341938, 0.010004788637161255, 0.03809699788689613, 0.019742153584957123, 0.032711297273635864, 0.004719991236925125, 0.0311114601790905, 0.059796158224344254, 0.1871591955423355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44653579592704773, 0.046672970056533813, 0.05944380909204483, 0.02088984102010727, 0.0699034258723259, 0.016033431515097618, 0.11247506737709045, 0.012347371317446232, 0.03601408749818802, 0.04911918193101883, 0.06199563294649124, 0.06856933981180191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5386839509010315, 0.049318332225084305, 0.04221874848008156, 0.023909546434879303, 0.04639865830540657, 0.026849130168557167, 0.06763651967048645, 0.013095703907310963, 0.03250829875469208, 0.028918739408254623, 0.042770810425281525, 0.06385144591331482, 0.02384018339216709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5528542995452881, 0.04440215602517128, 0.023740647360682487, 0.017464090138673782, 0.04140370339155197, 0.031910382211208344, 0.057406093925237656, 0.008456870913505554, 0.036294709891080856, 0.027469538152217865, 0.05832531675696373, 0.04376779496669769, 0.009243312291800976, 0.04726112633943558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39004087448120117, 0.03728759288787842, 0.05579560995101929, 0.03326279670000076, 0.05361097678542137, 0.028353339061141014, 0.08016125112771988, 0.012584317475557327, 0.05685098096728325, 0.03192013502120972, 0.05548670515418053, 0.06643126159906387, 0.019014738500118256, 0.053076643496751785, 0.026122812181711197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4580621123313904, 0.07956811785697937, 0.04989553987979889, 0.017160849645733833, 0.03378983587026596, 0.01973552070558071, 0.061425987631082535, 0.011119945906102657, 0.035352692008018494, 0.024100808426737785, 0.03483051434159279, 0.06331969052553177, 0.018147062510252, 0.0425756573677063, 0.017882205545902252, 0.03303340822458267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3796212673187256, 0.0410129614174366, 0.040767852216959, 0.020314866676926613, 0.05459614843130112, 0.022014081478118896, 0.05762866139411926, 0.014587106183171272, 0.05464673042297363, 0.06380866467952728, 0.0780872106552124, 0.058630410581827164, 0.016350803896784782, 0.04375274479389191, 0.01328892633318901, 0.018408721312880516, 0.022482840344309807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.35943037271499634, 0.04514352232217789, 0.04710540920495987, 0.014627178199589252, 0.050501272082328796, 0.011822500266134739, 0.08849689364433289, 0.009368587285280228, 0.03205806761980057, 0.044747211039066315, 0.07776890695095062, 0.06533300131559372, 0.017667628824710846, 0.06028788536787033, 0.009546731598675251, 0.027961887419223785, 0.012707361951470375, 0.025425558909773827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4464394152164459, 0.040994297713041306, 0.026916174218058586, 0.01942998170852661, 0.031921565532684326, 0.020301269367337227, 0.0361759252846241, 0.008117090910673141, 0.018082844093441963, 0.04892904311418533, 0.04367528483271599, 0.048116154968738556, 0.012889678589999676, 0.028488216921687126, 0.012631392106413841, 0.017041023820638657, 0.013281641528010368, 0.01658122055232525, 0.10998788475990295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.40306606888771057, 0.022810988128185272, 0.025901662185788155, 0.017516085878014565, 0.03604021295905113, 0.018132278695702553, 0.03344681113958359, 0.010914497077465057, 0.019132472574710846, 0.0660206601023674, 0.040669191628694534, 0.04119034484028816, 0.012773898430168629, 0.0225746538490057, 0.014476648531854153, 0.01787627302110195, 0.01561643648892641, 0.013942917808890343, 0.09775615483522415, 0.07014168053865433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.48848584294319153, 0.004439939744770527, 0.012058835476636887, 0.023788003250956535, 0.019313016906380653, 0.023362010717391968, 0.0285797081887722, 0.004186628852039576, 0.014734101481735706, 0.0067566861398518085, 0.016055908054113388, 0.023046353831887245, 0.009530526585876942, 0.013574065640568733, 0.008370582014322281, 0.010082762688398361, 0.02436009980738163, 0.008839697577059269, 0.028083140030503273, 0.016472259536385536, 0.21587984263896942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3052918314933777, 0.00874535832554102, 0.01906646601855755, 0.03849315643310547, 0.023509779945015907, 0.032891660928726196, 0.04914432018995285, 0.006159527227282524, 0.00979783944785595, 0.01407068781554699, 0.010473133996129036, 0.041329044848680496, 0.004288008436560631, 0.019678838551044464, 0.015736166387796402, 0.012343534268438816, 0.0403112918138504, 0.014600152149796486, 0.055848296731710434, 0.026189640164375305, 0.06500408798456192, 0.18702715635299683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21611866354942322, 0.029549766331911087, 0.03641846403479576, 0.021918313577771187, 0.0545266717672348, 0.018413152545690536, 0.076636902987957, 0.00580446096137166, 0.01724056527018547, 0.038074467331171036, 0.04337533935904503, 0.03521515801548958, 0.009035401046276093, 0.050451066344976425, 0.01293157134205103, 0.021416347473859787, 0.013106146827340126, 0.01121155358850956, 0.11794093251228333, 0.03566695749759674, 0.04286973923444748, 0.01180244144052267, 0.08027582615613937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24497053027153015, 0.018908634781837463, 0.01691591553390026, 0.010371037758886814, 0.029000625014305115, 0.011786445043981075, 0.03416994959115982, 0.008239717222750187, 0.025751536712050438, 0.08737188577651978, 0.07818567752838135, 0.03108120523393154, 0.01248079538345337, 0.018779048696160316, 0.006596757564693689, 0.011785618029534817, 0.0074180481024086475, 0.013844240456819534, 0.05451186001300812, 0.046277184039354324, 0.02911621332168579, 0.0020606552716344595, 0.02481168881058693, 0.1755646914243698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29819250106811523, 0.007306181360036135, 0.009252293966710567, 0.011875802651047707, 0.02294461987912655, 0.01950102485716343, 0.021725565195083618, 0.0060248845256865025, 0.013821283355355263, 0.14574967324733734, 0.07911382615566254, 0.019652191549539566, 0.005027467850595713, 0.013988971710205078, 0.005078436806797981, 0.0077042654156684875, 0.005026394035667181, 0.006144734565168619, 0.05317623168230057, 0.03752351179718971, 0.016601189970970154, 0.004783570300787687, 0.019457276910543442, 0.03369919955730438, 0.1366289108991623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34731853008270264, 0.03471774607896805, 0.012962999753654003, 0.008556575514376163, 0.021791983395814896, 0.01633581519126892, 0.021426619961857796, 0.0059920442290604115, 0.03642544150352478, 0.0425698384642601, 0.06312651932239532, 0.019444935023784637, 0.01043515745550394, 0.012344127520918846, 0.005676210857927799, 0.012815158814191818, 0.0072371033020317554, 0.012070988304913044, 0.030919412150979042, 0.021685784682631493, 0.013060340657830238, 0.0023133212234824896, 0.024171486496925354, 0.04884450510144234, 0.04182664304971695, 0.12593066692352295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24223162233829498, 0.009437029249966145, 0.015667587518692017, 0.010157723911106586, 0.04341868311166763, 0.010596837848424911, 0.06245097517967224, 0.003847883315756917, 0.014316042885184288, 0.03825585916638374, 0.054478179663419724, 0.020912591367959976, 0.005461590830236673, 0.031692177057266235, 0.003263052087277174, 0.010060703381896019, 0.005690687336027622, 0.005320440046489239, 0.08733957260847092, 0.02459087409079075, 0.028962809592485428, 0.003123754635453224, 0.030208347365260124, 0.02258833311498165, 0.037914715707302094, 0.046325091272592545, 0.13168685138225555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1844162791967392, 0.01736374944448471, 0.026535671204328537, 0.011049114167690277, 0.03714679554104805, 0.006405390799045563, 0.09182542562484741, 0.0024539276491850615, 0.015262056142091751, 0.020405219867825508, 0.0490507036447525, 0.030746987089514732, 0.007320188917219639, 0.04873437061905861, 0.003828110173344612, 0.013213972561061382, 0.006866618990898132, 0.008250377140939236, 0.07854799181222916, 0.015206773765385151, 0.06948117166757584, 0.003801827784627676, 0.032940130680799484, 0.02514093928039074, 0.025159133598208427, 0.04900611937046051, 0.10514853149652481, 0.014692493714392185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22062534093856812, 0.010324188508093357, 0.02021440677344799, 0.018919017165899277, 0.023025332018733025, 0.01846279948949814, 0.03390087932348251, 0.010378553532063961, 0.01761806569993496, 0.022298524156212807, 0.014431712217628956, 0.03293348103761673, 0.009232486598193645, 0.014611586928367615, 0.012448841705918312, 0.009991004131734371, 0.02700788713991642, 0.01210127305239439, 0.07093562185764313, 0.02592858485877514, 0.040966007858514786, 0.007715304382145405, 0.05957465618848801, 0.031818922609090805, 0.02799714170396328, 0.03013414703309536, 0.05321282893419266, 0.01738632656633854, 0.10580505430698395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23389467597007751, 0.02797011099755764, 0.0264182910323143, 0.018241455778479576, 0.015614233911037445, 0.015622658655047417, 0.02782832272350788, 0.013071618042886257, 0.012471342459321022, 0.014699346385896206, 0.014436689205467701, 0.04509958624839783, 0.015672598034143448, 0.01688159629702568, 0.0199158675968647, 0.023603595793247223, 0.022179385647177696, 0.032505106180906296, 0.053455203771591187, 0.01989869587123394, 0.03691788390278816, 0.02075882814824581, 0.047567252069711685, 0.03644523397088051, 0.018179411068558693, 0.02198648825287819, 0.028001056984066963, 0.02453652024269104, 0.05097188800573349, 0.04515499249100685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17731425166130066, 0.017004894092679024, 0.01930859312415123, 0.009710479527711868, 0.027792535722255707, 0.010517144575715065, 0.0321430005133152, 0.007252802606672049, 0.02579190582036972, 0.031608499586582184, 0.039440713822841644, 0.030711079016327858, 0.007423693779855967, 0.022074270993471146, 0.006244482938200235, 0.009649482555687428, 0.01252664066851139, 0.011742545291781425, 0.070147305727005, 0.02066165767610073, 0.05024110898375511, 0.005217545200139284, 0.039037857204675674, 0.03914717584848404, 0.042052071541547775, 0.06427573412656784, 0.061095889657735825, 0.016132378950715065, 0.0666407123208046, 0.013456881046295166, 0.0136366942897439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21326054632663727, 0.012249086052179337, 0.013917372561991215, 0.00940314494073391, 0.021779943257570267, 0.010084033012390137, 0.02282562106847763, 0.006017840467393398, 0.011236127465963364, 0.04108232259750366, 0.02633448876440525, 0.024487951770424843, 0.007420718669891357, 0.014642694033682346, 0.007410714868456125, 0.010091127827763557, 0.00854739174246788, 0.008414488285779953, 0.06738308072090149, 0.04807104542851448, 0.03406394645571709, 0.005222151055932045, 0.03211963176727295, 0.030542951077222824, 0.0508110336959362, 0.03669068217277527, 0.09280984103679657, 0.011727462522685528, 0.04942338913679123, 0.008648855611681938, 0.010333792306482792, 0.05294650048017502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22859340906143188, 0.0056822169572114944, 0.016307957470417023, 0.022877955809235573, 0.017472675070166588, 0.023061269894242287, 0.03463312238454819, 0.0073997401632368565, 0.020120929926633835, 0.01715860515832901, 0.024792881682515144, 0.02829248271882534, 0.012285011820495129, 0.017350099980831146, 0.01764640584588051, 0.011753913946449757, 0.017085924744606018, 0.012465324252843857, 0.026154467836022377, 0.017718536779284477, 0.03508739545941353, 0.011107080616056919, 0.032222993671894073, 0.02654748409986496, 0.019111955538392067, 0.032428208738565445, 0.04159815236926079, 0.02288781851530075, 0.040806274861097336, 0.011538989841938019, 0.020888572558760643, 0.017314428463578224, 0.1096077710390091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21231426298618317, 0.0027410376351326704, 0.012257386930286884, 0.012147203087806702, 0.04689387232065201, 0.007974931038916111, 0.0565236397087574, 0.00608081417158246, 0.019302666187286377, 0.01971050351858139, 0.04315030574798584, 0.018873637542128563, 0.010138006880879402, 0.029669824987649918, 0.005218506325036287, 0.017877912148833275, 0.012554778717458248, 0.008496502414345741, 0.03654300794005394, 0.035792119801044464, 0.07004593312740326, 0.004087487235665321, 0.022196657955646515, 0.029037827625870705, 0.023637505248188972, 0.03284067288041115, 0.06249765306711197, 0.014827013947069645, 0.0349702350795269, 0.00991535559296608, 0.014085500501096249, 0.04272092133760452, 0.013938510790467262, 0.010937832295894623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19756336510181427, 0.206142395734787, 0.013288931921124458, 0.005771404132246971, 0.004723843652755022, 0.007342012599110603, 0.008523580618202686, 0.003427043789997697, 0.0037256961222738028, 0.008077803067862988, 0.005464448593556881, 0.019135816022753716, 0.00647295918315649, 0.007152874022722244, 0.006339899264276028, 0.012563584372401237, 0.004507965873926878, 0.015174638479948044, 0.02033286914229393, 0.015286986716091633, 0.0064497157000005245, 0.006708052475005388, 0.021658560261130333, 0.017142606899142265, 0.007911995984613895, 0.01138471532613039, 0.014507146552205086, 0.006484906189143658, 0.010699054226279259, 0.006012407131493092, 0.005416628904640675, 0.017947759479284286, 0.004906671121716499, 0.009358991868793964, 0.28239256143569946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24277667701244354, 0.039459098130464554, 0.03818380832672119, 0.026328539475798607, 0.009376080706715584, 0.017340077087283134, 0.025426840409636497, 0.006542535033077002, 0.01688888482749462, 0.00720843905583024, 0.008764988742768764, 0.035396330058574677, 0.015786632895469666, 0.011913308873772621, 0.02135203406214714, 0.024512186646461487, 0.022842859849333763, 0.023400278761982918, 0.011991960927844048, 0.013669387437403202, 0.025233754888176918, 0.016079578548669815, 0.042962126433849335, 0.018191276118159294, 0.0078049697913229465, 0.014032796956598759, 0.014606454409658909, 0.02414494752883911, 0.027413260191679, 0.007533500902354717, 0.029517823830246925, 0.014562120661139488, 0.012622347101569176, 0.024344298988580704, 0.044422537088394165, 0.0573672354221344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22212496399879456, 0.06045117229223251, 0.022978628054261208, 0.01045622956007719, 0.019864892587065697, 0.010773503221571445, 0.02753094583749771, 0.0040292637422680855, 0.0075396327301859856, 0.01781798154115677, 0.030161667615175247, 0.02436237782239914, 0.008736335672438145, 0.027199141681194305, 0.009902384132146835, 0.02621765248477459, 0.004504067823290825, 0.014184381812810898, 0.03921576216816902, 0.023109067231416702, 0.01880718395113945, 0.0049792989157140255, 0.027614900842308998, 0.018915927037596703, 0.019362395629286766, 0.018159544095396996, 0.033059585839509964, 0.009617476724088192, 0.0151754729449749, 0.011645318008959293, 0.004421350080519915, 0.02377525344491005, 0.011826269328594208, 0.011981029063463211, 0.07135867327451706, 0.029545556753873825, 0.0585947223007679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17049618065357208, 0.02490774355828762, 0.026551084592938423, 0.017057133838534355, 0.02316970005631447, 0.010507003404200077, 0.046984653919935226, 0.0033344835974276066, 0.012920168228447437, 0.01860816590487957, 0.02998524159193039, 0.03075716271996498, 0.0074020070023834705, 0.03447911515831947, 0.0079794367775321, 0.014994741417467594, 0.008963828906416893, 0.010178599506616592, 0.04119403287768364, 0.016026079654693604, 0.02527037262916565, 0.005745221395045519, 0.0490896962583065, 0.021432746201753616, 0.02280351147055626, 0.02945786900818348, 0.04443966969847679, 0.01454493124037981, 0.03321575000882149, 0.011799733154475689, 0.010736441239714622, 0.018033510074019432, 0.027607081457972527, 0.014612674713134766, 0.023777326568961143, 0.043069176375865936, 0.02211720123887062, 0.025750527158379555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15222635865211487, 0.007651491090655327, 0.01616640016436577, 0.010019646026194096, 0.03407267481088638, 0.008814997039735317, 0.030027227476239204, 0.005533064715564251, 0.026048671454191208, 0.03266069293022156, 0.0555078387260437, 0.020942844450473785, 0.006284660194069147, 0.022449102252721786, 0.004946807399392128, 0.008167204447090626, 0.00862005352973938, 0.0074083819054067135, 0.04071184992790222, 0.02060755155980587, 0.055483557283878326, 0.004163782577961683, 0.02527337707579136, 0.02676769718527794, 0.04134301468729973, 0.046140484511852264, 0.05964326485991478, 0.013756879605352879, 0.040734630078077316, 0.007446873467415571, 0.010786875151097775, 0.02387557178735733, 0.03545378893613815, 0.0129670025780797, 0.007625695783644915, 0.02903643436729908, 0.007823273539543152, 0.011500031687319279, 0.021310338750481606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3003881275653839, 0.005028429441154003, 0.010439293459057808, 0.0150349335744977, 0.009383244439959526, 0.01831532083451748, 0.01208336278796196, 0.005068314727395773, 0.014619600959122181, 0.027346711605787277, 0.014852821826934814, 0.016320819035172462, 0.006198607850819826, 0.005152419675141573, 0.011844949796795845, 0.007172406185418367, 0.012813552282750607, 0.00722641684114933, 0.018515633419156075, 0.02019898034632206, 0.013278738595545292, 0.004395710304379463, 0.03148019313812256, 0.02284904196858406, 0.03262319788336754, 0.029638240113854408, 0.022082781419157982, 0.010174362920224667, 0.04001083970069885, 0.003474175464361906, 0.016861578449606895, 0.020155001431703568, 0.02834576927125454, 0.024348603561520576, 0.005554721690714359, 0.01755436696112156, 0.003940512426197529, 0.004086413886398077, 0.02413221448659897, 0.10700961202383041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15593452751636505, 0.007752944715321064, 0.013505632989108562, 0.009597779251635075, 0.026644917204976082, 0.008977124467492104, 0.030784310773015022, 0.0056007299572229385, 0.02539876103401184, 0.028768368065357208, 0.04151301085948944, 0.019192373380064964, 0.0072881365194916725, 0.017476603388786316, 0.004199390299618244, 0.006913723424077034, 0.007618695963174105, 0.006565991789102554, 0.03262946754693985, 0.017081905156373978, 0.028694892302155495, 0.0024869265034794807, 0.023684822022914886, 0.026685386896133423, 0.03491225838661194, 0.04875370115041733, 0.059580400586128235, 0.011380982585251331, 0.04358220100402832, 0.005574796814471483, 0.009433631785213947, 0.018874669447541237, 0.0299215167760849, 0.01228615827858448, 0.007501666434109211, 0.021212296560406685, 0.007548971567302942, 0.009008624590933323, 0.01549629494547844, 0.05629520118236542, 0.053640298545360565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20092721283435822, 0.007617018185555935, 0.007246249355375767, 0.005546188447624445, 0.018642671406269073, 0.006564529612660408, 0.023853177204728127, 0.003281446872279048, 0.007627282291650772, 0.031441014260053635, 0.03144468367099762, 0.015279993414878845, 0.003372247563675046, 0.013935079798102379, 0.0020038096699863672, 0.005023240111768246, 0.0034009614028036594, 0.004537593107670546, 0.05010034888982773, 0.020311476662755013, 0.014314389787614346, 0.0020468009170144796, 0.018214358016848564, 0.030374404042959213, 0.03626064956188202, 0.03099750354886055, 0.07855334877967834, 0.005228733643889427, 0.025254908949136734, 0.005633670371025801, 0.0037758469115942717, 0.02456766739487648, 0.026595907285809517, 0.007939298637211323, 0.005971560254693031, 0.010439824312925339, 0.004996398463845253, 0.006142019294202328, 0.005792497657239437, 0.05333421751856804, 0.026311401277780533, 0.11509839445352554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09086547791957855, 0.00749617675319314, 0.014893178828060627, 0.008825507014989853, 0.02349063940346241, 0.0063225687481462955, 0.03370848670601845, 0.002789694583043456, 0.01181673351675272, 0.021964536979794502, 0.03300778567790985, 0.01652403548359871, 0.004654743708670139, 0.022191250696778297, 0.004092777613550425, 0.007676413748413324, 0.00577528728172183, 0.004938167054206133, 0.049518704414367676, 0.014956576749682426, 0.04935700073838234, 0.0033324395772069693, 0.023383302614092827, 0.01467848103493452, 0.02821861393749714, 0.03190595656633377, 0.0657987892627716, 0.009671724401414394, 0.03492726758122444, 0.008072850294411182, 0.006746002472937107, 0.01696384884417057, 0.03696895018219948, 0.00931826326996088, 0.009392628446221352, 0.028919711709022522, 0.007962378673255444, 0.011964118108153343, 0.013583880849182606, 0.07248040288686752, 0.04233275726437569, 0.07131388783454895, 0.017197972163558006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10008473694324493, 0.020906299352645874, 0.017155222594738007, 0.005632330663502216, 0.018256010487675667, 0.0040412344969809055, 0.032119665294885635, 0.002601136453449726, 0.011653388850390911, 0.016663840040564537, 0.028636211529374123, 0.020517881959676743, 0.0066637624986469746, 0.0202286746352911, 0.0032733408734202385, 0.008570421487092972, 0.0041394317522645, 0.00732831098139286, 0.046449288725852966, 0.010968852788209915, 0.0247848741710186, 0.0019245501607656479, 0.02385186031460762, 0.026459045708179474, 0.022048527374863625, 0.04996930807828903, 0.06406991183757782, 0.008694886229932308, 0.03438359871506691, 0.00726616894826293, 0.004570959135890007, 0.011805967427790165, 0.0262888353317976, 0.006127913482487202, 0.02671920508146286, 0.032938458025455475, 0.014591285958886147, 0.011812342330813408, 0.009489016607403755, 0.059038903564214706, 0.04030894860625267, 0.07404261082410812, 0.010098781436681747, 0.022823985666036606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10919901728630066, 0.005503688007593155, 0.010348108597099781, 0.004957194440066814, 0.03254447877407074, 0.007060380186885595, 0.022784654051065445, 0.0036697587929666042, 0.027077890932559967, 0.027822919189929962, 0.0666205957531929, 0.013536344282329082, 0.004817878361791372, 0.017471132799983025, 0.002493551466614008, 0.005847657565027475, 0.0036269943229854107, 0.004088975489139557, 0.0418795682489872, 0.010736677795648575, 0.032179415225982666, 0.0015932866372168064, 0.012449728325009346, 0.01142652053385973, 0.03298941254615784, 0.05510924383997917, 0.05513385310769081, 0.007753467187285423, 0.028174959123134613, 0.00443160068243742, 0.003703705035150051, 0.010208004154264927, 0.01923893205821514, 0.007873743772506714, 0.004099482670426369, 0.01408360991626978, 0.00583669263869524, 0.005650454666465521, 0.007944976910948753, 0.04359070211648941, 0.031975604593753815, 0.051776815205812454, 0.006974674295634031, 0.017177265137434006, 0.106536366045475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2306368201971054, 0.004443737678229809, 0.011370479129254818, 0.008108345791697502, 0.018073290586471558, 0.009719692170619965, 0.02558189444243908, 0.005291537381708622, 0.014590430073440075, 0.012673652730882168, 0.013752948492765427, 0.016893111169338226, 0.0048167225904762745, 0.011443697847425938, 0.004026318900287151, 0.0059821633622050285, 0.011995986104011536, 0.006138759199529886, 0.0327112041413784, 0.01488057617098093, 0.030218465253710747, 0.0036979818250983953, 0.02316529117524624, 0.015213539823889732, 0.01615525595843792, 0.02037184312939644, 0.03797391802072525, 0.010510590858757496, 0.0380181260406971, 0.010382155887782574, 0.013011669740080833, 0.015974968671798706, 0.025488467887043953, 0.012760105542838573, 0.005332975648343563, 0.01870114542543888, 0.005373967345803976, 0.010323794558644295, 0.0167305376380682, 0.044754184782505035, 0.042557090520858765, 0.04476600140333176, 0.014261966571211815, 0.019490526989102364, 0.02687167003750801, 0.014762437902390957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26976877450942993, 0.00550153199583292, 0.008168630301952362, 0.003031423082575202, 0.012281485833227634, 0.006438309792429209, 0.007484623696655035, 0.010065334849059582, 0.03803449496626854, 0.022285331040620804, 0.034133780747652054, 0.015648869797587395, 0.006524545140564442, 0.006275631953030825, 0.005234758369624615, 0.009794310666620731, 0.004241371992975473, 0.01159136276692152, 0.011085540987551212, 0.010721377097070217, 0.0037608235143125057, 0.0015414096415042877, 0.010532437823712826, 0.013234993442893028, 0.021793320775032043, 0.03456593677401543, 0.015939529985189438, 0.007812716998159885, 0.013924744911491871, 0.0035601851996034384, 0.004614572506397963, 0.009587117470800877, 0.006645931396633387, 0.006256966385990381, 0.00485600670799613, 0.009568224661052227, 0.010447010397911072, 0.0029746645595878363, 0.007835508324205875, 0.02405143529176712, 0.014495380222797394, 0.019411195069551468, 0.0035233369562774897, 0.01878955215215683, 0.057217907160520554, 0.023460883647203445, 0.15128670632839203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11049102991819382, 0.0012515407288447022, 0.007764326874166727, 0.006644696928560734, 0.03518267348408699, 0.006746967323124409, 0.04100077226758003, 0.0029034996405243874, 0.015740323811769485, 0.02226782776415348, 0.04778476431965828, 0.01004510372877121, 0.0027607218362390995, 0.02065282315015793, 0.0017080664401873946, 0.0037926980294287205, 0.004480010364204645, 0.0021784971468150616, 0.03828907012939453, 0.010715046897530556, 0.046106383204460144, 0.0019567704293876886, 0.011152825318276882, 0.01087392307817936, 0.024339934810996056, 0.026387643069028854, 0.06604895740747452, 0.006676647812128067, 0.029518181458115578, 0.0070890383794903755, 0.005045922938734293, 0.012572399340569973, 0.0449402742087841, 0.007390780374407768, 0.0008177821873687208, 0.010850460268557072, 0.0020029875449836254, 0.008163386955857277, 0.006248425226658583, 0.046046823263168335, 0.03384029120206833, 0.06402698904275894, 0.010848644189536572, 0.012153456918895245, 0.04134054481983185, 0.004173130262643099, 0.011205444112420082, 0.05578150600194931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12189563363790512, 0.0021589575335383415, 0.009094676934182644, 0.008412276394665241, 0.036922354251146317, 0.005114470608532429, 0.04259574040770531, 0.004215307999402285, 0.013001788407564163, 0.014014591462910175, 0.03147333115339279, 0.012050994671881199, 0.006715882569551468, 0.022786304354667664, 0.0034704215358942747, 0.012989388778805733, 0.00838895421475172, 0.005523109342902899, 0.0274738147854805, 0.024073677137494087, 0.049858249723911285, 0.002663084538653493, 0.016679007560014725, 0.020401673391461372, 0.016310203820466995, 0.02290186658501625, 0.045655541121959686, 0.009155476465821266, 0.02453531138598919, 0.007144030649214983, 0.009558520279824734, 0.030825430527329445, 0.011179584078490734, 0.00732354586943984, 0.0026509028393775225, 0.016880644485354424, 0.0058756000362336636, 0.014826892875134945, 0.012345721013844013, 0.03277301415801048, 0.028676040470600128, 0.04519205167889595, 0.017650874331593513, 0.019045434892177582, 0.041410643607378006, 0.009548335336148739, 0.022312209010124207, 0.03667521849274635, 0.007573298178613186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2020236700773239, 0.005127882584929466, 0.010550590232014656, 0.008032572455704212, 0.018733320757746696, 0.009568692184984684, 0.024623487144708633, 0.004921814426779747, 0.016276706010103226, 0.015496277250349522, 0.01936236023902893, 0.01552261970937252, 0.004421645309776068, 0.011940885335206985, 0.0030698764603585005, 0.005788655951619148, 0.010235861875116825, 0.005580112338066101, 0.02881862036883831, 0.011490311473608017, 0.033845264464616776, 0.003983369097113609, 0.01976284198462963, 0.015825863927602768, 0.019038928672671318, 0.02448730170726776, 0.0330984964966774, 0.010384686291217804, 0.03255197033286095, 0.007939066737890244, 0.010932291857898235, 0.013825861737132072, 0.02283507026731968, 0.013256526552140713, 0.004975730087608099, 0.015564711764454842, 0.004714569076895714, 0.009399039670825005, 0.01415952481329441, 0.036125849932432175, 0.03554532676935196, 0.038215186446905136, 0.013186817988753319, 0.02038521319627762, 0.035216428339481354, 0.011374980211257935, 0.013508175499737263, 0.034779634326696396, 0.014355837367475033, 0.005139495711773634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07422041147947311, 0.007722916081547737, 0.014227086678147316, 0.008458096534013748, 0.022225316613912582, 0.005966053809970617, 0.031531378626823425, 0.002471295418217778, 0.010966950096189976, 0.019780131056904793, 0.03270657733082771, 0.015617146156728268, 0.004199006594717503, 0.02248106151819229, 0.003920529969036579, 0.007298241835087538, 0.0051292721182107925, 0.004831829108297825, 0.042392224073410034, 0.01283008512109518, 0.045102596282958984, 0.0031508475076407194, 0.01919439062476158, 0.012029435485601425, 0.022380473092198372, 0.025157468393445015, 0.05037901550531387, 0.008789913728833199, 0.028817595914006233, 0.006977755110710859, 0.00576345669105649, 0.014766224659979343, 0.02954990416765213, 0.00787887629121542, 0.008430160582065582, 0.02402557246387005, 0.007384228520095348, 0.01042458787560463, 0.01180261094123125, 0.05851896107196808, 0.03601931780576706, 0.05953137204051018, 0.015352880582213402, 0.019957317039370537, 0.047221217304468155, 0.008623627945780754, 0.011108682490885258, 0.025572188198566437, 0.008513055741786957, 0.0033856001682579517, 0.015215069986879826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15297527611255646, 0.009896533563733101, 0.018088463693857193, 0.010709642432630062, 0.007593769114464521, 0.008125538006424904, 0.012167541310191154, 0.006123260594904423, 0.01714717037975788, 0.009332270361483097, 0.014601127244532108, 0.026991458609700203, 0.01012849435210228, 0.008652453310787678, 0.013098780065774918, 0.009014339186251163, 0.011041748337447643, 0.014901893213391304, 0.01259115431457758, 0.00818653404712677, 0.03021584078669548, 0.005592893809080124, 0.016383996233344078, 0.012502048164606094, 0.009685777127742767, 0.013658668845891953, 0.014545083045959473, 0.019454197958111763, 0.02687203511595726, 0.006651703268289566, 0.013438212685286999, 0.007799298036843538, 0.027688469737768173, 0.010526955127716064, 0.013776610605418682, 0.028598535805940628, 0.008966188877820969, 0.008053770288825035, 0.026180757209658623, 0.03534921258687973, 0.03142250329256058, 0.027576768770813942, 0.015584834851324558, 0.0330272912979126, 0.04065440595149994, 0.03143748268485069, 0.011273466050624847, 0.01958487741649151, 0.011547867208719254, 0.018561307340860367, 0.015871604904532433, 0.026149846613407135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11920668929815292, 0.003911111503839493, 0.011696657165884972, 0.0071938238106667995, 0.011462696827948093, 0.0071630277670919895, 0.01886860840022564, 0.005122564733028412, 0.012449475936591625, 0.0078118909150362015, 0.006656667683273554, 0.017129691317677498, 0.0063172210939228535, 0.005540038459002972, 0.004622633568942547, 0.0051683844067156315, 0.01374084036797285, 0.007131520193070173, 0.03364860266447067, 0.011521534062922001, 0.06176968663930893, 0.004280456807464361, 0.014285378158092499, 0.01137757208198309, 0.009938336908817291, 0.015651781111955643, 0.03248519077897072, 0.01185500156134367, 0.05384528636932373, 0.009614849463105202, 0.01444635633379221, 0.010768813081085682, 0.021277830004692078, 0.010127227753400803, 0.006150827277451754, 0.022230131551623344, 0.002988901687785983, 0.007057619746774435, 0.02024727687239647, 0.03413264453411102, 0.04087410494685173, 0.04014195501804352, 0.013609835878014565, 0.022879477590322495, 0.04424641281366348, 0.019566185772418976, 0.011414920911192894, 0.019064318388700485, 0.011381017044186592, 0.008803749457001686, 0.014305480755865574, 0.012433535419404507, 0.05038421228528023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17541345953941345, 0.006641192361712456, 0.008082504384219646, 0.00880911573767662, 0.01722385734319687, 0.010498997755348682, 0.02414092794060707, 0.0024512331001460552, 0.005772081203758717, 0.016933757811784744, 0.024446886032819748, 0.014624013565480709, 0.00305423466488719, 0.016916371881961823, 0.0033889953047037125, 0.00684077013283968, 0.0046505434438586235, 0.004531947895884514, 0.04441161826252937, 0.016111310571432114, 0.0330282486975193, 0.004407105967402458, 0.01818789914250374, 0.009522168897092342, 0.01869722083210945, 0.015079534612596035, 0.036810923367738724, 0.006837104447185993, 0.019808454439044, 0.006765339523553848, 0.004835797473788261, 0.017002929002046585, 0.01548189576715231, 0.011427708901464939, 0.005451457109302282, 0.01168096624314785, 0.006758184637874365, 0.00887408759444952, 0.009272926487028599, 0.04308874160051346, 0.02314114384353161, 0.052865806967020035, 0.014339517802000046, 0.014416221529245377, 0.024706067517399788, 0.007920635864138603, 0.008486004546284676, 0.024117115885019302, 0.012595601379871368, 0.00343587645329535, 0.014130338095128536, 0.009659187868237495, 0.005127588752657175, 0.06709636002779007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06553003937005997, 0.015188747085630894, 0.013408771716058254, 0.004292211029678583, 0.015698354691267014, 0.003066930454224348, 0.029545316472649574, 0.0020321421325206757, 0.009870612993836403, 0.014602908864617348, 0.025097135454416275, 0.015674738213419914, 0.004904087167233229, 0.018608205020427704, 0.002330329967662692, 0.006084942724555731, 0.00294348387978971, 0.005054498091340065, 0.0379520021378994, 0.008786642923951149, 0.02236969769001007, 0.0014874389162287116, 0.017113571986556053, 0.018185971304774284, 0.017163677141070366, 0.03894953802227974, 0.05516159161925316, 0.006690297741442919, 0.028793292120099068, 0.006083689630031586, 0.0035403587389737368, 0.009739371947944164, 0.02064882032573223, 0.004372958559542894, 0.019110066816210747, 0.02645723894238472, 0.011696696281433105, 0.009992461651563644, 0.007384908385574818, 0.050101254135370255, 0.03478879854083061, 0.06786216795444489, 0.008838977664709091, 0.019770579412579536, 0.04619230702519417, 0.010806725360453129, 0.013646677136421204, 0.01968427747488022, 0.00499936705455184, 0.0039269267581403255, 0.008958522230386734, 0.012882484123110771, 0.01069621555507183, 0.042256638407707214, 0.018974412232637405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12604844570159912, 0.011027038097381592, 0.00954609178006649, 0.004332737997174263, 0.017726803198456764, 0.004952180664986372, 0.022247636690735817, 0.0020094814244657755, 0.011148463003337383, 0.010635728016495705, 0.02336687035858631, 0.014099761843681335, 0.00362091651186347, 0.015841828659176826, 0.0015752960462123156, 0.0038637197576463223, 0.003180788131430745, 0.003635494038462639, 0.038010310381650925, 0.008244102820754051, 0.05229722335934639, 0.003083895891904831, 0.009993785992264748, 0.006783054210245609, 0.011116079986095428, 0.023084916174411774, 0.05265865474939346, 0.008262070827186108, 0.020923029631376266, 0.005221083294600248, 0.003935101442039013, 0.009588376618921757, 0.015812445431947708, 0.00631307065486908, 0.0092169139534235, 0.015371780842542648, 0.005082606337964535, 0.008348559960722923, 0.008164966478943825, 0.028890855610370636, 0.029534583911299706, 0.06679998338222504, 0.0081512201577425, 0.018267834559082985, 0.04538894072175026, 0.0052663404494524, 0.006728941574692726, 0.01551997009664774, 0.0068572829477488995, 0.001770931645296514, 0.008104179054498672, 0.010645383968949318, 0.010629026219248772, 0.0495300367474556, 0.01663867197930813, 0.060904502868652344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04843921214342117, 0.00871760118752718, 0.009484546259045601, 0.005082127638161182, 0.015483184717595577, 0.004319517407566309, 0.022084524855017662, 0.0030660403426736593, 0.012405101209878922, 0.015237637795507908, 0.01811911165714264, 0.012773200869560242, 0.0028299924451857805, 0.013382517732679844, 0.0017984024016186595, 0.0034788409247994423, 0.005864758510142565, 0.00369464373216033, 0.037610992789268494, 0.00876172911375761, 0.03662988916039467, 0.0019443576456978917, 0.01922795921564102, 0.015741616487503052, 0.019086744636297226, 0.03160326927900314, 0.03442045673727989, 0.006488963030278683, 0.04252200946211815, 0.006103853229433298, 0.007419160567224026, 0.010617174208164215, 0.020926762372255325, 0.006652848795056343, 0.010282841511070728, 0.019901536405086517, 0.006246912758797407, 0.008673302829265594, 0.0152149498462677, 0.05516320839524269, 0.04629766196012497, 0.05516069754958153, 0.012610935606062412, 0.020785119384527206, 0.040775276720523834, 0.008297393098473549, 0.00819574948400259, 0.02524230070412159, 0.007953538559377193, 0.002794791478663683, 0.012925129383802414, 0.00977564137428999, 0.011822403408586979, 0.04765098914504051, 0.021592315286397934, 0.025097953155636787, 0.01552068255841732, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0705145075917244, 0.02032620646059513, 0.009880910627543926, 0.004939628764986992, 0.016061678528785706, 0.0056054117158055305, 0.014010745100677013, 0.003297391114756465, 0.016443025320768356, 0.024085573852062225, 0.026326658204197884, 0.012785245664417744, 0.003909513354301453, 0.012602802366018295, 0.002793744904920459, 0.00462238397449255, 0.0038437319453805685, 0.004196754191070795, 0.02832120656967163, 0.009887207299470901, 0.011374209076166153, 0.0020704769995063543, 0.02151956781744957, 0.012186728417873383, 0.02686896361410618, 0.04502201825380325, 0.03351264074444771, 0.006256525404751301, 0.02712424471974373, 0.0032894713804125786, 0.005166210699826479, 0.012071714736521244, 0.013032904826104641, 0.008004766888916492, 0.019473547115921974, 0.01575273461639881, 0.010063092224299908, 0.005412857048213482, 0.01206835638731718, 0.04907529428601265, 0.03471221402287483, 0.0454665832221508, 0.009139729663729668, 0.0206525269895792, 0.05592808872461319, 0.010421199724078178, 0.02142651006579399, 0.012754649855196476, 0.008971231989562511, 0.004730811808258295, 0.009046136401593685, 0.008256422355771065, 0.00728259701281786, 0.031509920954704285, 0.02102900668978691, 0.018697455525398254, 0.011883500032126904, 0.03429076075553894, 0.0, 0.0, 0.0, 0.0], [0.0706215426325798, 0.008601936511695385, 0.010354401543736458, 0.005194458179175854, 0.01416888739913702, 0.0046706367284059525, 0.01617642678320408, 0.0029740002937614918, 0.011379332281649113, 0.015173017978668213, 0.019008101895451546, 0.0142683619633317, 0.0038645381573587656, 0.012362247332930565, 0.0033143137115985155, 0.0051604826003313065, 0.005715302191674709, 0.005301313940435648, 0.0324111208319664, 0.009650594554841518, 0.028536586090922356, 0.002532697282731533, 0.018741434440016747, 0.016800498589873314, 0.01768289878964424, 0.026088694110512733, 0.028253115713596344, 0.007743828929960728, 0.034030355513095856, 0.00619550934061408, 0.006849408149719238, 0.011696306988596916, 0.021613797172904015, 0.007088741287589073, 0.01115817204117775, 0.020152904093265533, 0.006664005108177662, 0.007533928845077753, 0.014463198371231556, 0.05484409257769585, 0.03494250774383545, 0.04631273075938225, 0.011345247738063335, 0.022225303575396538, 0.04182307794690132, 0.011618247255682945, 0.010889152996242046, 0.02064090222120285, 0.008303116075694561, 0.004495855420827866, 0.011376109905540943, 0.011954018846154213, 0.010834748856723309, 0.04323899745941162, 0.02379104495048523, 0.02516738325357437, 0.01325346902012825, 0.020917024463415146, 0.007829830050468445, 0.0, 0.0, 0.0], [0.09810925275087357, 0.009641933254897594, 0.014510523527860641, 0.005627335049211979, 0.012852557003498077, 0.004372656345367432, 0.02338007465004921, 0.0032498647924512625, 0.014201431535184383, 0.01029181107878685, 0.020630663260817528, 0.019243162125349045, 0.004464943427592516, 0.015587660484015942, 0.003746633417904377, 0.007933506742119789, 0.004971728660166264, 0.00802291464060545, 0.020675256848335266, 0.007216671481728554, 0.01718985103070736, 0.0020634999964386225, 0.01937045529484749, 0.01547010987997055, 0.011955926194787025, 0.02030191197991371, 0.022985639050602913, 0.00869806855916977, 0.02434050478041172, 0.006283682305365801, 0.005556860007345676, 0.007637856528162956, 0.017254874110221863, 0.005872167181223631, 0.010827883146703243, 0.024770542979240417, 0.011655373498797417, 0.009412907063961029, 0.012373103760182858, 0.03549759462475777, 0.03187498077750206, 0.03581622242927551, 0.010150124318897724, 0.02493472211062908, 0.04584387317299843, 0.016805358231067657, 0.019716773182153702, 0.023814857006072998, 0.006850863806903362, 0.008066864684224129, 0.010350550524890423, 0.01318820659071207, 0.007965647615492344, 0.030513809993863106, 0.025664566084742546, 0.017874686047434807, 0.014012550935149193, 0.017051134258508682, 0.0065957228653132915, 0.03465911000967026, 0.0, 0.0], [0.08587761968374252, 0.006564433220773935, 0.007789487950503826, 0.004748323932290077, 0.012919378466904163, 0.0044563706032931805, 0.01327239628881216, 0.0025954642333090305, 0.005237976089119911, 0.020270666107535362, 0.014480824582278728, 0.010540932416915894, 0.0034747382160276175, 0.008143465965986252, 0.0033732173033058643, 0.005450154189020395, 0.0038221008144319057, 0.003794040996581316, 0.03716561570763588, 0.02155197039246559, 0.01989738643169403, 0.0023971840273588896, 0.016654087230563164, 0.014459637925028801, 0.02475014328956604, 0.018407529219985008, 0.046393319964408875, 0.005044184625148773, 0.024251552298665047, 0.004289157688617706, 0.004449320957064629, 0.025051170960068703, 0.0159674771130085, 0.00661113765090704, 0.010547255165874958, 0.015979455783963203, 0.004922101739794016, 0.004557082429528236, 0.009450376965105534, 0.06073726341128349, 0.023427171632647514, 0.06548429280519485, 0.009976831264793873, 0.014789359644055367, 0.029692256823182106, 0.01161919441074133, 0.01078759040683508, 0.014506364241242409, 0.0076810517348349094, 0.004447626415640116, 0.010701012797653675, 0.011470888741314411, 0.01026680413633585, 0.04974589869379997, 0.016282575204968452, 0.027171866968274117, 0.007767087314277887, 0.015623976476490498, 0.005976682063192129, 0.00870136171579361, 0.03353414312005043, 0.0], [0.07105536013841629, 0.002755393972620368, 0.006234457716345787, 0.011806238442659378, 0.00883826520293951, 0.008758094161748886, 0.019137300550937653, 0.0018406276358291507, 0.002940565813332796, 0.005276741459965706, 0.003763640532270074, 0.012475088238716125, 0.001336181303486228, 0.007556276395916939, 0.0043952069245278835, 0.004002459812909365, 0.011673015542328358, 0.004264631308615208, 0.023296678438782692, 0.009596596471965313, 0.028042983263731003, 0.05815991014242172, 0.022848542779684067, 0.0033332433085888624, 0.008443341590464115, 0.00432644272223115, 0.015952177345752716, 0.012362423352897167, 0.01777924783527851, 0.010329456068575382, 0.013730085454881191, 0.011281890794634819, 0.008868031203746796, 0.015404274687170982, 0.002650221809744835, 0.013317112810909748, 0.0018069046782329679, 0.013223620131611824, 0.02308482676744461, 0.020335551351308823, 0.02932574413716793, 0.020950740203261375, 0.028732504695653915, 0.01631096936762333, 0.01214598212391138, 0.003945980221033096, 0.00438537634909153, 0.013606890104711056, 0.019229257479310036, 0.002576422179117799, 0.03361810743808746, 0.007249250076711178, 0.009127596393227577, 0.03773880377411842, 0.0212395079433918, 0.026465004310011864, 0.02587057463824749, 0.014589877799153328, 0.021400315687060356, 0.01315348781645298, 0.017678672447800636, 0.09437582641839981]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999022483825684, 9.773786587174982e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.872941154753789e-05, 0.9997879862785339, 0.00011330334382364526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.04835219569577e-07, 0.0010697185061872005, 0.9982153177261353, 0.0007145759300328791, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.5805619035802465e-09, 5.183812845643843e-07, 0.00010473507427377626, 0.9998801946640015, 1.459827853977913e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.9893419173940856e-08, 1.593032727953414e-08, 1.3669475265487563e-05, 0.0003272739995736629, 0.9990684390068054, 0.000590550946071744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.696697265491821e-06, 6.025068888249052e-09, 5.230895161467686e-10, 2.924183206687303e-07, 3.7582599361485336e-06, 0.999962568283081, 3.069124431931414e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002619281644001603, 2.856428704678393e-10, 1.0469373812327376e-08, 6.079858283492001e-10, 1.990488453884609e-05, 0.000651107111480087, 0.9966310858726501, 7.857548189349473e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00031168205896392465, 1.410283890536379e-12, 8.05454810379018e-14, 7.080656200253443e-11, 4.975546730179303e-08, 1.3462205970427021e-05, 0.004545609932392836, 0.9950450658798218, 8.422541577601805e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.290828529628925e-06, 4.1265042598215285e-12, 5.1030950027741023e-14, 2.569790951215123e-12, 1.0019726204291146e-07, 7.223906095532584e-08, 1.3424617009150097e-06, 0.00033144690678454936, 0.9970366954803467, 0.00262111215852201, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.78270953358151e-05, 2.5983388773909155e-09, 1.1527510930689169e-16, 1.2377455553699656e-16, 4.964095456173661e-15, 1.1437046622264635e-11, 6.616023701111473e-12, 2.1983963094385217e-08, 0.0004636971279978752, 0.9983506202697754, 0.0011178558925166726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0780531312093444e-07, 1.3139079234336659e-11, 6.259921557811042e-17, 2.501318896097336e-22, 1.0732149521288128e-19, 2.693673629237287e-17, 1.3232213176735119e-14, 7.353522460818839e-15, 1.563907198187664e-10, 6.078408205212327e-06, 0.9999821186065674, 1.1727516721293796e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.5798774004215375e-05, 6.151755549410609e-09, 3.9837640869770045e-15, 7.916722820967521e-19, 7.203197341567163e-20, 6.834295075800216e-15, 1.3099216806741754e-13, 3.239531212728686e-11, 2.382754583918345e-12, 1.2360980683467915e-08, 0.0001231878122780472, 0.9998494386672974, 1.5186168411673862e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.8988981764778146e-06, 1.3062279258235776e-08, 1.888658500426299e-11, 6.971821123885613e-14, 3.202398470101425e-13, 1.230511054379005e-13, 6.107721273185263e-11, 6.965486250010144e-07, 5.085573562269019e-08, 1.3601435533416861e-09, 6.16076420101308e-07, 0.02438833937048912, 0.9755842685699463, 2.4161705368896946e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.723892705979729e-12, 9.744120441079751e-12, 1.5869731472949872e-14, 2.884280271217565e-13, 2.3912070782651507e-13, 4.419084441180176e-16, 6.83363351659863e-17, 1.3353641803437455e-10, 1.0710517805989639e-08, 1.1055117932201597e-09, 5.779552947338118e-10, 1.0325801014232638e-07, 0.0006785027217119932, 0.993886411190033, 0.005434939172118902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.9553052550019302e-15, 1.3365151270861714e-13, 2.8457228062981222e-15, 4.141369072252889e-16, 1.001426010063976e-16, 5.59078399628732e-19, 1.80188932154393e-22, 3.9421853766174034e-19, 2.9550498333030806e-12, 2.6053489921018524e-10, 2.724913003571139e-11, 8.459386077915021e-13, 2.1542045491179662e-13, 4.777175490744412e-07, 0.9999988079071045, 7.443380809490918e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.240695456406376e-12, 1.3195022331713435e-11, 1.6235671729020358e-14, 1.4804112634226865e-17, 4.702407168218287e-16, 2.423529874590616e-16, 1.5246552984016486e-19, 6.43922315058296e-19, 1.5732446812313783e-12, 5.572501393658058e-08, 9.133282219409011e-07, 7.684666097906856e-11, 2.8558943404588533e-12, 4.257795183093549e-08, 0.005728859920054674, 0.9942699670791626, 8.66437517288432e-08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00017394984024576843, 3.3291946976987674e-08, 1.3913795246164873e-12, 2.1491387499922993e-14, 4.664023074002488e-13, 7.416484648636867e-10, 1.747959936515553e-11, 2.8336405444306934e-10, 2.3002484361711595e-09, 1.1064761338275275e-06, 8.323991096403915e-06, 8.840614214022935e-07, 6.343489289406534e-09, 3.2805666516644294e-10, 2.87069667592732e-07, 8.95697230589576e-05, 0.999312162399292, 0.0004137319338042289, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.6814174144962344e-11, 2.952220334861977e-08, 3.134130663871339e-14, 6.528148685347591e-19, 1.1968649990958394e-17, 1.9310455961178566e-16, 8.562950540091791e-17, 3.1258659040011384e-19, 4.742314463783683e-17, 1.8900468213081667e-13, 4.743156534203763e-09, 6.163167753925336e-10, 6.394625768572221e-14, 4.135952952095833e-19, 6.518411163483964e-14, 1.3485117023037674e-08, 4.523203824646771e-05, 0.999954342842102, 3.752060138140223e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.4625110199849587e-06, 1.9982035581733726e-08, 9.277335843993484e-12, 2.579131298720977e-14, 4.4578524086100885e-14, 4.0720182781228687e-10, 1.0400955097189524e-10, 6.379680637935703e-12, 6.049397924457649e-15, 6.126163758137654e-14, 5.911504792621702e-12, 2.0255143340364157e-07, 1.821120143574717e-09, 3.263665326676306e-16, 2.789857330597116e-16, 2.49991460908941e-13, 1.7130045307567343e-05, 0.0010494205635040998, 0.9976010918617249, 0.0013296514516696334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.643862772965804e-06, 1.1978975103521528e-11, 4.359550481031205e-12, 5.132963823949177e-13, 5.5565878287477943e-11, 1.1279891687365762e-08, 1.0264984666719101e-06, 2.3321167930134834e-07, 2.25975596741812e-12, 2.7063240530696402e-15, 3.5748202328722133e-16, 5.268864858298805e-11, 1.5687229293348537e-10, 9.042324469076728e-16, 1.8113445957321346e-19, 8.45983151659394e-19, 9.375767939800994e-10, 8.814394547584925e-09, 0.0006415279931388795, 0.9969577789306641, 0.002391772111877799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.9145662008668296e-05, 5.353617533012181e-14, 7.561143894597143e-16, 2.1758097846222638e-14, 1.4712413232143007e-10, 1.1055472093346452e-09, 2.305752104803105e-07, 4.8848585720406845e-05, 5.681656389810996e-08, 4.349344235460295e-12, 7.704335343726074e-16, 1.8668931418136525e-13, 7.509579763587126e-11, 1.00608531922175e-11, 9.647605319338705e-15, 5.57415111056865e-17, 8.229993943287273e-12, 7.97647484087477e-13, 1.3455119241001512e-09, 0.00014610779180657119, 0.9997381567955017, 4.743479803437367e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.4311051674885675e-05, 9.088928915046424e-11, 2.0054488378557764e-16, 9.72180286441934e-15, 3.868078275216791e-14, 9.019810939814299e-12, 4.0638239301449275e-13, 1.2683844197169947e-08, 1.1536399391331997e-08, 6.2692651070506145e-09, 7.562334547635274e-13, 4.429638513631096e-12, 6.270499310762068e-12, 1.2610457122974594e-09, 3.579908813833299e-09, 1.1246129028030794e-10, 1.496536050638042e-08, 1.8262896403498097e-11, 9.161676625679682e-12, 6.846963884754587e-09, 0.0008032814948819578, 0.999129593372345, 4.2777064663823694e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.711721013350711e-10, 4.723879707541068e-13, 2.7803164970630314e-17, 1.7486455977703222e-19, 7.275809861355997e-17, 4.1885345799084174e-17, 8.900237074454983e-17, 6.96575808322499e-17, 1.715241880820284e-12, 9.907812070775179e-11, 6.4662463751530286e-12, 1.3455974664504676e-16, 1.8322740105808187e-16, 2.038514891828172e-14, 2.4007190901897957e-08, 4.962356214832653e-08, 1.5684638310364818e-10, 1.419255546419862e-10, 2.9077203240812166e-15, 1.7361400327019715e-15, 1.3775228735468659e-09, 0.0017318973550572991, 0.9972323775291443, 0.0010357423452660441, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.60114197456096e-08, 5.671805798461438e-14, 2.8871507395973838e-21, 9.58398867780495e-24, 9.790670708289399e-23, 1.4275026407742022e-17, 2.4703720042574732e-18, 4.254179964192871e-18, 1.2555926719175117e-17, 1.1456575976526856e-13, 1.7895871552231837e-14, 8.098041551565793e-15, 1.05217987839856e-19, 6.13274412255264e-21, 2.2927279366765038e-17, 5.530457168612113e-12, 1.906711677435169e-09, 9.986896726266181e-12, 3.676259383716962e-12, 5.473035096652289e-16, 1.5747837062152215e-11, 6.385406777553726e-06, 0.0019619823433458805, 0.9978708028793335, 0.00016073323786258698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.3842237252259526e-11, 2.940765408694212e-15, 6.010742454291563e-22, 2.8165035433137125e-28, 1.2850360219740593e-27, 1.7973173361727588e-23, 1.2175527506728736e-20, 1.6319073407353341e-22, 6.437766998675118e-23, 4.913382114622611e-18, 1.3917674250487483e-13, 1.0955489580842873e-13, 1.9292373493135185e-19, 1.5951786859769824e-25, 1.0334521198223989e-23, 2.865364653312002e-15, 2.015007626900156e-13, 9.449899751601265e-10, 1.0799150202550623e-12, 1.2972933215207026e-15, 4.293386869390006e-16, 2.0265009830801317e-13, 9.984815196872887e-10, 4.8298916226485744e-05, 0.9999421834945679, 9.53341350395931e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.153277015779167e-06, 1.049545107940919e-13, 5.474560467332674e-19, 3.0007699340142592e-21, 3.413819674933192e-22, 5.2367163454396877e-17, 2.4713321260293533e-15, 9.189427647646187e-13, 1.3697004176218542e-17, 8.521819017219816e-16, 5.7868011936663445e-15, 1.0074970857587573e-09, 1.5865780911283878e-14, 1.8812199024957274e-19, 2.3674457926022196e-22, 2.9822307469198273e-18, 8.431309578456336e-13, 7.186498575048605e-13, 7.057032735957591e-10, 8.09750114183494e-11, 1.0267178218725803e-09, 9.715583892955237e-09, 4.247321383488156e-10, 3.0648217943962663e-05, 0.0007729030912742019, 0.9991523027420044, 3.900895535480231e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.355695111726618e-09, 3.0470641789868047e-16, 1.145823302410372e-18, 2.5151919617487336e-23, 1.5073143969292379e-22, 1.1168774990088718e-21, 2.5975760870100616e-17, 1.42637315939673e-14, 1.4869522781579998e-14, 2.1200992418352223e-14, 1.011813410833895e-09, 1.3255641029275012e-09, 3.4080414046400165e-09, 3.0464121351415907e-13, 6.9929722989082056e-15, 9.831734188445792e-15, 4.8839235336061576e-14, 6.001931468642939e-15, 8.178888305282375e-15, 4.694378227614558e-14, 1.7627769036132612e-11, 1.177165032117955e-10, 5.0458307671030767e-11, 1.0644667369774652e-09, 3.441150056460174e-06, 0.00385589268989861, 0.995851993560791, 0.00028870970709249377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.537565099331346e-11, 1.4438555382632326e-15, 8.699691853586844e-23, 1.6549470016598363e-22, 2.6893057119889513e-25, 1.783571239261778e-21, 2.629731729074098e-20, 1.2508900165686399e-12, 1.2741354195669463e-14, 3.951639430716143e-14, 1.2200228674541513e-11, 5.992543492538971e-07, 9.939600253972003e-09, 3.670656660570426e-12, 1.203844199856635e-15, 1.4030660711181607e-17, 1.1692108056477607e-13, 6.149592869453209e-17, 1.8594201261385635e-17, 1.5386472600882573e-16, 7.138318663382423e-14, 1.265987748660935e-12, 4.026347556669471e-16, 5.377969662483106e-13, 5.568425495011686e-13, 9.159523983726103e-07, 1.0072234545077663e-05, 0.999988317489624, 8.623761971193744e-08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.2023344993228324e-11, 2.61944965408172e-16, 5.656640704538765e-18, 1.6064232651752517e-19, 1.1061399949471458e-17, 1.8043803812092917e-19, 1.0489931304505113e-14, 1.6690141022707161e-12, 6.524983244687865e-12, 1.4418086407945452e-14, 6.2529356692486715e-12, 1.0914683379326107e-08, 2.6753823476610705e-06, 1.8407887436566739e-09, 1.8374789537145553e-11, 6.38857924505407e-17, 7.925496196825588e-12, 5.983958445941739e-13, 9.343686509732073e-15, 4.4442595437121923e-11, 4.801526398701128e-10, 1.7303933893403345e-12, 1.0543122856010315e-15, 9.032224659971905e-17, 3.123159554325322e-15, 8.167972076478236e-09, 4.286455350666074e-06, 0.0009599662153050303, 0.9990217685699463, 1.1273258678556886e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.7755842896558534e-08, 3.1690435408363244e-16, 1.2346923986418078e-16, 4.75893636834885e-14, 1.0681558448074474e-13, 4.882435601649693e-13, 3.29937527223257e-14, 2.1944140371488174e-07, 8.174560583995572e-09, 1.021987269117508e-11, 4.574666976475813e-15, 1.326871112983241e-10, 3.701654449628222e-08, 3.469497096375562e-05, 1.1191040316660406e-09, 2.533530602379184e-16, 1.6251542585353062e-15, 1.310017206436076e-18, 7.358868932781908e-15, 5.137340206018415e-14, 4.251076916261809e-06, 3.254658054174797e-08, 5.612961403176145e-14, 9.099125439728417e-16, 3.56692170854171e-19, 1.1878493744177376e-09, 1.629417600845784e-09, 0.00025837967405095696, 0.4595645070075989, 0.5400583744049072, 7.949866267153993e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.442748805603489e-16, 1.0531154842948428e-18, 3.487369681080954e-19, 2.1271267089156327e-16, 1.941824725646378e-15, 3.1466002200305457e-19, 1.949457908634348e-19, 4.8775050567450434e-14, 2.3906229426606806e-11, 2.544624828164084e-15, 7.3895518277934685e-19, 2.147434820134422e-17, 4.3217308204335225e-11, 9.62050847874707e-08, 3.639025408119778e-06, 3.2607853484811926e-17, 2.978030530564436e-17, 6.4669201422884655e-22, 3.858583113611399e-23, 1.2209912047699373e-20, 2.111671839992446e-13, 2.7508870181769396e-11, 2.0412134710354884e-13, 3.954439075115399e-18, 8.89639226926535e-24, 1.1417253462582077e-18, 2.8859248957989426e-15, 1.6171692457378484e-11, 8.739830263948534e-06, 0.0005375798209570348, 0.998647153377533, 0.0008028346346691251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.1625760303749602e-18, 2.229662614749387e-14, 2.88996935106714e-14, 2.0783949648134348e-12, 2.9279911828439253e-11, 9.925060913848981e-16, 2.517940111056889e-19, 2.2291827639673227e-17, 3.2893219398255624e-12, 4.5309537914130227e-13, 5.64379270365402e-16, 1.8115162357092394e-19, 1.6564561758126316e-16, 8.850600807797093e-11, 0.00013687257887795568, 2.7795959978149654e-10, 2.6170981614476174e-13, 5.32782453273534e-16, 4.9710530435322316e-20, 7.165037173464619e-20, 3.1705597298119096e-15, 1.1840921472494603e-11, 6.498860893877634e-10, 3.7008682116047506e-15, 4.188937618492005e-20, 3.357463010102096e-23, 5.519148604276579e-19, 1.2600301650316137e-17, 2.6417845775533744e-12, 1.9430854147906018e-10, 0.005011442117393017, 0.9946664571762085, 0.00018528026703279465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.596629626610205e-14, 7.769450366271538e-15, 7.136116922997022e-17, 2.606169186708529e-12, 9.028282678749666e-13, 2.449762940247291e-13, 4.7204653150837076e-17, 9.148540283080049e-15, 5.135491641314327e-14, 1.4932545759800686e-13, 2.1597666406713946e-19, 5.626997091087839e-21, 1.5546767726415915e-21, 6.3970945731519355e-16, 1.2156119860717851e-11, 1.5906538239351953e-12, 6.334039195921015e-14, 4.391987323666016e-19, 4.3114795924050315e-18, 3.608509661403885e-18, 7.536049150165536e-13, 1.75689185422101e-09, 4.30832369779921e-10, 5.066035438372474e-11, 7.791189374218591e-19, 1.0024632862803113e-19, 2.411819155412029e-21, 8.760470310226338e-19, 4.762769895869568e-18, 4.13578324148442e-13, 9.237365361514094e-08, 0.00010377181024523452, 0.9998530149459839, 4.3062354961875826e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.435907157747775e-14, 1.7413467315232495e-13, 7.393440243710914e-13, 3.0309180729451435e-13, 1.7683650767666426e-12, 2.110568088299538e-14, 3.116408913493942e-15, 8.836352757694655e-18, 3.845656296663433e-14, 2.712941362444793e-13, 4.5109023362065095e-15, 1.6850319189967852e-19, 1.4020710090304112e-19, 1.0095474678413686e-17, 9.453080679344694e-11, 5.962256383051923e-11, 2.4472386465392015e-13, 9.157265061249947e-14, 3.752254709429574e-17, 3.8667149995109867e-17, 1.1597656428968817e-13, 1.0900376157252367e-09, 3.436568295001052e-05, 2.352512922243477e-07, 6.17161460825244e-11, 2.261535617521619e-16, 9.275984860323931e-16, 8.728672453504034e-19, 8.374743789678826e-18, 1.5135871285992488e-16, 1.5706065337184327e-09, 2.71922726824414e-06, 0.003960497677326202, 0.9958817958831787, 0.00012041127774864435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.581840107655612e-12, 3.937667791657773e-13, 1.7264882312343517e-17, 2.332872944097613e-15, 1.768401638308536e-17, 4.628852097628144e-13, 1.3160371018522562e-15, 5.130238004162277e-15, 6.805661163414231e-18, 3.082783187795604e-15, 4.410037004337867e-17, 1.3711944050697985e-16, 1.2858317644519203e-21, 8.880838929885831e-23, 2.4605138402004767e-20, 1.133763764295248e-15, 8.835999525103316e-15, 1.1018985436382189e-17, 2.5788587235185505e-15, 1.2141576730224034e-16, 3.144245168997797e-15, 4.468812039165604e-12, 2.24131650738979e-11, 4.015959973457939e-07, 2.3976581831064436e-10, 3.1408469575167075e-11, 1.225414677363942e-14, 4.7624838270352455e-15, 3.405791368080998e-21, 7.322077050866293e-18, 5.700247978984111e-16, 4.511798920581178e-15, 1.4125047798074775e-08, 2.0322813725215383e-06, 0.9999973773956299, 2.3200384191568446e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.033381516086123e-11, 3.9998057130928086e-17, 5.037479108471103e-16, 5.927002934128824e-16, 1.102425133433615e-15, 4.1528344043478046e-15, 4.014092010173886e-12, 4.1965866545701225e-12, 3.194283428598608e-15, 1.532293983588258e-16, 7.368251927020228e-18, 3.0461000966741517e-15, 1.1234053983832752e-15, 3.1139793185987514e-19, 1.276357004263397e-19, 3.3778687717491484e-21, 6.612774225095441e-18, 1.1198561125789834e-19, 1.8468818878496072e-17, 1.7063307621782535e-14, 1.3256432410124752e-11, 2.3131867948888996e-11, 3.5145616885529085e-12, 1.3644041625682224e-11, 3.383713665164323e-12, 1.0793753446591836e-08, 8.394167139158526e-09, 6.785542266962707e-11, 1.7152340745646422e-12, 1.3565513729690837e-12, 4.141926385203831e-11, 4.9094635251416534e-15, 1.5560429333927317e-10, 8.455007360907985e-08, 1.045635508489795e-05, 0.999909520149231, 7.985075353644788e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.037915408476385e-14, 4.3519926886846796e-21, 2.845580635035044e-23, 3.644351629990355e-20, 1.190849377366455e-21, 4.9877029614167023e-20, 3.9160451767910206e-19, 9.29888327796946e-13, 5.5619711208942674e-15, 8.259026515938577e-17, 2.3063082777806697e-19, 3.789674623262187e-18, 3.406763866878836e-17, 1.633032273749702e-16, 1.9880879049850644e-17, 6.874986655180005e-22, 1.3310190045239771e-22, 2.0381209006963825e-28, 1.4369837247913882e-25, 1.0302359970206852e-22, 2.7759654079269943e-15, 2.026179788186533e-12, 9.266663262739398e-16, 3.963846954255267e-15, 3.061592160948178e-19, 3.5647743437672297e-13, 1.5508512529738283e-10, 1.2182480024769404e-10, 1.2900671199703173e-12, 2.926898723387694e-10, 9.55279499947892e-09, 2.3752143914895774e-12, 2.671577403745573e-10, 2.8171864147052972e-11, 4.758541365390556e-07, 0.00015002167492639273, 0.9998461008071899, 3.360702521604253e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.9387799634658478e-15, 1.7357678173495494e-19, 2.3390733865200353e-20, 4.6850156032985285e-20, 1.7105668035605382e-18, 2.1225158865665188e-20, 4.880967387958496e-19, 5.099844556190661e-16, 2.6781080825211134e-11, 3.7110498701808936e-11, 4.556664073840366e-12, 4.391097149113914e-15, 1.4783710720726612e-15, 3.5569217710085255e-11, 1.0813680617616228e-08, 2.9843918135374903e-12, 2.0112007375068373e-18, 6.917799996955908e-20, 1.0166876940640915e-25, 1.1785513884748841e-24, 1.9047571345064314e-16, 1.0361854603513354e-12, 2.1004850636607841e-10, 1.2181793388691547e-13, 9.157490033200738e-15, 2.3867869088277046e-16, 2.6858493207271295e-10, 3.062412476384502e-11, 1.7431428744885125e-08, 2.8111924246787545e-11, 1.2622494978131726e-05, 2.986073468491668e-07, 1.042403385831392e-09, 1.3954634425772383e-07, 2.897190543027506e-10, 2.2542042188433697e-07, 0.00012130538380006328, 0.9996635913848877, 0.00020191581279505044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.545202968679219e-13, 6.602058048561028e-20, 2.5248590281294806e-26, 2.736500055200897e-25, 1.2334754345704444e-24, 1.4517961637604695e-20, 4.194522703213872e-20, 1.006357727050466e-15, 3.0379510891501496e-14, 2.4968564542315885e-12, 2.1235850534637168e-13, 5.2355099693524726e-14, 8.691340882560842e-17, 7.810328679231843e-17, 6.351542284743078e-14, 3.7770170558980634e-16, 2.555002379372312e-14, 5.458868592618601e-20, 1.978563240965952e-22, 3.8488842265538875e-23, 3.862208453359349e-16, 6.344396535906682e-11, 9.26817476931685e-12, 2.8762961457040603e-10, 6.391265504167168e-15, 1.6972339332566033e-13, 1.9313219426497774e-11, 3.004611670576196e-08, 1.824386301751968e-11, 3.9296094156426875e-10, 5.116388646086989e-09, 4.292902838765045e-13, 1.8146542211591732e-12, 1.2716794848058321e-12, 1.651709435890325e-09, 2.9965008252474945e-09, 1.8630486010806635e-05, 0.0009430047357454896, 0.9990291595458984, 9.179587323160376e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.1100685355122124e-11, 2.061982490203268e-15, 1.9948340966704234e-21, 3.0766216253104952e-25, 5.765240357780135e-23, 2.819281297351618e-20, 6.6580301035888294e-18, 6.984696548785515e-17, 1.9556167937199304e-13, 6.747294278852678e-09, 1.4243750229070429e-05, 2.9690898628587092e-08, 1.862152576234677e-12, 4.6929945145919236e-15, 1.0031510344621353e-11, 1.2174317554070058e-08, 2.0047024040792394e-09, 5.238483535840999e-10, 1.1915454667509598e-16, 1.2118012339805869e-17, 7.337490668226157e-15, 7.390289075148715e-11, 3.198445597263344e-08, 4.676944627135526e-06, 0.0002765317331068218, 1.7611855085419847e-08, 2.311152456968557e-06, 3.0392186545213917e-06, 5.373648193085501e-09, 3.528825994435214e-13, 1.8989898195598265e-11, 3.9470329267357954e-14, 3.4237372424715095e-15, 9.400895860378622e-12, 4.213818460829799e-10, 1.739517752064046e-09, 2.5698698724596625e-09, 2.606163252494298e-05, 0.0011051552137359977, 0.9978629946708679, 0.0007049601408652961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.7888446279812342e-08, 4.1285424788023965e-17, 3.0753896628125334e-21, 8.997059598241508e-23, 4.226937106356664e-22, 4.3045327641846886e-17, 7.484221338646072e-15, 2.1466830049665653e-12, 5.7788589892364146e-15, 2.683738919029982e-13, 4.117347088272716e-12, 9.167719028368992e-09, 1.024316048647833e-12, 1.3859839973755526e-16, 2.286536593189121e-19, 2.7271453272881228e-17, 1.071878154811079e-12, 7.840438503515026e-14, 1.7691068878930571e-12, 1.3897901113366778e-13, 3.880466260819393e-12, 2.964918024636609e-12, 3.602914949892011e-14, 1.1825197765436002e-10, 1.4377985468883026e-09, 6.440575361921219e-06, 5.9842153454781055e-09, 5.746693932451308e-05, 2.0430336533650006e-08, 1.6104045874598683e-10, 4.3841130977660063e-16, 2.059841283970428e-21, 1.7029092824374051e-18, 1.676265071124036e-18, 1.9238988657396816e-13, 2.2594910387141454e-09, 1.4029204464804934e-09, 6.120327855629881e-11, 1.0342416317143943e-05, 0.0002374784671701491, 0.999579131603241, 0.00010905839008046314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.9094128907274086e-13, 1.8074100225941564e-23, 1.8120965269029386e-24, 4.600537806449799e-27, 1.6201843880563195e-21, 3.254165042052837e-20, 1.3927374175337908e-15, 6.115513504672057e-14, 4.456536267640821e-16, 5.150276198902565e-19, 1.0682429633372126e-17, 2.59022692211024e-14, 5.011546299477088e-12, 2.207296516216874e-18, 1.30305210576369e-21, 2.4674376579491685e-26, 6.169107838541652e-19, 5.31240566691449e-19, 3.3765290920010425e-17, 1.430388264973305e-14, 5.4467927564083585e-12, 4.0525092280366043e-16, 9.559625970924648e-22, 3.857374629191698e-21, 6.4402586773123e-19, 7.888154018864668e-11, 2.6831195598653323e-10, 3.280838711816614e-09, 2.9881465479775215e-07, 2.8885643876819245e-11, 6.006818848748596e-15, 1.545806391482954e-23, 7.556713181278292e-24, 7.600109366307586e-23, 1.4961181004123233e-21, 3.7212098094770163e-13, 2.996963354567894e-12, 1.404572801382703e-13, 1.027729013003409e-09, 1.9251884531001906e-09, 5.1096041715936735e-05, 0.9999418258666992, 6.76683748679352e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.511192321453081e-12, 1.1262130430443255e-22, 8.579907584977921e-24, 1.2213846810163969e-20, 1.4058005596172597e-19, 1.4383883376354e-16, 8.909824163928922e-16, 1.5027155075841847e-09, 3.781064437241577e-12, 5.814921416965766e-16, 1.297809778353595e-18, 3.6443026102332796e-16, 3.287236273658879e-14, 5.723726885249053e-14, 4.7775478911031345e-18, 2.622059855769065e-24, 7.163523174449705e-19, 2.708659231007191e-24, 4.619405123450986e-19, 8.239711200125864e-15, 5.832289651230838e-10, 4.0536031562649066e-13, 1.3799553660015257e-21, 4.2325046720555475e-21, 1.2231726153254186e-24, 7.57342322535437e-15, 5.2961473639805134e-14, 1.9924602245868783e-10, 1.497002632966371e-09, 3.865486917220551e-07, 1.5954630672165848e-10, 4.524037911394292e-16, 1.093133340820913e-16, 4.634135998470205e-22, 2.8263722385292436e-19, 3.479458203763802e-14, 4.544397214090168e-08, 1.3482778261908468e-12, 7.618653086183258e-08, 4.48100757888259e-11, 3.251597604503331e-07, 0.0028443755581974983, 0.9962441921234131, 0.0009105870267376304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0110146083153518e-15, 1.5677792600281076e-22, 8.482894259714746e-24, 9.501777854111705e-22, 2.508033072257918e-19, 1.1499225768816375e-19, 1.4680225793884798e-17, 4.1104997823473294e-14, 1.18259229991112e-13, 1.3031137845183768e-17, 7.215708933008167e-21, 5.704485658349445e-20, 1.4977486712767775e-16, 3.3949097466611303e-15, 4.3246004040732415e-15, 1.1732044300947282e-23, 2.3667808674250073e-19, 5.334916607764328e-22, 1.4885451871834954e-22, 4.9092405040136194e-17, 4.11203319658493e-12, 3.185215329340463e-12, 3.0466689438183207e-18, 4.0726730213124155e-22, 6.460385011473627e-26, 5.542090070824825e-20, 4.929886336532902e-16, 1.4768524944641648e-13, 1.2607206389958492e-09, 2.7855378448293777e-08, 5.407850380834134e-07, 1.6095100946467156e-11, 9.446804300730811e-15, 9.93234225390904e-18, 7.5002389335107205e-19, 7.84761626071006e-15, 4.607504100473392e-10, 2.3267414661631847e-09, 4.722189306249902e-09, 4.3154008469957483e-13, 2.8561686002404052e-11, 4.261667982063955e-06, 0.0011020590318366885, 0.9988700747489929, 2.295193371537607e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.455107633441171e-15, 8.933301007360512e-21, 4.046642662478476e-24, 2.2110987553000505e-19, 7.1620912214118e-18, 3.1403893344011913e-18, 1.0651104303574743e-18, 4.701256745009985e-13, 1.8493030457672477e-12, 6.859598609618156e-13, 8.89535865271536e-19, 2.2720271666983446e-20, 1.0804976441121857e-18, 1.5739609593966308e-13, 1.345829047164071e-12, 4.2620246142500786e-17, 4.0178031118140434e-16, 6.538856178908952e-22, 4.432604630162562e-22, 2.7429950177233126e-19, 2.1353173135923997e-12, 2.9405073931343395e-09, 4.776420144819715e-13, 1.8518494978572372e-14, 1.8970087811002865e-22, 3.8365716022414864e-20, 1.848394635753844e-18, 3.1609839799915523e-14, 5.750064188897799e-14, 1.4975856998944437e-08, 1.9198632799088955e-06, 5.303974717207893e-07, 1.7213804426319257e-07, 6.128153946750522e-14, 4.4631149904300615e-13, 2.6547056535057264e-15, 1.999019616505393e-09, 1.2210402466905634e-08, 6.031481802892813e-07, 1.857143128516925e-12, 6.706395557160363e-14, 2.2538310193859212e-12, 8.294608733194764e-07, 0.0005407140124589205, 0.9994471669197083, 8.140171303239185e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.493101953329935e-16, 1.6829984764065826e-20, 4.074784880841783e-24, 1.413201910429787e-24, 1.4932064085002653e-19, 2.0053152182015518e-20, 3.205903253836916e-20, 2.5005357139808905e-19, 3.9570207157333444e-15, 6.492592667515411e-15, 5.946961660800483e-18, 3.7518959239586263e-22, 9.043901275269318e-22, 1.9598422564961563e-19, 3.6324028095287286e-13, 3.456232907104202e-17, 3.293199089146018e-15, 3.224085065237889e-16, 4.608861349450805e-21, 7.019536362210482e-19, 6.167107623189505e-12, 7.3701835745509925e-09, 1.7114166750431536e-09, 2.436719012330335e-12, 6.53911619037137e-17, 4.982894650988811e-20, 2.1989443494948342e-17, 3.711180559804886e-17, 3.783314671745516e-14, 8.586801923801332e-14, 1.6918855649805664e-08, 2.1751427325966688e-09, 3.5804884057633046e-10, 3.2126787896658016e-09, 1.1765057244400579e-12, 9.056609086809109e-14, 2.0272971940505508e-13, 1.0506191472359205e-09, 1.927443621374536e-10, 6.7403795218912155e-12, 1.3012092183633302e-14, 3.8512308576585386e-13, 9.572960479875547e-12, 0.00013258996477816254, 0.0008012228645384312, 0.9990612864494324, 4.9175318963534664e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.4279834367920963e-13, 6.584823482004544e-19, 2.811493718045875e-27, 2.805431275766933e-26, 3.2838751066346856e-26, 8.583246088505027e-20, 2.1693298764698215e-22, 1.9601729994942068e-19, 2.602818716373392e-18, 5.2319592072375826e-14, 1.836068197060732e-18, 1.9134430786869e-20, 2.8117110399808e-25, 2.746896470820175e-22, 9.678985104090174e-18, 2.917004271051245e-14, 3.062902308084009e-13, 8.549498101789841e-18, 7.471604525643549e-20, 1.6175059465367173e-21, 6.479456880569391e-16, 9.979920179148394e-08, 3.163679309636791e-07, 5.694576884707203e-06, 1.3046561444032823e-12, 1.764983860366365e-16, 3.011580976209587e-18, 1.8491158048990924e-16, 1.4990732112286046e-21, 3.808914265283741e-17, 5.779683152294093e-15, 6.321111694376725e-15, 1.984574587998722e-10, 2.2146286193791553e-10, 2.820556801452767e-07, 6.339709573283114e-14, 2.926055665125604e-13, 3.9259497345775496e-13, 5.585842011157638e-09, 4.100362410719427e-12, 4.352197245714555e-14, 1.796377382933447e-18, 1.796510294314272e-15, 1.0425380177203625e-12, 2.700448931136634e-07, 0.0001240281853824854, 0.9998666048049927, 2.6707868983066874e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.2665725673127737e-13, 1.0219536260660155e-18, 8.439366098256009e-25, 2.3969112974622734e-29, 8.310554973194733e-25, 1.9470026200876146e-22, 4.195831328792325e-20, 8.562438260231802e-23, 8.636452219585513e-21, 4.2457039437177133e-16, 8.765993946078642e-15, 5.3931705479484015e-19, 7.047139328764279e-23, 2.878006170898475e-25, 7.606684250584452e-21, 1.9075111499025632e-13, 1.1805692057623163e-12, 1.0649039289267748e-10, 1.3844952575614144e-14, 1.5002562858473442e-16, 1.0823856256268229e-14, 1.2373162390499903e-11, 8.92879370439914e-09, 2.161492602681392e-06, 1.825827894208487e-05, 9.463231413764372e-12, 9.078685475919987e-15, 2.8752086717016446e-17, 5.451937594567231e-19, 2.628055080319609e-23, 5.722802215921239e-21, 7.59473859931645e-21, 6.578531677431767e-17, 5.839962844908508e-13, 1.5510013412489698e-11, 6.271085928511886e-15, 1.851824488465007e-19, 4.717286439310151e-19, 3.2616352533995337e-15, 6.60534474339336e-11, 3.0340351541910393e-13, 1.5404867774216773e-16, 1.880382834489915e-20, 6.211890157490293e-17, 1.2087788655765729e-14, 1.3232244633343271e-08, 0.0001935662148753181, 0.9993751645088196, 0.0004108338325750083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.667008083440564e-12, 1.4228182756062838e-18, 2.800738625738661e-23, 2.398796836803867e-25, 1.312254969705773e-22, 2.9790705033895685e-18, 2.19842594547878e-15, 9.765094771293066e-17, 7.292665911518205e-22, 7.10807984292969e-19, 4.470699039021995e-18, 2.5358215618037107e-16, 4.039644119505828e-20, 9.57752404280535e-27, 1.0185337085084013e-28, 8.263578243179949e-22, 6.364309442950453e-14, 4.874497073342754e-13, 3.9031342047302076e-10, 3.8416325676138285e-10, 2.899035005110573e-11, 1.3694136157069853e-13, 3.1671951031871787e-15, 1.57621271590358e-09, 2.8438510213391055e-08, 3.48895952129169e-07, 5.549337031562906e-13, 1.8959626349370623e-13, 6.9710485856662725e-19, 5.904772580277529e-20, 5.331232043579876e-24, 7.051094534362018e-27, 6.106610385074793e-21, 1.349642621596181e-19, 3.994278594942474e-13, 9.328033679679992e-14, 2.194075564409347e-17, 1.5112449235263167e-20, 1.3290353518234654e-15, 7.515029722647559e-13, 3.455896901982669e-09, 7.91683298778656e-12, 8.4554767498129e-15, 4.9468974050917284e-17, 3.868392058572101e-16, 2.831256330591966e-16, 3.4923967717759297e-08, 9.967816731659696e-05, 0.9998160004615784, 8.401207014685497e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.669753067366428e-13, 5.52522530618471e-27, 8.055536020874344e-30, 5.334973588043107e-31, 1.398131924615825e-26, 8.169610545788764e-21, 4.55147074429596e-18, 5.0787748101510576e-17, 1.1174015929507517e-23, 5.094837818549692e-26, 3.8808855789663317e-28, 5.600418915686878e-23, 2.971738820872062e-24, 1.812614757506104e-31, 3.2611972807434223e-35, 4.279247135036897e-35, 6.220628932436327e-24, 1.1711161575064271e-23, 6.249263501054419e-17, 1.951602196363124e-14, 1.0689101513638999e-11, 1.3762003697880714e-16, 1.2046739059840764e-23, 1.3492662544174694e-19, 1.478807003493307e-19, 1.5657081534059536e-11, 7.08399130951638e-17, 9.253940166127148e-17, 2.932633798722366e-20, 1.8735413076540198e-20, 3.618573997577988e-26, 4.549281146294816e-34, 1.9333840636439922e-26, 1.0213950119748199e-24, 2.3861443900830495e-19, 2.4678093160017227e-14, 1.81721091927733e-17, 1.4288069596416428e-24, 8.639117330895674e-18, 8.800704375220917e-19, 7.447919017633531e-12, 7.881266195219894e-10, 4.551707860449283e-13, 2.2338568169723294e-13, 9.383940532940472e-17, 2.1917323271701068e-17, 2.1324311945142976e-13, 7.29225447387849e-12, 4.648703907150775e-05, 0.999941349029541, 1.2177514690847602e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.015545190301953e-16, 6.515741476604765e-27, 2.9604575080261456e-30, 1.0453493527116758e-30, 3.008697388771462e-29, 1.4810989220231266e-25, 4.616345228682426e-23, 9.915249212785486e-20, 3.804957926996285e-23, 7.198147698077981e-25, 1.7169759824779483e-27, 1.8664734979607282e-24, 8.11770707807601e-25, 4.575221842516818e-28, 9.303428485718578e-29, 1.0147256618801696e-32, 2.5550626879495498e-24, 3.738381631260847e-26, 3.9112108644979513e-23, 9.88824732340537e-19, 2.914255818543994e-14, 1.2097237816512119e-13, 5.77423611253933e-19, 2.901930534595017e-18, 4.2711380456296086e-20, 2.924612998609841e-14, 1.1848167270152223e-14, 1.5837304298871899e-15, 2.1732487116848134e-16, 1.2456802688522682e-16, 4.4852313616136326e-17, 6.0773110497584894e-24, 1.2935560884874527e-21, 3.202000641556285e-19, 7.814381864233353e-17, 5.644082423650332e-11, 6.30036604484796e-12, 1.0524159058870712e-14, 2.524747121437909e-12, 6.473317162251219e-15, 2.025761502988388e-11, 8.141109120174406e-09, 1.538394189815051e-09, 8.324351874477998e-09, 9.843252948837922e-12, 2.2032768665081193e-10, 2.1676448830332262e-11, 1.553299849854639e-11, 1.4161010142288433e-08, 0.00024880669661797583, 0.9997497200965881, 1.470851771046e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.1320988634391793e-12, 4.800863961901412e-17, 2.2116996587981145e-22, 1.6312576585596213e-24, 1.0236962301689144e-25, 1.744558397717668e-24, 1.2471375943145268e-22, 2.574857736922415e-18, 3.0113934130056906e-18, 4.4286383110807146e-17, 3.615490678653306e-15, 3.375394107556391e-14, 1.850511609317049e-15, 1.126002321990218e-16, 1.9745001068476763e-16, 1.407165412797851e-17, 1.2790557327106396e-17, 6.830487583292969e-17, 7.840001819153228e-19, 9.862604724416226e-19, 1.225393078023787e-14, 2.2967088300629435e-11, 2.324416631394044e-10, 1.9627384439946383e-10, 2.315298397448373e-09, 2.027974410623301e-08, 2.5305432700406527e-06, 1.713511466050477e-07, 3.017304461838677e-10, 9.859498634190444e-12, 2.8190290813495666e-12, 2.8714125744345163e-16, 1.2877604851687801e-17, 8.291298047712493e-15, 5.5201732074294796e-11, 3.349875932201485e-09, 5.288305260364723e-07, 1.0286703400197439e-05, 2.970184596051695e-07, 1.1424014019212336e-06, 2.3391917238768656e-06, 1.565007039516786e-07, 2.6811508568869158e-09, 4.088827942894113e-09, 3.268438297787668e-10, 1.1391473542232688e-08, 8.169226184406853e-09, 5.887851557417889e-07, 2.6531031949161843e-07, 2.203442761583574e-07, 0.016373904421925545, 0.9812071919441223, 0.0024003414437174797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.636565296407442e-16, 2.583420116087499e-20, 1.1601449166948849e-23, 1.950637659584437e-23, 2.94208041184892e-24, 2.129666369484184e-26, 1.1477178725258025e-24, 5.340149304659518e-19, 1.0761833802298388e-18, 9.339339251579645e-21, 1.734246758218861e-21, 2.2209410672160893e-18, 2.218353666112358e-15, 4.755713238577958e-14, 6.2134859940326994e-15, 2.9830527188794607e-20, 1.8830044154203398e-19, 3.575820200916477e-21, 1.0976706670982361e-22, 9.723243790505735e-20, 5.885324254442702e-15, 4.891897650849408e-12, 1.463326801311865e-13, 2.2194866520886496e-16, 9.088168870032336e-18, 4.181704421212136e-14, 6.36788816121836e-11, 8.502611947847072e-09, 1.9205716128567474e-08, 1.199288557351963e-09, 1.0818201445772502e-07, 5.428690808516323e-13, 6.312293869637571e-16, 2.64622357145104e-16, 4.654449433294169e-15, 5.983534848152949e-12, 1.6171470917925035e-07, 8.440420060651377e-07, 2.6493450988596123e-08, 1.1364987423378992e-10, 1.2317249997728652e-10, 5.326464158628141e-09, 1.760100190040248e-07, 5.014678208681289e-06, 1.5857301249866396e-08, 3.2601161770173803e-09, 8.478986610049866e-12, 2.2545107328329067e-13, 3.000420414510027e-14, 1.6635734456649232e-10, 0.0006640892825089395, 0.0003139880718663335, 0.9985866546630859, 0.0004289457865525037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0272319275932623e-17, 1.2682927067342833e-17, 1.0755511234361642e-20, 9.396058476882781e-21, 4.9141313851612193e-23, 3.208730780601274e-24, 3.0084031066759594e-27, 5.2241287297996e-22, 6.982808922627669e-18, 5.002684450835775e-17, 3.269670922621237e-17, 2.101246197272682e-19, 2.0935673297198663e-17, 6.439513419026488e-12, 7.710422522677618e-09, 1.4619040353269774e-11, 9.761438500636684e-16, 2.267278794553121e-19, 6.640372909131642e-21, 3.6964159044742843e-22, 4.594821212248333e-17, 8.98228887102892e-12, 3.02762093173925e-10, 1.398167714418419e-12, 2.653675873200102e-16, 2.0728027802390702e-17, 1.4927866410986874e-14, 2.7268043779980072e-14, 3.865436345572987e-13, 2.0878702412796546e-12, 1.1452310211268468e-08, 5.681464188000973e-08, 8.328253364719984e-11, 7.058375693820562e-13, 4.580634916512283e-14, 9.24881694028524e-17, 1.865517506097203e-12, 7.684472502766937e-11, 2.1224945412345875e-11, 5.357922764313849e-13, 1.7351391838654517e-16, 8.836838643586469e-17, 6.559226208377065e-15, 4.4833003954268535e-13, 3.158520112123142e-09, 1.2137372884524211e-08, 3.4930069253702456e-11, 1.2387782314694784e-13, 1.05264349503732e-17, 7.525659434505394e-18, 5.278600364970465e-13, 7.576394267516662e-08, 1.3587504327006172e-05, 0.9999560117721558, 3.023029785254039e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.5587804019279764e-18, 4.523186431524065e-15, 1.3441357797592086e-20, 2.33045998595206e-23, 1.5318542819688531e-24, 5.7051063926185e-27, 5.346971341664435e-28, 1.9217832246239757e-27, 4.306927602146074e-22, 1.127279360643005e-18, 2.9675858864058516e-17, 6.04840667753368e-20, 2.2221835571196293e-20, 1.5525442252513932e-17, 4.749823364486039e-12, 1.614732680899067e-09, 3.871176382924668e-14, 2.649862480049586e-13, 2.216274547177417e-20, 1.043846700156781e-21, 4.401237076995434e-20, 1.3349612214275108e-12, 2.1076702694244887e-07, 3.550108818028974e-10, 3.1947385709107934e-11, 1.1992372703745802e-17, 9.223335409904972e-16, 3.5418468284223795e-16, 1.6936434368261576e-16, 7.858881699646868e-18, 5.157654251602972e-12, 1.909719743453664e-10, 4.526619530598186e-12, 8.790573130523782e-11, 8.228965252266018e-12, 3.657440951513031e-17, 5.4886686117061945e-17, 4.1240562397362734e-13, 2.3079803398437038e-15, 1.615680449130151e-14, 4.062972357613928e-19, 3.445146262869056e-21, 7.447298299941883e-22, 1.6396078963983556e-16, 2.2676262079288512e-15, 2.9952276769940056e-10, 1.3550312261134678e-10, 2.65119121101165e-10, 2.647049957970205e-16, 5.153326815152266e-20, 1.6964579155516468e-14, 1.1433556185158622e-10, 2.1765147462105006e-09, 0.0002927772584371269, 0.9997028708457947, 4.0448167055728845e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.965995566460083e-16, 3.970977019429611e-11, 2.0900775142725092e-14, 5.740986160931205e-17, 7.316841456415578e-21, 3.442090331337684e-19, 2.084201819511089e-25, 2.106599059724511e-25, 7.539598055078617e-23, 5.3623414231209736e-18, 6.69111188524252e-16, 2.0621557084409816e-15, 2.8555735236099554e-20, 1.7392113443902135e-18, 1.4635521459571525e-14, 5.890440579747747e-09, 3.014594129879811e-11, 2.478685257045754e-09, 2.3123702605487573e-11, 3.74236295279242e-17, 1.0103874697534162e-17, 7.010757449701704e-15, 8.500211201578622e-09, 2.1527820592837088e-07, 6.492604711638705e-07, 8.115491243430861e-13, 9.32010402721955e-17, 2.762585516673488e-16, 7.979531549607468e-20, 1.0810992919920216e-20, 1.0814793265535271e-19, 3.185337543065741e-16, 2.203494954859317e-13, 2.071273881576463e-11, 7.964921257264113e-12, 9.33671224227645e-19, 7.8036332079352e-22, 1.9085092371387053e-20, 1.3335186257914064e-20, 1.6232900051928485e-17, 1.1105562760484146e-19, 5.732690162172157e-25, 5.690878069005114e-25, 1.8143132260466097e-24, 9.542018858053024e-20, 3.5537989927037297e-16, 6.82211665631316e-13, 7.742228524953987e-10, 4.209159965018472e-10, 1.0767793018226373e-17, 6.55695525017975e-19, 3.813400604405631e-14, 1.5282017556618357e-16, 9.06027031177814e-10, 0.00016854210116434842, 0.9997758269309998, 5.4799696954432875e-05, 0.0, 0.0, 0.0, 0.0, 0.0], [5.649498423465843e-15, 1.973109252278505e-15, 3.038060525806935e-14, 1.6181993702670746e-17, 4.0308316035084476e-17, 5.93386747442183e-17, 1.0014102853605313e-18, 1.159072618066418e-23, 9.896503814017306e-24, 2.9591422110514023e-22, 1.622814462936101e-20, 6.40616800760235e-22, 2.437607491720247e-23, 1.3620572229754307e-25, 4.482287771549203e-21, 1.2976389903725211e-16, 2.019299229441703e-15, 5.770729488881188e-13, 1.780730944644926e-11, 4.567374039740613e-13, 3.355592510128659e-14, 7.801059941797174e-15, 4.992469285203249e-11, 4.544908338566245e-10, 4.053855029440001e-09, 1.6386684760852366e-12, 6.879678359960272e-17, 1.8211085985242065e-21, 8.34060135978828e-22, 3.7456003248412014e-24, 2.2716701219417544e-20, 2.3719265512205466e-18, 7.155778384117586e-14, 1.2760388301558123e-07, 1.0229399549643858e-09, 4.155662359367485e-12, 2.913123968493479e-20, 2.3433503707292676e-21, 4.235430298406635e-22, 5.2790291069125596e-21, 1.5026159918648395e-21, 4.51599107748564e-23, 4.893665653617899e-26, 1.4353158825250575e-22, 2.3448539572851032e-20, 6.073276105113268e-13, 1.3467806514108616e-12, 6.331856639008038e-08, 8.021654451795257e-08, 3.4594226788753346e-11, 5.560343716492708e-14, 8.434783904318066e-14, 1.2227595043600077e-15, 6.76920609951788e-14, 5.917029284319142e-07, 8.599429565947503e-05, 0.999240517616272, 0.0006726498249918222, 0.0, 0.0, 0.0, 0.0], [1.460662789519126e-15, 6.3083443076193474e-21, 7.837873961650921e-21, 1.0900500688054094e-21, 9.683827387286265e-23, 8.558194794406888e-20, 4.0793305024815015e-22, 2.715420037177643e-22, 6.117411015856875e-27, 2.1808401769992995e-26, 4.860785253160947e-28, 6.5398388353284545e-25, 5.264028279714482e-28, 2.898511626460976e-29, 1.0465645505596915e-29, 2.1097160463762655e-25, 4.022552822585289e-24, 3.5612192817068245e-22, 3.430698900385874e-16, 2.1027334421646583e-18, 1.1245916680259049e-14, 1.5750262663816455e-16, 1.957163195301953e-16, 2.913721510160866e-14, 2.5830591599039845e-14, 9.018592296572425e-12, 2.869713710892455e-18, 5.7366304300970096e-21, 1.6124266415619547e-23, 9.942928081074337e-25, 1.56830955969221e-26, 2.3829902521196547e-26, 1.4198927644271716e-15, 3.9328116501272103e-13, 8.046528721106228e-11, 1.5322602561762544e-11, 8.826329396622044e-19, 8.546484380425443e-27, 3.0669076788983033e-22, 2.128114954952336e-23, 1.031751405130502e-21, 3.8106288902717377e-23, 3.904328210872079e-24, 4.86405914917713e-24, 4.6320922807458304e-21, 4.494928916922475e-19, 1.1761501400088005e-14, 3.2222334067459613e-13, 4.378449158792819e-09, 1.247064951304111e-10, 3.3028790206307557e-12, 8.965073285517947e-14, 2.1941045104368305e-14, 7.097578644432625e-16, 1.892267267357417e-13, 6.422800069572077e-09, 6.704130441903544e-07, 0.9999992847442627, 1.2786572689549303e-08, 0.0, 0.0, 0.0], [8.377691060050746e-20, 3.1225350803189346e-20, 4.547019501242879e-22, 8.993890078383846e-26, 1.3098048532839646e-28, 1.4375744883943894e-27, 1.5658758005400866e-26, 3.1534556759954507e-27, 1.340164821722765e-29, 2.2956695899247085e-27, 1.1116622354348162e-23, 3.0497332303585556e-22, 2.9617887457111863e-26, 1.3070982784815917e-30, 3.027388057399254e-28, 5.969373578679814e-24, 6.722514073251513e-24, 7.547245184341408e-21, 1.960519833740111e-21, 7.894640240929331e-22, 1.378198061583732e-22, 6.364248469213434e-21, 5.608112499542117e-17, 1.9728193552523074e-14, 4.6178602608470953e-10, 2.353429083556957e-12, 5.608840757294342e-13, 1.074118117035447e-18, 1.015052885841205e-23, 2.1878207871199288e-27, 1.201937860263453e-24, 4.0625486128218667e-26, 6.590481003595043e-23, 3.987734977433733e-15, 7.335392709917343e-11, 6.729563434282326e-11, 9.170066566643333e-16, 1.5882137421897824e-17, 1.6507919084511464e-20, 2.435370942311846e-19, 2.0428239815717103e-19, 3.476190173543586e-21, 1.1471322542372407e-26, 1.2510810103860374e-25, 6.840256050002148e-27, 6.962167250826867e-20, 2.3853909836413785e-18, 6.313181314526739e-13, 4.681221035807148e-11, 7.773892884673297e-14, 6.395096583365623e-13, 1.3158828410589352e-12, 2.665417655673178e-15, 9.606109995815884e-17, 3.642965096251061e-11, 4.976610790130565e-10, 1.960303052328527e-06, 0.0010747667402029037, 0.9989122152328491, 1.1171872756676748e-05, 0.0, 0.0], [5.855379283946878e-17, 1.73001715110233e-22, 1.4713624556042429e-24, 3.0155852384022496e-25, 7.178441644516769e-29, 7.34134065107293e-27, 4.412121722652144e-25, 2.5530778145155397e-21, 2.7975257185312123e-26, 1.8135290135659024e-27, 3.613810017267552e-26, 3.0180915080158387e-19, 2.5198733872447903e-19, 3.295087383895818e-24, 6.201064938549301e-27, 7.495614621114396e-29, 4.103930283757498e-25, 2.865659573285393e-26, 1.5678376483568685e-21, 5.90507144370246e-22, 5.859101870706945e-20, 5.353527787844827e-20, 2.5072631157416475e-20, 2.3411433142376e-17, 2.005896838875535e-16, 2.0725843263846855e-09, 2.733142054692217e-12, 1.0056336189126491e-12, 3.347757169492937e-16, 1.33882705931117e-17, 1.1550289631357319e-20, 1.5437151261535938e-26, 1.1336601424251015e-22, 2.8740322528495323e-20, 2.2850177425117607e-14, 4.993089830485076e-10, 3.776514170827916e-11, 1.6057883325039943e-15, 4.224635100297594e-14, 1.898044133701645e-16, 2.8597447760542183e-12, 1.6241445105588843e-14, 1.4023035429422848e-16, 8.210437725131938e-20, 1.744751103815039e-21, 5.761117803506064e-20, 1.3184318046148482e-18, 2.6937555201179298e-17, 3.07481275683974e-12, 9.231941877629879e-10, 3.7732852398164596e-09, 1.8657546618783272e-08, 8.92658003071034e-10, 5.071800883493848e-16, 1.02493401985159e-16, 7.700800039962472e-14, 3.301184412635161e-12, 2.073265477520181e-06, 3.5668765576701844e-06, 0.9999934434890747, 9.344645945930097e-07, 0.0], [1.3510543604078677e-18, 5.671291934343457e-19, 1.3106711961078757e-18, 6.67319041136176e-20, 1.5236941785475021e-22, 4.6159558001009925e-26, 1.6467200028337225e-23, 3.079876148283353e-20, 1.2336817224860206e-20, 1.7545777358520982e-22, 1.4781192803621516e-19, 5.567843279371504e-18, 1.5560830627305727e-15, 2.0295923738167373e-15, 4.096883298909787e-17, 2.315405455061163e-19, 4.951296121241901e-24, 1.2940406131663267e-22, 4.637548232092956e-23, 5.506408657672134e-22, 4.309554768969015e-20, 1.2420119482423125e-19, 1.2065364940794829e-16, 1.0057203099422389e-18, 2.7166095741481492e-15, 7.537866273006621e-13, 3.650139746014247e-09, 1.5595023102749073e-12, 9.815671886403976e-11, 2.1624685498348875e-15, 6.475899460775536e-13, 4.263177809903096e-15, 1.673683957420141e-18, 4.824993164476718e-15, 6.409441391259235e-14, 3.1599733940623764e-10, 5.660776025706582e-08, 1.8586751693305814e-08, 1.8036579987803364e-13, 3.990675791123305e-13, 3.187285030630156e-14, 2.54397306172216e-13, 7.63893857684653e-16, 2.1543912436498705e-15, 6.865409246239549e-18, 1.7004705223810273e-16, 5.615556504669634e-19, 1.7586094742171333e-17, 3.0884208852369348e-18, 1.262637286121148e-15, 3.015789701299454e-11, 8.701798726029608e-10, 6.3555326335063e-08, 9.799943079258355e-10, 5.835468393222687e-12, 3.532253428552984e-13, 8.300324945594018e-13, 2.4678982815662387e-11, 1.8833720787370112e-06, 0.00023726887593511492, 0.999594509601593, 0.00016614947526250035]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9864429235458374, 0.013557130470871925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6932669878005981, 0.048144228756427765, 0.2585887610912323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.45400580763816833, 0.036761652678251266, 0.3720433712005615, 0.13718919456005096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5257108211517334, 0.06767012178897858, 0.2517397701740265, 0.036224108189344406, 0.11865513771772385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38353604078292847, 0.044768910855054855, 0.18124675750732422, 0.1431814283132553, 0.028279850259423256, 0.21898695826530457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2603915333747864, 0.08713163435459137, 0.20899149775505066, 0.02046600915491581, 0.08692530542612076, 0.013148455880582333, 0.3229455053806305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5625491738319397, 0.02702304534614086, 0.15378247201442719, 0.03524039313197136, 0.09162644296884537, 0.028814012184739113, 0.06526566296815872, 0.03569881618022919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47628912329673767, 0.029592731967568398, 0.12543144822120667, 0.01795400120317936, 0.08031816780567169, 0.008563181385397911, 0.1048726886510849, 0.04596250504255295, 0.11101608723402023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32270655035972595, 0.07701388746500015, 0.14857473969459534, 0.018309855833649635, 0.11650537699460983, 0.014061023481190205, 0.10782351344823837, 0.03130047395825386, 0.048334792256355286, 0.11536984145641327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2624054551124573, 0.06456426531076431, 0.11347578465938568, 0.018990857526659966, 0.1140381470322609, 0.008084086701273918, 0.1186605840921402, 0.030233537778258324, 0.06739377975463867, 0.09739761799573898, 0.10475592315196991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1767524629831314, 0.06996674835681915, 0.14877493679523468, 0.011048629879951477, 0.0800970196723938, 0.007613488472998142, 0.14674806594848633, 0.04542122036218643, 0.050679925829172134, 0.08180394023656845, 0.14092276990413666, 0.04017089679837227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2200499325990677, 0.07511278986930847, 0.1377701610326767, 0.06467261165380478, 0.036266133189201355, 0.06377287209033966, 0.08486118167638779, 0.03620816022157669, 0.03784508630633354, 0.0812627375125885, 0.07186418771743774, 0.060305602848529816, 0.030008459463715553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2010927051305771, 0.07750996202230453, 0.11608276516199112, 0.019471386447548866, 0.048411328345537186, 0.011089473962783813, 0.10988320410251617, 0.03220628947019577, 0.049216657876968384, 0.08177871257066727, 0.11760164052248001, 0.03205612674355507, 0.033872224390506744, 0.06972750276327133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19610564410686493, 0.06936335563659668, 0.1938539296388626, 0.05784989893436432, 0.03738275542855263, 0.021595971658825874, 0.09016623347997665, 0.030941471457481384, 0.026924364268779755, 0.05017571151256561, 0.06162945181131363, 0.057894106954336166, 0.022618865594267845, 0.05566626042127609, 0.027831977233290672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14348459243774414, 0.055615607649087906, 0.16808350384235382, 0.016991470009088516, 0.05719307065010071, 0.00704578123986721, 0.12836547195911407, 0.03670869767665863, 0.04117731750011444, 0.06719500571489334, 0.11366045475006104, 0.029704581946134567, 0.022304266691207886, 0.07414883375167847, 0.013303227722644806, 0.025018122047185898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16335216164588928, 0.026623742654919624, 0.13931190967559814, 0.03689616918563843, 0.04143824428319931, 0.01922575570642948, 0.06933411955833435, 0.02878413535654545, 0.03472893685102463, 0.06721346080303192, 0.08094462007284164, 0.05181720107793808, 0.03612438589334488, 0.07196195423603058, 0.026935197412967682, 0.045559339225292206, 0.0597485788166523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1706848293542862, 0.053270306438207626, 0.12035025656223297, 0.00905522145330906, 0.046025391668081284, 0.004124365281313658, 0.13424524664878845, 0.03108287788927555, 0.03846742585301399, 0.04889080673456192, 0.12675398588180542, 0.026239661499857903, 0.033340029418468475, 0.07500141113996506, 0.010175187140703201, 0.03944234922528267, 0.01216037105768919, 0.02069021202623844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11147670447826385, 0.08385702967643738, 0.12246678024530411, 0.006554802414029837, 0.08895409852266312, 0.0033194306306540966, 0.10796014964580536, 0.02158488519489765, 0.03675927221775055, 0.08469283580780029, 0.1127227395772934, 0.013300827704370022, 0.016557203605771065, 0.10776793956756592, 0.012521965429186821, 0.016567138954997063, 0.006462152116000652, 0.009245701134204865, 0.03722831606864929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16885481774806976, 0.028144093230366707, 0.03902266547083855, 0.07713563740253448, 0.01614130660891533, 0.07326294481754303, 0.027183352038264275, 0.01551019586622715, 0.013016905635595322, 0.033868301659822464, 0.017441125586628914, 0.07053639739751816, 0.021492596715688705, 0.03285788744688034, 0.05493824928998947, 0.026119332760572433, 0.18524733185768127, 0.020071616396307945, 0.024272451177239418, 0.054882898926734924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19921687245368958, 0.06773127615451813, 0.05034426972270012, 0.02739034965634346, 0.026763353496789932, 0.0104391323402524, 0.04744329676032066, 0.013825865462422371, 0.024572225287556648, 0.025703247636556625, 0.030021511018276215, 0.026773963123559952, 0.04907885938882828, 0.059735625982284546, 0.012684985995292664, 0.04791680723428726, 0.015857767313718796, 0.025115542113780975, 0.021930789574980736, 0.10556673258543015, 0.11188756674528122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2295992523431778, 0.09463345259428024, 0.056331999599933624, 0.025144286453723907, 0.01868152990937233, 0.012124800123274326, 0.08328521996736526, 0.01743737980723381, 0.011240202933549881, 0.018754737451672554, 0.02841942571103573, 0.046763885766267776, 0.01237853430211544, 0.05419674143195152, 0.021862074732780457, 0.018737539649009705, 0.06825663149356842, 0.02233273908495903, 0.022501265630126, 0.02187350206077099, 0.09952737390995026, 0.015917424112558365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15078315138816833, 0.022039035335183144, 0.05947408080101013, 0.011179666966199875, 0.029700126498937607, 0.011893556453287601, 0.03576179966330528, 0.014757842756807804, 0.016191549599170685, 0.046994417905807495, 0.04903068393468857, 0.022558610886335373, 0.01409069076180458, 0.04245304316282272, 0.013152243569493294, 0.022154029458761215, 0.024040337651968002, 0.0164017491042614, 0.03920285776257515, 0.044049475342035294, 0.14606650173664093, 0.012213773094117641, 0.15581072866916656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15694621205329895, 0.02793125808238983, 0.0485369972884655, 0.008915773592889309, 0.0419270284473896, 0.006874402053654194, 0.05021021515130997, 0.01521684043109417, 0.024949025362730026, 0.05536627024412155, 0.04926813766360283, 0.015549378469586372, 0.014555586501955986, 0.04490068927407265, 0.012885755859315395, 0.01303870603442192, 0.012247282080352306, 0.010644703172147274, 0.04154878854751587, 0.04310739412903786, 0.15155449509620667, 0.01610695756971836, 0.10463584214448929, 0.0330822691321373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13726870715618134, 0.04860251024365425, 0.05769648775458336, 0.007559227291494608, 0.05230195075273514, 0.005425767041742802, 0.05203599855303764, 0.012066635303199291, 0.017307782545685768, 0.03965115174651146, 0.032866112887859344, 0.014635942876338959, 0.008630793541669846, 0.055682383477687836, 0.013592680916190147, 0.009789684787392616, 0.009830549359321594, 0.00872405618429184, 0.03559049963951111, 0.030922062695026398, 0.17477382719516754, 0.0035397133324295282, 0.08339682221412659, 0.02198489010334015, 0.06612380594015121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11954937875270844, 0.03462942689657211, 0.03854062408208847, 0.008680712431669235, 0.03372061252593994, 0.00435222964733839, 0.04526032507419586, 0.012826252728700638, 0.018689516931772232, 0.030190329998731613, 0.030980931594967842, 0.011572667397558689, 0.01814350299537182, 0.056827690452337265, 0.00744986766949296, 0.020118173211812973, 0.006201690528541803, 0.012510447762906551, 0.025044789537787437, 0.05942150205373764, 0.13836133480072021, 0.003561049234122038, 0.09762418270111084, 0.0379798486828804, 0.06172038987278938, 0.06604256480932236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06289568543434143, 0.054865363985300064, 0.045012276619672775, 0.005554880015552044, 0.040116116404533386, 0.0025165278930217028, 0.060587476938962936, 0.01089964248239994, 0.016023270785808563, 0.026245038956403732, 0.02871013432741165, 0.009454307146370411, 0.011040614917874336, 0.05461978539824486, 0.0057013751938939095, 0.010392341762781143, 0.0034523846115916967, 0.008033964782953262, 0.019271083176136017, 0.030584899708628654, 0.17386719584465027, 0.0014522644923999906, 0.09383247047662735, 0.025732209905982018, 0.05301833525300026, 0.060163505375385284, 0.08595684915781021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07308458536863327, 0.061707012355327606, 0.04838729649782181, 0.0027238198090344667, 0.017107095569372177, 0.0017297115409746766, 0.06747661530971527, 0.01049825269728899, 0.011760287918150425, 0.013980059884488583, 0.034771885722875595, 0.010386279784142971, 0.015720490366220474, 0.03022135980427265, 0.002652711234986782, 0.024051740765571594, 0.003846612526103854, 0.012515420094132423, 0.017634276300668716, 0.02075604349374771, 0.1732214242219925, 0.0015336808282881975, 0.07054945081472397, 0.03675403818488121, 0.030015215277671814, 0.06180035322904587, 0.1012883186340332, 0.043825916945934296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03642711043357849, 0.02578159049153328, 0.04006703197956085, 0.001138310763053596, 0.021115876734256744, 0.0004815950524061918, 0.036835554987192154, 0.007941754534840584, 0.014113557524979115, 0.018489660695195198, 0.04696947708725929, 0.0022938833571970463, 0.007392215076833963, 0.024847740307450294, 0.0009933164110407233, 0.010130357928574085, 0.0006784225115552545, 0.004781707189977169, 0.012074591591954231, 0.019868280738592148, 0.20630396902561188, 0.00021478428971022367, 0.03280249238014221, 0.03899224102497101, 0.047648392617702484, 0.08244531601667404, 0.15046459436416626, 0.022019611671566963, 0.08668653666973114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09021393954753876, 0.043153680860996246, 0.031514644622802734, 0.004479465074837208, 0.018523484468460083, 0.003783194813877344, 0.026558423414826393, 0.007167256902903318, 0.01228023786097765, 0.022865334525704384, 0.028664326295256615, 0.0052131665870547295, 0.007903940044343472, 0.019553842023015022, 0.0047406163066625595, 0.010094842873513699, 0.004852264188230038, 0.006061502266675234, 0.020342476665973663, 0.024040214717388153, 0.10629485547542572, 0.010116546414792538, 0.06187179312109947, 0.024148833006620407, 0.05808020010590553, 0.10411369800567627, 0.10579732805490494, 0.029565852135419846, 0.08315630257129669, 0.02484767884016037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07708068192005157, 0.012657009065151215, 0.050523899495601654, 0.011591961607336998, 0.013427470810711384, 0.005711079575121403, 0.024147262796759605, 0.008274579420685768, 0.010311923921108246, 0.017642538994550705, 0.022637594491243362, 0.01344593707472086, 0.00902310386300087, 0.02040777914226055, 0.006444341037422419, 0.013443474657833576, 0.018900930881500244, 0.011862500570714474, 0.014275241643190384, 0.018172722309827805, 0.08764930069446564, 0.002728226827457547, 0.16310559213161469, 0.022374585270881653, 0.04787570610642433, 0.06044702231884003, 0.07800699025392532, 0.038620106875896454, 0.06061156839132309, 0.022251546382904053, 0.03634735196828842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09770314395427704, 0.014127387665212154, 0.016367705538868904, 0.03304039314389229, 0.0057579823769629, 0.03223613277077675, 0.010874990373849869, 0.005400003865361214, 0.004393367562443018, 0.010527031496167183, 0.0052596875466406345, 0.0240239929407835, 0.005816698540002108, 0.00945228524506092, 0.014960130676627159, 0.007128208409994841, 0.07048842310905457, 0.008005118928849697, 0.010887790471315384, 0.022766269743442535, 0.013178205117583275, 0.04144478589296341, 0.19174322485923767, 0.009901825338602066, 0.027170047163963318, 0.032754287123680115, 0.018228672444820404, 0.024444274604320526, 0.022913580760359764, 0.01906070113182068, 0.15086573362350464, 0.039077844470739365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0814681425690651, 0.019368086010217667, 0.029199551790952682, 0.0014536685775965452, 0.024932317435741425, 0.000771392893511802, 0.04466087371110916, 0.007342688739299774, 0.012105250731110573, 0.02027892880141735, 0.034177038818597794, 0.004684241488575935, 0.005197473336011171, 0.0331830196082592, 0.002361720660701394, 0.004271995276212692, 0.0013789820950478315, 0.0041374098509550095, 0.01625869609415531, 0.012467650696635246, 0.1593881994485855, 0.00037110268021933734, 0.0352855809032917, 0.01673322729766369, 0.04479731246829033, 0.08605612069368362, 0.11893834918737411, 0.02880469337105751, 0.08956672996282578, 0.018339617177844048, 0.0028273025527596474, 0.01879304274916649, 0.020399605855345726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07748439162969589, 0.014831330627202988, 0.022521691396832466, 0.018701914697885513, 0.0036075105890631676, 0.02187497168779373, 0.019184676930308342, 0.006228097248822451, 0.005028317682445049, 0.005302646663039923, 0.010102858766913414, 0.01599302515387535, 0.00830200407654047, 0.011084217578172684, 0.00580561300739646, 0.007405845448374748, 0.0090643260627985, 0.008338917046785355, 0.006828670389950275, 0.021614698693156242, 0.021874284371733665, 0.011747103184461594, 0.25813356041908264, 0.009499757550656796, 0.015017954632639885, 0.037466861307621, 0.05100908502936363, 0.04095741733908653, 0.052534520626068115, 0.00979864876717329, 0.025571288540959358, 0.0413338765501976, 0.01344562228769064, 0.1123042032122612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07470707595348358, 0.009402458555996418, 0.020012881606817245, 0.024370776489377022, 0.004202948417514563, 0.014844182878732681, 0.008683085441589355, 0.004465664736926556, 0.003434284357354045, 0.006459448020905256, 0.00458504119887948, 0.021779723465442657, 0.004368708003312349, 0.00952325388789177, 0.011843519285321236, 0.007348298095166683, 0.09170546382665634, 0.007855799980461597, 0.0071644107811152935, 0.009415230713784695, 0.013741815462708473, 0.004896942991763353, 0.1879463493824005, 0.006588517222553492, 0.013506453484296799, 0.016698073595762253, 0.012394856661558151, 0.018525267019867897, 0.01947806403040886, 0.017335833981633186, 0.2417442351579666, 0.019193831831216812, 0.007526605390012264, 0.05570085346698761, 0.01855003647506237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07977180927991867, 0.019062401726841927, 0.022123299539089203, 0.006755949463695288, 0.011130856350064278, 0.002826923504471779, 0.013917041011154652, 0.004751702304929495, 0.0071593234315514565, 0.012460529804229736, 0.013405277393758297, 0.006917398888617754, 0.008219634182751179, 0.017031030729413033, 0.0042320312932133675, 0.0109627153724432, 0.008640842512249947, 0.007468237541615963, 0.011565371416509151, 0.018826641142368317, 0.05422310531139374, 0.006088190712034702, 0.06797508150339127, 0.016065338626503944, 0.02742905542254448, 0.035202160477638245, 0.046366363763809204, 0.029525114223361015, 0.052603673189878464, 0.022820310667157173, 0.021814607083797455, 0.03682723268866539, 0.01671198382973671, 0.012536725960671902, 0.1023273915052414, 0.16425469517707825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05995384603738785, 0.03516215831041336, 0.029749060049653053, 0.023790715262293816, 0.005861589219421148, 0.007910523563623428, 0.010807960294187069, 0.0037905476056039333, 0.0033488173503428698, 0.005505072884261608, 0.004255958367139101, 0.012204350903630257, 0.004697072319686413, 0.009071639738976955, 0.006150522269308567, 0.007669372949749231, 0.04088614135980606, 0.0061764963902533054, 0.006102419458329678, 0.010159560479223728, 0.018308471888303757, 0.0029908446595072746, 0.17012643814086914, 0.006383971311151981, 0.01130084227770567, 0.015444431453943253, 0.012950167059898376, 0.013897860422730446, 0.018670527264475822, 0.014995653182268143, 0.10385151207447052, 0.021063579246401787, 0.00766189768910408, 0.029079176485538483, 0.07096397131681442, 0.15088172256946564, 0.038175132125616074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05202531814575195, 0.03624998778104782, 0.02841179259121418, 0.0031225222628563643, 0.010131030343472958, 0.0015595222357660532, 0.013684477657079697, 0.0036026265006512403, 0.004378260113298893, 0.00803556852042675, 0.010765230283141136, 0.005605749320238829, 0.0057671465910971165, 0.012402225285768509, 0.00200376333668828, 0.008484536781907082, 0.0037339047994464636, 0.006079073064029217, 0.008498189970850945, 0.010216517373919487, 0.05070220306515694, 0.0014418670907616615, 0.04467695206403732, 0.01178648415952921, 0.015928197652101517, 0.02731255628168583, 0.03478652983903885, 0.022659247741103172, 0.03334106504917145, 0.012225273996591568, 0.008940205909311771, 0.01917099393904209, 0.010607760399580002, 0.0059175011701881886, 0.17952877283096313, 0.17124049365520477, 0.06856949627399445, 0.046406954526901245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04285632446408272, 0.011936723254621029, 0.03982436656951904, 0.014136068522930145, 0.006623890716582537, 0.004049344453960657, 0.01661652885377407, 0.006085181143134832, 0.005235935561358929, 0.006677867379039526, 0.008527440950274467, 0.008587198331952095, 0.004591239616274834, 0.011067869141697884, 0.0046240161173045635, 0.006069945637136698, 0.012970575131475925, 0.005138542503118515, 0.004630816634744406, 0.008476668037474155, 0.035231124609708786, 0.0008283535717055202, 0.09579004347324371, 0.009699588641524315, 0.013759822584688663, 0.02108406275510788, 0.02648955024778843, 0.018838755786418915, 0.024080419912934303, 0.009824014268815517, 0.03345504403114319, 0.01710258051753044, 0.008534625172615051, 0.015866128727793694, 0.04517723619937897, 0.22768530249595642, 0.03655557706952095, 0.05753432586789131, 0.07373683899641037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09183648973703384, 0.011554925702512264, 0.01166918221861124, 0.0018838561372831464, 0.009439466521143913, 0.0014069483149796724, 0.00806912686675787, 0.003366577671840787, 0.00484311580657959, 0.010946448892354965, 0.010216059163212776, 0.0028161152731627226, 0.004618947394192219, 0.0125062745064497, 0.0018626046366989613, 0.0056535047478973866, 0.0015927327331155539, 0.0035036318004131317, 0.00981767289340496, 0.018103305250406265, 0.034315988421440125, 0.003206745022907853, 0.029435737058520317, 0.014261572621762753, 0.024986717849969864, 0.04117068275809288, 0.04169664904475212, 0.017820030450820923, 0.03167899698019028, 0.010129373520612717, 0.003953650128096342, 0.03538483753800392, 0.009303366765379906, 0.006678089965134859, 0.0908103734254837, 0.09572767466306686, 0.04644463211297989, 0.03581329807639122, 0.010877039283514023, 0.1905975192785263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03895283490419388, 0.013324573636054993, 0.025331541895866394, 0.0031423703767359257, 0.011220421642065048, 0.0011542432475835085, 0.018948977813124657, 0.004881320521235466, 0.0068106818944215775, 0.00984654575586319, 0.014198274351656437, 0.0032450060825794935, 0.004613909404724836, 0.01303019281476736, 0.0017546511953696609, 0.004730749875307083, 0.001592255779542029, 0.0033156767021864653, 0.0062557486817240715, 0.011054084636271, 0.05660964548587799, 0.0006633383454754949, 0.035412997007369995, 0.01254194788634777, 0.019794126972556114, 0.03137102350592613, 0.04740595817565918, 0.016257107257843018, 0.03646305575966835, 0.00847557745873928, 0.003697959240525961, 0.01942739635705948, 0.01084697525948286, 0.004184039309620857, 0.08159718662500381, 0.14799153804779053, 0.043844662606716156, 0.03473170846700668, 0.012321836315095425, 0.14270943403244019, 0.03624845668673515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03603975847363472, 0.018365172669291496, 0.013859184458851814, 0.0012735561467707157, 0.013690060004591942, 0.0007816955912858248, 0.020667055621743202, 0.0032822538632899523, 0.005073491018265486, 0.009579476900398731, 0.010149831883609295, 0.0030770148150622845, 0.003725663758814335, 0.020025258883833885, 0.0016800763551145792, 0.003208716632798314, 0.000767383084166795, 0.002345922403037548, 0.007168684620410204, 0.008118215948343277, 0.05637999251484871, 0.0007870342815294862, 0.027134213596582413, 0.00818952638655901, 0.018329408019781113, 0.02158733271062374, 0.03481986001133919, 0.01705455221235752, 0.03366599977016449, 0.00970503594726324, 0.001788392779417336, 0.016094913706183434, 0.0082384143024683, 0.0029450934380292892, 0.13092106580734253, 0.08904024213552475, 0.05586162209510803, 0.04572438448667526, 0.008197437971830368, 0.11631935089826584, 0.035433605313301086, 0.07890398055315018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03783963620662689, 0.005642881616950035, 0.01851535029709339, 0.0072929528541862965, 0.005006110295653343, 0.00250754551962018, 0.009739905595779419, 0.0030790818855166435, 0.0028971871361136436, 0.005763624329119921, 0.006700212601572275, 0.005985344760119915, 0.00446340162307024, 0.008668842725455761, 0.001588419545441866, 0.0061431387439370155, 0.004342702217400074, 0.004633839707821608, 0.004039799328893423, 0.01159660890698433, 0.022120775654911995, 0.0009432324441149831, 0.08982979506254196, 0.00880772527307272, 0.01528785191476345, 0.016483252868056297, 0.026507223024964333, 0.014528617262840271, 0.02150469273328781, 0.006764126010239124, 0.010966917499899864, 0.02313755638897419, 0.0059112198650836945, 0.012853382155299187, 0.04145290330052376, 0.17551879584789276, 0.03877221792936325, 0.05267291143536568, 0.026680203154683113, 0.08661917597055435, 0.02445124462246895, 0.052154868841171265, 0.06958463042974472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05419972538948059, 0.01752183400094509, 0.018280312418937683, 0.001602505100890994, 0.007997059263288975, 0.0007670469349250197, 0.018512515351176262, 0.003771431278437376, 0.004296303726732731, 0.005543327424675226, 0.010684049688279629, 0.0040851179510355, 0.005957010667771101, 0.013149235397577286, 0.0013292547082528472, 0.009039901196956635, 0.002033238997682929, 0.0051989471539855, 0.007289889268577099, 0.008503688499331474, 0.0453030988574028, 0.0007472730940207839, 0.028453519567847252, 0.013313773088157177, 0.011795916594564915, 0.021990835666656494, 0.03232395648956299, 0.017954962328076363, 0.030386677011847496, 0.0074417805299162865, 0.0037022046744823456, 0.013676170259714127, 0.008386966772377491, 0.0026652226224541664, 0.08159669488668442, 0.11572988331317902, 0.043141353875398636, 0.0367758646607399, 0.011421376839280128, 0.12112170457839966, 0.036394551396369934, 0.0729808434844017, 0.01081226859241724, 0.03212079033255577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.062116701155900955, 0.017200592905282974, 0.01766606979072094, 0.00382607732899487, 0.010407435707747936, 0.0018365810392424464, 0.015842437744140625, 0.003659222275018692, 0.006548375356942415, 0.008304513990879059, 0.010585872456431389, 0.003993394318968058, 0.005528644658625126, 0.011886686086654663, 0.002529227640479803, 0.004807888530194759, 0.0019449138781055808, 0.0035967137664556503, 0.007893787696957588, 0.014451961033046246, 0.037087805569171906, 0.002021891064941883, 0.02151736617088318, 0.008813487365841866, 0.01504246611148119, 0.02238927222788334, 0.03188927099108696, 0.01591620221734047, 0.02872953750193119, 0.009082146920263767, 0.0034958457108587027, 0.021296050399541855, 0.00897950492799282, 0.004884948022663593, 0.07715898007154465, 0.07497278600931168, 0.042809028178453445, 0.028470942750573158, 0.013690823689103127, 0.11285880208015442, 0.03570101037621498, 0.08177772164344788, 0.017874881625175476, 0.022850224748253822, 0.046061936765909195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04430293291807175, 0.006384043488651514, 0.010145525448024273, 0.03898152336478233, 0.0016179780941456556, 0.005553507711738348, 0.0044026984833180904, 0.003010975895449519, 0.002095177536830306, 0.0020922301337122917, 0.0015878202393651009, 0.0021019920241087675, 0.0011187618365511298, 0.0021548231597989798, 0.004514061380177736, 0.0012357186060398817, 0.029772954061627388, 0.0008711023256182671, 0.0010781654855236411, 0.0046685501001775265, 0.005065243225544691, 0.0012036445550620556, 0.057134419679641724, 0.0018105172784999013, 0.00459336256608367, 0.008337963372468948, 0.004829298239201307, 0.0023360401391983032, 0.006288317032158375, 0.003429829142987728, 0.07384712994098663, 0.008539404720067978, 0.0037431628443300724, 0.018997786566615105, 0.016417335718870163, 0.056176070123910904, 0.007859797216951847, 0.01940547116100788, 0.09782300889492035, 0.02031051553785801, 0.00593137601390481, 0.01603175327181816, 0.3086368143558502, 0.012754887342453003, 0.007751842960715294, 0.06305444240570068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.045309994369745255, 0.006955181714147329, 0.013013504445552826, 0.0018679030472412705, 0.007266037166118622, 0.0010251901112496853, 0.012495191767811775, 0.003441407112404704, 0.005231424700468779, 0.006421765778213739, 0.011375239118933678, 0.002651809249073267, 0.0036782613024115562, 0.008954971097409725, 0.0014750633854418993, 0.003577633760869503, 0.0011839827056974173, 0.0029538613744080067, 0.006157449912279844, 0.009150858037173748, 0.030714331194758415, 0.00048077013343572617, 0.01968347281217575, 0.008237560279667377, 0.014016804285347462, 0.028861412778496742, 0.03542644903063774, 0.01067239511758089, 0.026685303077101707, 0.00562801631167531, 0.002288506831973791, 0.013913649134337902, 0.009480925276875496, 0.003243127139285207, 0.04916224256157875, 0.07345618307590485, 0.034662988036870956, 0.02339516207575798, 0.00878501683473587, 0.11095530539751053, 0.04124153032898903, 0.09936905652284622, 0.013279338367283344, 0.0220046304166317, 0.052015360444784164, 0.042445361614227295, 0.06570831686258316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028888709843158722, 0.005126760806888342, 0.010702816769480705, 0.0005938410176895559, 0.008192192763090134, 0.0002102150028804317, 0.013891767710447311, 0.0029993702191859484, 0.005841439124196768, 0.005252213682979345, 0.01302978117018938, 0.0014735093573108315, 0.005802124738693237, 0.01374512817710638, 0.0004538778157439083, 0.0054039862006902695, 0.00019608660659287125, 0.0032535847276449203, 0.005095652304589748, 0.012714819982647896, 0.04998616501688957, 0.00014394133177120239, 0.008336809463799, 0.012639054097235203, 0.009590188041329384, 0.01411009393632412, 0.04148959740996361, 0.014007908292114735, 0.028896354138851166, 0.003941774368286133, 0.0003653395106084645, 0.01704026758670807, 0.005905676167458296, 0.0006147887324914336, 0.03414364531636238, 0.05973903462290764, 0.035543594509363174, 0.012880184687674046, 0.0019572351593524218, 0.1576778143644333, 0.03150399774312973, 0.11042619496583939, 0.004124731756746769, 0.018111681565642357, 0.051603373140096664, 0.02491568960249424, 0.07839247584342957, 0.029044467955827713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03503549471497536, 0.00580983143299818, 0.008590125478804111, 0.007725698873400688, 0.0016843776684254408, 0.007680732291191816, 0.008063090965151787, 0.002326195128262043, 0.0017428146675229073, 0.0019341509323567152, 0.003197707235813141, 0.005289826076477766, 0.0028452419210225344, 0.004509610589593649, 0.002348223701119423, 0.0027636003214865923, 0.003082466311752796, 0.0030022438149899244, 0.002456722082570195, 0.007764514070004225, 0.00801901239901781, 0.003984456416219473, 0.0903671607375145, 0.003051832551136613, 0.004655912518501282, 0.010295368731021881, 0.014550969004631042, 0.011817371472716331, 0.014613757841289043, 0.0028878520242869854, 0.007222498767077923, 0.013395383954048157, 0.0041473424062132835, 0.03187873959541321, 0.02971547096967697, 0.06859518587589264, 0.032894037663936615, 0.031290337443351746, 0.029090963304042816, 0.03003668785095215, 0.014290486462414265, 0.032255347818136215, 0.09171813726425171, 0.0450771227478981, 0.021602679044008255, 0.0842570886015892, 0.02664833702147007, 0.023609567433595657, 0.10017816722393036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03029448352754116, 0.005443480331450701, 0.006314102094620466, 0.029514752328395844, 0.0011709346435964108, 0.003841943573206663, 0.0030745987314730883, 0.002067217603325844, 0.00137308647390455, 0.0014042521361261606, 0.0011667311191558838, 0.00177109451033175, 0.0013138806680217385, 0.002146677579730749, 0.0032053347676992416, 0.001993561862036586, 0.02399582788348198, 0.0010738830314949155, 0.0008724906365387142, 0.004992084577679634, 0.004076321143656969, 0.0011735091684386134, 0.05614499747753143, 0.002081530401483178, 0.0033647408708930016, 0.006208236329257488, 0.0038435598835349083, 0.0024631929118186235, 0.004699711687862873, 0.002384716412052512, 0.053515560925006866, 0.009353725239634514, 0.003076103050261736, 0.01548014022409916, 0.015431100502610207, 0.03983988240361214, 0.006928701885044575, 0.01541981752961874, 0.06205747649073601, 0.01620999351143837, 0.0042169829830527306, 0.010718894191086292, 0.28039708733558655, 0.01479976437985897, 0.007759370841085911, 0.07044863700866699, 0.010259320959448814, 0.009674150496721268, 0.04335389286279678, 0.09758850187063217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03394996374845505, 0.005417141132056713, 0.015475431457161903, 0.006348930299282074, 0.0044412254355847836, 0.0020678823348134756, 0.008891446515917778, 0.002346697263419628, 0.0022263305727392435, 0.004340550396591425, 0.0050675272941589355, 0.005082206800580025, 0.003977904561907053, 0.0075739105232059956, 0.001314116409048438, 0.0054214103147387505, 0.00390886003151536, 0.004702362231910229, 0.0036010241601616144, 0.0107852378860116, 0.018633104860782623, 0.0007136759231798351, 0.07565117627382278, 0.006494955625385046, 0.010895909741520882, 0.01069963350892067, 0.017526280134916306, 0.010462536476552486, 0.015349539928138256, 0.004699793178588152, 0.0070471554063260555, 0.015464927069842815, 0.003674296895042062, 0.007444188464432955, 0.025847507640719414, 0.10296927392482758, 0.02445102483034134, 0.033936724066734314, 0.01714005321264267, 0.06104190647602081, 0.017510760575532913, 0.03770610690116882, 0.05571461468935013, 0.03876231610774994, 0.024869920685887337, 0.028407296165823936, 0.031199907884001732, 0.023122582584619522, 0.022998766973614693, 0.025650935247540474, 0.0869729295372963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.047291211783885956, 0.008274207822978497, 0.021363472566008568, 0.014780604280531406, 0.004609124269336462, 0.0052764154970645905, 0.008348509669303894, 0.0030837461818009615, 0.0030203701462596655, 0.00422256113961339, 0.0040283105336129665, 0.008173261769115925, 0.0023063374683260918, 0.005229059141129255, 0.0067515987902879715, 0.0032262199092656374, 0.02375931851565838, 0.0040647187270224094, 0.004650934599339962, 0.0061079696752130985, 0.013010653667151928, 0.0015420708805322647, 0.06406652182340622, 0.003975627478212118, 0.008175444789230824, 0.015232421457767487, 0.01038020197302103, 0.008061147294938564, 0.010467711836099625, 0.00670001283288002, 0.03779229149222374, 0.008238956332206726, 0.005243835970759392, 0.012079654261469841, 0.015957694500684738, 0.0651727169752121, 0.014047947712242603, 0.02869240753352642, 0.07205982506275177, 0.037420473992824554, 0.018571600317955017, 0.02727685682475567, 0.0652170181274414, 0.03191576898097992, 0.0212880689650774, 0.025115370750427246, 0.011304046027362347, 0.022064976394176483, 0.03143497183918953, 0.02109757997095585, 0.0835661068558693, 0.014262104406952858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05646491050720215, 0.01130295917391777, 0.016312848776578903, 0.0024630504194647074, 0.01083777379244566, 0.001594606670551002, 0.020799387246370316, 0.005444271024316549, 0.006739126984030008, 0.011961148120462894, 0.014485541731119156, 0.0032030714210122824, 0.002916015451774001, 0.011910811997950077, 0.0021055794786661863, 0.002158076735213399, 0.0019470772240310907, 0.002820502035319805, 0.008104934357106686, 0.006794771179556847, 0.04506644234061241, 0.0005198540166020393, 0.02738097310066223, 0.007050743792206049, 0.01999896951019764, 0.029130704700946808, 0.03258982673287392, 0.009208276867866516, 0.02246355265378952, 0.006197023205459118, 0.0027851283084601164, 0.007499217055737972, 0.007571012247353792, 0.0033742468804121017, 0.03430446237325668, 0.055413611233234406, 0.01720699481666088, 0.019833717495203018, 0.007847518660128117, 0.06705751270055771, 0.02633168362081051, 0.07400470227003098, 0.010239745490252972, 0.015005000866949558, 0.045514777302742004, 0.035711467266082764, 0.06597039848566055, 0.03038431704044342, 0.008922291919589043, 0.01495912205427885, 0.014714188873767853, 0.012097745202481747, 0.023278353735804558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04036412388086319, 0.016930818557739258, 0.013451937586069107, 0.0010264771990478039, 0.012485271319746971, 0.0004103225364815444, 0.012698284350335598, 0.0016614561900496483, 0.0034332498908042908, 0.007364434190094471, 0.006620059721171856, 0.0014861981617286801, 0.001941575901582837, 0.012110167182981968, 0.0009606796666048467, 0.00201500509865582, 0.0006437101401388645, 0.0013007728848606348, 0.0055831195786595345, 0.007544528692960739, 0.058837905526161194, 0.00028447265503928065, 0.01592916063964367, 0.005067544057965279, 0.014272994361817837, 0.0132526196539402, 0.020839637145400047, 0.007196300663053989, 0.022072896361351013, 0.007801966276019812, 0.001014264882542193, 0.0089061064645648, 0.003979377914220095, 0.0010681046405807137, 0.09934793412685394, 0.0676841139793396, 0.02875433675944805, 0.027761243283748627, 0.003832251997664571, 0.09635273367166519, 0.023782050237059593, 0.06144706904888153, 0.005946516525000334, 0.010851613245904446, 0.04454661160707474, 0.03513636440038681, 0.023043617606163025, 0.020950891077518463, 0.0031115664169192314, 0.00489141047000885, 0.008841174654662609, 0.014190460555255413, 0.02037881687283516, 0.06859365850687027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04857764020562172, 0.014300192706286907, 0.013591933995485306, 0.001347379176877439, 0.006815867032855749, 0.0007103529060259461, 0.016971025615930557, 0.0032221830915659666, 0.003704535309225321, 0.00468065869063139, 0.008326382376253605, 0.0039527080953121185, 0.005509055219590664, 0.011278202757239342, 0.0011294952128082514, 0.007569632958620787, 0.0018094211118295789, 0.005283782258629799, 0.0069938055239617825, 0.008787181228399277, 0.03988119214773178, 0.0007578068762086332, 0.02470260113477707, 0.011136692017316818, 0.009054102003574371, 0.015176314860582352, 0.022327862679958344, 0.013566583395004272, 0.02111673541367054, 0.005450439639389515, 0.0023902656976133585, 0.008919321931898594, 0.005044085904955864, 0.0016946063842624426, 0.04566472768783569, 0.06586682051420212, 0.026403259485960007, 0.022061044350266457, 0.0069688456133008, 0.07597295939922333, 0.024500001221895218, 0.05072455480694771, 0.008565276861190796, 0.027664033696055412, 0.037020545452833176, 0.017505303025245667, 0.020375031977891922, 0.03206901252269745, 0.005239342339336872, 0.012581522576510906, 0.0130019411444664, 0.047463610768318176, 0.018685469403862953, 0.04467612877488136, 0.04121052101254463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024064166471362114, 0.00644502229988575, 0.0153312087059021, 0.0011609923094511032, 0.008993502706289291, 0.00045448116725310683, 0.02094605565071106, 0.0029711280949413776, 0.005529843270778656, 0.007473922800272703, 0.012678723782300949, 0.0023749470710754395, 0.002091444795951247, 0.01231826189905405, 0.0016796835698187351, 0.0015879312995821238, 0.0009731391910463572, 0.0015783606795594096, 0.0044898223131895065, 0.004224242176860571, 0.07152090221643448, 0.00013565292465500534, 0.01729212887585163, 0.0051428028382360935, 0.014323774725198746, 0.020057106390595436, 0.03262738510966301, 0.009199212305247784, 0.02500421553850174, 0.005768439266830683, 0.0014404453104361892, 0.004543847404420376, 0.006417168769985437, 0.0010633461643010378, 0.031886741518974304, 0.061609406024217606, 0.01957252062857151, 0.017662132158875465, 0.005922697950154543, 0.06759587675333023, 0.026837622746825218, 0.08261217921972275, 0.006055162288248539, 0.012025194242596626, 0.040293652564287186, 0.039341654628515244, 0.03289181366562843, 0.0261090025305748, 0.0031879444140940905, 0.008306323550641537, 0.009522296488285065, 0.011970655992627144, 0.013884343206882477, 0.06737300008535385, 0.021968692541122437, 0.04146777465939522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03793920949101448, 0.004352450370788574, 0.017880471423268318, 0.0024856270756572485, 0.003957946784794331, 0.0010415799915790558, 0.007892830297350883, 0.0022551873698830605, 0.0027824086137115955, 0.004448732361197472, 0.005886462051421404, 0.0035957766231149435, 0.002664820058271289, 0.009103750810027122, 0.0015934751136228442, 0.0037079239264130592, 0.0036240722984075546, 0.0031814766116440296, 0.003526123706251383, 0.004276814870536327, 0.034127138555049896, 0.00030152752879075706, 0.05501614511013031, 0.005500937346369028, 0.009392403066158295, 0.009824472479522228, 0.017201410606503487, 0.008381298743188381, 0.014724444597959518, 0.005387655459344387, 0.0063232495449483395, 0.005702455528080463, 0.0027716748882085085, 0.003277891082689166, 0.01817215606570244, 0.1109570637345314, 0.01978975534439087, 0.024707697331905365, 0.014746276661753654, 0.05078081041574478, 0.0148537065833807, 0.040596358478069305, 0.0214688777923584, 0.021146688610315323, 0.02304711379110813, 0.017537659034132957, 0.019584348425269127, 0.019727664068341255, 0.010135659016668797, 0.009125560522079468, 0.034609708935022354, 0.03592294827103615, 0.014252652414143085, 0.04648570716381073, 0.03707236424088478, 0.046691685914993286, 0.044457659125328064, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06047686189413071, 0.0036923412699252367, 0.010418746620416641, 0.002537861466407776, 0.0036018206737935543, 0.0008067619055509567, 0.004353638272732496, 0.001358570996671915, 0.0019979930948466063, 0.003743701381608844, 0.004154013004153967, 0.0034071383997797966, 0.002908385591581464, 0.006670560222119093, 0.001220580074004829, 0.004117639269679785, 0.003266460495069623, 0.0033208185341209173, 0.0037082035560160875, 0.008912981487810612, 0.018984399735927582, 0.0007873806171119213, 0.04169754683971405, 0.006562171969562769, 0.008777037262916565, 0.010214719921350479, 0.014253039844334126, 0.009660414420068264, 0.013970051892101765, 0.005094876978546381, 0.005847285967320204, 0.01193119864910841, 0.0025391324888914824, 0.0028005382046103477, 0.013250977732241154, 0.06408665329217911, 0.013872569426894188, 0.02210685797035694, 0.011585871689021587, 0.07872297614812851, 0.014900180511176586, 0.03547295555472374, 0.021879738196730614, 0.021749038249254227, 0.02193848043680191, 0.015146699734032154, 0.025131745263934135, 0.01902972348034382, 0.009301402606070042, 0.01262179296463728, 0.03888596221804619, 0.031782716512680054, 0.012387968599796295, 0.0470336452126503, 0.04646671563386917, 0.036651190370321274, 0.03718668594956398, 0.06101259961724281, 0.0, 0.0, 0.0, 0.0], [0.03275315463542938, 0.003513692645356059, 0.011298991739749908, 0.0030332852620631456, 0.00315485754981637, 0.0012817379320040345, 0.0051485407166182995, 0.001789191155694425, 0.0023244076874107122, 0.004060092847794294, 0.00463189696893096, 0.003438011510297656, 0.0027832849882543087, 0.006372030358761549, 0.00185507838614285, 0.0036157516296952963, 0.005233354866504669, 0.0032915621995925903, 0.0035382481291890144, 0.00462124589830637, 0.019612900912761688, 0.0008119632839225233, 0.0426892526447773, 0.004561571404337883, 0.00884039606899023, 0.01015046052634716, 0.013439149595797062, 0.008075307123363018, 0.01189566683024168, 0.005088519304990768, 0.009554554708302021, 0.0068308692425489426, 0.0035636157263070345, 0.004456501919776201, 0.013920275494456291, 0.06128552556037903, 0.01444044429808855, 0.01944168470799923, 0.01639181189239025, 0.0417269691824913, 0.013475470244884491, 0.03170263394713402, 0.023360734805464745, 0.018599286675453186, 0.02057628706097603, 0.016924679279327393, 0.021243544295430183, 0.017763853073120117, 0.013201497495174408, 0.012603691779077053, 0.038986075669527054, 0.027560265734791756, 0.012995767407119274, 0.0464756079018116, 0.03982524946331978, 0.03369121253490448, 0.057089921087026596, 0.08959142863750458, 0.0398169681429863, 0.0, 0.0, 0.0], [0.037096332758665085, 0.00843838881701231, 0.017683178186416626, 0.0010022211354225874, 0.008025698363780975, 0.0003798249235842377, 0.010507389903068542, 0.0025048155803233385, 0.003737159539014101, 0.0061114514246582985, 0.009042068384587765, 0.001921844552271068, 0.002245392417535186, 0.010458657518029213, 0.0010467048268765211, 0.002470852807164192, 0.0010376208228990436, 0.0022002935875207186, 0.005015654489398003, 0.0046190982684493065, 0.0473925955593586, 0.0001370853278785944, 0.017391957342624664, 0.006386025343090296, 0.01051612664014101, 0.017328986898064613, 0.02324105240404606, 0.00724239693954587, 0.01819612644612789, 0.0054016271606087685, 0.0017892952309921384, 0.006704334169626236, 0.004745495971292257, 0.0010731251677498221, 0.031751908361911774, 0.06740784645080566, 0.014047011733055115, 0.0132596455514431, 0.004352640826255083, 0.06777462363243103, 0.019345004111528397, 0.05097682401537895, 0.004596048500388861, 0.011750818230211735, 0.035206761211156845, 0.017517944797873497, 0.030359679833054543, 0.019542932510375977, 0.002528188284486532, 0.006582220084965229, 0.007456083316355944, 0.015376860275864601, 0.016701925545930862, 0.06678836792707443, 0.026965927332639694, 0.06157790124416351, 0.017897116020321846, 0.05182133615016937, 0.007131440099328756, 0.028192080557346344, 0.0, 0.0], [0.03402165323495865, 0.003994432743638754, 0.003597519127652049, 0.008178464137017727, 0.0013001023326069117, 0.00659748213365674, 0.002190122613683343, 0.0010860213078558445, 0.0009010265930555761, 0.002135784365236759, 0.0008820760413073003, 0.004707245156168938, 0.0014032250037416816, 0.0023258603177964687, 0.0033111157827079296, 0.0015592643758282065, 0.013748412020504475, 0.0017028497532010078, 0.0021709289867430925, 0.004791975952684879, 0.0026292777620255947, 0.008843749761581421, 0.04299310967326164, 0.00181173300370574, 0.0042337095364928246, 0.004090884234756231, 0.0024672504514455795, 0.00373566010966897, 0.003163248300552368, 0.003065133234485984, 0.025932667776942253, 0.00793854147195816, 0.001527930609881878, 0.02211691066622734, 0.008579138666391373, 0.015982285141944885, 0.0059288544580340385, 0.020136700943112373, 0.03218061849474907, 0.012023404240608215, 0.0043684374541044235, 0.004992853384464979, 0.039044275879859924, 0.013053090311586857, 0.005525538697838783, 0.01050344668328762, 0.0037151535507291555, 0.00890464149415493, 0.04855213314294815, 0.00821737851947546, 0.07444131374359131, 0.008158771321177483, 0.003761514090001583, 0.009707423858344555, 0.030687017366290092, 0.012243865057826042, 0.1134171187877655, 0.10885819047689438, 0.11581719666719437, 0.014009775593876839, 0.03203461319208145, 0.0], [0.05661533772945404, 0.01935652643442154, 0.007937423884868622, 0.0038512051105499268, 0.002231677994132042, 0.001480979030020535, 0.009801513515412807, 0.0019505997188389301, 0.0012163707287982106, 0.0018028162885457277, 0.0022287152241915464, 0.004486355930566788, 0.0013350839726626873, 0.005958341993391514, 0.0018973775440827012, 0.0017378038028255105, 0.006054059602320194, 0.002584250643849373, 0.0024706453550606966, 0.0027539627626538277, 0.010901782661676407, 0.0016844545025378466, 0.0631944015622139, 0.0035421252250671387, 0.003294697729870677, 0.005356637295335531, 0.005997776053845882, 0.011280358768999577, 0.008515718393027782, 0.003415142884477973, 0.010256611742079258, 0.003933242987841368, 0.002084366511553526, 0.004557787906378508, 0.012573270127177238, 0.03245888277888298, 0.006648677866905928, 0.025209462270140648, 0.02288498543202877, 0.02632742188870907, 0.006680973339825869, 0.012160251848399639, 0.020569799467921257, 0.017439059913158417, 0.008853797800838947, 0.011809798888862133, 0.0058252145536243916, 0.01910136453807354, 0.010685143992304802, 0.01907370612025261, 0.03634697198867798, 0.013756628148257732, 0.006997040938585997, 0.02240797132253647, 0.03959980607032776, 0.037576157599687576, 0.09040006995201111, 0.11332596093416214, 0.05287797376513481, 0.020982615649700165, 0.020473627373576164, 0.011187287047505379]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7060514092445374, 0.29394859075546265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5568602681159973, 0.11883646249771118, 0.3243032991886139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3494352698326111, 0.09275238960981369, 0.3840203583240509, 0.17379198968410492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26286786794662476, 0.04025813564658165, 0.09161403030157089, 0.2180880308151245, 0.38717201352119446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2717580795288086, 0.023270029574632645, 0.007276351563632488, 0.2424030900001526, 0.010128086432814598, 0.4451643228530884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44180503487586975, 0.030268795788288116, 0.030624836683273315, 0.020553268492221832, 0.06320977210998535, 0.24826034903526306, 0.1652778685092926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06718789786100388, 0.004876494873315096, 0.003752616699784994, 0.004009188152849674, 0.021902643144130707, 0.02453290857374668, 0.0604182705283165, 0.8133199214935303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11202457547187805, 0.00271191680803895, 0.000607713358476758, 0.001375503372400999, 0.016590701416134834, 0.003863928373903036, 0.019140321761369705, 0.4532065689563751, 0.3904787600040436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15623217821121216, 0.00035548178129829466, 0.00028252453193999827, 0.0013615941861644387, 0.004993902985006571, 0.0008263859199360013, 0.008922027423977852, 0.07560283690690994, 0.28259211778640747, 0.46883097290992737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18052510917186737, 0.00022839047596789896, 6.16353572695516e-05, 9.781250992091373e-05, 0.0011448180302977562, 6.483597098849714e-05, 0.001337265595793724, 0.0055409884080290794, 0.04169183596968651, 0.42120587825775146, 0.34810134768486023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09753900021314621, 0.0018298315117135644, 0.0007843587663955986, 0.0011752719292417169, 0.001184041379019618, 0.0012156707234680653, 0.004638356156647205, 0.006600350607186556, 0.044952888041734695, 0.14479082822799683, 0.3715800344944, 0.3237094283103943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05210816115140915, 0.016035029664635658, 0.006040356121957302, 0.0013133527245372534, 0.00038884623791091144, 0.002325225155800581, 0.0012290807208046317, 0.003372841514647007, 0.0030791775789111853, 0.020976321771740913, 0.06631291657686234, 0.7280608415603638, 0.09875791519880295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18879763782024384, 0.020189832895994186, 0.011581922881305218, 0.0026738832239061594, 0.001193180214613676, 0.001024026656523347, 0.0007934237946756184, 0.005179741885513067, 0.009824174456298351, 0.05356142297387123, 0.12602639198303223, 0.16611118614673615, 0.1828572303056717, 0.23018594086170197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09571775048971176, 0.002239957684651017, 0.0008804369135759771, 0.0007044949452392757, 0.006009038537740707, 0.00028982575167901814, 0.003188865026459098, 0.0018573594279587269, 0.0055135018192231655, 0.003919323440641165, 0.029364805668592453, 0.04168647900223732, 0.13746199011802673, 0.6034212112426758, 0.06774504482746124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13390813767910004, 0.04627149924635887, 0.011575490236282349, 0.0016795617993921041, 0.0014541551936417818, 0.001770355855114758, 0.0002148203639080748, 0.0020810554269701242, 0.006531089544296265, 0.017591077834367752, 0.034241095185279846, 0.07332706451416016, 0.026629887521266937, 0.15333622694015503, 0.1771744340658188, 0.3122139871120453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11730636656284332, 0.008373511955142021, 0.00042488487088121474, 0.0009386222809553146, 0.0009801210835576057, 0.00019889924442395568, 0.0004543139657471329, 0.0002726182865444571, 0.004993128590285778, 0.005239319987595081, 0.011208182200789452, 0.01132955588400364, 0.0019624605774879456, 0.00582100311294198, 0.12020359188318253, 0.3700803220272064, 0.34021303057670593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29721570014953613, 0.06339292228221893, 0.00546085461974144, 0.0025661159306764603, 0.002549399621784687, 0.0014433700125664473, 0.00032442223164252937, 0.0016063872026279569, 0.007814766839146614, 0.014939934015274048, 0.024437282234430313, 0.010785653255879879, 0.0014172587543725967, 0.010970045812427998, 0.007198477163910866, 0.07397140562534332, 0.2775183618068695, 0.19638754427433014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11112640053033829, 0.007348851300776005, 0.0013165960554033518, 0.00036929233465343714, 0.0011843275278806686, 0.0012193808797746897, 0.0003732639888767153, 0.00046505004866048694, 0.001186786568723619, 0.003950317390263081, 0.008803189732134342, 0.00249738828279078, 0.0015908601926639676, 0.001429446041584015, 0.0019764553289860487, 0.009385812096297741, 0.13828866183757782, 0.18722890317440033, 0.5202590227127075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08141138404607773, 0.0028334553353488445, 0.004611964337527752, 0.0021039191633462906, 0.0013536346377804875, 0.0015595327131450176, 0.0006393940420821309, 0.0006377576501108706, 0.0005068559548817575, 0.0007972100283950567, 0.0011264636414125562, 0.0035652436781674623, 0.0009721684618853033, 0.0020574978552758694, 0.0002536573156248778, 0.003456676611676812, 0.027176275849342346, 0.09475917369127274, 0.4148736000061035, 0.3553042411804199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06984522193670273, 0.0002263905043946579, 0.00046528485836461186, 0.001496821641921997, 0.0012346099829301238, 0.00031680113170295954, 0.0012673762394115329, 0.00046089591342024505, 0.0013852620031684637, 0.0014962820569053292, 0.0007563072140328586, 0.0003362330317031592, 0.00019848991360049695, 0.0006275630439631641, 0.0004432667337823659, 0.0002728476538322866, 0.004854787606745958, 0.008989558555185795, 0.1648889034986496, 0.11141703277826309, 0.6290200352668762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18229298293590546, 0.006018379703164101, 0.0003673038736451417, 0.00022754752717446536, 0.00017374545859638602, 0.0015781603287905455, 0.0002464668359607458, 0.004615613725036383, 0.002502255607396364, 0.0007619420066475868, 0.00027144260820932686, 0.0009161249618045986, 0.0003947290242649615, 0.0005967994220554829, 0.0008105665328912437, 0.0005118033150210977, 0.00199941941536963, 0.006612217053771019, 0.00759384548291564, 0.038354530930519104, 0.22213581204414368, 0.5210182666778564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03881361335515976, 0.001808356144465506, 0.0003679190995171666, 0.00026760698528960347, 3.978631866630167e-05, 4.9860504077514634e-05, 5.4869997256901115e-05, 0.00026799211627803743, 0.0003549954853951931, 0.00039381830720230937, 0.00013048118853475899, 0.0002892390184570104, 0.0001785239583114162, 0.000653558352496475, 0.00219283951446414, 0.000897762191016227, 0.0008467438747175038, 0.001613218104466796, 0.0016524031525477767, 0.0036328816786408424, 0.02788401208817959, 0.04414947330951691, 0.873460054397583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09561034291982651, 0.0011372435837984085, 0.00014171079965308309, 8.195118425646797e-05, 0.0002118965785484761, 3.684062903630547e-05, 8.286107185995206e-05, 0.0005740149645134807, 0.0012024338357150555, 0.0029307599179446697, 0.00139884022064507, 0.00020737051090691239, 0.00014750150148756802, 0.00048045575385913253, 0.0012395791709423065, 0.0009749892051331699, 0.005042795557528734, 0.002991646761074662, 0.008021614514291286, 0.011241300031542778, 0.02696351893246174, 0.035037972033023834, 0.3760741651058197, 0.4281682074069977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10611224174499512, 0.0003538145683705807, 9.01016392163001e-05, 8.595993131166324e-05, 7.295721297850832e-05, 1.3702215255761985e-05, 5.503360807779245e-05, 0.00024325193953700364, 0.0003838021366391331, 0.0017283667111769319, 0.001132958335801959, 6.518484588013962e-05, 3.197146361344494e-05, 0.00010870178084587678, 6.867474439786747e-05, 0.00017439994553569704, 0.0005994149832986295, 0.0005637113354168832, 0.00711414311081171, 0.008270439691841602, 0.008904548361897469, 0.004757410380989313, 0.020865626633167267, 0.2538563013076782, 0.5843472480773926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09016624093055725, 9.4625647761859e-05, 4.540612644632347e-05, 1.9770082872128114e-05, 2.5953502699849196e-05, 3.4815361686924007e-06, 3.354397995281033e-05, 6.518384179798886e-05, 6.925522757228464e-05, 0.0005666185170412064, 0.0012675583129748702, 4.1972460167016834e-05, 5.140190478414297e-05, 3.510956230456941e-05, 1.1848273061332293e-05, 1.4977106729929801e-05, 8.018293010536581e-05, 9.736996435094625e-05, 0.0033202795311808586, 0.013316746801137924, 0.0036734023597091436, 0.0002639188023749739, 0.003914502914994955, 0.04258366674184799, 0.452743798494339, 0.3874932527542114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1493755578994751, 0.00017103752179536968, 5.651447645504959e-05, 1.662638533161953e-05, 1.3670219232153613e-05, 4.190815616311738e-06, 2.3227717974805273e-05, 5.2789637265959755e-05, 8.273663115687668e-05, 0.0006566541269421577, 0.0008096592500805855, 6.628765549976379e-05, 0.00015088195505086333, 0.0001360460591968149, 1.2162162420281675e-05, 3.6075012758374214e-05, 7.952447776915506e-05, 5.770953794126399e-05, 0.0018115186830982566, 0.00501713203266263, 0.004346689209342003, 0.00043905069469474256, 0.0016280058771371841, 0.013701047748327255, 0.22573736310005188, 0.22139082849025726, 0.3741269111633301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02978435531258583, 0.0018705357797443867, 0.0001603203418198973, 4.741836164612323e-05, 2.6191028155153617e-05, 1.9693699869094416e-05, 4.39434006693773e-05, 0.0001289766514673829, 0.0004919384373351932, 0.00037453765980899334, 0.0012489232467487454, 0.002866429276764393, 0.0009171772981062531, 0.0019944484811276197, 0.00035695440601557493, 0.0002765515528153628, 0.000864149013068527, 0.0006075503770262003, 0.0016945498064160347, 0.001165370806120336, 0.0038376417942345142, 0.0005110186757519841, 0.0106597188860178, 0.006882455665618181, 0.03267116844654083, 0.13338567316532135, 0.36697015166282654, 0.400142103433609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.040582895278930664, 9.418614354217425e-05, 2.451571708661504e-05, 1.353687639493728e-05, 8.73753015184775e-06, 8.704097126610577e-06, 1.589403473190032e-05, 0.00012638236512430012, 0.000208121127798222, 0.0005205294000916183, 0.0016510726418346167, 0.0037965725641697645, 0.003306066617369652, 0.001502742525190115, 0.001042265328578651, 0.0005569747881963849, 0.0016344661125913262, 0.000914950855076313, 0.0007299251738004386, 0.0006724174018017948, 0.001082457136362791, 0.0006297517102211714, 0.0020599947310984135, 0.0031072080601006746, 0.007677117362618446, 0.02237069234251976, 0.06243303790688515, 0.3023971915245056, 0.5408315658569336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0020033949986100197, 1.7484404452261515e-05, 5.401111593528185e-06, 4.1713792597875e-06, 1.3693315850105137e-06, 8.477051949284942e-08, 1.202113594445109e-06, 4.086697117600124e-06, 2.387670610914938e-05, 9.984651114791632e-05, 9.02672327356413e-05, 9.959582530427724e-05, 4.081943188793957e-05, 8.715006697457284e-05, 6.059221050236374e-05, 0.00012113455886719748, 8.459822129225358e-05, 8.149071800289676e-05, 0.00021468430350068957, 0.0003220083308406174, 0.00021254383318591863, 3.471771560725756e-05, 6.578226020792499e-05, 0.0002003888803301379, 0.0004521335940808058, 0.00042101426515728235, 0.0023343386128544807, 0.00724766543135047, 0.8549632430076599, 0.13070492446422577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02645709738135338, 0.00033484987216070294, 2.8383439712342806e-05, 8.931889169616625e-05, 3.070855382247828e-05, 4.484946202865103e-06, 4.6392327931243926e-05, 0.00015351026377175003, 0.0011896403739228845, 0.0003120852343272418, 0.0002983077138196677, 0.0006642444641329348, 0.00033185453503392637, 0.0007089332793839276, 0.002325356239452958, 0.0003549830580595881, 0.00032526213908568025, 0.0003535505384206772, 6.488532380899414e-05, 0.0008244540658779442, 0.0003503946354612708, 0.0004830338875763118, 0.0007436745218001306, 0.0016380114248022437, 0.00026162955327890813, 0.0003195345925632864, 0.0038171408232301474, 0.017136074602603912, 0.06460417062044144, 0.7334200143814087, 0.14232803881168365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.039291951805353165, 0.00012461526785045862, 0.00023448604042641819, 0.00031039895839057863, 0.0002456797519698739, 9.855697862803936e-05, 4.611653639585711e-05, 0.00018522344180382788, 0.0005758262705057859, 0.0007767855422571301, 0.000564891321118921, 0.0006879320135340095, 0.0004863100475631654, 0.0049221450462937355, 0.0012872342485934496, 0.0012399734696373343, 0.0009767476003617048, 0.00037518859608098865, 0.000325804459862411, 0.00043558471952565014, 0.0013281094143167138, 0.0010720877908170223, 0.0026164113078266382, 0.0015780400717630982, 0.00032738858135417104, 0.0010955194011330605, 0.0009608034160919487, 0.004022666718810797, 0.08616004139184952, 0.16133253276348114, 0.37032896280288696, 0.3159860074520111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08217168599367142, 0.0002366686676396057, 0.00021428977197501808, 0.0005729542463086545, 0.0017215539701282978, 0.00015826986054889858, 0.0004404091741889715, 0.0016087712720036507, 0.0021085881162434816, 0.004484943579882383, 0.0024641079362481833, 0.0002499144757166505, 0.0007700550486333668, 0.0008544388692826033, 0.002423160942271352, 0.0013088114792481065, 0.0006270171725191176, 0.0005595728871412575, 0.0003502753097563982, 0.00031366123585030437, 0.0009756817016750574, 0.0009095315472222865, 0.0014671726385131478, 0.003740729996934533, 0.002108523854985833, 0.000602671061642468, 0.0006696073687635362, 0.0007400096510536969, 0.012240772135555744, 0.02061884105205536, 0.03456791862845421, 0.23129981756210327, 0.5864195823669434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12645091116428375, 0.0019959916826337576, 0.00022225556313060224, 0.005478259176015854, 9.276041964767501e-05, 0.0043754493817687035, 0.00012801829143427312, 0.000652407412417233, 0.00040423840982839465, 0.0006188638508319855, 9.093539119930938e-05, 0.0006928699440322816, 0.0001220846315845847, 4.8877020162763074e-05, 0.0026856493204832077, 0.0024854165967553854, 0.0011594329262152314, 0.000632096198387444, 5.171774682821706e-05, 0.00012146933295298368, 0.00019429155508987606, 0.002874768106266856, 0.028651053085923195, 0.00206003081984818, 0.0005911855259910226, 0.00012024462193949148, 3.9979171560844406e-05, 0.0008838713401928544, 0.00014087706222198904, 0.0002986443287227303, 0.02266627363860607, 0.028756659477949142, 0.037808679044246674, 0.7264037728309631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.042258650064468384, 0.0021262995433062315, 0.00038966102874837816, 0.00022996887855697423, 0.00022831832757219672, 0.0004356694407761097, 0.00016343027527909726, 0.0002565737522672862, 0.0002655352291185409, 0.0006719147204421461, 0.00021760829258710146, 0.000125938662677072, 2.7875676096300595e-05, 3.225962427677587e-05, 4.989021545043215e-05, 0.0005422810791060328, 0.0002499375550542027, 0.00013145447883289307, 0.00013462305651046336, 6.549831596203148e-05, 7.845816435292363e-05, 0.0001621015544515103, 0.002688450738787651, 0.0016215157229453325, 0.0021613705903291702, 0.0004422728670760989, 0.0002612711687106639, 0.0002538088883738965, 0.0003091911494266242, 0.00023662620515096933, 0.0026808162219822407, 0.006283702794462442, 0.0184622909873724, 0.07791361957788467, 0.8378410339355469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14211824536323547, 0.00029842331423424184, 0.0011533405631780624, 0.0032931938767433167, 0.0009954163106158376, 0.0011405637487769127, 0.002505788579583168, 0.0006615641759708524, 0.00022157806961331517, 0.0007891870336607099, 0.0006658093188889325, 0.0006918648141436279, 7.18798692105338e-05, 3.0517698178300634e-05, 4.70927006972488e-05, 0.00013226910959929228, 0.000245094794081524, 0.00018593331333249807, 0.00030307366978377104, 0.00015237329353112727, 0.00019806819909717888, 0.0001865706144599244, 0.001125072012655437, 0.0017891846364364028, 0.005616277456283569, 0.0057932110503315926, 0.001355171436443925, 0.0015411458443850279, 0.0005350111168809235, 0.00021103984909132123, 0.00143837567884475, 0.0036768026184290648, 0.015261361375451088, 0.052598949521780014, 0.19356653094291687, 0.5594040155410767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04451800882816315, 0.0003117109299637377, 4.777963113156147e-05, 3.1448165827896446e-05, 4.1022325603989884e-05, 0.00013368741201702505, 0.00010982238018186763, 0.000261342414887622, 0.000161938980454579, 0.00018559949239715934, 8.115962555166334e-05, 0.00010836996079888195, 2.433440022286959e-05, 8.473738489556126e-06, 6.166063485579798e-06, 4.151712346356362e-05, 2.0041918105562218e-05, 1.274706119147595e-05, 1.3063855476502795e-05, 1.6767429769970477e-05, 1.4862120224279352e-05, 2.284094261995051e-05, 9.192732977680862e-05, 0.0002125793107552454, 0.0005133924423716962, 0.0004791380779352039, 0.000680345285218209, 0.0008412760798819363, 0.0006609009578824043, 0.00018678547348827124, 0.0007461905479431152, 0.0005757563631050289, 0.0010988591238856316, 0.005397510249167681, 0.19237227737903595, 0.08306366205215454, 0.6669067144393921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009475772269070148, 4.035079837194644e-05, 4.892148353974335e-06, 1.4054502571525518e-05, 1.4039458619663492e-05, 1.715165672067087e-05, 2.8606425985344686e-05, 0.00011205188638996333, 0.00030399023671634495, 0.00026545088621787727, 0.00011297208402538672, 3.665041003841907e-05, 9.195770871883724e-06, 2.0704044800368138e-05, 8.518586582795251e-06, 8.63763034431031e-06, 9.220948413712904e-06, 2.0234360817994457e-06, 2.142374114555423e-06, 6.1192231441964395e-06, 2.1628031390719116e-05, 6.4734335865068715e-06, 8.563634764868766e-05, 0.000138303468702361, 0.00033104742760770023, 0.00021931373339612037, 0.0007657477399334311, 0.000552390469238162, 0.000236762294662185, 0.0004260762070771307, 0.000946706859394908, 0.0012363676214590669, 0.000768160680308938, 0.001122688059695065, 0.04905454441905022, 0.020145421847701073, 0.7852935194969177, 0.12815673649311066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.039600443094968796, 4.5099412091076374e-05, 8.120887287077494e-06, 1.3864920219930355e-05, 4.710884240921587e-05, 4.952308881911449e-05, 7.937628834042698e-05, 6.917468999745324e-05, 0.0007486343965865672, 0.0005242323968559504, 0.0006138227763585746, 0.00017298497550655156, 1.2390139090712182e-05, 0.00020437677449081093, 0.0001625038858037442, 0.00037769199116155505, 0.00016008080274332315, 2.6229574359604158e-05, 2.661636972334236e-05, 6.534361318699666e-07, 4.518991045188159e-05, 4.121407982893288e-06, 0.0001890996500151232, 0.00016676404629833996, 0.0002394025505054742, 0.0003048276121262461, 0.0010657473467290401, 0.0011064414866268635, 0.013511945493519306, 0.0010971016017720103, 0.0027465964667499065, 0.00034877806319855154, 0.0008246562210842967, 0.002867092378437519, 0.014011594466865063, 0.01659870520234108, 0.14609777927398682, 0.3284962773323059, 0.42733490467071533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04817367345094681, 5.2545474318321794e-06, 3.7375807551143225e-06, 5.982544735161355e-06, 7.768914656480774e-05, 1.5847079339437187e-05, 7.821696635801345e-05, 0.0001240926794707775, 0.0006689400179311633, 0.003689405508339405, 0.010744008235633373, 0.00014895040658302605, 4.787759098690003e-05, 0.00023720630269963294, 4.5757322368444875e-05, 5.603620957117528e-05, 0.0001436338061466813, 2.0455550838960335e-05, 5.62021232326515e-05, 4.577796789817512e-05, 8.991708455141634e-05, 9.71857753029326e-06, 5.6376371503574774e-05, 0.0008566266042180359, 0.0022376691922545433, 0.0018023920711129904, 0.003073727712035179, 0.0003894865803886205, 0.003470989177003503, 0.0012476603733375669, 0.0003220834769308567, 0.005016050301492214, 0.003660104237496853, 0.0003862879239022732, 0.002255957340821624, 0.005654900800436735, 0.021725807338953018, 0.013925263658165932, 0.04690593108534813, 0.82252436876297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011807096190750599, 1.2116430298192427e-05, 1.196733933284122e-06, 8.409417660004692e-07, 9.92441982816672e-06, 6.978454166528536e-06, 2.4422046408290043e-05, 3.670829755719751e-05, 0.0001397807354805991, 0.0008136944961734116, 0.002117237774655223, 0.00043248795554973185, 0.0001077534761861898, 6.207230762811378e-05, 8.033457561396062e-05, 0.0001795888674678281, 0.00040258027729578316, 0.00016561741358600557, 9.863151353783906e-05, 2.8601099984371103e-05, 2.4691269572940655e-05, 1.3777641470369417e-05, 9.848525223787874e-05, 0.000763605406973511, 0.0017582623986527324, 0.0008496115915477276, 0.0018449625931680202, 0.00099264457821846, 0.0029820334166288376, 0.0011388456914573908, 0.0005450836615636945, 0.0005060300463810563, 0.00033046334283426404, 0.0002101253194268793, 0.0026818688493222, 0.0014670630916953087, 0.013755575753748417, 0.009221765212714672, 0.057290446013212204, 0.32968053221702576, 0.5573164820671082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029644062742590904, 3.701257810462266e-06, 1.7627282886678586e-06, 2.313364348083269e-06, 1.2107483598811086e-05, 5.265788331598742e-06, 3.126671799691394e-05, 7.821634790161625e-05, 0.00011743837967514992, 0.0009015934192575514, 0.0012323121773079038, 5.832496754010208e-05, 0.00011288812675047666, 4.637808524421416e-05, 1.3230793229013216e-05, 7.724552233412396e-06, 5.018316733185202e-05, 1.6178428268176503e-05, 0.000156038673594594, 0.00019712329958565533, 0.0001822153863031417, 1.5573710697935894e-05, 1.436498587281676e-05, 0.00020694884005934, 0.0015523398760706186, 0.0014556623063981533, 0.005063936114311218, 0.0003517999139148742, 0.004892253316938877, 0.002474250504747033, 0.00017733358254190534, 0.0004867239622399211, 0.0004756508569698781, 3.2193092920351774e-05, 0.0003613460576161742, 0.0006694510811939836, 0.003338207956403494, 0.0018643824150785804, 0.004746215883642435, 0.11221614480018616, 0.1756407916545868, 0.6510941386222839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008098180405795574, 3.048560756724328e-06, 5.618487648462178e-06, 3.6251753954275046e-06, 1.6783147657406516e-05, 1.2779749340552371e-05, 6.683114042971283e-05, 5.476360456668772e-05, 0.00012129008973715827, 0.00011381258809706196, 0.00015978595183696598, 5.7175431720679626e-05, 0.00011625552724581212, 0.00011113860091427341, 5.818482350150589e-06, 1.6205900465138257e-05, 2.8302998543949798e-05, 1.950445403053891e-05, 6.265757838264108e-05, 2.6628073101164773e-05, 0.0003749913885258138, 3.401568756089546e-05, 2.2576246919925325e-05, 6.114340067142621e-05, 8.883458940545097e-05, 0.0007803712505847216, 0.0018331138417124748, 0.0006157308234833181, 0.005021338351070881, 0.00528816320002079, 0.0011041408870369196, 8.247304504038766e-05, 0.0001099466098821722, 0.00010407390800537542, 0.00010132398165296763, 0.001976720755919814, 0.0021824161522090435, 0.0016510412096977234, 0.010802358388900757, 0.027708522975444794, 0.083859384059906, 0.7202922105789185, 0.12680493295192719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0035360960755497217, 2.2898948373040184e-05, 2.612585376482457e-06, 6.0129905250505544e-06, 1.660342786635738e-05, 1.8142376575269736e-05, 3.6770750739378855e-05, 0.0001611110637895763, 0.0005687675438821316, 0.00018088085926137865, 8.786413673078641e-05, 8.597229316364974e-05, 3.0437806344707496e-05, 8.816849731374532e-05, 4.742600503959693e-05, 7.811724572093226e-06, 4.6227687562350184e-05, 2.1987476429785602e-05, 7.438004831783473e-05, 8.287768287118524e-05, 0.000533372163772583, 5.168562711332925e-05, 0.00012473990500438958, 6.357343954732642e-05, 3.608523911680095e-05, 0.00013374816626310349, 0.0004797322617378086, 0.0019008931703865528, 0.0020108544267714024, 0.005502793937921524, 0.003946022596210241, 0.0008466719300486147, 0.00017557341197971255, 0.00013709095946978778, 0.0021004341542720795, 0.0006300130626186728, 0.026843948289752007, 0.005077275447547436, 0.005298754666000605, 0.008473455905914307, 0.03733159601688385, 0.21712099015712738, 0.20989365875720978, 0.4661639332771301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006265232805162668, 3.2145205750566674e-06, 2.111175945174182e-06, 3.2301934425049694e-06, 1.8588338207337074e-05, 6.686334472760791e-06, 2.3546404918306507e-05, 9.063626930583268e-05, 0.00023101791157387197, 0.0003646270779427141, 0.0001232266367878765, 1.986780989682302e-05, 1.600960604264401e-05, 4.621325570042245e-05, 8.046025322983041e-05, 4.100204478163505e-06, 4.794870619662106e-05, 1.8952319805976003e-05, 0.0001189828835777007, 0.0003244492691010237, 0.0009691606974229217, 0.0002927849709521979, 0.0004838518798351288, 0.00020287664665374905, 7.23504854249768e-05, 0.0002204371412517503, 0.0003238310164306313, 0.0003557008458301425, 0.002468318911269307, 0.004430559463799, 0.00563944922760129, 0.007183312904089689, 0.0013864010106772184, 0.0002293823636136949, 0.00038898689672350883, 0.0006166808307170868, 0.002270534634590149, 0.0010802069446071982, 0.009437124244868755, 0.010068017058074474, 0.04885870963335037, 0.06723107397556305, 0.08673753589391708, 0.2427937388420105, 0.4984498620033264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0031521725468337536, 2.4273331291624345e-05, 1.739768293873567e-07, 4.268599695933517e-06, 9.831449006014736e-07, 6.338726234389469e-05, 4.795207587449113e-06, 0.0002195865527028218, 7.554233161499724e-05, 0.00010212380584562197, 1.6687383322278038e-05, 8.942584099713713e-05, 0.00012280150258447975, 1.5336871683757636e-06, 0.000529107463080436, 7.369084778474644e-05, 0.0002232914266642183, 0.00011488024756545201, 2.405471832389594e-06, 2.646676693984773e-05, 2.3530423277406953e-05, 0.0002509568294044584, 0.005532561801373959, 0.00020573826623149216, 3.687113712658174e-05, 7.918984010757413e-06, 3.7988168060110183e-06, 0.0012510298984125257, 2.331508949282579e-05, 7.84390140324831e-05, 0.00797369983047247, 0.0019328584894537926, 0.00022519429330714047, 0.006765416357666254, 0.0034330026246607304, 5.867677100468427e-05, 0.00431373855099082, 0.009453076869249344, 0.02048281393945217, 0.00226368336006999, 0.0014906289288774133, 0.0007741922163404524, 0.024046866223216057, 0.5700767040252686, 0.026310663670301437, 0.30813705921173096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00387991638854146, 5.616849648504285e-06, 1.027483904181281e-06, 4.2617745066309e-07, 3.078287591051776e-06, 3.092095766987768e-06, 7.1718209255777765e-06, 5.976349348202348e-05, 6.0738737374776974e-05, 0.00018110856763087213, 3.4476222936064005e-05, 4.7821481530263554e-06, 3.3486048778286204e-06, 5.049684205005178e-06, 1.0038138498202898e-05, 1.3003815183765255e-05, 6.076846693758853e-05, 3.449467112659477e-05, 4.146737410337664e-05, 5.909280662308447e-05, 0.0001789398811524734, 0.0005945489974692464, 0.0007240033010020852, 0.0009471644880250096, 0.000416758528444916, 0.0001161068503279239, 6.348038732539862e-05, 4.242294016876258e-05, 0.0001138153238571249, 0.00023395988682750612, 0.00038822868373245, 0.0007392002735286951, 0.001405447139404714, 0.0004610932373907417, 0.0016605397686362267, 0.0004496463807299733, 0.000878670543897897, 0.00040423101745545864, 0.000991369248367846, 0.0028355258982628584, 0.001723055960610509, 0.002149164443835616, 0.0014286066871136427, 0.00964544527232647, 0.0723324790596962, 0.04643551632761955, 0.848172128200531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011063618585467339, 1.1812738193839323e-05, 1.389243720950617e-06, 3.3378578336851206e-06, 1.1838361388072371e-05, 4.127423380850814e-06, 9.012079317471944e-06, 2.3381127903121524e-05, 6.617192411795259e-05, 0.0005068524042144418, 0.0002026865113293752, 1.0603462214930914e-05, 1.564956733091094e-06, 2.7343689907866064e-06, 2.621535531943664e-05, 2.0861751181655563e-05, 0.000282212917227298, 8.822027302812785e-05, 0.000484574498841539, 0.0019993723835796118, 0.0009909587679430842, 0.0001990978344110772, 0.0053190188482403755, 0.015268550254404545, 0.009048879146575928, 0.0018730134470388293, 0.000606916262768209, 0.00010424631182104349, 0.00011447033466538414, 0.00020446839334908873, 0.00017091036716010422, 0.005776372738182545, 0.0016773835523054004, 0.00046277244109660387, 0.005212459713220596, 0.0013099281350150704, 0.001804729225113988, 0.0007255853270180523, 0.006029900163412094, 0.025241509079933167, 0.03396935388445854, 0.004850884433835745, 0.006428486667573452, 0.004531709477305412, 0.08287140727043152, 0.10302267223596573, 0.1196887195110321, 0.5476750135421753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012802192941308022, 5.3025367378722876e-05, 1.5984047649908462e-06, 8.571164471504744e-06, 3.246284734359506e-07, 4.068341513630003e-05, 3.92238416679902e-06, 1.3363586731429677e-05, 9.7971878858516e-06, 2.756119101832155e-05, 1.003455417958321e-05, 7.212570199044421e-05, 5.954116659268038e-06, 8.022136626095744e-07, 3.4053005947498605e-05, 0.00011785729293478653, 0.00025082306819967926, 0.0006398691330105066, 5.683693598257378e-05, 0.0001393601851304993, 0.00012011123908450827, 0.0009180600754916668, 0.009636830538511276, 0.0018746900605037808, 0.0018482853192836046, 0.00032190445926971734, 4.550993617158383e-05, 0.00040323377470485866, 1.7418004063074477e-05, 6.5802437347883824e-06, 6.0897164075868204e-05, 2.9005723263253458e-05, 2.7323036192683503e-05, 0.0016264088917523623, 0.0011539930710569024, 0.00022573969908989966, 0.0005071672494523227, 0.0008410720038227737, 0.0006727267173118889, 0.0013593652984127402, 0.0015783071285113692, 0.00045369318104349077, 0.007548742461949587, 0.00267366087064147, 0.0004495318862609565, 0.17670977115631104, 0.019541800022125244, 0.037322260439395905, 0.717737078666687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0026037185452878475, 2.490591759851668e-05, 4.815868805962964e-07, 3.8491452869493514e-06, 9.985988924654521e-08, 5.580323704634793e-05, 2.0309548744990025e-06, 1.625545701244846e-05, 1.4349748198583256e-06, 3.555202283678227e-06, 1.1477313819341362e-06, 4.359089507488534e-05, 9.246388799510896e-06, 4.3135113259040736e-08, 4.7912117224768735e-06, 9.111365216085687e-06, 9.299506200477481e-05, 0.0002779779606498778, 2.0794515876332298e-05, 0.00024846382439136505, 2.5908824682119302e-05, 0.000236189691349864, 0.0028043417260050774, 0.00017433099856134504, 0.000314074830384925, 0.00010403992200735956, 1.1536863894434646e-05, 0.0008607993368059397, 3.5516509342414793e-06, 3.2657555948389927e-06, 6.218565977178514e-05, 8.977637662610505e-06, 1.3185008356231265e-06, 0.0005664210766553879, 0.0008176837000064552, 5.421943569672294e-05, 0.0004537790082395077, 0.00027210061671212316, 0.0005039751413278282, 0.00022478133905678988, 0.0007103264797478914, 0.00020767196838278323, 0.003377244109287858, 0.004386525601148605, 4.9785598093876615e-05, 0.00245304754935205, 0.0017008950235322118, 0.0024417347740381956, 0.7469385862350464, 0.22681045532226562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008415658958256245, 1.1710985745594371e-05, 7.537270903412718e-06, 2.5385688786627725e-06, 7.489564723073272e-06, 8.888388038030826e-06, 3.6467281461227685e-05, 3.197627665940672e-05, 3.832121365121566e-05, 2.0448391296667978e-05, 8.858491128194146e-06, 3.035427880604402e-06, 5.377216439228505e-06, 5.988207249174593e-06, 3.2212017231358914e-07, 2.4034504804149037e-06, 7.765124792058486e-06, 1.3927819054515567e-05, 0.00021812572958879173, 0.0001531895832158625, 0.003134914906695485, 0.0002892315969802439, 0.00023727484222035855, 0.000882292864844203, 0.001084298943169415, 0.005637209862470627, 0.0027317057829350233, 0.00013906271487940103, 0.00021759801893495023, 0.00026387907564640045, 5.052364576840773e-05, 5.874613634659909e-06, 3.463043685769662e-05, 9.6371048130095e-05, 0.00016353029059246182, 0.0014574822271242738, 0.0005092124338261783, 9.923939796863124e-05, 0.00031886858050711453, 0.0006286951247602701, 0.001868654042482376, 0.017055822536349297, 0.004208820406347513, 0.0018677276093512774, 0.011383714154362679, 0.0036936721298843622, 0.025577817112207413, 0.036964595317840576, 0.06876108050346375, 0.6431007981300354, 0.15853531658649445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005191487725824118, 5.091028651804663e-05, 1.635988155612722e-05, 1.8278243487657164e-06, 3.4705667530943174e-06, 7.137417014746461e-06, 1.6449055692646652e-05, 8.414092008024454e-05, 4.2559295252431184e-05, 2.5684988941065967e-05, 1.6035315638873726e-05, 4.348404036136344e-05, 7.446255040122196e-06, 1.2244481695233844e-05, 7.031414043012774e-06, 2.1548744371102657e-06, 1.3399412637227215e-05, 3.553175338311121e-05, 0.0001343998301308602, 0.00014332475257106125, 0.0013915132731199265, 0.0010482869111001492, 0.0036074251402169466, 0.0007711344514973462, 0.0008339526248164475, 0.007824035361409187, 0.0027836172375828028, 0.0036704628728330135, 0.0014963879948481917, 0.0008697551093064249, 0.00045803948887623847, 6.780788680771366e-05, 8.818010974209756e-05, 0.0003720568784046918, 0.0013502594083547592, 0.004365046974271536, 0.004709157627075911, 0.0008964950684458017, 0.004338295664638281, 0.0012060945155099034, 0.004979732912033796, 0.006822988856583834, 0.0050309752114117146, 0.030161811038851738, 0.01510912086814642, 0.026147594675421715, 0.03217347338795662, 0.0407102145254612, 0.06317467987537384, 0.1913256198167801, 0.26326173543930054, 0.2730989456176758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002217524219304323, 7.081511284923181e-06, 2.1802077299071243e-06, 9.510933978162939e-07, 6.091532895879936e-07, 2.9600940365526185e-07, 4.038066379052907e-07, 3.899025614373386e-06, 3.3843932669697097e-06, 6.4212922552542295e-06, 4.631735464499798e-06, 2.7772621251642704e-06, 5.030300144426292e-06, 1.320325827691704e-05, 1.5627114407834597e-05, 1.724133653624449e-06, 8.465991413686424e-06, 5.401899670687271e-06, 3.952052429667674e-05, 8.569957572035491e-05, 0.00033042763243429363, 0.0002945573360193521, 0.002111326204612851, 0.0005187530186958611, 0.00098795082885772, 0.0025721131823956966, 0.002535034203901887, 0.0007902536890469491, 0.00041564524872228503, 0.00029639515560120344, 0.00024498175480403006, 0.0001818262826418504, 7.20272510079667e-05, 7.934180757729337e-05, 0.00019158092618454248, 0.0006561800255440176, 0.0010022148489952087, 0.0005496059311553836, 0.001183738000690937, 0.0015173990977928042, 0.002347236964851618, 0.0037369171623140574, 0.004203211981803179, 0.00223266682587564, 0.00393719831481576, 0.004930868744850159, 0.006734249647706747, 0.007500371430069208, 0.009899215772747993, 0.02443559095263481, 0.20754696428775787, 0.20430219173431396, 0.49923714995384216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00655325036495924, 3.1505044262303272e-06, 7.684348588554712e-07, 2.777931626951613e-07, 5.603217800853599e-07, 1.0330583499751356e-08, 7.226109488556176e-08, 3.862514290631225e-07, 1.40961094530212e-06, 6.0643706092378125e-06, 5.679567948391195e-06, 1.358497456749319e-07, 3.819352059508674e-06, 2.3579686967423186e-05, 3.8319499253702816e-06, 1.8011137399298605e-06, 1.7507626353108208e-06, 7.173551352934737e-07, 9.978661182685755e-06, 3.282231045886874e-05, 0.00014379697677213699, 2.3649410650250502e-05, 9.481178858550265e-05, 0.00012527072976808995, 0.00049615278840065, 0.00039352511521428823, 0.0025868096854537725, 6.982294144108891e-05, 0.0007743631722405553, 0.0004192450433038175, 0.0001164477871498093, 0.0006295990315265954, 0.00038659884012304246, 5.729476470150985e-06, 6.447191844927147e-05, 8.028857700992376e-05, 0.0005278523312881589, 0.00017538493557367474, 8.584242459619418e-05, 0.0009663288365118206, 0.0005649677477777004, 0.004304461646825075, 0.00035449786810204387, 0.00017438241047784686, 0.0033780131489038467, 0.00028964856755919755, 0.0033255007583647966, 0.0013844186905771494, 8.065495057962835e-05, 0.0005096305394545197, 0.004466214682906866, 0.04735145345330238, 0.21010634303092957, 0.7088937163352966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007550876471213996, 0.0002637490979395807, 1.0280831702402793e-05, 5.550870810111519e-06, 4.084528882231098e-06, 9.504719287178887e-07, 2.7350003506398934e-07, 1.1131446626677644e-06, 8.044185051403474e-06, 6.016042789269704e-06, 7.673596883250866e-06, 1.3944591955805663e-05, 1.0625911272654776e-05, 0.00015121439355425537, 0.00022967875702306628, 0.00017356335592921823, 0.0002518109977245331, 0.00012143941421527416, 0.00014179156278260052, 3.340313196531497e-05, 0.00014284612552728504, 7.618415838805959e-05, 0.002557493979111314, 0.0009355173096992075, 0.0005581169971264899, 0.00026490690652281046, 0.000712814973667264, 0.001101211877539754, 0.00044704409083351493, 0.0004544904222711921, 0.0012999437749385834, 0.0009126007207669318, 0.00026358728064224124, 0.0003616172180045396, 0.002841700566932559, 0.00017402329831384122, 0.0026383602526038885, 0.0010899477638304234, 0.0004540937370620668, 0.0006341779371723533, 0.00047407945385202765, 0.0006603815127164125, 0.00042871315963566303, 0.001766122062690556, 0.002916801255196333, 0.006103700026869774, 0.0033875650260597467, 0.002829347737133503, 0.0012876508990302682, 0.002913223346695304, 0.004292292520403862, 0.0178835391998291, 0.06264214217662811, 0.42977824807167053, 0.442525178194046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01441780012100935, 0.00012498510477598757, 5.156614861334674e-05, 4.4051583245163783e-05, 4.49960571131669e-05, 8.502796845277771e-06, 2.2934564185561612e-06, 1.6194570662264596e-06, 8.422655810136348e-06, 6.631878932239488e-05, 0.00020771568233612925, 9.079468327399809e-06, 2.599784784251824e-05, 0.00021765800192952156, 0.00026923971017822623, 0.00016018275346141309, 0.0006189162377268076, 0.00016502653306815773, 0.001488525071181357, 0.0010068719275295734, 0.0010882728965952992, 0.00024643438518978655, 0.0067559583112597466, 0.005294747184962034, 0.011882192455232143, 0.003398807253688574, 0.004283980932086706, 0.00015191599959507585, 0.0006807237514294684, 0.00033491943031549454, 0.0005465238355100155, 0.009843491017818451, 0.004749293904751539, 0.0027208200190216303, 0.0010104088578373194, 0.0004287150513846427, 0.00031451202812604606, 0.00019550698925741017, 0.0005166580667719245, 0.003244689665734768, 0.003230402013286948, 0.0014170646900311112, 0.0003026958438567817, 0.00010482590005267411, 0.0020103571005165577, 0.0022175745107233524, 0.002504288451746106, 0.024048667401075363, 0.0060144891031086445, 0.0014383400557562709, 0.004311573226004839, 0.028113849461078644, 0.04433559998869896, 0.4627463221549988, 0.09998973459005356, 0.24058577418327332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028272604569792747, 0.003278163494542241, 0.0006203416851349175, 0.0018169968388974667, 0.0001750054507283494, 1.0119892067450564e-05, 8.247430741903372e-06, 5.038505605625687e-06, 1.3790484445053153e-05, 5.135640094522387e-05, 6.947619112906978e-05, 7.76570086600259e-05, 2.3439486540155485e-05, 0.0001266050385311246, 0.00018275271577294916, 0.0014467135770246387, 0.0014888363657519221, 0.001710920361801982, 0.0034823112655431032, 0.0005228351219557226, 0.0002993597590830177, 6.770458276150748e-05, 0.004702521488070488, 0.001792023191228509, 0.021999351680278778, 0.006920107640326023, 0.005987378302961588, 0.00046606562682427466, 0.00045810843585059047, 0.0005413137259893119, 0.0005990670179016888, 0.0008704030769877136, 0.0009355621878057718, 0.0006685842527076602, 0.004610606003552675, 0.0008761344361118972, 0.0010619189124554396, 0.0006099064485169947, 0.00019143664394505322, 0.0006308604497462511, 0.0003489891532808542, 0.00073050003265962, 0.0007205661968328059, 8.608833741163835e-05, 0.0003627656842581928, 0.0011512122582644224, 0.0020101044792681932, 0.007874228060245514, 0.0017138624098151922, 0.008329224772751331, 0.008279605768620968, 0.010415222495794296, 0.01578935608267784, 0.17984336614608765, 0.10051330924034119, 0.13098321855068207, 0.43317675590515137, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003409772412851453, 0.00035474609467200935, 0.0005085223820060492, 9.619740740163252e-05, 0.00011334046575939283, 5.00014575663954e-05, 1.5795281797181815e-05, 7.5978869062964804e-06, 2.552369551267475e-06, 2.3049240098771406e-06, 4.750819698529085e-06, 2.5876492145471275e-05, 1.1592765076784417e-05, 1.4381027540366631e-05, 2.5244688004022464e-05, 7.003217615419999e-05, 5.430356031865813e-05, 0.0003118422464467585, 0.00044329030788503587, 0.00015235127648338675, 7.88302713772282e-05, 5.5035867262631655e-05, 0.0003943512274418026, 0.0008168405038304627, 0.0007924738456495106, 0.002014340367168188, 0.00027230221894569695, 0.00013380929885897785, 8.145604078890756e-05, 1.642353890929371e-05, 3.358447065693326e-05, 8.545658783987164e-05, 0.0004846635856665671, 0.0022802292369306087, 0.001846508588641882, 0.003754020668566227, 0.000330273003783077, 0.00016863089695107192, 7.714214007137343e-05, 0.00017042236868292093, 0.00018760142847895622, 3.63495055353269e-05, 1.9376440832274966e-05, 4.0594568417873234e-05, 7.669321348657832e-05, 0.0007584562990814447, 0.0006151595152914524, 0.001978857209905982, 0.003956574946641922, 0.008021341636776924, 0.0006537251174449921, 0.0013868322130292654, 0.002113601891323924, 0.0040145739912986755, 0.025609388947486877, 0.17203998565673828, 0.2920056879520416, 0.46692395210266113, 0.0, 0.0, 0.0, 0.0], [0.0037174858152866364, 0.00037233027978800237, 4.819862806471065e-05, 8.964340668171644e-05, 1.987499672395643e-05, 4.248383447702508e-06, 1.561511271575e-05, 6.071349616831867e-06, 9.336853509012144e-06, 1.7289867173531093e-06, 1.556406459712889e-06, 4.602086846716702e-06, 6.460431336563488e-07, 6.015395115355204e-07, 3.70383486369974e-06, 1.3890513400838245e-05, 1.7472242689109407e-05, 7.304922473849729e-05, 4.3160125642316416e-05, 0.00030892324866726995, 3.065924101974815e-05, 1.4084494978305884e-05, 0.00010437874152557924, 0.0013394032139331102, 0.001225415151566267, 0.0003889241488650441, 0.0008243447518907487, 0.0001271059300052002, 2.9969050956424326e-05, 7.997427019290626e-05, 2.248831333417911e-05, 0.00012082124885637313, 0.00010041070345323533, 0.00019287764735054225, 0.021925153210759163, 0.002534757135435939, 0.006652337033301592, 0.00017040784587152302, 7.12621767888777e-05, 0.0004359068116173148, 4.099628858966753e-05, 9.484725160291418e-05, 4.6749537432333454e-05, 1.8083521354128607e-05, 0.00012000476999673992, 0.0004985195701010525, 0.0011171650839969516, 0.0009547884692437947, 0.0007058570045046508, 0.011677442118525505, 0.0035812067799270153, 0.0014930812176316977, 0.006462952122092247, 0.0018828291213139892, 0.005290490575134754, 0.0017073196358978748, 0.0187991950660944, 0.6644665598869324, 0.23989906907081604, 0.0, 0.0, 0.0], [0.0016985159600153565, 5.447915827971883e-05, 3.165346060995944e-05, 8.380056897294708e-06, 6.590516477444908e-06, 1.3400433545029955e-06, 2.093722059726133e-06, 2.1130308596184477e-06, 9.97371557787119e-07, 1.193544903799193e-06, 2.290346628797124e-06, 3.55026872966846e-06, 1.0314523706256296e-06, 9.468895427744428e-07, 6.099496658862336e-07, 2.639448211994022e-06, 3.301592187199276e-06, 8.510960469720885e-06, 4.6063993067946285e-05, 2.4890432541724294e-05, 1.3141653653292451e-05, 1.6042654351622332e-06, 7.19546151231043e-05, 0.00013094820315018296, 0.0011331925634294748, 0.0020622904412448406, 0.0011944918660447001, 0.00015936371346469969, 7.863034988986328e-05, 7.164589078456629e-06, 7.484675279556541e-06, 1.2144819265813567e-05, 1.6994354155031033e-05, 6.077994839870371e-05, 0.002219396410509944, 0.0035177054814994335, 0.0035839760676026344, 0.00039021388511173427, 0.00023602921282872558, 0.0001504209212725982, 0.0003778027312364429, 7.332782843150198e-05, 1.3196082363720052e-05, 1.0382409527665004e-05, 1.617940688447561e-05, 4.484377132030204e-05, 7.45528595871292e-05, 0.0005226329667493701, 0.00031355448300018907, 0.0021425753366202116, 0.000685706443618983, 0.0043577635660767555, 0.0024656574241816998, 0.0016107050469145179, 0.0018946526106446981, 0.004117632284760475, 0.027305977419018745, 0.11642007529735565, 0.16193360090255737, 0.6586700677871704, 0.0, 0.0], [0.0008800908108241856, 9.153625796898268e-06, 2.1621848645736463e-05, 1.1237300896027591e-05, 2.550144699853263e-06, 1.255909637620789e-06, 6.336804290185682e-07, 1.2784214504790725e-06, 7.074962127262552e-07, 7.535705321970454e-07, 1.6574640540056862e-06, 8.709056601219345e-06, 3.2836696846061386e-06, 7.909392479632515e-06, 6.437325055230758e-07, 3.322335487609962e-06, 2.9059231110295514e-06, 2.807573537211283e-06, 1.0820584066095762e-05, 1.4319369256554637e-05, 1.0466726962476969e-05, 2.4730645691306563e-06, 1.4103688044997398e-05, 3.854125316138379e-05, 0.00012945894559379667, 0.001190261566080153, 0.0006457041017711163, 0.0003741438267752528, 0.0005390400183387101, 0.00010419723548693582, 5.963900912320241e-05, 4.003461799584329e-05, 1.442067059542751e-05, 4.9183538067154586e-05, 0.00014287783415056765, 0.0027931269723922014, 0.0014940311666578054, 0.0011382087832316756, 0.0005992438527755439, 0.00033885674201883376, 0.00044040626380592585, 0.00016917656466830522, 0.00015426045865751803, 2.8460577595978975e-05, 2.186105848522857e-05, 1.4911102880432736e-05, 2.4144897906808183e-05, 0.00019466514640953392, 0.00021002422727178782, 0.000819366832729429, 0.0012579062022268772, 0.001858985866419971, 0.002778748283162713, 0.0019570111762732267, 0.0006836280226707458, 0.003936120308935642, 0.0050031207501888275, 0.01903332583606243, 0.07255513966083527, 0.5797531604766846, 0.29840192198753357, 0.0], [0.0017608656780794263, 3.5050736187258735e-05, 9.516068530501798e-06, 7.644858669664245e-06, 2.0669258447014727e-06, 4.206066478218418e-06, 3.5150856092514005e-07, 3.551461986717186e-06, 1.2210095974296564e-06, 5.273362830848782e-07, 1.1786145250880509e-06, 7.57123689254513e-06, 3.940087935916381e-06, 5.501792202267097e-06, 6.566904175997479e-06, 4.5323199628910515e-06, 1.676814463280607e-06, 1.866895217972342e-06, 7.9326167679028e-07, 2.3106806565920124e-06, 4.056999387103133e-06, 1.4199400538927875e-05, 4.352390533313155e-05, 2.0134608348598704e-05, 2.3588392650708556e-05, 6.599415792152286e-05, 0.00016842412878759205, 0.0005549842608161271, 0.00024225265951827168, 1.2523447367129847e-05, 0.00014399939391296357, 9.620470518711954e-05, 1.874909139587544e-05, 0.000395112088881433, 0.0003660093934740871, 0.0008643721812404692, 0.004978333134204149, 0.004476348403841257, 0.0007636858499608934, 0.0005841711536049843, 0.00015038755373097956, 0.0001511843438493088, 0.00013993926404509693, 8.856033673509955e-05, 2.2430480385082774e-05, 8.947924652602524e-05, 3.792252755374648e-05, 6.550057150889188e-05, 0.00029947751318104565, 0.0005447434377856553, 0.0005052059423178434, 0.00984484888613224, 0.0027961067389696836, 0.0016886441735550761, 0.0014504453865811229, 0.000697037554346025, 0.0025698631070554256, 0.006717897951602936, 0.022302336990833282, 0.06304117292165756, 0.21238680183887482, 0.6587123870849609]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9308944344520569, 0.06910556554794312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7291266918182373, 0.17664039134979248, 0.09423291683197021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47600945830345154, 0.20028646290302277, 0.18636052310466766, 0.1373436003923416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4380291998386383, 0.20662495493888855, 0.13603883981704712, 0.18860915303230286, 0.03069782629609108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2755725383758545, 0.19002142548561096, 0.12586507201194763, 0.2958502471446991, 0.06861577928066254, 0.0440748929977417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2978724539279938, 0.19770127534866333, 0.10871727764606476, 0.1739204078912735, 0.04657089337706566, 0.040499452501535416, 0.13471819460391998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32429471611976624, 0.0926910862326622, 0.1451156735420227, 0.17137235403060913, 0.05823070928454399, 0.07092481106519699, 0.09476394206285477, 0.04260668158531189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.27194157242774963, 0.06537686288356781, 0.11176840960979462, 0.1550818681716919, 0.06383445858955383, 0.11313196271657944, 0.10367473214864731, 0.08670216053724289, 0.02848793938755989, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2971765995025635, 0.09799844026565552, 0.12230976670980453, 0.09821091592311859, 0.047138746827840805, 0.06814780086278915, 0.20030687749385834, 0.03043137490749359, 0.012724663130939007, 0.02555484138429165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25815534591674805, 0.05225592479109764, 0.09301784634590149, 0.10429433733224869, 0.05208546668291092, 0.07478722184896469, 0.23321501910686493, 0.049202241003513336, 0.016827035695314407, 0.04698856920003891, 0.01917102374136448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.43002015352249146, 0.047741662710905075, 0.06690958142280579, 0.08895016461610794, 0.028712285682559013, 0.045444902032613754, 0.04439781606197357, 0.020007094368338585, 0.030682800337672234, 0.015131357125937939, 0.035465653985738754, 0.14653648436069489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28077754378318787, 0.06472945213317871, 0.044176843017339706, 0.11800180375576019, 0.006198036018759012, 0.024750802665948868, 0.021241145208477974, 0.02923670783638954, 0.012233935296535492, 0.027993232011795044, 0.0348515622317791, 0.32577139139175415, 0.010037587024271488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22128377854824066, 0.05904841423034668, 0.018886685371398926, 0.05447005107998848, 0.006746696773916483, 0.01895052008330822, 0.01952643319964409, 0.014095150865614414, 0.011336836963891983, 0.012003688141703606, 0.011931505985558033, 0.23726868629455566, 0.20095950365066528, 0.11349199712276459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16770751774311066, 0.015707053244113922, 0.02315814048051834, 0.03901821747422218, 0.0065072886645793915, 0.0173012837767601, 0.018813950940966606, 0.007922200486063957, 0.006843691226094961, 0.021056529134511948, 0.06802229583263397, 0.2895571291446686, 0.09212908893823624, 0.07205642014741898, 0.15419918298721313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12809006869792938, 0.020545674487948418, 0.014275791123509407, 0.04204779118299484, 0.004128062631934881, 0.009411959908902645, 0.017238350585103035, 0.006544746924191713, 0.004284534603357315, 0.007668276317417622, 0.005698832217603922, 0.21420663595199585, 0.19046923518180847, 0.13634318113327026, 0.11621049791574478, 0.08283630758523941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08101072162389755, 0.019868573173880577, 0.0069693224504590034, 0.012615907937288284, 0.0056167300790548325, 0.0037740592379122972, 0.02025192603468895, 0.0019576051272451878, 0.003142806701362133, 0.0038835585583001375, 0.005253481213003397, 0.06851670891046524, 0.1050422191619873, 0.1748196929693222, 0.15241332352161407, 0.2830389440059662, 0.05182446539402008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06504374742507935, 0.01478861179202795, 0.00953205581754446, 0.011622552759945393, 0.00320531171746552, 0.0029589124023914337, 0.005594862625002861, 0.001604200922884047, 0.0018587505910545588, 0.0015536086866632104, 0.0015272191958501935, 0.035165365785360336, 0.13144618272781372, 0.09311230480670929, 0.2748827040195465, 0.23373860120773315, 0.07232426106929779, 0.04004067927598953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.053038738667964935, 0.0171444620937109, 0.00567645113915205, 0.009483175352215767, 0.0034136853646486998, 0.0017677720170468092, 0.010403908789157867, 0.001703797373920679, 0.0016177123179659247, 0.003138072555884719, 0.003500963095575571, 0.03676590323448181, 0.08408349007368088, 0.08766532689332962, 0.0932294949889183, 0.2642577588558197, 0.1382756531238556, 0.09961304068565369, 0.0852205753326416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.27977731823921204, 0.020253876224160194, 0.011576714925467968, 0.013349051587283611, 0.0028657419607043266, 0.0034658932127058506, 0.009741907007992268, 0.0018984383204951882, 0.0024129250086843967, 0.006368096452206373, 0.007529174443334341, 0.028234923258423805, 0.04581625759601593, 0.049559615552425385, 0.120171919465065, 0.09245659410953522, 0.10851938277482986, 0.05740409716963768, 0.11343276500701904, 0.025165272876620293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05848078429698944, 0.009885447099804878, 0.00597754493355751, 0.006983814295381308, 0.0011176607804372907, 0.0016235106159001589, 0.007593832910060883, 0.0008257863228209317, 0.00028174123144708574, 0.0004568116273730993, 0.0010790660744532943, 0.04484788328409195, 0.07089211791753769, 0.04305216297507286, 0.05879613012075424, 0.1329105645418167, 0.11415942013263702, 0.1149793267250061, 0.22925300896167755, 0.07606173306703568, 0.02074153535068035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08457688242197037, 0.00462007150053978, 0.007316845469176769, 0.010235930792987347, 0.0028962555807083845, 0.005083173979073763, 0.006294848397374153, 0.002556858118623495, 0.003310158383101225, 0.005825631786137819, 0.006966738495975733, 0.03115074895322323, 0.034114208072423935, 0.033683791756629944, 0.05839245766401291, 0.0880829468369484, 0.19224998354911804, 0.09834927320480347, 0.09829793870449066, 0.04763871803879738, 0.13073571026325226, 0.04762091115117073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20586541295051575, 0.010123148560523987, 0.005144421476870775, 0.007529750932008028, 0.0010361516615375876, 0.004928417969495058, 0.0012454387033358216, 0.0010636443039402366, 0.00135771872010082, 0.0016840470489114523, 0.0038055090699344873, 0.014820089563727379, 0.006358009763062, 0.012336418963968754, 0.03846488147974014, 0.024107592180371284, 0.04545692726969719, 0.02288220077753067, 0.029895585030317307, 0.02783815562725067, 0.037392329424619675, 0.11882349103689194, 0.37784072756767273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07359447330236435, 0.008112158626317978, 0.0038923341780900955, 0.004204163793474436, 0.0018518734723329544, 0.002034358447417617, 0.006176792550832033, 0.0010932828299701214, 0.0005713533028028905, 0.0012696643825620413, 0.0014108923496678472, 0.01332381647080183, 0.020714353770017624, 0.017440956085920334, 0.037439264357089996, 0.0466800220310688, 0.03629620373249054, 0.030004015192389488, 0.07485807687044144, 0.049548711627721786, 0.08030930906534195, 0.04817136004567146, 0.41049736738204956, 0.03050518035888672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05656728893518448, 0.004517412278801203, 0.0031021200120449066, 0.0020284762140363455, 0.0009497543796896935, 0.0012354676146060228, 0.0031693854834884405, 0.0005671004764735699, 0.00020766741363331676, 0.0004829775425605476, 0.00034737438545562327, 0.010465532541275024, 0.01642029732465744, 0.013199490495026112, 0.02461112104356289, 0.035249363631010056, 0.03299644589424133, 0.02850532718002796, 0.043000727891922, 0.03907632827758789, 0.03839928284287453, 0.03268734738230705, 0.5592764616012573, 0.0401640422642231, 0.012773087248206139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06819678843021393, 0.006637624464929104, 0.0026513971388339996, 0.0025289026089012623, 0.0013037379831075668, 0.0012601001653820276, 0.0029664463363587856, 0.0009871077490970492, 0.00044856060412712395, 0.0006734924972988665, 0.00045011829934082925, 0.008863414637744427, 0.023653587326407433, 0.009484664537012577, 0.015624391846358776, 0.04101623222231865, 0.023963123559951782, 0.022674376145005226, 0.04429370537400246, 0.04258169233798981, 0.06985864788293839, 0.0316048189997673, 0.4936442971229553, 0.04448836296796799, 0.01751418225467205, 0.0226302407681942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06708811223506927, 0.006510528270155191, 0.003477527527138591, 0.004231224302202463, 0.000855850288644433, 0.0008875219500623643, 0.003642617492005229, 0.00043110025580972433, 0.00024560774909332395, 0.00037038265145383775, 0.0001952269085450098, 0.007307491265237331, 0.013247017748653889, 0.009995779953897, 0.021846620365977287, 0.04720846191048622, 0.02610148675739765, 0.018673203885555267, 0.029393130913376808, 0.02169811725616455, 0.042618751525878906, 0.02953486144542694, 0.5649711489677429, 0.023697800934314728, 0.010914266109466553, 0.0130782350897789, 0.03177806735038757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08629966527223587, 0.0035184731241315603, 0.0018938727444037795, 0.002248074160888791, 0.0005214019329287112, 0.0006775967194698751, 0.0006931344396434724, 0.00033576146233826876, 0.00044813452404923737, 0.00019754179811570793, 0.00044476776383817196, 0.0030634310096502304, 0.0064836847595870495, 0.007512249052524567, 0.020439431071281433, 0.013458718545734882, 0.008044400252401829, 0.002466545905917883, 0.003651184495538473, 0.004112535156309605, 0.009943731129169464, 0.02416108548641205, 0.6617055535316467, 0.006413833238184452, 0.004149819258600473, 0.006486780010163784, 0.016925619915127754, 0.10370301455259323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07467414438724518, 0.002984651830047369, 0.0012657508486881852, 0.0019688475877046585, 0.0005235657445155084, 0.00042165929335169494, 0.0016379095613956451, 0.000475008855573833, 0.00040653147152625024, 0.0008078917162492871, 0.0012843991862609982, 0.007002560421824455, 0.0062177968211472034, 0.004709481727331877, 0.008034387603402138, 0.015292519703507423, 0.013932737521827221, 0.009668935090303421, 0.010045524686574936, 0.01003093458712101, 0.0191812627017498, 0.009842905215919018, 0.23592524230480194, 0.012578779831528664, 0.020269596949219704, 0.033395275473594666, 0.10260500758886337, 0.3550345003604889, 0.03978217393159866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06867478787899017, 0.0014352666912600398, 0.0006092824623920023, 0.0008430515881627798, 0.00033737681224010885, 0.000275349710136652, 0.0014153034426271915, 0.0005588035564869642, 0.0005227014189586043, 0.0006727048894390464, 0.0007648676983080804, 0.004578408319503069, 0.011043929494917393, 0.005553257651627064, 0.004203659947961569, 0.013632543385028839, 0.008431549184024334, 0.008121303282678127, 0.009498750790953636, 0.005642666947096586, 0.013769002631306648, 0.006076701916754246, 0.3032643795013428, 0.01991516351699829, 0.015295048244297504, 0.03455903008580208, 0.06583524495363235, 0.2223253697156906, 0.11648600548505783, 0.05565847456455231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06517057120800018, 0.0017894385382533073, 0.0009691568557173014, 0.0013473952421918511, 0.0005266757216304541, 0.00038559440872631967, 0.002725031226873398, 0.00020065919670742005, 0.00028440463938750327, 0.00033181754406541586, 0.0004492926236707717, 0.005752294324338436, 0.005823476705700159, 0.007648547645658255, 0.007342668250203133, 0.01531228143721819, 0.003499226178973913, 0.005240396596491337, 0.009726100601255894, 0.0021097471471875906, 0.004900563042610884, 0.004834932275116444, 0.14280341565608978, 0.004975988995283842, 0.007054348010569811, 0.027084922417998314, 0.06774547696113586, 0.08141645789146423, 0.3950437903404236, 0.0587189719080925, 0.06878633797168732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23764349520206451, 0.002487566089257598, 0.002170316642150283, 0.0020709424279630184, 0.00040996159077621996, 0.0005331351421773434, 0.0023270780220627785, 0.00038870132993906736, 0.00040647847345098853, 0.0009157145977951586, 0.0013189571909606457, 0.005310873035341501, 0.006153791677206755, 0.004512505140155554, 0.008264445699751377, 0.00548609858378768, 0.006093901582062244, 0.0038512235041707754, 0.009077557362616062, 0.0024316664785146713, 0.012699981220066547, 0.008400878868997097, 0.08924665302038193, 0.00726334098726511, 0.010843132622539997, 0.03816906362771988, 0.030139781534671783, 0.08316588401794434, 0.1586553454399109, 0.07543390244245529, 0.15613298118114471, 0.027994703501462936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.051546428352594376, 0.0011052682530134916, 0.001500530750490725, 0.0011130640050396323, 0.00037439537118189037, 0.0004934078897349536, 0.001452041557058692, 0.00030793281621299684, 0.00014980362902861089, 0.0001236929965671152, 0.00039383553666993976, 0.005986202508211136, 0.005742475390434265, 0.0029336856678128242, 0.01050339825451374, 0.0051031108014285564, 0.006330533884465694, 0.005560672841966152, 0.010283009149134159, 0.006270292215049267, 0.003541029756888747, 0.0025790324434638023, 0.08878861367702484, 0.002957535209134221, 0.0015342759434133768, 0.0072730835527181625, 0.03960445523262024, 0.13564921915531158, 0.0769839808344841, 0.16094708442687988, 0.22806815803050995, 0.11288286745548248, 0.021916821599006653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03951046243309975, 0.002028579590842128, 0.001414624392054975, 0.0030020831618458033, 0.0006262892857193947, 0.000401889206841588, 0.0019480697810649872, 0.0005056998343206942, 0.00026544160209596157, 0.00017703753837849945, 0.00046621475485153496, 0.007577786687761545, 0.0068699950352311134, 0.0021255924366414547, 0.0042569926008582115, 0.003970470279455185, 0.005114899016916752, 0.005082742776721716, 0.007071685045957565, 0.0019048781832680106, 0.0012358322273939848, 0.0018859239062294364, 0.4163312017917633, 0.0015485811745747924, 0.001228961395099759, 0.004153116140514612, 0.009614052250981331, 0.14483799040317535, 0.0411294624209404, 0.06400075554847717, 0.14430414140224457, 0.03634650260210037, 0.0098536042496562, 0.029208466410636902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1738971322774887, 0.005291780922561884, 0.007800149265676737, 0.004656669218093157, 0.0007158710504882038, 0.0015343505656346679, 0.0025056342128664255, 0.00041517624049447477, 0.0006112491828389466, 0.0005231588147580624, 0.0005859839147888124, 0.004025275353342295, 0.00802861899137497, 0.00804048776626587, 0.010651123709976673, 0.00454502971842885, 0.00526404706761241, 0.0024271823931485415, 0.0025705904699862003, 0.0011638265568763018, 0.0031169443391263485, 0.006722687277942896, 0.09980711340904236, 0.0043088472448289394, 0.0024169867392629385, 0.008746106177568436, 0.006095421966165304, 0.06041458249092102, 0.020220812410116196, 0.06261168420314789, 0.13791249692440033, 0.021589156240224838, 0.020445164293050766, 0.07053739577531815, 0.22980135679244995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1253923624753952, 0.00312032806687057, 0.0028334606904536486, 0.0038822705391794443, 0.0005765738314948976, 0.0020027661230415106, 0.0007709710043855011, 0.00040176443872042, 0.0003819973499048501, 0.00036424482823349535, 0.00031937292078509927, 0.003464378882199526, 0.003590876469388604, 0.002185629680752754, 0.008730312809348106, 0.003016050672158599, 0.002731101820245385, 0.0016494693700224161, 0.001967656658962369, 0.0014536691596731544, 0.0020168344490230083, 0.0035065265838056803, 0.025951862335205078, 0.0036158764269202948, 0.0017089429311454296, 0.0036659312900155783, 0.008084042929112911, 0.02441723830997944, 0.01746552810072899, 0.030712196603417397, 0.07197084277868271, 0.03604258596897125, 0.04194030165672302, 0.11367708444595337, 0.21348531544208527, 0.2329035997390747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12957154214382172, 0.0033910039346665144, 0.00436395825818181, 0.0033276176545768976, 0.00034944925573654473, 0.0009331239270977676, 0.0014398316852748394, 0.00020187863265164196, 0.0002072860224870965, 0.00030629397951997817, 0.00021596765145659447, 0.0019154222682118416, 0.002567738527432084, 0.0038531951140612364, 0.0038506805431097746, 0.0025039049796760082, 0.0022085842210799456, 0.001008743536658585, 0.0012988303788006306, 0.0008314221631735563, 0.0012006844626739621, 0.0030025916639715433, 0.03640848770737648, 0.0024548135697841644, 0.001477920450270176, 0.004500051494687796, 0.0030062235891819, 0.02876545488834381, 0.007740238215774298, 0.017055584117770195, 0.0459626205265522, 0.016869425773620605, 0.014138148166239262, 0.04498770833015442, 0.1653648167848587, 0.2748969793319702, 0.1678217500448227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14215190708637238, 0.0022226625587791204, 0.0023879550863057375, 0.0034706685692071915, 0.0005497654201462865, 0.0010454038856551051, 0.0009613973088562489, 0.0002334721211809665, 0.00029290709062479436, 0.00018292061577085406, 0.00024091328668873757, 0.0022007685620337725, 0.0021443155128508806, 0.002340256469324231, 0.005731064360588789, 0.002606825903058052, 0.0012472430244088173, 0.0006848218617960811, 0.0009270203881897032, 0.0005525327869690955, 0.0008667272632010281, 0.0024522424209862947, 0.0353759303689003, 0.0007816727738827467, 0.0007207468734122813, 0.0012280193623155355, 0.0029378763865679502, 0.015314827673137188, 0.0044583589769899845, 0.009631584398448467, 0.026836268603801727, 0.00939151644706726, 0.010122033767402172, 0.039643142372369766, 0.16514472663402557, 0.18207253515720367, 0.18499159812927246, 0.13585540652275085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.043049637228250504, 0.0013072320725768805, 0.000371764472220093, 0.0011007918510586023, 0.0001468913396820426, 0.00025011805701069534, 0.0005078620160929859, 9.725145355332643e-05, 0.00012267929560039192, 0.00012400589184835553, 0.00012743836850859225, 0.0022116026375442743, 0.0010951646836474538, 0.0009861799189820886, 0.0012793214991688728, 0.0032265116460621357, 0.0011017643846571445, 0.0009102755575440824, 0.0003969070385210216, 0.00013824869529344141, 0.0006029713549651206, 0.0005044511635787785, 0.016301995143294334, 0.0004970952286385, 0.0006113518611527979, 0.0015419094124808908, 0.001808601780794561, 0.02002418041229248, 0.0067567662335932255, 0.005597104784101248, 0.02420980855822563, 0.002953935880213976, 0.0060697076842188835, 0.012818439863622189, 0.15608403086662292, 0.06538335978984833, 0.2871397137641907, 0.2899995744228363, 0.042543333023786545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024779899045825005, 0.0005267086671665311, 0.0003717021900229156, 0.0004486570251174271, 0.00016519561177119613, 0.00019313840311951935, 0.0005764645175077021, 0.00011066281149396673, 5.7500456023262814e-05, 7.21214892109856e-05, 0.00012045443145325407, 0.0017875342164188623, 0.0023584002628922462, 0.000805657880846411, 0.001721372944302857, 0.0017663870239630342, 0.0013112635351717472, 0.000845388974994421, 0.0011226425413042307, 0.00042895376100204885, 0.0007237301324494183, 0.0005732131539843976, 0.013610546477138996, 0.00048260638141073287, 0.00040568129043094814, 0.0009514704579487443, 0.005449865013360977, 0.015825292095541954, 0.006527114659547806, 0.0113251693546772, 0.02803095616400242, 0.010733135044574738, 0.005877521820366383, 0.017643986269831657, 0.15236563980579376, 0.12432874739170074, 0.20633646845817566, 0.1533958464860916, 0.17941540479660034, 0.02642756700515747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03129805624485016, 0.0003872264642268419, 0.0002776701294351369, 0.0003419334825593978, 0.00013595455675385892, 0.00011145210737595335, 0.0004438781179487705, 5.6338456488447264e-05, 6.73657632432878e-05, 8.842125680530444e-05, 0.00010911260324064642, 0.0008061545668169856, 0.001399640110321343, 0.001021696487441659, 0.0021151567343622446, 0.002454486209899187, 0.0010217241942882538, 0.0004317084385547787, 0.0005280602490529418, 0.00028219050727784634, 0.0008863515686243773, 0.000522657239343971, 0.015338973142206669, 0.0004649115726351738, 0.000505397969391197, 0.0006808348116464913, 0.00556841678917408, 0.009236154146492481, 0.0037008884828537703, 0.0070388056337833405, 0.01679701916873455, 0.005616266746073961, 0.003909847233444452, 0.008644632995128632, 0.14691118896007538, 0.10740615427494049, 0.21835097670555115, 0.17251528799533844, 0.0803488940000534, 0.06294809281826019, 0.08922992646694183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013287077657878399, 0.00019647684530355036, 0.00024115885025821626, 0.0003576671006157994, 0.00010330010991310701, 0.0001180596518679522, 0.0005236879806034267, 4.083648673258722e-05, 2.7528296413947828e-05, 3.472731987130828e-05, 2.5327915864181705e-05, 0.0008084410219453275, 0.0010105590336024761, 0.0006859167478978634, 0.0015944119077175856, 0.0023371141869574785, 0.001189172500744462, 0.0007740182336419821, 0.000788930628914386, 0.0004947767592966557, 0.0006303288391791284, 0.0006005056784488261, 0.01150625292211771, 0.00042990391375496984, 0.0002156086266040802, 0.00040196379995904863, 0.0017673239344730973, 0.015555011108517647, 0.002602164400741458, 0.009193439036607742, 0.016580525785684586, 0.008373607881367207, 0.0035473164170980453, 0.009775716811418533, 0.09290442615747452, 0.09819642454385757, 0.08099455386400223, 0.13046881556510925, 0.11366237699985504, 0.04835040494799614, 0.3070298135280609, 0.02257438749074936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07788225263357162, 0.00038585966103710234, 0.000566844129934907, 0.0005744732334278524, 4.777434514835477e-05, 6.981414480833337e-05, 0.0002233935083495453, 4.351936877355911e-05, 7.336799171753228e-05, 8.444667764706537e-05, 0.0001817410229705274, 0.0006270367302931845, 0.00031017340370453894, 0.0006417280528694391, 0.0016898761969059706, 0.0014024577103555202, 0.0006976798758842051, 0.00033748423447832465, 0.0005382818635553122, 0.0002579759166110307, 0.0013774425024166703, 0.0008191326633095741, 0.014116481877863407, 0.0005424180417321622, 0.0006638594786636531, 0.001619973685592413, 0.0013400844763964415, 0.005070274695754051, 0.003822226542979479, 0.0024529972579330206, 0.007650718092918396, 0.0027610789984464645, 0.0028473916463553905, 0.004425550810992718, 0.06596729904413223, 0.12380237877368927, 0.09782054275274277, 0.0875171646475792, 0.0364680290222168, 0.032446760684251785, 0.0677182748913765, 0.041644539684057236, 0.31046921014785767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06689027696847916, 0.00035011343425139785, 0.00039271096466109157, 0.0004992583999410272, 0.00014869053848087788, 0.0001745087356539443, 0.00020420076907612383, 6.886992196086794e-05, 8.220505696954206e-05, 3.752490010811016e-05, 8.183636236935854e-05, 0.0005751947173848748, 0.0010833903215825558, 0.0006919752340763807, 0.0022968435660004616, 0.0012710451846942306, 0.0010253034997731447, 0.0004141810641158372, 0.0005029359017498791, 0.0003186431713402271, 0.0009635179885663092, 0.001228358712978661, 0.03434458374977112, 0.00030390487518161535, 0.0002678628370631486, 0.0003660500224214047, 0.0016712076030671597, 0.008175878785550594, 0.0010761978337541223, 0.00465242937207222, 0.010013184510171413, 0.0022677467204630375, 0.0020189047791063786, 0.006865736097097397, 0.06040187552571297, 0.06034053489565849, 0.07431529462337494, 0.06981276720762253, 0.046027734875679016, 0.04057895019650459, 0.08671549707651138, 0.018643485382199287, 0.23840954899787903, 0.1534290611743927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01284314226359129, 0.0001348224759567529, 9.586721716914326e-05, 0.00019175646593794227, 4.5202097680885345e-05, 6.565266812685877e-05, 0.00018191846902482212, 7.677676330786198e-05, 1.6762094674049877e-05, 3.3345644624205306e-05, 3.0120279916445725e-05, 0.0006910825031809509, 0.0006566397496499121, 0.00018260748765897006, 0.00029522451222874224, 0.0006097676232457161, 0.0005673331907019019, 0.001145417452789843, 0.0015001349383965135, 0.0015255368780344725, 0.0009691216400824487, 0.000512999074999243, 0.00662637734785676, 0.0005464128917083144, 0.00029350255499593914, 0.0008824297692626715, 0.0020618790294975042, 0.008271406404674053, 0.0020520903635770082, 0.002533026970922947, 0.004937387071549892, 0.007329737767577171, 0.003068700432777405, 0.0029071196913719177, 0.029859647154808044, 0.01955251209437847, 0.03303501009941101, 0.043616943061351776, 0.04898873344063759, 0.025145038962364197, 0.12437202036380768, 0.04322271794080734, 0.2145768254995346, 0.32030540704727173, 0.03344389796257019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013025594875216484, 7.116729830158874e-05, 6.632698932662606e-05, 0.000154997716890648, 4.799236194230616e-05, 0.0001342979521723464, 9.734468767419457e-05, 7.802614709362388e-05, 4.839387474930845e-05, 2.4665932869538665e-05, 4.017483661300503e-05, 0.0006144156213849783, 0.0003227452398277819, 0.00013723174924962223, 0.0005981114227324724, 0.00047599905519746244, 0.0006512175896205008, 0.0012506996281445026, 0.0005941772251389921, 0.001314705703407526, 0.0011053059715777636, 0.00038509551086463034, 0.005778688937425613, 0.0009239493519999087, 0.00021030232892371714, 0.0006177281611599028, 0.0014292417326942086, 0.009043714962899685, 0.002139149233698845, 0.008220633491873741, 0.006915031000971794, 0.006963725667446852, 0.002247604075819254, 0.005686701275408268, 0.014030802994966507, 0.012574288062751293, 0.04422862455248833, 0.08662988990545273, 0.05099658668041229, 0.016488539054989815, 0.09747011214494705, 0.026483098044991493, 0.1466299444437027, 0.3137682378292084, 0.05756102874875069, 0.0617237314581871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006457928102463484, 8.409947622567415e-05, 4.750668813358061e-05, 7.982770330272615e-05, 3.78218901460059e-05, 3.4132750442950055e-05, 0.00014122949505690485, 5.118823901284486e-05, 1.5240760149026755e-05, 2.0591740394593216e-05, 1.654712832532823e-05, 0.00022914126748219132, 0.00022100534988567233, 8.245648496085778e-05, 0.000148786319186911, 0.00031521954224444926, 0.00037778072874061763, 0.0008956958772614598, 0.0007502040825784206, 0.0009815412340685725, 0.0012275890912860632, 0.00031410143128596246, 0.005517067387700081, 0.0006350611220113933, 0.00027384396526031196, 0.0006976391887292266, 0.0023714990820735693, 0.004463036544620991, 0.0013295802054926753, 0.0024781408719718456, 0.0035444111563265324, 0.004884812515228987, 0.002521736081689596, 0.002246446907520294, 0.024302221834659576, 0.011585082858800888, 0.0321815200150013, 0.03064568154513836, 0.03425675630569458, 0.02114539034664631, 0.09282992780208588, 0.042269669473171234, 0.15140801668167114, 0.2651757001876831, 0.07468212395906448, 0.14555560052394867, 0.03046940453350544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008841374889016151, 5.4391177400248125e-05, 4.913974044029601e-05, 0.00010425567597849295, 3.885264595737681e-05, 4.954659380018711e-05, 0.00010308036871720105, 3.6787751014344394e-05, 1.1729982361430302e-05, 2.3345080990111455e-05, 2.2002697733114474e-05, 0.000282569119008258, 0.0003335030050948262, 0.00014170442591421306, 0.0003168541006743908, 0.0005806380650028586, 0.0005675858701579273, 0.0007567345746792853, 0.0012343019479885697, 0.0010699151316657662, 0.0010749573120847344, 0.0005167642375454307, 0.008521005511283875, 0.0005379347712732852, 0.00034434127155691385, 0.0007718047709204257, 0.002655981807038188, 0.006321623455733061, 0.0013857976300641894, 0.002132916357368231, 0.004367712419480085, 0.004580921493470669, 0.0022271699272096157, 0.0028978600166738033, 0.014056414365768433, 0.011641047894954681, 0.017970561981201172, 0.029848013073205948, 0.038517095148563385, 0.02134804055094719, 0.08405801653862, 0.025672895833849907, 0.14065030217170715, 0.23889650404453278, 0.06140473857522011, 0.20279833674430847, 0.037148576229810715, 0.023034442216157913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009928165003657341, 0.00011810039723059162, 6.759084499208257e-05, 0.00018112277030013502, 5.241608232608996e-05, 3.987723175669089e-05, 0.00017433828907087445, 4.946655826643109e-05, 2.9827870093868114e-05, 2.049851718766149e-05, 3.906824713340029e-05, 0.0004203065764158964, 0.00041267939377576113, 0.00019641537801362574, 0.0005986752803437412, 0.0007380747701972723, 0.001227282453328371, 0.0012666801922023296, 0.0016921514179557562, 0.0005395942716859281, 0.000495940272230655, 0.0006850603385828435, 0.14051513373851776, 0.00047860053018666804, 0.00029063766123726964, 0.0006604831432923675, 0.0010188539745286107, 0.00959302019327879, 0.0015295378398150206, 0.0019981912337243557, 0.004347187001258135, 0.0012180893681943417, 0.00041707471245899796, 0.001555772963911295, 0.015555943362414837, 0.007816523313522339, 0.030543826520442963, 0.03564484044909477, 0.017316017299890518, 0.006337739527225494, 0.027763115242123604, 0.009100036695599556, 0.110779769718647, 0.14155793190002441, 0.047821640968322754, 0.2950669527053833, 0.018861109390854836, 0.02011430636048317, 0.03312426060438156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021732192486524582, 0.0001242412836290896, 6.751075125066563e-05, 0.0002329341950826347, 6.845810275990516e-05, 0.00015111880202312022, 9.86613958957605e-05, 4.469326086109504e-05, 2.808180943247862e-05, 2.1193056454649195e-05, 2.9166645617806353e-05, 0.0005941594718024135, 0.0005864280974492431, 0.00022667323355562985, 0.0007116572232916951, 0.0009603932267054915, 0.0013767813798040152, 0.0020445799455046654, 0.0009180152555927634, 0.0014439390506595373, 0.0021148116793483496, 0.0008515578228980303, 0.025947976857423782, 0.0021659540943801403, 0.0003723289701156318, 0.0009483465692028403, 0.0020365389063954353, 0.01117556169629097, 0.000870229268912226, 0.0026090240571647882, 0.003606422571465373, 0.0023853552993386984, 0.001603894168511033, 0.004703348968178034, 0.011125512421131134, 0.0064153363928198814, 0.02191903255879879, 0.044892918318510056, 0.027967805042862892, 0.007798630744218826, 0.041597913950681686, 0.01437123492360115, 0.10129262506961823, 0.20480985939502716, 0.04881647974252701, 0.149354949593544, 0.01180071197450161, 0.04126553609967232, 0.1185307577252388, 0.055188484489917755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0487155057489872, 0.00042878263047896326, 0.00039516828837804496, 0.00034035046701319516, 3.181858119205572e-05, 4.131582682020962e-05, 0.00011428725701989606, 2.2895475922268815e-05, 3.201783692929894e-05, 3.634198219515383e-05, 5.8436155086383224e-05, 0.00022444962814915925, 0.0001584478741278872, 0.00041638975380919874, 0.0011625358602032065, 0.0012866012984886765, 0.0007842591148801148, 0.0005569207132793963, 0.0010781188029795885, 0.000579978572204709, 0.0028273232746869326, 0.0015491913072764874, 0.023284712806344032, 0.0009173037251457572, 0.0008738344185985625, 0.0015401479322463274, 0.000802381953690201, 0.002177102956920862, 0.0012122690677642822, 0.0005809972062706947, 0.0017482007388025522, 0.0006853998638689518, 0.0007892011781223118, 0.0011008442379534245, 0.013644669204950333, 0.02135893702507019, 0.01491672545671463, 0.013606349006295204, 0.005512208677828312, 0.006068631540983915, 0.011230397038161755, 0.008967732079327106, 0.09010926634073257, 0.03372327238321304, 0.018491176888346672, 0.1138843223452568, 0.013661026954650879, 0.03862283378839493, 0.032572392374277115, 0.16240157186985016, 0.3046749234199524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.038086358457803726, 0.000681807694490999, 0.0002068707108264789, 0.0003743030538316816, 3.288813240942545e-05, 0.00012318874360062182, 8.754817099543288e-05, 9.941267489921302e-05, 6.316951476037502e-05, 7.296231342479587e-05, 6.47560300421901e-05, 0.000575419282540679, 0.00023428324493579566, 0.0001708367926767096, 0.00043224325054325163, 0.0004061605141032487, 0.001305456506088376, 0.0013146812561899424, 0.0020522158592939377, 0.0008023477857932448, 0.0014227714855223894, 0.0019324914319440722, 0.022589989006519318, 0.0013176253996789455, 0.0011240642052143812, 0.004185971338301897, 0.0008553370134904981, 0.007116042077541351, 0.0013464267831295729, 0.0014953365316614509, 0.003317655064165592, 0.0007439806358888745, 0.0009196235332638025, 0.0021921824663877487, 0.02072279155254364, 0.009794655255973339, 0.017923718318343163, 0.016972336918115616, 0.013759812340140343, 0.003951456863433123, 0.03443118557333946, 0.005607001017779112, 0.07316578179597855, 0.08823198825120926, 0.012131891213357449, 0.050382282584905624, 0.01603427529335022, 0.022828344255685806, 0.06468793749809265, 0.07906892895698547, 0.3366182744503021, 0.035940926522016525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007123459130525589, 7.550017471658066e-05, 4.745931801153347e-05, 4.68173784611281e-05, 1.6520905774086714e-05, 2.3041056920192204e-05, 4.822803020942956e-05, 2.5806482881307602e-05, 9.558157216815744e-06, 2.4090881197480485e-05, 1.961565612873528e-05, 0.00017232679238077253, 0.0002555435348767787, 0.0001472759759053588, 0.0001667226606514305, 0.0003996033628936857, 0.0004710989014711231, 0.0007800853927619755, 0.0011374198365956545, 0.0009799329563975334, 0.0013781365705654025, 0.0005224704509600997, 0.0070368568412959576, 0.0012692938325926661, 0.000834419799502939, 0.0024170195683836937, 0.002589049283415079, 0.004310735035687685, 0.0010098502971231937, 0.0009511160897091031, 0.0016012024134397507, 0.0011814860627055168, 0.0010611427715048194, 0.001019278191961348, 0.007150494027882814, 0.006684216670691967, 0.008847188204526901, 0.011340736411511898, 0.01146111823618412, 0.007895676419138908, 0.028416821733117104, 0.012088954448699951, 0.038058068603277206, 0.07560177147388458, 0.024303020909428596, 0.05390138179063797, 0.0254038255661726, 0.03323398903012276, 0.06269992887973785, 0.11775524914264679, 0.2792811691761017, 0.11039159446954727, 0.046332571655511856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0039393785409629345, 6.254953041207045e-05, 2.4947108613559976e-05, 2.828144897648599e-05, 6.024903086654376e-06, 9.141154805547558e-06, 2.979537021019496e-05, 3.985835064668208e-06, 2.93048447019828e-06, 4.1069033613894135e-06, 2.8622559966606786e-06, 5.150780998519622e-05, 0.00011520364205352962, 0.00011399098730180413, 0.0001415016158716753, 0.0004145365965086967, 0.0003221838269382715, 0.00021562041365541518, 0.0004386445216368884, 0.00031751295318827033, 0.0006033997633494437, 0.0004449390107765794, 0.007351607549935579, 0.00033359878580085933, 0.00022305446327663958, 0.0003107591182924807, 0.0005307315732352436, 0.003172617405653, 0.0005152883823029697, 0.0009013285161927342, 0.0019358795834705234, 0.0006126839434728026, 0.000321481900755316, 0.0007812394178472459, 0.006688271649181843, 0.006155895534902811, 0.009113219566643238, 0.00825363490730524, 0.005810358561575413, 0.0024065806064754725, 0.013806348666548729, 0.002647900488227606, 0.03344051539897919, 0.029650511220097542, 0.010539653711020947, 0.043780598789453506, 0.005502853076905012, 0.012965139001607895, 0.03392604738473892, 0.09037842601537704, 0.24946705996990204, 0.34762042760849, 0.023568857461214066, 0.03999442234635353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009309966117143631, 0.00014940378605388105, 7.632982305949554e-05, 6.842552102170885e-05, 2.1327663489500992e-05, 2.0664028852479532e-05, 2.2549627828993835e-05, 1.0995860066032037e-05, 1.2565537872433197e-05, 6.330882570182439e-06, 1.4644161637988873e-05, 0.00014135589299257845, 0.0004157066869083792, 0.000409534084610641, 0.0011347216786816716, 0.000713018816895783, 0.0005755756865255535, 0.00025250556063838303, 0.00033171786344610155, 0.0002622742031235248, 0.0008244997006841004, 0.001258215750567615, 0.03143938258290291, 0.00032578789978288114, 0.0002326130634173751, 0.0002889561001211405, 0.0009714924381114542, 0.0041948468424379826, 0.0003830190107692033, 0.0010556348133832216, 0.0026041886303573847, 0.0004296290862839669, 0.000330720009515062, 0.0008542189607396722, 0.0055265650153160095, 0.005804757587611675, 0.0075378334149718285, 0.006443898659199476, 0.0037783479783684015, 0.003909540828317404, 0.006171255372464657, 0.0015511944657191634, 0.023275302723050117, 0.01811854913830757, 0.00553572503849864, 0.02473851852118969, 0.0019249058095738292, 0.004695127718150616, 0.02112835831940174, 0.0633053332567215, 0.15343597531318665, 0.3977281153202057, 0.009811053052544594, 0.04981304332613945, 0.1266237199306488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0031706492882221937, 0.00014504521095659584, 2.5054214347619563e-05, 5.553762457566336e-05, 7.64171636546962e-06, 7.4053268690477125e-06, 2.0248098735464737e-05, 5.990757017571013e-06, 5.266776042844867e-06, 5.7070242291956674e-06, 6.45509362584562e-06, 0.0002304856025148183, 0.00042067578760907054, 0.00023713233531452715, 0.0006362054264172912, 0.002020329236984253, 0.0004942681989632547, 0.0005852280301041901, 0.0005464638816192746, 0.00035962119000032544, 0.0005437383078970015, 0.0005790601135231555, 0.010326498188078403, 0.0003011932712979615, 0.00021033859229646623, 0.0003606941900216043, 0.0005423762486316264, 0.0067652626894414425, 0.0011845732806250453, 0.0006484237965196371, 0.0027990478556603193, 0.0009654136374592781, 0.0007597162621095777, 0.00046012483653612435, 0.006049423944205046, 0.002963703591376543, 0.008392278105020523, 0.0073414756916463375, 0.003359277034178376, 0.0022885960061103106, 0.0075406706891953945, 0.0012388628674671054, 0.022134294733405113, 0.027964351698756218, 0.0036665690131485462, 0.01377013511955738, 0.0027064981404691935, 0.0032276117708534002, 0.007874550297856331, 0.01619720458984375, 0.14826849102973938, 0.2573642432689667, 0.015970494598150253, 0.04779708757996559, 0.27569499611854553, 0.08275730162858963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0069786012172698975, 0.00019968237029388547, 7.466403621947393e-05, 6.558321911143139e-05, 1.961024281627033e-05, 1.3796739949611947e-05, 3.223521343898028e-05, 4.332014668761985e-06, 2.904441316786688e-06, 2.8806476620957255e-05, 1.0420564649393782e-05, 0.0002157255366910249, 0.0002952963695861399, 0.00026140984846279025, 0.0006235050386749208, 0.0008578944252803922, 0.0005798789788968861, 0.00046788016334176064, 0.0005865997518412769, 0.0001316514826612547, 0.0002361312072025612, 0.0004942775121890008, 0.007763954345136881, 0.0004883857909590006, 0.00088446622248739, 0.0010120109654963017, 0.003161114174872637, 0.002785835647955537, 0.0032737678848206997, 0.001350856269709766, 0.0025224180426448584, 0.0003383294679224491, 0.0004057209298480302, 0.000589291681535542, 0.008143382146954536, 0.0053481231443583965, 0.012650583870708942, 0.006576568353921175, 0.0012776819057762623, 0.005497107747942209, 0.0037363809533417225, 0.00454523041844368, 0.01164504885673523, 0.011869031004607677, 0.009698868729174137, 0.013679686933755875, 0.0029496620409190655, 0.007316274102777243, 0.007066989783197641, 0.028631042689085007, 0.06786677241325378, 0.09966219216585159, 0.009142789989709854, 0.32819628715515137, 0.1504477858543396, 0.12591113150119781, 0.04138433560729027, 0.0, 0.0, 0.0, 0.0, 0.0], [0.033168092370033264, 0.00040779891423881054, 0.00032864566310308874, 0.0002535043458919972, 3.296196518931538e-05, 4.556670319288969e-05, 3.673184255603701e-05, 2.1341129468055442e-05, 2.45784867729526e-05, 5.5794364016037434e-05, 0.0001855344307841733, 0.0003045927733182907, 0.000411089276894927, 0.0006833610823377967, 0.0007115558255463839, 0.0014845883706584573, 0.0010532946325838566, 0.0004496967885643244, 0.0005784398526884615, 0.00022977948538027704, 0.003229578258469701, 0.0007607354200445116, 0.008939668536186218, 0.0009270986192859709, 0.0014071539044380188, 0.007463909685611725, 0.0032125096768140793, 0.0037982522044330835, 0.0018171523697674274, 0.0011929707834497094, 0.004417643416672945, 0.0006144135259091854, 0.001551615889184177, 0.0013081395300105214, 0.004260517191141844, 0.00924459658563137, 0.00688203377649188, 0.006745198275893927, 0.004023522604256868, 0.0033645001240074635, 0.005228648893535137, 0.0036680123303085566, 0.01326808426529169, 0.006569385062903166, 0.006798253860324621, 0.034164536744356155, 0.006281324662268162, 0.006081960629671812, 0.008415140211582184, 0.058807797729969025, 0.06588652729988098, 0.06803695112466812, 0.011844356544315815, 0.10542409121990204, 0.07415837794542313, 0.10397730022668839, 0.05247480422258377, 0.2532862722873688, 0.0, 0.0, 0.0, 0.0], [0.0031073722057044506, 0.00014678864681627601, 4.6256143832579255e-05, 5.33473830728326e-05, 1.911666913656518e-05, 1.105840510717826e-05, 4.555790656013414e-05, 3.498161277093459e-06, 4.441802957444452e-06, 4.962098500982393e-06, 5.1821493798343e-06, 9.308537119068205e-05, 0.00014657239080406725, 0.0002804706455208361, 0.0002615463163238019, 0.0007375311688520014, 0.0001298695569857955, 0.00025021209148690104, 0.00041576672811061144, 7.266981265274808e-05, 0.00014937399828340858, 0.0001770306844264269, 0.005095936823636293, 0.00015728588914498687, 0.00019218772649765015, 0.00045676849549636245, 0.0007878760807216167, 0.0008851091261021793, 0.0027009034529328346, 0.0003728978044819087, 0.0006685765692964196, 0.0002364942483836785, 0.0004744588222820312, 0.0006768156890757382, 0.0060686711221933365, 0.003309547435492277, 0.005025580059736967, 0.0029021319933235645, 0.0007053297595120966, 0.00498459255322814, 0.0015513073885813355, 0.0006995939183980227, 0.00591129157692194, 0.004393944051116705, 0.00296224607154727, 0.007920469157397747, 0.001368255354464054, 0.003414551494643092, 0.005637197755277157, 0.013615562580525875, 0.04280226677656174, 0.0795946717262268, 0.010602359659969807, 0.20255903899669647, 0.0839797854423523, 0.05677546188235283, 0.043265506625175476, 0.32813820242881775, 0.0629454180598259, 0.0, 0.0, 0.0], [0.010822329670190811, 0.00038746208883821964, 9.430740465177223e-05, 9.5824507297948e-05, 1.794212221284397e-05, 2.9637978514074348e-05, 2.2995118342805654e-05, 1.3602423678094056e-05, 1.4328067663882393e-05, 1.2342746231297497e-05, 1.4622303751821164e-05, 0.00010572590690571815, 0.0001454697921872139, 0.0001407509989803657, 0.0002949171466752887, 0.00033072399673983455, 0.00029809746774844825, 0.00021220238704700023, 0.00021844111324753612, 0.0001260458811884746, 0.0003717192739713937, 0.00033417282975278795, 0.005277993623167276, 0.0002729463449213654, 0.00026651917141862214, 0.0004133705224376172, 0.000519769499078393, 0.0015407555038109422, 0.0005037980736233294, 0.00043599275522865355, 0.0016782957827672362, 0.0004703152517322451, 0.0007345109479501843, 0.0013110662112012506, 0.009497306309640408, 0.0045294566079974174, 0.008218726143240929, 0.004363964777439833, 0.0019295220263302326, 0.0017031683819368482, 0.002167269354686141, 0.0008077875827439129, 0.0041639795526862144, 0.003931049723178148, 0.0016011608531698585, 0.005441468209028244, 0.0011928288731724024, 0.0028252399060875177, 0.005873179994523525, 0.010521850548684597, 0.030488107353448868, 0.03684965893626213, 0.007264081388711929, 0.034194983541965485, 0.07264284789562225, 0.03173164650797844, 0.07010363787412643, 0.2972102761268616, 0.12682600319385529, 0.19639183580875397, 0.0, 0.0], [0.014327963814139366, 0.00022413260012399405, 0.0001290878135478124, 0.00010033786384155974, 1.7312475392827764e-05, 2.121990291925613e-05, 5.6007429520832375e-05, 9.662474440119695e-06, 1.1068091225752141e-05, 2.473045969964005e-05, 2.4508653950761072e-05, 0.00012045292533002794, 0.00018217437900602818, 0.0001920898794196546, 0.00032242239103652537, 0.00029250208172015846, 0.00021567194198723882, 0.00013583656982518733, 0.00031119497725740075, 7.067461410770193e-05, 0.0004207467136438936, 0.00030631525442004204, 0.003829853842034936, 0.0003347880847286433, 0.000465170422103256, 0.0010662423446774483, 0.0006233248859643936, 0.0012143685016781092, 0.0013006547233089805, 0.0004929238930344582, 0.0013646638253703713, 0.0002591731317806989, 0.0005336629110388458, 0.00092442671302706, 0.005069935228675604, 0.006861522793769836, 0.005227396264672279, 0.004098826088011265, 0.0022076901514083147, 0.0015779838431626558, 0.003164243418723345, 0.0011416136985644698, 0.004160035401582718, 0.002497272565960884, 0.001478864811360836, 0.004750469699501991, 0.001903566182591021, 0.003063937183469534, 0.003491657553240657, 0.008190060965716839, 0.026060398668050766, 0.024434175342321396, 0.006515163462609053, 0.040441110730171204, 0.04411744698882103, 0.041497811675071716, 0.05735207349061966, 0.2498730719089508, 0.11250611394643784, 0.29020383954048157, 0.01818840578198433, 0.0], [0.0024957465939223766, 3.4615059121279046e-05, 5.2894236432621256e-05, 5.3046747780172154e-05, 1.1748037650249898e-05, 2.0018707800772972e-05, 2.3030515876598656e-05, 8.541884199075866e-06, 1.1119530427095015e-05, 1.7247462892555632e-05, 1.9303886801935732e-05, 0.00011342477955622599, 0.0001029944178299047, 0.00011135529348393902, 0.00012952003453392535, 0.00021618243772536516, 0.0002635334967635572, 0.0001424315560143441, 0.00013608467997983098, 6.285666313488036e-05, 0.00020037616195622832, 8.473636989947408e-05, 0.0029629103373736143, 0.00023794248409103602, 0.0003395605308469385, 0.0005748397670686245, 0.0009844704763963819, 0.0018770304741337895, 0.0009886384941637516, 0.0008385922410525382, 0.0026107649318873882, 0.0003280366654507816, 0.0003634946478996426, 0.001099392189644277, 0.003020943608134985, 0.004679367411881685, 0.008356429636478424, 0.007470788434147835, 0.004553008358925581, 0.001799771562218666, 0.003733408637344837, 0.0010583706898614764, 0.0038790698163211346, 0.003707182127982378, 0.001867715734988451, 0.009080715477466583, 0.0017598612466827035, 0.0013352500973269343, 0.00457755709066987, 0.01887214370071888, 0.022332919761538506, 0.016255507245659828, 0.01012096181511879, 0.011587884277105331, 0.05454912409186363, 0.016900325194001198, 0.0816865861415863, 0.15460962057113647, 0.24412620067596436, 0.2190842479467392, 0.036292944103479385, 0.035185638815164566]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9864069819450378, 0.013593015260994434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8913042545318604, 0.03884054347872734, 0.06985516101121902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9362483024597168, 0.008636794053018093, 0.04235289990901947, 0.012762011960148811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5109453201293945, 0.027638375759124756, 0.08851921558380127, 0.008091042749583721, 0.36480599641799927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3031323552131653, 0.04981511831283569, 0.07713795453310013, 0.14355780184268951, 0.1795354038476944, 0.24682143330574036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13908565044403076, 0.017116686329245567, 0.03332929313182831, 0.005769366864115, 0.11116642504930496, 0.013252186588943005, 0.6802804470062256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6732416152954102, 0.033711232244968414, 0.019566884264349937, 0.001308912644162774, 0.05852022394537926, 0.10276661813259125, 0.006473466753959656, 0.1044110655784607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16618958115577698, 0.0009019157150760293, 0.002819724613800645, 0.00022080809867475182, 0.011625138111412525, 0.001422231667675078, 0.003987572155892849, 0.026240937411785126, 0.7865921258926392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19736216962337494, 0.0007315733819268644, 0.002303137443959713, 0.00316623761318624, 0.03482936695218086, 0.0037301736883819103, 0.00047367450315505266, 0.00401621637865901, 0.05304066091775894, 0.7003467679023743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20220692455768585, 0.0012385082663968205, 0.00038105889689177275, 0.000507261254824698, 0.019026421010494232, 0.0006986623047851026, 0.00015450608043465763, 0.013084021396934986, 0.0434407964348793, 0.022087369114160538, 0.6971744298934937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18465900421142578, 0.002939873607829213, 0.05877487733960152, 0.033832523971796036, 0.004140579607337713, 0.0039683920331299305, 0.020702246576547623, 0.024098718538880348, 0.042569294571876526, 0.140255868434906, 0.2680067718029022, 0.21605177223682404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39880234003067017, 0.034100912511348724, 0.045124784111976624, 0.0013421950861811638, 0.012567835859954357, 0.005856286734342575, 0.014953226782381535, 0.0009700873633846641, 0.011759363114833832, 0.019574403762817383, 0.04414168745279312, 0.16140447556972504, 0.24940232932567596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19539056718349457, 0.10720394551753998, 0.023641571402549744, 0.046712517738342285, 0.019671477377414703, 0.0011882735416293144, 0.0015914267860352993, 0.002140824915841222, 0.014719940721988678, 0.018694622442126274, 0.02936377003788948, 0.2607112526893616, 0.04531623050570488, 0.2336534857749939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33017492294311523, 0.13448449969291687, 0.06294535845518112, 0.007164270617067814, 0.026393884792923927, 0.006600318942219019, 0.003792341100051999, 0.0017301114276051521, 0.03838956728577614, 0.009646194986999035, 0.0052952212281525135, 0.010062637738883495, 0.0902927964925766, 0.15710756182670593, 0.11592032760381699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0795799195766449, 0.02812403440475464, 0.08037544041872025, 0.01832488179206848, 0.025156641378998756, 0.0007063992088660598, 0.003771418472751975, 0.0008976187091320753, 0.012938542291522026, 0.047439515590667725, 0.02185644768178463, 0.10711938142776489, 0.02527078613638878, 0.16032472252845764, 0.21621011197566986, 0.17190411686897278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1250254213809967, 0.011560550890862942, 0.003934795036911964, 2.6706829885370098e-05, 0.028934182599186897, 0.00044431607238948345, 0.0005162283196114004, 1.7781016140361317e-05, 0.0010515983449295163, 0.007833443582057953, 0.0013536467449739575, 0.0014427507994696498, 0.0104741919785738, 0.5455529689788818, 0.011020535603165627, 0.14272797107696533, 0.10808291286230087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1897064596414566, 0.010251463390886784, 0.01712186075747013, 0.016105391085147858, 0.016280991956591606, 0.0023577262181788683, 0.004184184595942497, 0.005337799433618784, 0.009755333885550499, 0.04474453628063202, 0.04304858297109604, 0.012110041454434395, 0.03540748730301857, 0.003373250598087907, 0.374107301235199, 0.01144308689981699, 0.016039252281188965, 0.1886252909898758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.42198747396469116, 0.002340315841138363, 0.00648277485743165, 0.002255943836644292, 0.03601110726594925, 0.007020622491836548, 0.0017005031695589423, 0.002174107823520899, 0.013729764148592949, 0.05132283270359039, 0.05232847109436989, 0.004265972413122654, 0.016817936673760414, 0.004565732087939978, 0.005592617206275463, 0.0071435291320085526, 0.021177878603339195, 0.014673828147351742, 0.32840868830680847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5127825140953064, 0.0013326307525858283, 0.005511971190571785, 0.0004565207345876843, 0.00901103112846613, 0.03029794804751873, 0.009126031771302223, 0.0010987564455717802, 0.0025425106287002563, 0.0027190488763153553, 0.002679348224774003, 0.01187530905008316, 0.004684485495090485, 0.0076681096106767654, 0.0037810029461979866, 0.008820958435535431, 0.02834567427635193, 0.05646485090255737, 0.2667684555053711, 0.03403281420469284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026191532611846924, 0.00028498395113274455, 0.0008133626542985439, 0.00463245389983058, 0.0038928715512156487, 7.612977060489357e-05, 0.0004008364921901375, 0.0013230802724137902, 0.0005065139848738909, 0.0005610861699096859, 0.002542542526498437, 0.0007257975521497428, 0.0002259549655718729, 0.0012350059114396572, 0.009414630010724068, 5.231937757343985e-05, 0.0015075678238645196, 0.0016900472110137343, 0.0190877765417099, 0.0777692049741745, 0.8470662236213684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.056448571383953094, 0.0015599883627146482, 6.536446744576097e-05, 0.0007018796750344336, 0.00043501221807673573, 0.002715548500418663, 6.0691516409860924e-05, 0.0004256725369486958, 0.0007006076630204916, 0.0010462264763191342, 9.940349991666153e-05, 0.010641265660524368, 0.004186993930488825, 0.0016742903972044587, 0.011746769770979881, 0.012145917862653732, 0.012990837916731834, 0.03653035685420036, 0.0045039053075015545, 0.011838652193546295, 0.0018207456450909376, 0.827661395072937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.483066588640213, 0.05550505965948105, 0.015696855261921883, 0.0017046905122697353, 0.015031855553388596, 0.010731725953519344, 0.0004627346061170101, 0.000964767241384834, 0.008109934628009796, 0.00860390905290842, 0.006215973757207394, 0.0028185530100017786, 0.006462243385612965, 0.0037825240287929773, 0.002834867686033249, 0.0018990510143339634, 0.006390328519046307, 0.01770571991801262, 0.006502050906419754, 0.0037047676742076874, 0.0044740051962435246, 0.1596633940935135, 0.17766831815242767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13700194656848907, 0.0012069831136614084, 0.001701037515886128, 0.00021861093409825116, 0.011249654926359653, 0.0019064265070483088, 0.000680343946442008, 0.005445570684969425, 0.00851566530764103, 0.010261998511850834, 0.023949243128299713, 0.0007761048036627471, 0.00137355737388134, 0.00398111529648304, 0.0012744684936478734, 0.0031331011559814215, 0.0036658758763223886, 0.006830360274761915, 0.03350953012704849, 0.005531481932848692, 0.031086010858416557, 0.024897372350096703, 0.0014296910958364606, 0.6803738474845886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.080314040184021, 0.0005378363421186805, 0.0009892767993733287, 0.0008362480439245701, 0.006647275760769844, 0.00041882501682266593, 4.645436638384126e-05, 0.0003500704187899828, 0.002288773190230131, 0.04224014654755592, 0.010652369819581509, 0.0014474026393145323, 0.0014109411276876926, 0.0003759496903512627, 0.00014668550284113735, 0.0007978187641128898, 0.001172143965959549, 0.0023140578996390104, 0.0144323306158185, 0.0019507406977936625, 0.0005640772869810462, 0.005749087780714035, 0.008641381748020649, 0.05402015149593353, 0.761655867099762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030258504673838615, 0.001557682640850544, 0.0004076723416801542, 5.789218266727403e-05, 0.0031184167601168156, 9.61335827014409e-05, 9.313050213677343e-06, 0.00034658145159482956, 0.0027802945114672184, 0.002160363830626011, 0.00824770051985979, 0.0001942479721037671, 0.002903565764427185, 0.0005363424425013363, 3.0477140171569772e-05, 0.00021152000408619642, 0.0005152473459020257, 0.000502888928167522, 0.016215583309531212, 0.002057804726064205, 0.0006920892046764493, 0.0017865479458123446, 0.0002933554642368108, 0.015014851465821266, 0.05859843268990517, 0.8514065146446228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.053452249616384506, 0.0020050557795912027, 0.0009903701720759273, 0.00015520615852437913, 0.010140630416572094, 7.573440962005407e-05, 8.953257201937959e-05, 0.000975673901848495, 0.004100354854017496, 0.0032615801319479942, 0.017097990959882736, 0.001319467555731535, 0.004934229888021946, 0.00021494498651009053, 7.288156484719366e-05, 0.00016261231212411076, 0.00024769880110397935, 0.0005729565164074302, 0.005970005411654711, 0.0033020537812262774, 0.0008721430203877389, 0.0005620618467219174, 0.0002650994574651122, 0.0132077531889081, 0.02663559280335903, 0.23102234303951263, 0.6182937622070312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.043467503041028976, 0.002509173471480608, 0.0011640364537015557, 0.0003471366362646222, 0.0003878543502651155, 0.00011606731277424842, 0.0006271377787925303, 0.0004927933332510293, 0.0008431460009887815, 0.0005783500382676721, 0.0008646846399642527, 0.0006789602339267731, 0.0037049755919724703, 0.00034153746673837304, 0.041319042444229126, 4.917365367873572e-05, 0.00035042993840761483, 0.001421977998688817, 0.0014235086273401976, 0.0008122580475173891, 0.017280766740441322, 0.0017720411997288465, 0.002958593424409628, 0.011483046226203442, 0.003719011787325144, 0.014340453781187534, 0.8020787239074707, 0.044867634773254395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0730297788977623, 0.0006815980304963887, 0.0015109559753909707, 0.00022075870947446674, 0.0038697626441717148, 0.0002040403342107311, 0.00011083688877988607, 0.0005329745472408831, 0.0010107671841979027, 0.007709774654358625, 0.0029290199745446444, 0.00018347727018408477, 0.0007558783399872482, 0.0006785313016735017, 9.102650074055418e-05, 8.694105054019019e-05, 0.0005298019386827946, 0.00020698763546533883, 0.0059625147841870785, 0.0004622129490599036, 0.0016920354682952166, 0.0009137105080299079, 0.00021892337827011943, 0.004082570318132639, 0.023234829306602478, 0.04233181104063988, 0.017988532781600952, 0.0022875461727380753, 0.8064824938774109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003262190381065011, 6.0812490119133145e-05, 2.6771393095259555e-05, 2.1619587187160505e-06, 6.708577711833641e-05, 1.2453077715690597e-06, 4.8649176278559025e-06, 5.21417041454697e-06, 2.662802444319823e-06, 0.0001523147220723331, 4.8508180043427274e-05, 1.1918703421542887e-05, 0.0001698879204923287, 0.00027747132116928697, 4.241735496179899e-06, 9.646690887166187e-05, 2.4788456357782707e-05, 9.506718924967572e-05, 0.00024532992392778397, 4.385776992421597e-05, 2.1007337636547163e-05, 4.682154394686222e-05, 1.661207761571859e-06, 2.7714828320313245e-05, 0.0009738102089613676, 0.002311466261744499, 0.00029817878385074437, 0.00026016918127425015, 0.8883271217346191, 0.1031292974948883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003928304184228182, 0.00013915004092268646, 0.00011519015242811292, 6.942936465748062e-07, 0.00029698509024456143, 2.695395778573584e-06, 7.658312824787572e-06, 7.90474075529346e-07, 2.6125129807041958e-05, 0.00010654016659827903, 1.2565591532620601e-05, 2.0206118279020302e-05, 0.00021257912158034742, 0.009607688523828983, 6.322743138298392e-05, 0.0002657185832504183, 0.0001870840642368421, 0.00021465214376803488, 0.004505592864006758, 0.00014491411275230348, 0.0008174208924174309, 0.0001448005496058613, 0.00018747021385934204, 0.00018853232904803008, 0.0005373840103857219, 0.01055779866874218, 0.0028544943779706955, 0.0003121800546068698, 0.5507405996322632, 0.39649292826652527, 0.017307978123426437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37026169896125793, 0.00037788230110891163, 0.0024140789173543453, 0.00027150410460308194, 0.005988491233438253, 0.00886134710162878, 0.0037300020921975374, 0.0007653354550711811, 0.0032287652138620615, 0.0032402402721345425, 0.002281248802319169, 0.004401774145662785, 0.002442889381200075, 0.00888868048787117, 0.005595579743385315, 0.004536852240562439, 0.005228178575634956, 0.006211268715560436, 0.014147372916340828, 0.0020505732391029596, 0.007537307683378458, 0.04398875683546066, 0.0037426340859383345, 0.014376945793628693, 0.005024822428822517, 0.02676462195813656, 0.004803428426384926, 0.0076989890076220036, 0.26460784673690796, 0.033463358879089355, 0.0923822745680809, 0.04068527743220329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1288818120956421, 0.0013020465848967433, 0.003880163189023733, 0.0012490316294133663, 0.023806460201740265, 0.0014911674661561847, 0.002141630509868264, 0.014345169998705387, 0.017058702185750008, 0.007379407063126564, 0.01651683636009693, 0.0004356123972684145, 0.002545454539358616, 0.0014636148698627949, 0.0005377374473027885, 0.001394843915477395, 0.0021691443398594856, 0.0008027316071093082, 0.007443947251886129, 0.002142011420801282, 0.02135869488120079, 0.0017650912050157785, 0.00045032426714897156, 0.03517434000968933, 0.007627153769135475, 0.023116009309887886, 0.004692451097071171, 0.0005280240438878536, 0.05426201969385147, 0.012430173344910145, 0.015527663752436638, 0.04554397985339165, 0.5405365824699402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.060080867260694504, 0.0051061962731182575, 0.009115670807659626, 0.009106790646910667, 0.007647274062037468, 0.004898737650364637, 0.0022354384418576956, 0.0005665738135576248, 0.003659214824438095, 0.0026960421819239855, 0.0011103794677183032, 0.003660729620605707, 0.0017695279093459249, 0.0009424170712009072, 0.00040776259265840054, 0.0005287952953949571, 0.0016294537344947457, 0.005382294300943613, 0.002510151593014598, 0.002157037379220128, 0.004307630471885204, 0.001382559072226286, 0.4853389859199524, 0.052040405571460724, 0.00860014371573925, 0.009084168821573257, 0.004719055723398924, 0.020886924117803574, 0.010139207355678082, 0.011291875503957272, 0.02151639014482498, 0.06238657608628273, 0.03096139058470726, 0.15213331580162048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12761777639389038, 0.0019214308122172952, 0.00919262319803238, 0.003997703082859516, 0.001049756072461605, 0.03479103371500969, 0.0017892684554681182, 0.0006865219329483807, 0.0019120260840281844, 0.0010747385676950216, 0.0032336493022739887, 0.002723231678828597, 0.0009525080095045269, 7.495321187889203e-05, 0.0009553737472742796, 0.00018009188352152705, 0.011063924990594387, 0.004469182342290878, 0.00023891107412055135, 0.0003573611902538687, 0.0030366259161382914, 0.010545150376856327, 0.12548474967479706, 0.006406333297491074, 0.0021152961999177933, 0.001932807033881545, 0.0028470882680267096, 0.027486052364110947, 0.004707023501396179, 0.0008720696205273271, 0.06648441404104233, 0.004650570452213287, 0.0035252596717327833, 0.46747469902038574, 0.06414982676506042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32038751244544983, 0.0027823136188089848, 0.01181521825492382, 0.004230655264109373, 0.011150971055030823, 0.009229693561792374, 0.0003264771366957575, 0.004404890816658735, 0.006504021119326353, 0.0038865816313773394, 0.005679035559296608, 0.002936634235084057, 0.0008194217225536704, 0.00018233663286082447, 0.0005728630931116641, 0.00025857618311420083, 0.002128290245309472, 0.0016192644834518433, 0.003195583587512374, 0.002034706063568592, 0.0009281753445975482, 0.0017221684101969004, 0.0007963431417010725, 0.015532647259533405, 0.013380073010921478, 0.015715133398771286, 0.010949363000690937, 0.00551978312432766, 0.004809910897165537, 0.002595696598291397, 0.007002902217209339, 0.010087713599205017, 0.014726884663105011, 0.06510738283395767, 0.07180424779653549, 0.36517655849456787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3124753534793854, 0.0010989009169861674, 0.00991459283977747, 0.002761127194389701, 0.0023007572162896395, 0.013032023794949055, 0.0016583106480538845, 0.0023531513288617134, 0.0051739029586315155, 0.00491597643122077, 0.006519550457596779, 0.0035523802507668734, 0.0022108997218310833, 0.0002495331864338368, 0.0005498566897585988, 0.0002368779678363353, 0.0018998081795871258, 0.003208510810509324, 0.0005957196117378771, 0.00020047876751050353, 0.0030776907224208117, 0.0016295249806717038, 0.006284648552536964, 0.007690496277064085, 0.008787907660007477, 0.009471398778259754, 0.024101298302412033, 0.09111139178276062, 0.022628245875239372, 0.003731462638825178, 0.011548158712685108, 0.0010097938356921077, 0.0041731116361916065, 0.05833623930811882, 0.01986529491841793, 0.2727907598018646, 0.07885477691888809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.045310650020837784, 0.010164030827581882, 0.004224013537168503, 0.0016827997751533985, 0.0013024742947891355, 0.001128259114921093, 0.00019386842905078083, 0.00043802609434351325, 0.0008346701506525278, 0.0006866654730401933, 0.00017923828272614628, 0.0010478988988325, 0.000644817715510726, 0.001490184455178678, 0.007186803501099348, 0.0001903919328469783, 0.002541058696806431, 0.0014191855443641543, 0.00030160066671669483, 0.00041758728912100196, 0.0018541382160037756, 0.0010586821008473635, 0.027395986020565033, 0.0021890634670853615, 0.0009422607836313546, 0.0009724820265546441, 0.0029369215480983257, 0.012221836484968662, 0.011739515699446201, 0.003858062671497464, 0.030076440423727036, 0.0069115436635911465, 0.0034422879107296467, 0.007722062990069389, 0.16854524612426758, 0.233420729637146, 0.08877883106470108, 0.3145497739315033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0028191013261675835, 0.0015526372008025646, 0.00021684120292775333, 6.208103150129318e-05, 0.00017450684390496463, 5.252894698060118e-05, 0.0004034401790704578, 4.474649358598981e-06, 7.120191003195941e-05, 3.0355471608345397e-05, 0.00011525754234753549, 5.289591717883013e-05, 3.9264770748559386e-05, 0.0007686492754146457, 0.0003484441840555519, 0.00043007213389500976, 0.0009484629263170063, 0.002498969668522477, 0.00022887883824296296, 1.6720710846129805e-05, 0.000763996213208884, 9.835642413236201e-05, 0.0013013561256229877, 0.0010895149316638708, 6.239787035156041e-05, 0.002253365470096469, 0.0007623446872457862, 0.0019463887438178062, 0.13058902323246002, 0.00147837377153337, 0.007218536920845509, 0.0006869204808026552, 0.0008633869583718479, 0.0008904421119950712, 0.19137457013130188, 0.0198102705180645, 0.10223818570375443, 0.15869487822055817, 0.3670428693294525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0750177875161171, 0.00021348240261431783, 0.00020300429605413228, 7.118839857866988e-05, 0.005173880606889725, 0.0016166912391781807, 0.000246976938797161, 0.0005723812500946224, 0.0070625483058393, 0.007198895327746868, 0.02091359533369541, 0.0004255666281096637, 0.0005818351055495441, 0.00039110908983275294, 4.052105941809714e-05, 0.0007102672825567424, 0.0008925998699851334, 0.00023242550378199667, 0.0030403826385736465, 0.00021196011221036315, 0.00018952151003759354, 0.0002700548793654889, 2.0554292859742418e-05, 0.003662637434899807, 0.00475280499085784, 0.025826318189501762, 0.015891313552856445, 0.0010674858931452036, 0.0067449589259922504, 0.0007628155872225761, 0.0006054788827896118, 0.0011464450508356094, 0.0037754422519356012, 0.00374268158338964, 0.0005207275971770287, 0.003684127936139703, 0.002528842305764556, 0.006756708491593599, 0.022798771038651466, 0.7704352140426636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09013057500123978, 0.00040753764915280044, 0.0021250236313790083, 0.00015684810932725668, 0.012945274822413921, 0.0009314534836448729, 0.0016742818988859653, 0.0003410424687899649, 0.011884612031280994, 0.007186887785792351, 0.007141528185456991, 0.0010156616335734725, 0.004182510543614626, 0.0007566144922748208, 0.0001301515003433451, 0.00042624291381798685, 0.0015884863678365946, 0.0007265220046974719, 0.008103624917566776, 0.0003165060479659587, 0.0005531462375074625, 0.0008059532265178859, 0.0016219286480918527, 0.003945231903344393, 0.010786890052258968, 0.02034616842865944, 0.012895571067929268, 0.0017400215147063136, 0.023238055408000946, 0.0012380804400891066, 0.0017228653887286782, 0.001251460867933929, 0.0037025564815849066, 0.0034590226132422686, 0.003328849794343114, 0.024440772831439972, 0.004021211061626673, 0.004167499952018261, 0.018087729811668396, 0.13148628175258636, 0.5749894380569458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023491615429520607, 6.439911521738395e-05, 0.00014603641466237605, 5.9641977713909e-05, 0.0058508627116680145, 0.00015400370466522872, 5.9193022025283426e-05, 0.003962574526667595, 0.003627148689702153, 0.006618874613195658, 0.032774340361356735, 0.0006337141385301948, 0.004162653349339962, 5.035739013692364e-05, 2.430080894555431e-05, 4.071347211720422e-05, 0.00018737111531663686, 0.00033526626066304743, 0.0022951411083340645, 0.00048085764865390956, 0.00032874022144824266, 0.00011460956011433154, 1.4944647773518227e-05, 0.003442778717726469, 0.008719256147742271, 0.02123481035232544, 0.050135817378759384, 0.0021193167194724083, 0.006619815714657307, 0.000517204636707902, 0.0003836331597995013, 0.0008298271568492055, 0.0008008094155229628, 0.00030692381551489234, 0.0006999700563028455, 0.0014046268770471215, 0.0005987161421217024, 0.00029151601484045386, 0.0029489253647625446, 0.05918930470943451, 0.16072727739810944, 0.5935521125793457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29870614409446716, 0.00018499080033507198, 0.001413507736288011, 0.00023741149925626814, 0.006276336032897234, 0.0048394473269581795, 0.0019485070370137691, 0.0003295541100669652, 0.002279936335980892, 0.0032783164642751217, 0.0021345822606235743, 0.002005677204579115, 0.0024162246845662594, 0.0007214057259261608, 0.000618039513938129, 0.0001659264089539647, 0.0010011405684053898, 0.00217663636431098, 0.004000704735517502, 0.0018657003529369831, 0.002575764199718833, 0.00411574961617589, 0.0011976342648267746, 0.00469798082485795, 0.004043378867208958, 0.01222340390086174, 0.019868070259690285, 0.01001734659075737, 0.02218269556760788, 0.004958028439432383, 0.006035434082150459, 0.002522371942177415, 0.010645221918821335, 0.012736519798636436, 0.0011023064143955708, 0.00992425438016653, 0.003922781441360712, 0.00315386732108891, 0.01289429422467947, 0.11826905608177185, 0.11761068552732468, 0.26782771944999695, 0.010875256732106209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06422451883554459, 0.0023032405879348516, 0.0014141773572191596, 0.0006779754185117781, 0.0005687479861080647, 0.000520552508533001, 0.0004624016291927546, 0.0009555697906762362, 0.0005004643462598324, 0.00032135797664523125, 0.00034178278292529285, 0.0003785521839745343, 0.002460880670696497, 0.00025353036471642554, 0.01427940558642149, 6.689685687888414e-05, 0.0008024373673833907, 0.002126088133081794, 0.0012720746453851461, 0.0015390532789751887, 0.008402831852436066, 0.002798723056912422, 0.0032944546546787024, 0.004227433353662491, 0.00031913002021610737, 0.0009475694969296455, 0.024181723594665527, 0.005412970669567585, 0.0036448172759264708, 0.007677826099097729, 0.010847892612218857, 0.006932888645678759, 0.007955239154398441, 0.003454633755609393, 0.044067684561014175, 0.02085385099053383, 0.017961695790290833, 0.000490777485538274, 0.04063813015818596, 0.02226606197655201, 0.05072439834475517, 0.28792789578437805, 0.11044909060001373, 0.21905255317687988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04544837772846222, 5.832284296047874e-05, 0.00012806033191736788, 1.058777252183063e-05, 0.0014324040384963155, 1.318802242167294e-05, 9.81563061941415e-06, 2.6749294192995876e-05, 0.0013611353933811188, 0.00018755215569399297, 0.00030267867259681225, 1.3639719327329658e-05, 0.0003420936409384012, 3.394992381799966e-05, 5.317483100952813e-06, 1.5099406482477207e-05, 2.1073878087918274e-05, 2.0333147404016927e-05, 0.0005303376237861812, 8.489177707815543e-05, 3.061862662434578e-05, 5.55201004317496e-05, 5.656170833390206e-05, 0.0001448463008273393, 0.00018911311053670943, 0.0020962292328476906, 0.0007385745411738753, 0.00011712830018950626, 0.0012670285068452358, 0.0002680536126717925, 0.00017970817862078547, 0.00021473698143381625, 0.0003105737851001322, 9.221121581504121e-05, 0.0002249224780825898, 0.001126062823459506, 0.000488757505081594, 5.650655657518655e-05, 0.0001403239875799045, 0.002815141109749675, 0.008300814777612686, 0.0020943547133356333, 0.0005853439215570688, 0.003304494544863701, 0.9250567555427551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004455578047782183, 0.0003626149264164269, 0.00045646875514648855, 6.578107422683388e-05, 0.00021999978343956172, 0.00014598261623177677, 0.00012873475498054177, 0.00017743791977409273, 0.001150404685176909, 0.0004688895132858306, 8.016813080757856e-05, 5.9346803027438e-05, 0.0004128392320126295, 0.000162104784976691, 0.00013793558173347265, 0.000367937667760998, 0.0001713613310130313, 0.0008534573717042804, 0.0010763646569103003, 0.0006344522116705775, 0.006452776491641998, 0.0011610285146161914, 0.011533779092133045, 0.017583005130290985, 0.001167404931038618, 0.0007802809122949839, 0.0005151870427653193, 0.0006894984398968518, 0.0026454804465174675, 0.006902217864990234, 0.002009384101256728, 0.008439033292233944, 0.007499413564801216, 0.003972628153860569, 0.012802965939044952, 0.016564350575208664, 0.010270983912050724, 0.006446883548051119, 0.01244479138404131, 0.016723092645406723, 0.014898471534252167, 0.008839275687932968, 0.010533572174608707, 0.018564661964774132, 0.723873496055603, 0.06509849429130554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013231543824076653, 1.247762884304393e-05, 1.2303466974117327e-05, 3.4193724331998965e-06, 5.5188978876685724e-05, 6.97749201208353e-05, 9.605386003386229e-05, 0.00016423720808234066, 0.0007812249241396785, 0.0007802398758940399, 0.00010433929128339514, 5.197024438530207e-05, 0.00024041962751653045, 1.050529408530565e-05, 5.578590389632154e-06, 0.00021682889200747013, 2.460734685882926e-05, 8.419633377343416e-05, 0.00021852992358617485, 5.2259005315136164e-05, 3.542944250511937e-05, 0.0007092697196640074, 3.930495586246252e-05, 0.00021221650240477175, 0.0022880597971379757, 0.0020542980637401342, 0.002780216746032238, 0.0003237075579818338, 0.0005151226068846881, 0.0002733432629611343, 8.048948075156659e-05, 0.0001778432633727789, 0.0008833066676743329, 0.0014685956994071603, 0.0001066458789864555, 0.00022214556520339102, 0.000227104319492355, 5.111019345349632e-05, 0.0013837554724887013, 0.0071009439416229725, 0.007894068956375122, 0.0064089554361999035, 0.0001870790438260883, 0.007059411145746708, 0.012222045101225376, 0.005076161585748196, 0.9240036606788635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006995873060077429, 1.2115319805161562e-05, 1.853093272075057e-05, 5.110573511046823e-06, 0.00047426429227925837, 3.2259165436698822e-06, 4.091124719707295e-05, 2.2396741769625805e-05, 0.00024198598111979663, 0.00012208624684717506, 0.0002743266522884369, 1.2675114703597501e-05, 2.663643863343168e-05, 5.763017725257669e-06, 6.7392306846159045e-06, 2.9958891900605522e-05, 1.0590333658910822e-05, 3.512765761115588e-05, 0.0011661467142403126, 9.352128836326301e-05, 9.863301238510758e-05, 1.1195567822142038e-05, 3.0542265449184924e-05, 0.007970769889652729, 0.0007368189981207252, 0.004276287276297808, 0.0005410604644566774, 2.80362455669092e-05, 0.0008100125705823302, 3.2819418265717104e-05, 1.1511605407577008e-05, 0.00023719696037005633, 0.0015142165357246995, 3.614835441112518e-05, 0.0004939843784086406, 0.0006141570047475398, 0.0005594795802608132, 9.206364484271035e-05, 0.00010866449156310409, 0.01846618950366974, 0.029688386246562004, 0.001465735025703907, 0.00030518011772073805, 0.0003037825517822057, 0.5179573893547058, 0.000988026731647551, 0.1921001523733139, 0.2109237015247345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012548300437629223, 0.00045632183901034296, 0.0005512581556104124, 0.00027382324333302677, 0.00036063618608750403, 0.0003139860345982015, 0.00021180498879402876, 3.962965274695307e-05, 0.0002911771589424461, 0.00023059415980242193, 0.00018945489136967808, 0.000564179674256593, 0.0002529718622099608, 8.18984626675956e-05, 3.732231925823726e-05, 8.227924263337627e-05, 0.0004013997095171362, 0.0025722640566527843, 0.0011897982330992818, 0.0011886050924658775, 0.0012835668167099357, 0.000443526660092175, 0.09440125524997711, 0.015052691102027893, 0.004442880395799875, 0.004177618306130171, 0.0017410487635061145, 0.0044296677224338055, 0.0012917846906930208, 0.0006902507157064974, 0.0009295524796471, 0.0017676332499831915, 0.0005858779768459499, 0.005328218452632427, 0.009194727055728436, 0.016601333394646645, 0.0033864988945424557, 0.0006275448831729591, 0.004448332358151674, 0.028093958273530006, 0.022838091477751732, 0.00916358083486557, 0.018704207614064217, 0.024311020970344543, 0.09974516928195953, 0.11825370788574219, 0.18195971846580505, 0.1639474332332611, 0.14032144844532013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01809285394847393, 0.0021236632019281387, 0.0008881090325303376, 7.657117384951562e-05, 0.0003900956944562495, 0.0005948350881226361, 6.916771235410124e-05, 0.0002469837781973183, 0.00043255824130028486, 0.00026831909781321883, 0.00013767840573564172, 0.00017209145880769938, 0.0011743651703000069, 5.924290235270746e-05, 1.6120200598379597e-05, 9.010753274196759e-05, 0.0001728544884826988, 0.0020235746633261442, 0.003544081235304475, 0.0020678259897977114, 0.006863988935947418, 0.0009801292326301336, 0.006143101025372744, 0.031793780624866486, 0.0044044554233551025, 0.00686907023191452, 0.0031567318364977837, 0.0025051399134099483, 0.0024735445622354746, 0.005191360134631395, 0.0005159104475751519, 0.0012033625971525908, 0.0010559880174696445, 0.0041961767710745335, 0.029313763603568077, 0.017566097900271416, 0.014899944886565208, 0.0017789601115509868, 0.00709287216886878, 0.010570072568953037, 0.027637366205453873, 0.01970512978732586, 0.004658060614019632, 0.005907729268074036, 0.09512712061405182, 0.007201725151389837, 0.04536677151918411, 0.09958166629076004, 0.24525383114814758, 0.2583450675010681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21994730830192566, 0.0002951287024188787, 0.0007930106949061155, 8.484035060973838e-05, 0.0018747233552858233, 0.0019662855193018913, 0.0005620344309136271, 0.00014779636694584042, 0.0008245758363045752, 0.0009445369360037148, 0.0004146158753428608, 0.000508837285451591, 0.0007167302537709475, 0.00029366565286181867, 0.0001519582001492381, 6.305977876763791e-05, 0.0004078987112734467, 0.0010670361807569861, 0.003133108839392662, 0.001856601214967668, 0.004043382592499256, 0.009841176681220531, 0.0024121091701090336, 0.009085266850888729, 0.005496824160218239, 0.018487598747015, 0.018139326944947243, 0.00660869712010026, 0.004559354856610298, 0.0008808667189441621, 0.0011501823319122195, 0.0003037314163520932, 0.0016718169208616018, 0.003797850338742137, 0.0005590062355622649, 0.0034624566324055195, 0.0013353569665923715, 0.0005734878359362483, 0.0018312684260308743, 0.009342602454125881, 0.007838649675250053, 0.016836166381835938, 0.00092920265160501, 0.005030940752476454, 0.005012448411434889, 0.0068953935988247395, 0.055036772042512894, 0.012393511831760406, 0.05850532650947571, 0.48548388481140137, 0.00640157051384449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1459568291902542, 0.005870390683412552, 0.004468750674277544, 0.00019591330783441663, 0.0003679498331621289, 0.0017864617984741926, 0.0006917592836543918, 0.001513254246674478, 0.0019678855314850807, 0.00017800877685658634, 0.0004408165405038744, 0.0009285784908570349, 0.002111357869580388, 0.002127045067027211, 0.0003131123667117208, 0.0005874757771380246, 0.0023717002477496862, 0.004597996361553669, 0.004120914731174707, 0.005204407032579184, 0.019836749881505966, 0.03611458092927933, 0.01540834829211235, 0.013334088958799839, 0.0009569923277013004, 0.020393788814544678, 0.01745591312646866, 0.017816826701164246, 0.036316607147455215, 0.008322129026055336, 0.028530631214380264, 0.004936895798891783, 0.002298649400472641, 0.013006499037146568, 0.007304868195205927, 0.029445655643939972, 0.007214638404548168, 0.017178064212203026, 0.08763372898101807, 0.0037794753443449736, 0.012988032773137093, 0.009602285921573639, 0.0031080488115549088, 0.01595591939985752, 0.014557460322976112, 0.015551401302218437, 0.03931755572557449, 0.013172293081879616, 0.08643317967653275, 0.15373294055461884, 0.03224993869662285, 0.03024524450302124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013195098377764225, 4.6764511353103444e-05, 0.0003055627166759223, 1.3000199032831006e-05, 0.00011276412988081574, 3.673237642942695e-06, 8.826690464047715e-05, 1.8808705135597847e-05, 0.00014258990995585918, 5.8505778724793345e-05, 8.666663052281365e-05, 7.406777876894921e-05, 0.00015683438687119633, 8.246012293966487e-05, 2.4122937247739173e-05, 8.014993363758549e-05, 3.248827124480158e-05, 6.116092845331877e-05, 0.0007609865861013532, 0.0001694212987786159, 0.000641012447886169, 0.00019234656065236777, 0.0028242417611181736, 0.0022178618237376213, 0.0005286068771965802, 0.0013330631190910935, 0.0008213366381824017, 0.00029188182088546455, 0.006564101204276085, 0.00015025591710582376, 0.00020715611753985286, 0.0002271325356559828, 0.00021734218171332031, 4.9629161367192864e-05, 0.00014821829972788692, 0.00196100608445704, 0.0008714555879123509, 0.0010567903518676758, 0.0002643633051775396, 0.0014230484375730157, 0.00654223095625639, 0.0008364145760424435, 0.0004504594544414431, 0.0011038878001272678, 0.10278014093637466, 0.00037474618875421584, 0.045854102820158005, 0.011978395283222198, 0.0008207642822526395, 0.0015416594687849283, 0.005642200820147991, 0.024231836199760437, 0.7603389024734497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024864988401532173, 0.00022000032186042517, 8.56274928082712e-05, 6.689524161629379e-05, 0.0015295426128432155, 1.022991637000814e-05, 2.823098611770547e-06, 0.00014020752860233188, 0.00020099936227779835, 0.00014680471213068813, 0.0015050697838887572, 3.1533927540294826e-05, 0.0008664944325573742, 0.0003418120031710714, 0.0001762221218086779, 3.273910260759294e-05, 8.688946400070563e-05, 7.842266495572403e-05, 0.0004348946094978601, 0.00266927108168602, 0.0018264490645378828, 0.0002514090738259256, 8.515119407093152e-05, 0.003005754901096225, 0.000877506798133254, 0.003265360603109002, 0.008507068268954754, 0.001068232930265367, 0.00191147078294307, 0.00027602407499216497, 0.0004692323855124414, 0.005250727757811546, 0.00046934562851674855, 6.4629472035449e-05, 0.0003625736280810088, 0.0002270702680107206, 0.0003641648800112307, 0.0003109461395069957, 0.0002793724706862122, 0.0018082940950989723, 0.0009398029069416225, 0.0034374676179140806, 0.0007076116162352264, 0.00124746176879853, 0.09668461978435516, 0.0005268285749480128, 0.004839878063648939, 0.00435048108920455, 0.0003693069738801569, 0.001446475274860859, 0.003957700915634632, 0.004563882946968079, 0.0164167582988739, 0.7963395118713379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01731850579380989, 0.004545231349766254, 0.00115578668192029, 0.00045763453817926347, 0.0002900223480537534, 0.00014558360271621495, 5.543581210076809e-05, 0.00017866464622784406, 0.0001352430263068527, 9.070856322068721e-05, 0.00011156620166730136, 0.00010704105807235464, 0.0013608186272904277, 0.0003452843811828643, 0.033091168850660324, 0.00016733023221604526, 0.0009456251282244921, 0.0023170190397650003, 0.0007594507187604904, 0.0006391305360011756, 0.003803434781730175, 0.002799182664602995, 0.007017508149147034, 0.007260838523507118, 0.0005233649862930179, 0.0006382415303960443, 0.020908502861857414, 0.002787461271509528, 0.001066362950950861, 0.0010904971277341247, 0.0032237970735877752, 0.003451974829658866, 0.0028907714877277613, 0.0019257424864917994, 0.014399159699678421, 0.0034288091119378805, 0.0033608966041356325, 0.0001349608792224899, 0.008412625640630722, 0.0032021827064454556, 0.0025424722116440535, 0.008911347948014736, 0.003603878431022167, 0.00816381350159645, 0.034117620438337326, 0.0654248520731926, 0.006605604663491249, 0.005523418076336384, 0.005580984055995941, 0.019508956000208855, 0.012682324275374413, 0.010928084142506123, 0.027512934058904648, 0.4784311056137085, 0.15391896665096283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06655971705913544, 0.0006644052336923778, 0.0011457012733444571, 0.00027917270199395716, 0.003790250513702631, 0.0002986159233842045, 0.00012524993508122861, 0.0005867993459105492, 0.005211799405515194, 0.0021389212924987078, 0.001821582787670195, 0.0008323961519636214, 0.0018665239913389087, 0.0011425229022279382, 0.0025302425492554903, 0.0023671931121498346, 0.0011060212273150682, 0.0017923037521541119, 0.007257368881255388, 0.0018316637724637985, 0.0007633587811142206, 0.00387383415363729, 0.0009414149099029601, 0.014735533855855465, 0.026646098122000694, 0.019461974501609802, 0.055048566311597824, 0.003734224708750844, 0.002761454787105322, 0.000960104342084378, 0.0019382123136892915, 0.006614747457206249, 0.008919736370444298, 0.005714536644518375, 0.002963606035336852, 0.0058777122758328915, 0.002417182782664895, 0.0025142827071249485, 0.0030318815261125565, 0.020910313352942467, 0.02157176285982132, 0.016871068626642227, 0.0015895568067207932, 0.002779097529128194, 0.031171008944511414, 0.020292164757847786, 0.05001695454120636, 0.0472712516784668, 0.0132658202201128, 0.017091786488890648, 0.004425285384058952, 0.046901289373636246, 0.08419055491685867, 0.09535830467939377, 0.05703038349747658, 0.1969965100288391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11818898469209671, 0.002030252246186137, 0.0026667178608477116, 3.143033609376289e-05, 0.00862724706530571, 0.002308767754584551, 2.1788710000691935e-05, 2.4662717805767898e-06, 7.539630314568058e-05, 0.0002203492185799405, 0.00022664507559966296, 5.9817725741595495e-06, 9.846970351645723e-05, 0.0005744993686676025, 0.00019531598081812263, 0.0003043392498511821, 0.0023970005568116903, 0.0008880264358595014, 0.0064711119048297405, 3.4231572499265894e-05, 0.00011799202911788598, 0.005003822036087513, 0.0001899536291602999, 0.005314241163432598, 0.002287034410983324, 0.006976983044296503, 0.026445206254720688, 0.00010387061774963513, 0.006750938482582569, 0.000742378004360944, 0.003963739611208439, 5.1539624109864235e-05, 0.0006524763884954154, 0.01794557459652424, 0.00524087343364954, 0.0031903227791190147, 0.0009515134152024984, 0.0003886669874191284, 0.001837864168919623, 0.019670937210321426, 0.004199078772217035, 0.0051551940850913525, 2.4722427042433992e-05, 6.835047770437086e-06, 0.004349075257778168, 0.0005140314460732043, 0.008473163470625877, 0.00785147212445736, 0.025836020708084106, 0.017312737181782722, 4.639227699954063e-05, 0.00035787446540780365, 0.02426997385919094, 0.05976763740181923, 8.122088911477476e-05, 0.024107422679662704, 0.5644521713256836, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4460105299949646, 0.0021533952094614506, 0.0034665109124034643, 0.0001117613646783866, 0.01632220670580864, 0.018112873658537865, 5.244963540462777e-05, 0.0006113044801168144, 0.00488585140556097, 0.000997339840978384, 0.002750639570876956, 6.883763853693381e-05, 0.0024258862249553204, 0.0003121922491118312, 2.7880907509825192e-05, 0.00013402363401837647, 0.0010514119639992714, 0.001020725117996335, 0.004514108411967754, 0.0004910555435344577, 0.0007669264450669289, 0.01356885302811861, 0.00010364902846049517, 0.003455926664173603, 0.008184060454368591, 0.08784180879592896, 0.03423825278878212, 0.0009234367753379047, 0.002002398483455181, 0.0009008749038912356, 0.0015814225189387798, 0.00036598133738152683, 0.002594091696664691, 0.07211272418498993, 0.00402785511687398, 0.00849885307252407, 0.0011131425853818655, 0.00042428693268448114, 0.006029471289366484, 0.0024695182219147682, 0.005002071615308523, 0.008905305527150631, 4.439755866769701e-05, 0.0002031323529081419, 0.0015188396209850907, 0.0008777883485890925, 0.002092234091833234, 0.004769966006278992, 0.05616002157330513, 0.016537459567189217, 0.00010825003118952736, 0.00015895633259788156, 0.004568173084408045, 0.007637634873390198, 0.0016909755067899823, 0.024075474590063095, 0.09751255065202713, 0.01141221821308136, 0.0, 0.0, 0.0, 0.0], [0.001299603609368205, 8.792664448264986e-05, 5.5701846576994285e-05, 3.108596899892291e-07, 0.0001424147340003401, 1.6574668961766292e-06, 3.2551185995544074e-06, 1.572619225953531e-07, 2.5880735847749747e-06, 7.78309185989201e-06, 1.0881674370466499e-06, 1.8119467313226778e-06, 1.114621409215033e-05, 0.00033994647674262524, 3.878672941937111e-06, 3.964827919844538e-05, 2.3187321858131327e-05, 5.746540773543529e-05, 0.0012545789359137416, 3.0349334338097833e-05, 0.00011784593516495079, 1.0779076546896249e-05, 2.5053164790733717e-05, 5.1630187954287976e-05, 0.0002499585098121315, 0.0033981248270720243, 0.0008246283978223801, 2.7754236725741066e-05, 0.012266409583389759, 0.003910430707037449, 0.0001548916770843789, 5.927881284151226e-05, 0.00025248274323530495, 3.205889152013697e-05, 0.005270447116345167, 0.0031621791422367096, 0.0002706740633584559, 0.00045795695041306317, 0.0003631295112427324, 0.005750203039497137, 0.0017345895757898688, 0.0005051671178080142, 5.917169346503215e-06, 1.6627365766908042e-05, 0.000563639507163316, 0.00021293727331794798, 0.0014614984393119812, 0.0017015165649354458, 0.00026416798937134445, 0.0009230574942193925, 5.9936519392067567e-05, 0.0002504090080037713, 0.02020239643752575, 0.09864532202482224, 0.0003182052751071751, 0.6263982057571411, 0.12233670055866241, 0.007723817136138678, 0.0766555592417717, 0.0, 0.0, 0.0], [0.023440513759851456, 0.0002622099709697068, 0.0018590536201372743, 6.553179991897196e-05, 0.000814150320366025, 4.935639299219474e-05, 8.808786515146494e-05, 7.175069185905159e-05, 0.0016684525180608034, 0.00018364901188760996, 0.0003274522314313799, 5.7736386224860325e-05, 0.0007980564259923995, 8.182629244402051e-05, 7.0092169153213035e-06, 0.00010915475286310539, 2.3464919649995863e-05, 0.00010774569091154262, 0.0007910553249530494, 0.00014561593707185239, 6.512956315418705e-05, 0.00012517183495219797, 0.00026668637292459607, 0.0015185689553618431, 0.0020239083096385, 0.010701119899749756, 0.009096047841012478, 0.00030485526076518, 0.0010095755569636822, 0.00010959847713820636, 6.216230394784361e-05, 0.00012131792027503252, 0.0003547230444382876, 0.00014891014143358916, 0.0011214111000299454, 0.01111578568816185, 0.0017115864902734756, 0.0005174802499823272, 0.0004979858640581369, 0.007533692754805088, 0.0031218857038766146, 0.001449283678084612, 7.731945515843108e-05, 9.657395276008174e-05, 0.009005766361951828, 8.592832455178723e-05, 0.006155691109597683, 0.002408693777397275, 0.00039092314545996487, 0.0006515391869470477, 0.00037745776353403926, 0.0029861661605536938, 0.009582784958183765, 0.004021461587399244, 0.0007033054134808481, 0.0013678797986358404, 0.0018358450615778565, 0.05998549610376358, 0.003855988848954439, 0.8124823570251465, 0.0, 0.0], [0.13769926130771637, 0.0002986751205753535, 0.0011546637397259474, 9.549216338200495e-05, 0.0016587958671152592, 0.0034955693408846855, 0.0011326562380418181, 0.0002692429698072374, 0.0005492516793310642, 0.00031920670880936086, 0.00035691101220436394, 0.0016605155542492867, 0.0009283241233788431, 0.0014389620628207922, 0.0004310795047786087, 0.0006393450312316418, 0.0007181065739132464, 0.0011678279843181372, 0.003928452264517546, 0.0005507683963514864, 0.0011676897993311286, 0.005120932124555111, 0.0003299080999568105, 0.0020220810547471046, 0.0018007304752245545, 0.020187238231301308, 0.0044856444001197815, 0.004342729225754738, 0.032941192388534546, 0.0014429781585931778, 0.0022338598500937223, 0.0006359881954267621, 0.0017034768825396895, 0.008946702815592289, 0.00029118548263795674, 0.006104310508817434, 0.0011517680250108242, 0.0021205865778028965, 0.006427943706512451, 0.018426276743412018, 0.012528740800917149, 0.001393713871948421, 0.00017032866890076548, 0.0008531814673915505, 0.0003145134833175689, 0.0006610292475670576, 0.0016742934240028262, 0.002025364898145199, 0.013491530902683735, 0.00962954293936491, 0.0004481333598960191, 0.0023688909132033587, 0.04132522642612457, 0.008978599682450294, 0.00460837734863162, 0.021055197343230247, 0.11167919635772705, 0.014188247732818127, 0.0503726452589035, 0.3697543442249298, 0.05210253596305847, 0.0], [0.00046143331564962864, 1.0846118129848037e-05, 8.456810860479891e-07, 1.4508589629258495e-05, 5.716571195080178e-06, 2.0049730665050447e-05, 5.058998908680223e-07, 2.3237464574776823e-06, 3.1317654247686733e-06, 4.00991575588705e-06, 6.129263852017175e-07, 8.86207926669158e-05, 3.32713607349433e-05, 1.1013432413164992e-05, 0.00010405022476334125, 9.022589802043512e-05, 2.802947892632801e-05, 8.218202128773555e-05, 5.733518719353015e-06, 1.0627190022205468e-05, 9.770316182766692e-07, 0.0003657555498648435, 6.170309461595025e-06, 0.00016386265633627772, 4.6421377192018554e-05, 6.719089287798852e-05, 0.00020481720275711268, 0.003288599429652095, 0.0002341223880648613, 0.00012623982911463827, 0.0007247577304951847, 0.00011509470641613007, 2.3931163013912737e-05, 0.0005273222923278809, 0.0008651379612274468, 3.410925637581386e-05, 0.0005355364410206676, 0.0004244279698468745, 0.0019883783534169197, 0.002030378207564354, 0.00025186027050949633, 0.0001753893739078194, 0.0006514206761494279, 0.0020144202280789614, 1.646596319915261e-05, 0.0042077237740159035, 0.0003382285940460861, 0.00012093265831936151, 0.0014905650168657303, 0.05884096771478653, 0.0019726187456399202, 0.04703548178076744, 0.0034721188712865114, 0.00010432565613882616, 0.013467656448483467, 0.0007774670957587659, 0.026581209152936935, 0.00041190514457412064, 0.041910335421562195, 0.004643147345632315, 0.025192299857735634, 0.7535724639892578]]]}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "text = \"We think that powerful, significantly superhuman machine intelligence is more likely than not to be created this century. If current machine learning techniques were scaled up to this level, we think they would by default produce systems that are deceptive or manipulative, and that no solid plans are known for how to avoid this.\"\n",
        "\n",
        "logits, cache = model.run_with_cache(text, remove_batch_dim=True)\n",
        "# Get attention pattern using cache, and then use circuitvision to visualize\n",
        "attention_patterns = cache[\"pattern\", 0]\n",
        "cv.attention.attention_patterns(tokens=model.to_str_tokens(text),attention=attention_patterns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ReGSoWXQGxl"
      },
      "source": [
        "*(Note that we've run the model on the string `text`, rather than on tokens like we did previously when creating a cache - this is something that `HookedTransformer` allows.)*\n",
        "\n",
        "Inspect the attention patterns. What do you notice about the attention heads?\n",
        "\n",
        "You should spot three relatively distinctive basic patterns, which occur in multiple heads. What are these patterns, and can you guess why they might be present?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "g-DtkA6TQGxl"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE - visualize attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1SnDflCQGxm"
      },
      "source": [
        "<details>\n",
        "<summary>Aside - what to do if your plots won't show up</summary>\n",
        "\n",
        "A common mistake is to fail to pass the tokens in as arguments. If you do this, your attention patterns won't render.\n",
        "\n",
        "If this isn't the problem, then it might be an issue with the Circuitsvis library.Rather than plotting inline, you can do the following, and then open in your browser from the left-hand file explorer menu of VSCode:\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Discussion of results </summary>\n",
        "\n",
        "We notice that there are three basic patterns which repeat quite frequently:\n",
        "\n",
        "* `prev_token_heads`, which attend mainly to the previous token (e.g. head `0.7`)\n",
        "* `current_token_heads`, which attend mainly to the current token (e.g. head `1.6`)\n",
        "* `first_token_heads`, which attend mainly to the first token (e.g. heads `0.3` or `1.4`, although these are a bit less clear-cut than the other two)\n",
        "\n",
        "The `prev_token_heads` and `current_token_heads` are perhaps unsurprising, because words that are close together in a sequence probably have a lot more mutual information (i.e. we could get quite far using bigram or trigram prediction).\n",
        "\n",
        "The `first_token_heads` are a bit more surprising. The basic intuition here is that the first token in a sequence is often used as a resting or null position for heads that only sometimes activate (since our attention probabilities always have to add up to 1).\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "str_tokens = model.to_str_tokens(text)\n",
        "for layer in range(model.cfg.n_layers):\n",
        "    attention_pattern = cache[\"pattern\", layer]\n",
        "    display(cv.attention.attention_patterns(tokens=str_tokens, attention=attention_pattern))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-kAyKv6QGxm"
      },
      "source": [
        "Now that we've observed our three basic attention patterns, it's time to make detectors for those patterns!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfgV2IMBQGxm"
      },
      "source": [
        "### Exercise - write your own detectors\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You shouldn't spend more than 10-25 minutes on these exercises.\n",
        "> These exercises aren't meant to be too challenging, just to get you thinking about how to characterize head behaviour.\n",
        "> Use the hints if you're stuck.\n",
        "> ```\n",
        "\n",
        "You should fill in the functions below, which act as detectors for particular types of heads. Validate your detectors by comparing these results to the visual attention patterns above - summary statistics on their own can be dodgy, but are much more reliable if you can validate it by directly playing with the data.\n",
        "\n",
        "Tasks like this are useful, because we need to be able to take our observations / intuitions about what a model is doing, and translate these into quantitative measures. As the exercises proceed, we'll be creating some much more interesting tools and detectors!\n",
        "\n",
        "Note - there's no objectively correct answer for which heads are doing which tasks, and which detectors can spot them. You should just try and come up with something plausible-seeming, which identifies the kind of behaviour you're looking for. **Don't spend too much time here!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHmz7qAzQGxn",
        "outputId": "a3c1162a-9ef1-44a9-cb69-0b0eda496ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heads attending to current token  =  0.9\n",
            "Heads attending to previous token =  0.7\n",
            "Heads attending to first token    =  0.3, 1.4, 1.10\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def current_attn_detector(cache: ActivationCache) -> list[str]:\n",
        "    \"\"\"\n",
        "    Returns a list e.g. [\"0.2\", \"1.4\", \"1.9\"] of \"layer.head\" which you judge to be current-token heads\n",
        "    \"\"\"\n",
        "    attn_heads = []\n",
        "    for layer in range(model.cfg.n_layers):\n",
        "      for head in range(model.cfg.n_heads):\n",
        "        attn_pattern = cache[\"pattern\",layer][head]\n",
        "        diagonal = attn_pattern.diagonal().mean()\n",
        "        if diagonal > 0.4:\n",
        "          attn_heads.append((f\"{layer}.{head}\"))\n",
        "    return attn_heads\n",
        "\n",
        "\n",
        "def prev_attn_detector(cache: ActivationCache) -> list[str]:\n",
        "    \"\"\"\n",
        "    Returns a list e.g. [\"0.2\", \"1.4\", \"1.9\"] of \"layer.head\" which you judge to be prev-token heads\n",
        "    \"\"\"\n",
        "    attn_heads = []\n",
        "    for layer in range(model.cfg.n_layers):\n",
        "      for head in range(model.cfg.n_heads):\n",
        "        attn_pattern = cache[\"pattern\",layer][head]\n",
        "        diagonal = attn_pattern.diagonal(-1).mean()\n",
        "        if diagonal > 0.4:\n",
        "          attn_heads.append((f\"{layer}.{head}\"))\n",
        "    return attn_heads\n",
        "\n",
        "\n",
        "\n",
        "def first_attn_detector(cache: ActivationCache) -> list[str]:\n",
        "    \"\"\"\n",
        "    Returns a list e.g. [\"0.2\", \"1.4\", \"1.9\"] of \"layer.head\" which you judge to be first-token heads\n",
        "    \"\"\"\n",
        "    attn_heads = []\n",
        "    for layer in range(model.cfg.n_layers):\n",
        "      for head in range(model.cfg.n_heads):\n",
        "        attn_pattern = cache[\"pattern\",layer][head]\n",
        "        vert = attn_pattern[:,0].mean()\n",
        "        if vert > 0.4:\n",
        "          attn_heads.append((f\"{layer}.{head}\"))\n",
        "    return attn_heads\n",
        "\n",
        "\n",
        "\n",
        "print(\"Heads attending to current token  = \", \", \".join(current_attn_detector(cache)))\n",
        "print(\"Heads attending to previous token = \", \", \".join(prev_attn_detector(cache)))\n",
        "print(\"Heads attending to first token    = \", \", \".join(first_attn_detector(cache)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAUH_VfMQGxn"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Try and compute the average attention probability along the relevant tokens. For instance, you can get the tokens just below the diagonal by using `t.diagonal` with appropriate `offset` parameter:\n",
        "\n",
        "```python\n",
        ">>> arr = t.arange(9).reshape(3, 3)\n",
        ">>> arr\n",
        "tensor([[0, 1, 2],\n",
        "        [3, 4, 5],\n",
        "        [6, 7, 8]])\n",
        "\n",
        ">>> arr.diagonal()\n",
        "tensor([0, 4, 8])\n",
        "\n",
        ">>> arr.diagonal(-1)\n",
        "tensor([3, 7])\n",
        "```\n",
        "\n",
        "Remember that you should be using `cache[\"pattern\", layer]` to get all the attention probabilities for a given layer, and then indexing on the 0th dimension to get the correct head.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Expected output (yours might vary slightly depending on method)</summary>\n",
        "\n",
        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Heads attending to current token  =  0.9\n",
        "Heads attending to previous token =  0.7\n",
        "Heads attending to first token    =  0.3, 1.4, 1.10\n",
        "</pre>\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Solution (one possible method)</summary>\n",
        "\n",
        "Note - choosing `score=0.4` as a threshold in the code below is a bit arbitrary, but it seems to work well enough. In this particular case, a threshold of `0.5` results in no head being classified as a current-token head.\n",
        "\n",
        "```python\n",
        "def current_attn_detector(cache: ActivationCache) -> list[str]:\n",
        "    \"\"\"\n",
        "    Returns a list e.g. [\"0.2\", \"1.4\", \"1.9\"] of \"layer.head\" which you judge to be current-token heads\n",
        "    \"\"\"\n",
        "    attn_heads = []\n",
        "    for layer in range(model.cfg.n_layers):\n",
        "        for head in range(model.cfg.n_heads):\n",
        "            attention_pattern = cache[\"pattern\", layer][head]\n",
        "            # take avg of diagonal elements\n",
        "            score = attention_pattern.diagonal().mean()\n",
        "            if score > 0.4:\n",
        "                attn_heads.append(f\"{layer}.{head}\")\n",
        "    return attn_heads\n",
        "\n",
        "\n",
        "def prev_attn_detector(cache: ActivationCache) -> list[str]:\n",
        "    \"\"\"\n",
        "    Returns a list e.g. [\"0.2\", \"1.4\", \"1.9\"] of \"layer.head\" which you judge to be prev-token heads\n",
        "    \"\"\"\n",
        "    attn_heads = []\n",
        "    for layer in range(model.cfg.n_layers):\n",
        "        for head in range(model.cfg.n_heads):\n",
        "            attention_pattern = cache[\"pattern\", layer][head]\n",
        "            # take avg of sub-diagonal elements\n",
        "            score = attention_pattern.diagonal(-1).mean()\n",
        "            if score > 0.4:\n",
        "                attn_heads.append(f\"{layer}.{head}\")\n",
        "    return attn_heads\n",
        "\n",
        "\n",
        "def first_attn_detector(cache: ActivationCache) -> list[str]:\n",
        "    \"\"\"\n",
        "    Returns a list e.g. [\"0.2\", \"1.4\", \"1.9\"] of \"layer.head\" which you judge to be first-token heads\n",
        "    \"\"\"\n",
        "    attn_heads = []\n",
        "    for layer in range(model.cfg.n_layers):\n",
        "        for head in range(model.cfg.n_heads):\n",
        "            attention_pattern = cache[\"pattern\", layer][head]\n",
        "            # take avg of 0th elements\n",
        "            score = attention_pattern[:, 0].mean()\n",
        "            if score > 0.4:\n",
        "                attn_heads.append(f\"{layer}.{head}\")\n",
        "    return attn_heads\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZK-PEPsQGxo"
      },
      "source": [
        "Compare the printouts to your attention visualisations above. Do they seem to make sense? As a bonus exercise, try inputting different text, and see how stable your results are. Do certain heads always get classified the same way?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2eBLT_VQGxo"
      },
      "source": [
        "Now, it's time to turn our attention to induction heads.\n",
        "\n",
        "## What are induction heads?\n",
        "\n",
        "(Note: I use induction **head** to refer to the head in the second layer which attends to the 'token immediately after the copy of the current token', and induction **circuit** to refer to the circuit consisting of the composition of a **previous token head** in layer 0 and an **induction head** in layer 1)\n",
        "\n",
        "[Induction heads](https://transformer-circuits.pub/2021/framework/index.html#induction-heads) are the first sophisticated circuit we see in transformers! And are sufficiently interesting that we wrote [another paper just about them](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html).\n",
        "\n",
        "<details>\n",
        "<summary>An aside on why induction heads are a big deal</summary>\n",
        "\n",
        "There's a few particularly striking things about induction heads:\n",
        "\n",
        "* They develop fairly suddenly in a phase change - from about 2B to 4B tokens we go from no induction heads to pretty well developed ones. This is a striking divergence from a 1L model [see the comparison of in context learning performance curves curves for models with different layers](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html#:~:text=Our%20first%20observation) and can be observed in much larger models (eg a 13B one)\n",
        "    * Phase changes are particularly interesting (and depressing) from an alignment perspective, because the prospect of a sharp left turn, or emergent capabilities like deception or situational awareness seems like worlds where alignment may be harder, and we get caught by surprise without warning shots or simpler but analogous models to test our techniques on.\n",
        "* They are responsible for a significant loss decrease - so much so that there's a visible bump in the loss curve when they develop (this change in loss can be pretty comparable to the increase in loss from major increases in model size, though this is hard to make an apples-to-apples comparison)\n",
        "* They seem to be responsible for the vast majority of in-context learning - the ability to use far back tokens in the context to predict the next token. This is a significant way in which transformers outperform older architectures like RNNs or LSTMs, and induction heads seem to be a big part of this.\n",
        "* The same core circuit seems to be used in a bunch of more sophisticated settings, such as translation or few-shot learning - there are heads that seem clearly responsible for those *and* which double as induction heads.\n",
        "\n",
        "</details>\n",
        "\n",
        "Again, you are strongly recommended to read the [corresponding section of the glossary](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=_Jzi6YHRHKP1JziwdE02qdYZ), before continuing (or [this LessWrong post](https://www.lesswrong.com/posts/TvrfY4c9eaGLeyDkE/induction-heads-illustrated)). In brief, however, the induction circuit consists of a previous token head in layer 0 and an induction head in layer 1, where the induction head learns to attend to the token immediately *after* copies of the current token via K-Composition with the previous token head.\n",
        "\n",
        "##### Question - why couldn't an induction head form in a 1L model?\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "Because this would require a head which attends a key position based on the *value of the token before it*. Attention scores are just a function of the key token and the query token, and are not a function of other tokens.\n",
        "\n",
        "(The attention pattern *does* in fact include effects from other tokens because of softmax - if another key token has a high attention score, softmax inhibits this pair. But this inhibition is symmetric across positions, so can't systematically favour the token *next* to the relevant one.)\n",
        "\n",
        "Note that a key detail is that the value of adjacent tokens are (approximately) unrelated - if the model wanted to attend based on relative *position* this is easy.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl4HqI6CQGxp"
      },
      "source": [
        "## Checking for the induction capability\n",
        "\n",
        "A striking thing about models with induction heads is that, given a repeated sequence of random tokens, they can predict the repeated half of the sequence. This is nothing like it's training data, so this is kind of wild! The ability to predict this kind of out of distribution generalisation is a strong point of evidence that you've really understood a circuit.\n",
        "\n",
        "To check that this model has induction heads, we're going to run it on exactly that, and compare performance on the two halves - you should see a striking difference in the per token losses.\n",
        "\n",
        "Note - we're using small sequences (and just one sequence), since the results are very obvious and this makes it easier to visualise. In practice we'd obviously use larger ones on more subtle tasks. But it's often easiest to iterate and debug on small tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVlD74MAQGxp"
      },
      "source": [
        "### Exercise - plot per-token loss on repeated sequence\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You shouldn't spend more than 10-15 minutes on these exercises.\n",
        "> ```\n",
        "\n",
        "You should fill in the functions below. We've given you the first line of the first function, which defines a prefix (remember we need the BOS token for GPT-2, since it was trained to have one). We've also given you the `get_log_probs` function from the previous set of exercises."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "zSgT4nR5QGxp",
        "outputId": "4ebe0430-d0f9-4eb4-ca30-1a8f3ee62b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance on the first half: -15.042\n",
            "Performance on the second half: -6.210\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"da72bee0-3265-4bce-a6c2-55fc7f2155ef\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"da72bee0-3265-4bce-a6c2-55fc7f2155ef\")) {                    Plotly.newPlot(                        \"da72bee0-3265-4bce-a6c2-55fc7f2155ef\",                        [{\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003evariable=0\\u003cbr\\u003eSequence position=%{x}\\u003cbr\\u003eLog prob=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\" reign\",\"ای\",\" aides\",\" freight\",\" Break\",\" compete\",\" Ment\",\"··\",\" vaginal\",\" burn\",\"을\",\"Connell\",\" affiliates\",\"Back\",\"Trigger\",\" blade\",\"ų\",\" emotion\",\" Ash\",\" rupture\",\"ian\",\" pickup\",\" Theresa\",\" creepy\",\" libert\",\"uclidean\",\" repairs\",\"ylvan\",\"τή\",\" playwright\",\" decou\",\" deliver\",\" Steele\",\"70\",\" employing\",\"idopsis\",\"hidden\",\" Ren\",\"UTR\",\" morale\",\" vacant\",\" _(\",\" contra\",\"ィ\",\" vocals\",\" reduces\",\"Civil\",\"ussion\",\" deeds\",\" veterinary\",\" reign\",\"ای\",\" aides\",\" freight\",\" Break\",\" compete\",\" Ment\",\"··\",\" vaginal\",\" burn\",\"을\",\"Connell\",\" affiliates\",\"Back\",\"Trigger\",\" blade\",\"ų\",\" emotion\",\" Ash\",\" rupture\",\"ian\",\" pickup\",\" Theresa\",\" creepy\",\" libert\",\"uclidean\",\" repairs\",\"ylvan\",\"τή\",\" playwright\",\" decou\",\" deliver\",\" Steele\",\"70\",\" employing\",\"idopsis\",\"hidden\",\" Ren\",\"UTR\",\" morale\",\" vacant\",\" _(\",\" contra\",\"ィ\",\" vocals\",\" reduces\",\"Civil\",\"ussion\",\" deeds\",\" veterinary\"],\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[-11.88452,-16.481445,-20.777891,-16.196253,-15.264792,-15.960416,-18.454327,-19.666456,-15.27057,-9.934699,-14.988466,-17.688005,-15.659916,-15.794279,-13.471202,-12.816176,-12.937435,-13.796629,-13.955221,-15.342695,-10.980198,-12.549491,-14.005465,-17.396318,-10.931456,-26.203459,-10.993031,-15.492592,-18.76858,-15.832043,-17.1832,-12.145483,-15.251759,-13.095759,-16.06965,-22.987415,-15.428786,-9.932365,-15.003525,-17.03479,-14.047636,-13.499637,-13.215174,-15.054024,-12.772778,-12.264209,-15.267663,-10.555833,-12.900246,-18.880928,-11.907457,-15.004154,-7.394825,-8.30278,-0.43645978,-6.5730677,-9.410075,-8.288167,-9.042983,-4.548896,-10.278141,-6.1433854,-8.3036995,-2.0437565,-0.21907386,-1.5814118,-2.6397524,-6.038819,-3.2192395,-4.1004887,-5.8519435,-5.389542,-7.083892,-6.880504,-1.0232801,-15.271112,-2.9831898,-3.7456698,-11.477291,-10.276444,-6.6218796,-1.7268152,-3.6108804,-0.37804633,-5.1550655,-16.743341,-11.642304,-0.28569046,-3.5410864,-10.70459,-7.5203695,-4.424458,-1.5434022,-3.4775498,-7.7939434,-6.139751,-3.6477025,-5.8294225,-6.389193,-7.8653636],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Sequence position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Log prob\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Per token log prob on correct token, for sequence of length 50*2 (repeated twice)\"},\"showlegend\":false,\"hovermode\":\"x unified\",\"shapes\":[{\"fillcolor\":\"red\",\"line\":{\"width\":0},\"opacity\":0.2,\"type\":\"rect\",\"x0\":0,\"x1\":49.5,\"xref\":\"x\",\"y0\":0,\"y1\":1,\"yref\":\"y domain\"},{\"fillcolor\":\"green\",\"line\":{\"width\":0},\"opacity\":0.2,\"type\":\"rect\",\"x0\":49.5,\"x1\":99,\"xref\":\"x\",\"y0\":0,\"y1\":1,\"yref\":\"y domain\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('da72bee0-3265-4bce-a6c2-55fc7f2155ef');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def generate_repeated_tokens(\n",
        "    model: HookedTransformer, seq_len: int, batch_size: int = 1\n",
        ") -> Int[Tensor, \"batch_size full_seq_len\"]:\n",
        "    \"\"\"\n",
        "    Generates a sequence of repeated random tokens\n",
        "\n",
        "    Outputs are:\n",
        "        rep_tokens: [batch_size, 1+2*seq_len]\n",
        "    \"\"\"\n",
        "    t.manual_seed(0)  # for reproducibility\n",
        "    prefix = (t.ones(batch_size, 1) * model.tokenizer.bos_token_id).long()\n",
        "    first = t.randint(0,model.cfg.d_vocab,())\n",
        "    rep_tokens_half = t.randint(0, model.cfg.d_vocab, (batch_size, seq_len), dtype=t.int64)\n",
        "    rep_tokens = t.cat([prefix, rep_tokens_half, rep_tokens_half], dim=-1).to(device)\n",
        "    return rep_tokens\n",
        "\n",
        "\n",
        "def run_and_cache_model_repeated_tokens(\n",
        "    model: HookedTransformer, seq_len: int, batch_size: int = 1\n",
        ") -> tuple[Tensor, Tensor, ActivationCache]:\n",
        "    \"\"\"\n",
        "    Generates a sequence of repeated random tokens, and runs the model on it, returning (tokens, logits, cache). This\n",
        "    function should use the `generate_repeated_tokens` function above\n",
        "\n",
        "    Outputs are:\n",
        "        rep_tokens: [batch_size, 1+2*seq_len]\n",
        "        rep_logits: [batch_size, 1+2*seq_len, d_vocab]\n",
        "        rep_cache: The cache of the model run on rep_tokens\n",
        "    \"\"\"\n",
        "    rep_tokens = generate_repeated_tokens(model, seq_len, batch_size)\n",
        "    rep_logits, rep_cache = model.run_with_cache(rep_tokens)\n",
        "    return rep_tokens, rep_logits, rep_cache\n",
        "\n",
        "\n",
        "\n",
        "def get_log_probs(\n",
        "    logits: Float[Tensor, \"batch posn d_vocab\"], tokens: Int[Tensor, \"batch posn\"]\n",
        ") -> Float[Tensor, \"batch posn-1\"]:\n",
        "    logprobs = logits.log_softmax(dim=-1)\n",
        "    # We want to get logprobs[b, s, tokens[b, s+1]], in eindex syntax this looks like:\n",
        "    correct_logprobs = eindex(logprobs, tokens, \"b s [b s+1]\")\n",
        "    return correct_logprobs\n",
        "\n",
        "\n",
        "seq_len = 50\n",
        "batch_size = 1\n",
        "(rep_tokens, rep_logits, rep_cache) = run_and_cache_model_repeated_tokens(model, seq_len, batch_size)\n",
        "rep_cache.remove_batch_dim()\n",
        "rep_str = model.to_str_tokens(rep_tokens)\n",
        "model.reset_hooks()\n",
        "log_probs = get_log_probs(rep_logits, rep_tokens).squeeze()\n",
        "\n",
        "print(f\"Performance on the first half: {log_probs[:seq_len].mean():.3f}\")\n",
        "print(f\"Performance on the second half: {log_probs[seq_len:].mean():.3f}\")\n",
        "\n",
        "plot_loss_difference(log_probs, rep_str, seq_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWEQef7JQGxq"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "You can define the first half of the repeated tokens using `t.randint(low, high, shape)`. Also remember to specify `dtype=t.long`.\n",
        "\n",
        "Then you can concatenate together your prefix and two copies of the repeated tokens, using `t.concat`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def generate_repeated_tokens(\n",
        "    model: HookedTransformer, seq_len: int, batch_size: int = 1\n",
        ") -> Int[Tensor, \"batch_size full_seq_len\"]:\n",
        "    \"\"\"\n",
        "    Generates a sequence of repeated random tokens\n",
        "\n",
        "    Outputs are:\n",
        "        rep_tokens: [batch_size, 1+2*seq_len]\n",
        "    \"\"\"\n",
        "    t.manual_seed(0)  # for reproducibility\n",
        "    prefix = (t.ones(batch_size, 1) * model.tokenizer.bos_token_id).long()\n",
        "    rep_tokens_half = t.randint(0, model.cfg.d_vocab, (batch_size, seq_len), dtype=t.int64)\n",
        "    rep_tokens = t.cat([prefix, rep_tokens_half, rep_tokens_half], dim=-1).to(device)\n",
        "    return rep_tokens\n",
        "\n",
        "\n",
        "def run_and_cache_model_repeated_tokens(\n",
        "    model: HookedTransformer, seq_len: int, batch_size: int = 1\n",
        ") -> tuple[Tensor, Tensor, ActivationCache]:\n",
        "    \"\"\"\n",
        "    Generates a sequence of repeated random tokens, and runs the model on it, returning (tokens, logits, cache). This\n",
        "    function should use the `generate_repeated_tokens` function above\n",
        "\n",
        "    Outputs are:\n",
        "        rep_tokens: [batch_size, 1+2*seq_len]\n",
        "        rep_logits: [batch_size, 1+2*seq_len, d_vocab]\n",
        "        rep_cache: The cache of the model run on rep_tokens\n",
        "    \"\"\"\n",
        "    rep_tokens = generate_repeated_tokens(model, seq_len, batch_size)\n",
        "    rep_logits, rep_cache = model.run_with_cache(rep_tokens)\n",
        "    return rep_tokens, rep_logits, rep_cache\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlJctSn9QGxq"
      },
      "source": [
        "### Looking for Induction Attention Patterns\n",
        "\n",
        "The next natural thing to check for is the induction attention pattern.\n",
        "\n",
        "First, go back to the attention patterns visualisation code from earlier (i.e. `cv.attention.attention_heads` or `attention_patterns`) and manually check for likely heads in the second layer. Which ones do you think might be serving as induction heads?\n",
        "\n",
        "Note - above, we defined the `rep_str` object for you, so you can use it in your `circuitsvis` functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDY3fXsZQGxq"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE - display the attention patterns stored in `rep_cache`, for each layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHeKwn8TQGxr"
      },
      "source": [
        "<details>\n",
        "<summary>Some observations</summary>\n",
        "\n",
        "The characteristic pattern of induction heads is a diagonal stripe, with the diagonal offset as `seq_len-1` (because the destination token attends to the token *after* the destination token's previous occurrence).\n",
        "\n",
        "You should see that heads 4 and 10 are strongly induction-y, head 6 is very weakly induction-y, and the rest aren't.\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "for layer in range(model.cfg.n_layers):\n",
        "    attention_pattern = rep_cache[\"pattern\", layer]\n",
        "    display(cv.attention.attention_patterns(tokens=rep_str, attention=attention_pattern))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzpY4isDQGxr"
      },
      "source": [
        "### Exercise - make an induction-head detector\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You shouldn't spend more than 5-15 minutes on this exercise.\n",
        "> This exercise should be very similar to the earlier detector exercises (the only difference being how you index attention).\n",
        "> ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZF7jiwnQGxr"
      },
      "source": [
        "Now, you should make an induction pattern score function, which looks for the average attention paid to the offset diagonal. Do this in the same style as our earlier head scorers, just with a different kind of indexing that is appropriate for detecting the characteristic attention head pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv3XGMMWQGxs"
      },
      "outputs": [],
      "source": [
        "def induction_attn_detector(cache: ActivationCache) -> list[str]:\n",
        "    \"\"\"\n",
        "    Returns a list e.g. [\"0.2\", \"1.4\", \"1.9\"] of \"layer.head\" which you judge to be induction heads\n",
        "\n",
        "    Remember - the tokens used to generate rep_cache are (bos_token, *rand_tokens, *rand_tokens)\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "print(\"Induction heads = \", \", \".join(induction_attn_detector(rep_cache)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnTLPeTEQGxs"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure what offset to use.</summary>\n",
        "\n",
        "The offset in your diagonal should be `-(seq_len-1)` (where `seq_len` is the length of the random tokens which you repeat twice), because the second instance of random token `T` will attend to the token **after** the first instance of `T`.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def induction_attn_detector(cache: ActivationCache) -> list[str]:\n",
        "    \"\"\"\n",
        "    Returns a list e.g. [\"0.2\", \"1.4\", \"1.9\"] of \"layer.head\" which you judge to be induction heads\n",
        "\n",
        "    Remember - the tokens used to generate rep_cache are (bos_token, *rand_tokens, *rand_tokens)\n",
        "    \"\"\"\n",
        "    attn_heads = []\n",
        "    for layer in range(model.cfg.n_layers):\n",
        "        for head in range(model.cfg.n_heads):\n",
        "            attention_pattern = cache[\"pattern\", layer][head]\n",
        "            # take avg of (-seq_len+1)-offset elements\n",
        "            seq_len = (attention_pattern.shape[-1] - 1) // 2\n",
        "            score = attention_pattern.diagonal(-seq_len + 1).mean()\n",
        "            if score > 0.4:\n",
        "                attn_heads.append(f\"{layer}.{head}\")\n",
        "    return attn_heads\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPFqHDcHQGxs"
      },
      "source": [
        "If this function works as expected, then you should see output that matches your observations from `circuitsvis` (i.e. the heads which you observed to be induction heads are being classified as induction heads by your function here)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs3ASC1sQGxs"
      },
      "source": [
        "# 3️⃣ TransformerLens: Hooks\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand what hooks are, and how they are used in TransformerLens\n",
        "> - Use hooks to access activations, process the results, and write them to an external tensor\n",
        "> - Build tools to perform attribution, i.e. detecting which components of your model are responsible for performance on a given task\n",
        "> - Understand how hooks can be used to perform basic interventions like **ablation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUMw-Nn-QGxt"
      },
      "source": [
        "## What are hooks?\n",
        "\n",
        "One of the great things about interpreting neural networks is that we have *full control* over our system. From a computational perspective, we know exactly what operations are going on inside (even if we don't know what they mean!). And we can make precise, surgical edits and see how the model's behaviour and other internals change. This is an extremely powerful tool, because it can let us e.g. set up careful counterfactuals and causal intervention to easily understand model behaviour.\n",
        "\n",
        "Accordingly, being able to do this is a pretty core operation, and this is one of the main things TransformerLens supports! The key feature here is **hook points**. Every activation inside the transformer is surrounded by a hook point, which allows us to edit or intervene on it.\n",
        "\n",
        "We do this by adding a **hook function** to that activation, and then calling `model.run_with_hooks`.\n",
        "\n",
        "*(Terminology note - because basically all the activations in our model have an associated hook point, we'll sometimes use the terms \"hook\" and \"activation\" interchangeably.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnEjVrQ7QGxt"
      },
      "source": [
        "### Hook functions\n",
        "\n",
        "Hook functions take two arguments: `activation_value` and `hook_point`. The `activation_value` is a tensor representing some activation in the model, just like the values in our `ActivationCache`. The `hook_point` is an object which gives us methods like `hook.layer()` or attributes like `hook.name` that are sometimes useful to call within the function.\n",
        "\n",
        "If we're using hooks to edit activations, then the hook function should return a tensor of the same shape as the activation value. But we can also just have our hook function access the activation, do some processing, and write the results to some external variable (in which case our hook function should just not return anything).\n",
        "\n",
        "An example hook function for changing the attention patterns at a particular layer might look like:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk8F_bQgQGxt"
      },
      "source": [
        "```python\n",
        "def hook_function(\n",
        "    attn_pattern: Float[Tensor, \"batch heads seq_len seq_len\"],\n",
        "    hook: HookPoint\n",
        ") -> Float[Tensor, \"batch heads seq_len seq_len\"]:\n",
        "\n",
        "    # modify attn_pattern (can be inplace)\n",
        "    return attn_pattern\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j96kXqlQGxu"
      },
      "source": [
        "### Running with hooks\n",
        "\n",
        "Once you've defined a hook function (or functions), you should call `model.run_with_hooks`. A typical call to this function might look like:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWEQ_vsVQGxv"
      },
      "source": [
        "```python\n",
        "loss = model.run_with_hooks(\n",
        "    tokens,\n",
        "    return_type=\"loss\",\n",
        "    fwd_hooks=[\n",
        "        ('blocks.1.attn.hook_pattern', hook_function)\n",
        "    ]\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzEbXgEHQGxv"
      },
      "source": [
        "Let's break this code down.\n",
        "\n",
        "* `tokens` represents our model's input.\n",
        "* `return_type=\"loss\"` is used here because we're modifying our activations and seeing how this affects the loss.\n",
        "    * We could also return the logits, or just use `return_type=None` if we only want to access the intermediate activations and we don't care about the output.\n",
        "* `fwd_hooks` is a list of 2-tuples of (hook name, hook function).\n",
        "    * The hook name is a string that specifies which activation we want to hook.\n",
        "    * The hook function gets run with the corresponding activation as its first argument.\n",
        "\n",
        "### A bit more about hooks\n",
        "\n",
        "Here are a few extra notes for how to squeeze even more functionality out of hooks. If you'd prefer, you can [jump ahead](#hooks-accessing-activations) to see an actual example of hooks being used, and come back to this section later.\n",
        "\n",
        "<details>\n",
        "<summary>Resetting hooks</summary>\n",
        "\n",
        "`model.run_with_hooks` has the default parameter `reset_hooks_end=True` which resets all hooks at the end of the run (including both those that were added before and during the run). Despite this, it's possible to shoot yourself in the foot with hooks, e.g. if there's an error in one of your hooks so the function never finishes. In this case, you can use `model.reset_hooks()` to reset all hooks.\n",
        "\n",
        "If you don't want to reset hooks (i.e. you want to keep them between forward passes), you can either set `reset_hooks_end=False` in the `run_with_hooks` function, or just add the hooks directly using the `add_hook` method before your forward passes (this way they won't reset automatically).\n",
        "\n",
        "</details>\n",
        "<details>\n",
        "<summary>Adding multiple hooks at once</summary>\n",
        "\n",
        "Including more than one tuple in the `fwd_hooks` list is one way to add multiple hooks:\n",
        "\n",
        "```python\n",
        "loss = model.run_with_hooks(\n",
        "    tokens,\n",
        "    return_type=\"loss\",\n",
        "    fwd_hooks=[\n",
        "        ('blocks.0.attn.hook_pattern', hook_function),\n",
        "        ('blocks.1.attn.hook_pattern', hook_function)\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "Another way is to use a **name filter** rather than a single name:\n",
        "\n",
        "```python\n",
        "loss = model.run_with_hooks(\n",
        "    tokens,\n",
        "    return_type=\"loss\",\n",
        "    fwd_hooks=[\n",
        "        (lambda name: name.endswith(\"pattern\"), hook_function)\n",
        "    ]\n",
        ")\n",
        "```\n",
        "</details>\n",
        "<details>\n",
        "<summary><code>utils.get_act_name</code></summary>\n",
        "\n",
        "When we were indexing the cache in the previous section, we found we could use strings like `cache['blocks.0.attn.hook_pattern']`, or use the shorthand of `cache['pattern', 0]`. The reason the second one works is that it calls the function `utils.get_act_name` under the hood, i.e. we have:\n",
        "\n",
        "```python\n",
        "utils.get_act_name('pattern', 0) == 'blocks.0.attn.hook_pattern'\n",
        "```\n",
        "\n",
        "Using `utils.get_act_name` in your forward hooks is often easier than using the full string, since the only thing you need to remember is the activation name (you can refer back to the diagram in the previous section for this).\n",
        "</details>\n",
        "<details>\n",
        "<summary>Using <code>functools.partial</code> to create variations on hooks</summary>\n",
        "\n",
        "A useful trick is to define a hook function with more arguments than it needs, and then use `functools.partial` to fill in the extra arguments. For instance, if you want a hook function which only modifies a particular head, but you want to run it on all heads separately (rather than just adding all the hooks and having them all run on the next forward pass), then you can do something like:\n",
        "\n",
        "```python\n",
        "def hook_all_attention_patterns(\n",
        "    attn_pattern: Float[Tensor, \"batch heads seq_len seq_len\"],\n",
        "    hook: HookPoint,\n",
        "    head_idx: int\n",
        ") -> Float[Tensor, \"batch heads seq_len seq_len\"]:\n",
        "    # modify attn_pattern inplace, at head_idx\n",
        "    return attn_pattern\n",
        "\n",
        "for head_idx in range(12):\n",
        "    temp_hook_fn = functools.partial(hook_all_attention_patterns, head_idx=head_idx)\n",
        "    model.run_with_hooks(tokens, fwd_hooks=[('blocks.1.attn.hook_pattern', temp_hook_fn)])\n",
        "```\n",
        "</details>\n",
        "\n",
        "And here are some points of interest, which aren't vital to understand:\n",
        "\n",
        "<details>\n",
        "<summary>Relationship to PyTorch hooks</summary>\n",
        "\n",
        "[PyTorch hooks](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/) are a great and underrated, yet incredibly janky, feature. They can act on a layer, and edit the input or output of that layer, or the gradient when applying autodiff. The key difference is that **Hook points** act on *activations* not layers. This means that you can intervene within a layer on each activation, and don't need to care about the precise layer structure of the transformer. And it's immediately clear exactly how the hook's effect is applied. This adjustment was shamelessly inspired by [Garcon's use of ProbePoints](https://transformer-circuits.pub/2021/garcon/index.html).\n",
        "\n",
        "They also come with a range of other quality of life improvements. PyTorch's hooks are global state, which can be a massive pain if you accidentally leave a hook on a model. TransformerLens hooks are also global state, but `run_with_hooks` tries to create an abstraction where these are local state by removing all hooks at the end of the function (and they come with a helpful `model.reset_hooks()` method to remove all hooks).\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>How are TransformerLens hooks actually implemented?</summary>\n",
        "\n",
        "They are implemented as modules with the identity function as their forward method:\n",
        "\n",
        "```python\n",
        "class HookPoint(nn.Module):\n",
        "    ...\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "```\n",
        "\n",
        "but also with special features for adding and removing hook functions. This is why you see hooks when you print a HookedTransformer model, because all its modules are recursively printed.\n",
        "\n",
        "When you run the model normally, hook modules won't change the model's behaviour (since applying the identity function does nothing). It's only once you add functions to the hook modules (e.g. a function which ablates any inputs into the hook module) that the model's behaviour changes.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q20oBNTeQGxw"
      },
      "source": [
        "## Hooks: Accessing Activations\n",
        "\n",
        "In later sections, we'll write some code to intervene on hooks, which is really the core feature that makes them so useful for interpretability. But for now, let's just look at how to access them without changing their value. This can be achieved by having the hook function write to a global variable, and return nothing (rather than modifying the activation in place).\n",
        "\n",
        "Why might we want to do this? It turns out to be useful for things like:\n",
        "\n",
        "* Extracting activations for a specific task\n",
        "* Doing some long-running calculation across many inputs, e.g. finding the text that most activates a specific neuron\n",
        "\n",
        "Note that, in theory, this could all be done using the `run_with_cache` function we used in the previous section, combined with post-processing of the cache result. But using hooks can be more intuitive and memory efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieNWJss0QGxw"
      },
      "source": [
        "### Exercise - calculate induction scores with hooks\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You shouldn't spend more than 15-20 minutes on this exercise.\n",
        "> This is our first exercise with hooks, which are an absolutely vital TransformerLens tool. Use the hints if you're stuck.\n",
        "> ```\n",
        "\n",
        "To start with, we'll look at how hooks can be used to get the same results as from the previous section (where we ran our induction head detector functions on the values in the cache).\n",
        "\n",
        "Most of the code has already been provided for you below; the only thing you need to do is **implement the `induction_score_hook` function**. As mentioned, this function takes two arguments: the activation value (which in this case will be our attention pattern) and the hook object (which gives us some useful methods and attributes that we can access in the function, e.g. `hook.layer()` to return the layer, or `hook.name` to return the name, which is the same as the name in the cache).\n",
        "\n",
        "Your function should do the following:\n",
        "\n",
        "* Calculate the induction score for the attention pattern `pattern`, using the same methodology as you used in the previous section when you wrote your induction head detectors.\n",
        "    * Note that this time, the batch dimension is greater than 1, so you should compute the average attention score over the batch dimension.\n",
        "    * Also note that you are computing the induction score for all heads at once, rather than one at a time. You might find the arguments `dim1` and `dim2` of the `torch.diagonal` function useful.\n",
        "* Write this score to the tensor `induction_score_store`, which is a global variable that we've provided for you. The `[i, j]`th element of this tensor should be the induction score for the `j`th head in the `i`th layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7Ft6z7cQGxy"
      },
      "outputs": [],
      "source": [
        "seq_len = 50\n",
        "batch_size = 10\n",
        "rep_tokens_10 = generate_repeated_tokens(model, seq_len, batch_size)\n",
        "\n",
        "# We make a tensor to store the induction score for each head.\n",
        "# We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
        "induction_score_store = t.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
        "\n",
        "\n",
        "def induction_score_hook(pattern: Float[Tensor, \"batch head_index dest_pos source_pos\"], hook: HookPoint):\n",
        "    \"\"\"\n",
        "    Calculates the induction score, and stores it in the [layer, head] position of the `induction_score_store` tensor.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "# We make a boolean filter on activation names, that's true only on attention pattern names\n",
        "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
        "\n",
        "# Run with hooks (this is where we write to the `induction_score_store` tensor`)\n",
        "model.run_with_hooks(\n",
        "    rep_tokens_10,\n",
        "    return_type=None,  # For efficiency, we don't need to calculate the logits\n",
        "    fwd_hooks=[(pattern_hook_names_filter, induction_score_hook)],\n",
        ")\n",
        "\n",
        "# Plot the induction scores for each head in each layer\n",
        "imshow(\n",
        "    induction_score_store,\n",
        "    labels={\"x\": \"Head\", \"y\": \"Layer\"},\n",
        "    title=\"Induction Score by Head\",\n",
        "    text_auto=\".2f\",\n",
        "    width=900,\n",
        "    height=350,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyL_xhUfQGxy"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to implement this function.</summary>\n",
        "\n",
        "To get the induction stripe, you can use:\n",
        "\n",
        "```python\n",
        "torch.diagonal(pattern, dim1=-2, dim2=-1, offset=1-seq_len)\n",
        "```\n",
        "\n",
        "since this returns the diagonal of each attention scores matrix, for every element in the batch and every attention head.\n",
        "\n",
        "Once you have this, you can then take the mean over the batch and diagonal dimensions, giving you a tensor of length `n_heads`. You can then write this to the global `induction_score_store` tensor, using the `hook.layer()` method to get the correct row number.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def induction_score_hook(pattern: Float[Tensor, \"batch head_index dest_pos source_pos\"], hook: HookPoint):\n",
        "    \"\"\"\n",
        "    Calculates the induction score, and stores it in the [layer, head] position of the `induction_score_store` tensor.\n",
        "    \"\"\"\n",
        "    # Take the diagonal of attn paid from each dest posn to src posns (seq_len-1) tokens back\n",
        "    # (This only has entries for tokens with index>=seq_len)\n",
        "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1 - seq_len)\n",
        "    # Get an average score per head\n",
        "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
        "    # Store the result.\n",
        "    induction_score_store[hook.layer(), :] = induction_score\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWD1Q--GQGxy"
      },
      "source": [
        "If this function has been implemented correctly, you should see a result matching your observations from the previous section: a high induction score (>0.6) for all the heads which you identified as induction heads, and a low score (close to 0) for all others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gRm2VTNQGxy"
      },
      "source": [
        "### Exercise - find induction heads in GPT2-small\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You shouldn't spend more than 10-20 minutes on this exercise.\n",
        "> Here, you mostly just need to use previously defined functions and interpret the results, rather than writing new code.\n",
        "> ```\n",
        "\n",
        "*This is your first opportunity to investigate a larger and more extensively trained model, rather than the simple 2-layer model we've been using so far. None of the code required is new (you can copy most of it from previous sections), so these exercises shouldn't take very long.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGPqpZZSQGxz"
      },
      "source": [
        "Perform the same analysis on your `gpt2_small`. You should observe that some heads, particularly in a couple of the middle layers, have high induction scores. Use CircuitsVis to plot the attention patterns for these heads when run on the repeated token sequences, and verify that they look like induction heads.\n",
        "\n",
        "Note - you can make CircuitsVis plots (and other visualisations) using hooks rather than plotting directly from the cache. For example, we've given you a hook function which will display the attention patterns at a given hook when you include it in a call to `model.run_with_hooks`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBsq6jxiQGxz"
      },
      "outputs": [],
      "source": [
        "def visualize_pattern_hook(\n",
        "    pattern: Float[Tensor, \"batch head_index dest_pos source_pos\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "    print(\"Layer: \", hook.layer())\n",
        "    display(cv.attention.attention_patterns(tokens=gpt2_small.to_str_tokens(rep_tokens[0]), attention=pattern.mean(0)))\n",
        "\n",
        "\n",
        "# YOUR CODE HERE - find induction heads in gpt2_small"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc2mQmOpQGxz"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "seq_len = 50\n",
        "batch_size = 10\n",
        "rep_tokens_batch = generate_repeated_tokens(gpt2_small, seq_len, batch_size)\n",
        "\n",
        "induction_score_store = t.zeros((gpt2_small.cfg.n_layers, gpt2_small.cfg.n_heads), device=gpt2_small.cfg.device)\n",
        "\n",
        "gpt2_small.run_with_hooks(\n",
        "    rep_tokens_batch,\n",
        "    return_type=None,  # For efficiency, we don't need to calculate the logits\n",
        "    fwd_hooks=[(pattern_hook_names_filter, induction_score_hook)],\n",
        ")\n",
        "\n",
        "imshow(\n",
        "    induction_score_store,\n",
        "    labels={\"x\": \"Head\", \"y\": \"Layer\"},\n",
        "    title=\"Induction Score by Head\",\n",
        "    text_auto=\".1f\",\n",
        "    width=700,\n",
        "    height=500,\n",
        ")\n",
        "\n",
        "# Observation: heads 5.1, 5.5, 6.9, 7.2, 7.10 are all strongly induction-y.\n",
        "# Confirm observation by visualizing attn patterns for layers 5 through 7:\n",
        "\n",
        "induction_head_layers = [5, 6, 7]\n",
        "fwd_hooks = [\n",
        "    (utils.get_act_name(\"pattern\", induction_head_layer), visualize_pattern_hook)\n",
        "    for induction_head_layer in induction_head_layers\n",
        "]\n",
        "gpt2_small.run_with_hooks(\n",
        "    rep_tokens,\n",
        "    return_type=None,\n",
        "    fwd_hooks=fwd_hooks,\n",
        ")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n2z5o_uQGx0"
      },
      "source": [
        "## Building interpretability tools\n",
        "\n",
        "In order to develop a mechanistic understanding for how transformers perform certain tasks, we need to be able to answer questions like:\n",
        "\n",
        "> *How much of the model's performance on some particular task is attributable to each component of the model?*\n",
        "\n",
        "where \"component\" here might mean, for example, a specific head in a layer.\n",
        "\n",
        "There are many ways to approach a question like this. For example, we might look at how a head interacts with other heads in different layers, or we might perform a causal intervention by seeing how well the model performs if we remove the effect of this head. However, we'll keep things simple for now, and ask the question: **what are the direct contributions of this head to the output logits?**\n",
        "\n",
        "### Direct Logit attribution\n",
        "\n",
        "A consequence of the residual stream is that the output logits are the sum of the contributions of each layer, and thus the sum of the results of each head. This means we can decompose the output logits into a term coming from each head and directly do attribution like this!\n",
        "\n",
        "<details>\n",
        "<summary>A concrete example</summary>\n",
        "\n",
        "Let's say that our model knows that the token Harry is followed by the token Potter, and we want to figure out how it does this. The logits on Harry are `residual @ W_U`. But this is a linear map, and the residual stream is the sum of all previous layers `residual = embed + attn_out_0 + attn_out_1`. So `logits = (embed @ W_U) + (attn_out @ W_U) + (attn_out_1 @ W_U)`\n",
        "\n",
        "We can be even more specific, and *just* look at the logit of the Potter token - this corresponds to a column of `W_U`, and so a direction in the residual stream - our logit is now a single number that is the sum of `(embed @ potter_U) + (attn_out_0 @ potter_U) + (attn_out_1 @ potter_U)`. Even better, we can decompose each attention layer output into the sum of the result of each head, and use this to get many terms.\n",
        "</details>\n",
        "\n",
        "Your mission here is to write a function to look at how much each component contributes to the correct logit. Your components are:\n",
        "\n",
        "* The direct path (i.e. the residual connections from the embedding to unembedding),\n",
        "* Each layer 0 head (via the residual connection and skipping layer 1)\n",
        "* Each layer 1 head\n",
        "\n",
        "To emphasise, these are not paths from the start to the end of the model, these are paths from the output of some component directly to the logits - we make no assumptions about how each path was calculated!\n",
        "\n",
        "A few important notes for this exercise:\n",
        "\n",
        "* Here we are just looking at the DIRECT effect on the logits, i.e. the thing that this component writes / embeds into the residual stream - if heads compose with other heads and affect logits like that, or inhibit logits for other tokens to boost the correct one we will not pick up on this!\n",
        "* By looking at just the logits corresponding to the correct token, our data is much lower dimensional because we can ignore all other tokens other than the correct next one (Dealing with a 50K vocab size is a pain!). But this comes at the cost of missing out on more subtle effects, like a head suppressing other plausible logits, to increase the log prob of the correct one.\n",
        "    * There are other situations where our job might be easier. For instance, in the IOI task (which we'll discuss shortly) we're just comparing the logits of the indirect object to the logits of the direct object, meaning we can use the **difference between these logits**, and ignore all the other logits.\n",
        "* When calculating correct output logits, we will get tensors with a dimension `(position - 1,)`, not `(position,)` - we remove the final element of the output (logits), and the first element of labels (tokens). This is because we're predicting the *next* token, and we don't know the token after the final token, so we ignore it.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - centering <code>W_U</code></summary>\n",
        "\n",
        "While we won't worry about this for this exercise, logit attribution is often more meaningful if we first center `W_U` - i.e. ensure the mean of each row writing to the output logits is zero. Log softmax is invariant when we add a constant to all the logits, so we want to control for a head that just increases all logits by the same amount. We won't do this here for ease of testing.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Question - why don't we do this to the log probs instead?</summary>\n",
        "\n",
        "Because log probs aren't linear, they go through `log_softmax`, a non-linear function.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P02LsbnYQGx0"
      },
      "source": [
        "### Exercise - build logit attribution tool\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You shouldn't spend more than 10-15 minutes on this exercise.\n",
        "> This exercise is important, but has quite a few messy einsums, so you might get more value from reading the solution than doing the exercises.\n",
        "> ```\n",
        "\n",
        "You should implement the `logit_attribution` function below. This should return the contribution of each component in the \"correct direction\". We've already given you the unembedding vectors for the correct direction, `W_U_correct_tokens` (note that we take the `[1:]` slice of tokens, for reasons discussed above).\n",
        "\n",
        "The code below this function will check your logit attribution function is working correctly, by taking the sum of logit attributions and comparing it to the actual values in the residual stream at the end of your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_nfLC7RQGx0"
      },
      "outputs": [],
      "source": [
        "def logit_attribution(\n",
        "    embed: Float[Tensor, \"seq d_model\"],\n",
        "    l1_results: Float[Tensor, \"seq nheads d_model\"],\n",
        "    l2_results: Float[Tensor, \"seq nheads d_model\"],\n",
        "    W_U: Float[Tensor, \"d_model d_vocab\"],\n",
        "    tokens: Int[Tensor, \"seq\"],\n",
        ") -> Float[Tensor, \"seq-1 n_components\"]:\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        embed: the embeddings of the tokens (i.e. token + position embeddings)\n",
        "        l1_results: the outputs of the attention heads at layer 1 (with head as one of the dimensions)\n",
        "        l2_results: the outputs of the attention heads at layer 2 (with head as one of the dimensions)\n",
        "        W_U: the unembedding matrix\n",
        "        tokens: the token ids of the sequence\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape (seq_len-1, n_components)\n",
        "        represents the concatenation (along dim=-1) of logit attributions from:\n",
        "            the direct path (seq-1,1)\n",
        "            layer 0 logits (seq-1, n_heads)\n",
        "            layer 1 logits (seq-1, n_heads)\n",
        "        so n_components = 1 + 2*n_heads\n",
        "    \"\"\"\n",
        "    W_U_correct_tokens = W_U[:, tokens[1:]]\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "text = \"We think that powerful, significantly superhuman machine intelligence is more likely than not to be created this century. If current machine learning techniques were scaled up to this level, we think they would by default produce systems that are deceptive or manipulative, and that no solid plans are known for how to avoid this.\"\n",
        "logits, cache = model.run_with_cache(text, remove_batch_dim=True)\n",
        "str_tokens = model.to_str_tokens(text)\n",
        "tokens = model.to_tokens(text)\n",
        "\n",
        "with t.inference_mode():\n",
        "    embed = cache[\"embed\"]\n",
        "    l1_results = cache[\"result\", 0]\n",
        "    l2_results = cache[\"result\", 1]\n",
        "    logit_attr = logit_attribution(embed, l1_results, l2_results, model.W_U, tokens[0])\n",
        "    # Uses fancy indexing to get a len(tokens[0])-1 length tensor, where the kth entry is the predicted logit for the correct k+1th token\n",
        "    correct_token_logits = logits[0, t.arange(len(tokens[0]) - 1), tokens[0, 1:]]\n",
        "    t.testing.assert_close(logit_attr.sum(1), correct_token_logits, atol=1e-3, rtol=0)\n",
        "    print(\"Tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpApbGrFQGx1"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def logit_attribution(\n",
        "    embed: Float[Tensor, \"seq d_model\"],\n",
        "    l1_results: Float[Tensor, \"seq nheads d_model\"],\n",
        "    l2_results: Float[Tensor, \"seq nheads d_model\"],\n",
        "    W_U: Float[Tensor, \"d_model d_vocab\"],\n",
        "    tokens: Int[Tensor, \"seq\"],\n",
        ") -> Float[Tensor, \"seq-1 n_components\"]:\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        embed: the embeddings of the tokens (i.e. token + position embeddings)\n",
        "        l1_results: the outputs of the attention heads at layer 1 (with head as one of the dimensions)\n",
        "        l2_results: the outputs of the attention heads at layer 2 (with head as one of the dimensions)\n",
        "        W_U: the unembedding matrix\n",
        "        tokens: the token ids of the sequence\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape (seq_len-1, n_components)\n",
        "        represents the concatenation (along dim=-1) of logit attributions from:\n",
        "            the direct path (seq-1,1)\n",
        "            layer 0 logits (seq-1, n_heads)\n",
        "            layer 1 logits (seq-1, n_heads)\n",
        "        so n_components = 1 + 2*n_heads\n",
        "    \"\"\"\n",
        "    W_U_correct_tokens = W_U[:, tokens[1:]]\n",
        "\n",
        "    direct_attributions = einops.einsum(W_U_correct_tokens, embed[:-1], \"emb seq, seq emb -> seq\")\n",
        "    l1_attributions = einops.einsum(W_U_correct_tokens, l1_results[:-1], \"emb seq, seq nhead emb -> seq nhead\")\n",
        "    l2_attributions = einops.einsum(W_U_correct_tokens, l2_results[:-1], \"emb seq, seq nhead emb -> seq nhead\")\n",
        "    return t.concat([direct_attributions.unsqueeze(-1), l1_attributions, l2_attributions], dim=-1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk7fQ58wQGx1"
      },
      "source": [
        "Once you've got the tests working, you can visualise the logit attributions for each path through the model. We've provided you with the helper function `plot_logit_attribution`, which presents the results in a nice way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S1lcc5kQGx1"
      },
      "outputs": [],
      "source": [
        "embed = cache[\"embed\"]\n",
        "l1_results = cache[\"result\", 0]\n",
        "l2_results = cache[\"result\", 1]\n",
        "logit_attr = logit_attribution(embed, l1_results, l2_results, model.W_U, tokens.squeeze())\n",
        "\n",
        "plot_logit_attribution(model, logit_attr, tokens, title=\"Logit attribution (demo prompt)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5agiuPXQGx2"
      },
      "source": [
        "#### Question - what is the interpretation of this plot?\n",
        "\n",
        "You should find that the most variation in the logit attribution comes from the direct path. In particular, some of the tokens in the direct path have a very high logit attribution (e.g. tokens 7, 12, 24, 38, 46, 58). Can you guess what gives them in particular such a high logit attribution?\n",
        "\n",
        "<details>\n",
        "<summary>Answer - what is special about these tokens?</summary>\n",
        "\n",
        "The tokens with very high logit attribution are the ones which are the first token in common bigrams. For instance, the highest contribution on the direct path comes from `| manip|`, because this is very likely to be followed by `|ulative|` (or presumably a different stem like `| ulation|`). `| super| -> |human|` is another example of a bigram formed when the tokenizer splits one word into multiple tokens.\n",
        "\n",
        "There are also examples that come from two different words, rather than a single word split by the tokenizer. These include:\n",
        "\n",
        "* `| more| -> | likely|` (12)\n",
        "* `| machine| -> | learning|` (24)\n",
        "* `| by| -> | default|` (38)\n",
        "* `| how| -> | to|` (58)\n",
        "\n",
        "See later for a discussion of all the ~infuriating~ fun quirks of tokenization!\n",
        "</details>\n",
        "\n",
        "Another feature of the plot - the heads in layer 1 seem to have much higher contributions than the heads in layer 0. Why do you think this might be?\n",
        "\n",
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Think about what this graph actually represents, in terms of paths through the transformer.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Answer - why might layer-1 heads have higher contributions?</summary>\n",
        "\n",
        "This is because of a point we discussed earlier - this plot doesn't pick up on things like a head's effect in composition with another head. So the attribution for layer-0 heads won't involve any composition, whereas the attributions for layer-1 heads will involve not only the single-head paths through those attention heads, but also the 2-layer compositional paths through heads in layer 0 and layer 1.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X0parA1QGx2"
      },
      "source": [
        "### Exercise - interpret logit attribution for the induction heads\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You shouldn't spend more than 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "*This exercise just involves calling `logit_attribution` and `plot_logit_attribution` with appropriate arguments - the important part is interpreting the results. Please do look at the solutions if you're stuck on the code; this part isn't important.*\n",
        "\n",
        "Perform logit attribution for your attention-only model `model`, on the `rep_cache`. What do you expect to see?\n",
        "\n",
        "<!-- Remember, you'll need to split the sequence in two, with one overlapping token (since predicting the next token involves removing the final token with no label) - your `logit_attr` should both have shape `[seq_len, 2*n_heads + 1]` (ie `[50, 25]` here). -->\n",
        "<!--\n",
        "<details>\n",
        "<summary>Note - the first plot will be pretty meaningless. Can you see why?</summary>\n",
        "\n",
        "Because the first plot shows the logit attribution for the first half of the sequence, i.e. the first occurrence of each of the tokens. Since there is no structure to this sequence (it is purely random), there is no reason to expect the heads to be doing meaningful computation. The structure lies in the second half of the sequence, when the tokens are repeated, and the heads with high logit attributions will be the ones that can perform induction.\n",
        "</details> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGq1cU72QGx2"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE - plot logit attribution for the induction sequence (i.e. using `rep_tokens` and `rep_cache`), and\n",
        "# interpret the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFMA51hLQGx2"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "seq_len = 50\n",
        "\n",
        "embed = rep_cache[\"embed\"]\n",
        "l1_results = rep_cache[\"result\", 0]\n",
        "l2_results = rep_cache[\"result\", 1]\n",
        "\n",
        "logit_attr = logit_attribution(embed, l1_results, l2_results, model.W_U, rep_tokens.squeeze())\n",
        "plot_logit_attribution(model, logit_attr, rep_tokens.squeeze(), title=\"Logit attribution (random induction prompt)\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGKkFOE_QGx3"
      },
      "source": [
        "What is the interpretation of this plot, in the context of our induction head circuit?\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "The first half of the plot is mostly meaningless, because the sequences here are random and carry no predictable pattern, and so there can't be any part of the model that is doing meaningful computation to make predictions.\n",
        "\n",
        "In the second half, we see that heads `1.4` and `1.10` have a large logit attribution score. This makes sense given our previous observation that these heads seemed to be performing induction (since they both exhibited the characteristic induction pattern), however it's worth emphasizing that this plot gives us a different kind of evidence than looking at attention patterns does, because just observing some head is attending to a particular token doesn't mean it's necessarily using that information to make a concrete prediction. Note that we see head `1.10` has a larger direct effect than `1.4`, which agrees with our attention scores result (where `1.10` also scored higher than `1.4`).\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u33uyCTTQGx3"
      },
      "source": [
        "## Hooks: Intervening on Activations\n",
        "\n",
        "Now that we've built some tools to decompose our model's output, it's time to start making causal interventions.\n",
        "\n",
        "### Ablations\n",
        "\n",
        "Let's start with a simple example: **ablation**. An ablation is a simple causal intervention on a model - we pick some part of it and set it to zero. This is a crude proxy for how much that part matters. Further, if we have some story about how a specific circuit in the model enables some capability, showing that ablating *other* parts does nothing can be strong evidence of this.\n",
        "\n",
        "As mentioned in [the glossary](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=fh-HJyz1CgUVrXuoiban6bYx), there are many ways to do ablation. We'll focus on the simplest: zero-ablation (even though it's somewhat unprincipled)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tzr_Hc8QGx3"
      },
      "source": [
        "### Exercise - induction head ablation\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should aim to spend 20-35 mins on this exercise.\n",
        "> ```\n",
        "\n",
        "The code below provides a template for performing zero-ablation on the output vectors at a particular head (i.e. the vectors we get when taking a weighted sum of the value vectors according to the attention probabilities, before projecting them up & adding them back to the residual stream). If you're confused about what different activations mean, you can refer back to [the diagram](https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/small-merm.svg).\n",
        "\n",
        "You need to do 2 things:\n",
        "\n",
        "1. Fill in `head_zero_ablation_hook` so that it performs zero-ablation on the head given by `head_index_to_ablate`.\n",
        "2. Fill in the missing code in the `get_ablation_scores` function (i.e. where you see the `raise NotImplementedError()` line), so that `loss_with_ablation` is computed as the loss of the model after ablating head `head` in layer `layer`.\n",
        "\n",
        "The rest of the `get_ablation_scores` function is designed to return a tensor of shape `(n_layers, n_heads)` containing the increase in loss from ablating each of these heads.\n",
        "\n",
        "A few notes about this function / tips on how to implement it:\n",
        "\n",
        "- You can create a temporary hook function by applying `functools.partial` to the `ablation_function`, fixing the head index to a particular value.\n",
        "- You can use `utils.get_act_name(\"z\", layer)` to get the name of the hook point (to see the full diagram of named hook points and how to get the names, you can refer to the streamlit reference page, which can be found on the left hand sidebar after you navigate to the [homepage](https://arena-chapter1-transformer-interp.streamlit.app/)).\n",
        "- See that `loss_no_ablation` is computed with the `get_log_probs` function, and that we only take the last `seq_len - 1` tokens - this is because we're dealing with sequences of length `2 * seq_len + 1` (a BOS token plus 2 repeated random sequences), and we only care about the loss on the second half of the sequence.\n",
        "- Note that we call `model.reset_hooks()` at the start of the function - this is a useful practice in general, to make sure you've not accidentally left in any hooks that might change your model's behaviour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNmFjux4QGx4"
      },
      "outputs": [],
      "source": [
        "def head_zero_ablation_hook(\n",
        "    z: Float[Tensor, \"batch seq n_heads d_head\"],\n",
        "    hook: HookPoint,\n",
        "    head_index_to_ablate: int,\n",
        ") -> None:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def get_ablation_scores(\n",
        "    model: HookedTransformer,\n",
        "    tokens: Int[Tensor, \"batch seq\"],\n",
        "    ablation_function: Callable = head_zero_ablation_hook,\n",
        ") -> Float[Tensor, \"n_layers n_heads\"]:\n",
        "    \"\"\"\n",
        "    Returns a tensor of shape (n_layers, n_heads) containing the increase in cross entropy loss from ablating the output\n",
        "    of each head.\n",
        "    \"\"\"\n",
        "    # Initialize an object to store the ablation scores\n",
        "    ablation_scores = t.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
        "\n",
        "    # Calculating loss without any ablation, to act as a baseline\n",
        "    model.reset_hooks()\n",
        "    seq_len = (tokens.shape[1] - 1) // 2\n",
        "    logits = model(tokens, return_type=\"logits\")\n",
        "    loss_no_ablation = -get_log_probs(logits, tokens)[:, -(seq_len - 1) :].mean()\n",
        "\n",
        "    for layer in tqdm(range(model.cfg.n_layers)):\n",
        "        for head in range(model.cfg.n_heads):\n",
        "            raise NotImplementedError()\n",
        "\n",
        "    return ablation_scores\n",
        "\n",
        "\n",
        "ablation_scores = get_ablation_scores(model, rep_tokens)\n",
        "tests.test_get_ablation_scores(ablation_scores, model, rep_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_roMy0_QGx4"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def head_zero_ablation_hook(\n",
        "    z: Float[Tensor, \"batch seq n_heads d_head\"],\n",
        "    hook: HookPoint,\n",
        "    head_index_to_ablate: int,\n",
        ") -> None:\n",
        "    z[:, :, head_index_to_ablate, :] = 0.0\n",
        "\n",
        "\n",
        "def get_ablation_scores(\n",
        "    model: HookedTransformer,\n",
        "    tokens: Int[Tensor, \"batch seq\"],\n",
        "    ablation_function: Callable = head_zero_ablation_hook,\n",
        ") -> Float[Tensor, \"n_layers n_heads\"]:\n",
        "    \"\"\"\n",
        "    Returns a tensor of shape (n_layers, n_heads) containing the increase in cross entropy loss from ablating the output\n",
        "    of each head.\n",
        "    \"\"\"\n",
        "    # Initialize an object to store the ablation scores\n",
        "    ablation_scores = t.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
        "\n",
        "    # Calculating loss without any ablation, to act as a baseline\n",
        "    model.reset_hooks()\n",
        "    seq_len = (tokens.shape[1] - 1) // 2\n",
        "    logits = model(tokens, return_type=\"logits\")\n",
        "    loss_no_ablation = -get_log_probs(logits, tokens)[:, -(seq_len - 1) :].mean()\n",
        "\n",
        "    for layer in tqdm(range(model.cfg.n_layers)):\n",
        "        for head in range(model.cfg.n_heads):\n",
        "            # Use functools.partial to create a temporary hook function with the head number fixed\n",
        "            temp_hook_fn = functools.partial(ablation_function, head_index_to_ablate=head)\n",
        "            # Run the model with the ablation hook\n",
        "            ablated_logits = model.run_with_hooks(tokens, fwd_hooks=[(utils.get_act_name(\"z\", layer), temp_hook_fn)])\n",
        "            # Calculate the loss difference (= negative correct logprobs), only on the last `seq_len` tokens\n",
        "            loss = -get_log_probs(ablated_logits, tokens)[:, -(seq_len - 1) :].mean()\n",
        "            # Store the result, subtracting the clean loss so that a value of zero means no change in loss\n",
        "            ablation_scores[layer, head] = loss - loss_no_ablation\n",
        "\n",
        "    return ablation_scores\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z7VvH4lQGx4"
      },
      "source": [
        "Once you've passed the tests, you can plot the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo3YdCoWQGx9"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    ablation_scores,\n",
        "    labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Logit diff\"},\n",
        "    title=\"Loss Difference After Ablating Heads\",\n",
        "    text_auto=\".2f\",\n",
        "    width=900,\n",
        "    height=350,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhkaEszWQGx9"
      },
      "source": [
        "What is your interpretation of these results?\n",
        "\n",
        "<details>\n",
        "<summary>Interpretation</summary>\n",
        "\n",
        "This tells us not just which heads are responsible for writing output to the residual stream that gets us the correct result, but **which heads play an important role in the induction circuit**.\n",
        "\n",
        "This chart tells us that - for sequences of repeated tokens - head `0.7` is by far the most important in layer 0 (which makes sense, since we observed it to be the strongest \"previous token head\"), and heads `1.4`, `1.10` are the most important in layer 1 (which makes sense, since we observed these to be the most induction-y).\n",
        "\n",
        "This is a good illustration of the kind of result which we can get from ablation, but **wouldn't be able to get from something like direct logit attribution**, because it isn't a causal intervention.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiVp2TYZQGx-"
      },
      "source": [
        "### Exercise - mean ablation\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴⚪⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should aim to spend 5-15 mins on this exercise.\n",
        "> ```\n",
        "\n",
        "An alternative to zero-ablation is **mean-ablation**, where rather than setting values to zero, we set them to be their mean across some suitable distribution (commonly we'll use the mean over some batch dimension). This can be more informative, because zero-ablation takes a model out of its normal distribution, and so the results from it aren't necessarily representative of what you'd get if you \"switched off\" the effect from some particular component. Mean ablation on the other hand works slightly better (although it does come with its own set of risks). You can read more [here](https://www.neelnanda.io/mechanistic-interpretability/glossary#:~:text=Ablation%20aka%20Knockout) or [here](https://arxiv.org/html/2404.15255v1).\n",
        "\n",
        "You should fill in the `head_mean_ablation_hook` function below, and run the code (also make sure in your previous `get_ablation_scores` function that you were actually using the `ablation_function` rather than hardcoding the zero ablation function, otherwise your code won't work here). You should see that the results are slightly cleaner, with the unimportant heads having values much closer to zero relative to the important heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCvyK2yMQGx-"
      },
      "outputs": [],
      "source": [
        "def head_mean_ablation_hook(\n",
        "    z: Float[Tensor, \"batch seq n_heads d_head\"],\n",
        "    hook: HookPoint,\n",
        "    head_index_to_ablate: int,\n",
        ") -> None:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "rep_tokens_batch = run_and_cache_model_repeated_tokens(model, seq_len=50, batch_size=10)[0]\n",
        "mean_ablation_scores = get_ablation_scores(model, rep_tokens_batch, ablation_function=head_mean_ablation_hook)\n",
        "\n",
        "imshow(\n",
        "    mean_ablation_scores,\n",
        "    labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Logit diff\"},\n",
        "    title=\"Loss Difference After Ablating Heads\",\n",
        "    text_auto=\".2f\",\n",
        "    width=900,\n",
        "    height=350,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dItvBnGkQGx-"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def head_mean_ablation_hook(\n",
        "    z: Float[Tensor, \"batch seq n_heads d_head\"],\n",
        "    hook: HookPoint,\n",
        "    head_index_to_ablate: int,\n",
        ") -> None:\n",
        "    z[:, :, head_index_to_ablate, :] = z[:, :, head_index_to_ablate, :].mean(0)\n",
        "\n",
        "\n",
        "rep_tokens_batch = run_and_cache_model_repeated_tokens(model, seq_len=50, batch_size=10)[0]\n",
        "mean_ablation_scores = get_ablation_scores(model, rep_tokens_batch, ablation_function=head_mean_ablation_hook)\n",
        "\n",
        "imshow(\n",
        "    mean_ablation_scores,\n",
        "    labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Logit diff\"},\n",
        "    title=\"Loss Difference After Ablating Heads\",\n",
        "    text_auto=\".2f\",\n",
        "    width=900,\n",
        "    height=350,\n",
        ")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN54O2auQGx_"
      },
      "source": [
        "## Bonus - understand heads 0.4 & 0.11 (very hard!)\n",
        "\n",
        "There are 2 heads which appeared strongly in our induction ablation experiments, but haven't stood out as much in the other analysis we've done in this section `0.4` and `0.11`. Can you construct causal experiments (i.e. targeted ablations) to try and figure out what these heads are doing?\n",
        "\n",
        "> Note - you might want to attempt this once you've made some headway into the next section, as this will give you a more mechanistic understanding of the induction circuit. Even once you've done that, you might still find this bonus exercise challenging, because it ventures outside of the well-defined induction circuit we've been working with and into potentially more ambiguous results. **To restate - the material here is very challenging!**\n",
        "\n",
        "<details>\n",
        "<summary>Here's a hint to get you started</summary>\n",
        "\n",
        "Look at the positions that heads `0.4` and `0.11` are attending to. Can you figure out which source positions are important to attend to for the model to perform well?\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Partial answer (and some sample code)</summary>\n",
        "\n",
        "Below is some sample code which plots the effect of ablating the inputs to heads `0.4` and `0.11` at all offset positions minus a few (e.g. the first row shows the effect on loss of mean ablating all inputs to the heads except for those that come from self-attention, and the second row shows the effect when we ablate all inputs except for those that come from the token immediately before it in the sequence).\n",
        "\n",
        "```python\n",
        "def head_z_ablation_hook(\n",
        "    z: Float[Tensor, \"batch seq n_heads d_head\"],\n",
        "    hook: HookPoint,\n",
        "    head_index_to_ablate: int,\n",
        "    seq_posns: list[int],\n",
        "    cache: ActivationCache,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    We perform ablation at the z vector, by doing the equivalent of mean ablating all the inputs to this attention head\n",
        "    except for those which come from the tokens `n` positions back, where `n` is in the `seq_posns` list.\n",
        "    \"\"\"\n",
        "    batch, seq = z.shape[:2]\n",
        "    v = cache[\"v\", hook.layer()][:, :, head_index_to_ablate]  # shape [batch seq_K d_head]\n",
        "    pattern = cache[\"pattern\", hook.layer()][:, head_index_to_ablate]  # shape [batch seq_Q seq_K]\n",
        "\n",
        "    # Get a repeated version of v, and mean ablate all but the previous token values\n",
        "    v_repeated = einops.repeat(v, \"b sK h -> b sQ sK h\", sQ=seq)\n",
        "    v_ablated = einops.repeat(v_repeated.mean(0), \"sQ sK h -> b sQ sK h\", b=batch).clone()\n",
        "    for offset in seq_posns:\n",
        "        seqQ_slice = t.arange(offset, seq)\n",
        "        v_ablated[:, seqQ_slice, seqQ_slice - offset] = v_repeated[:, seqQ_slice, seqQ_slice - offset]\n",
        "\n",
        "    # Take weighted sum of this new v, and use it to edit `z` inplace.\n",
        "    z[:, :, head_index_to_ablate] = einops.einsum(v_ablated, pattern, \"b sQ sK h, b sQ sK -> b sQ h\")\n",
        "\n",
        "\n",
        "def get_ablation_scores_cache_assisted(\n",
        "    model: HookedTransformer,\n",
        "    tokens: Int[Tensor, \"batch seq\"],\n",
        "    ablation_function: Callable = head_zero_ablation_hook,\n",
        "    seq_posns: list[int] = [0],\n",
        "    layers: list[int] = [0],\n",
        ") -> Float[Tensor, \"n_layers n_heads\"]:\n",
        "    \"\"\"\n",
        "    Version of `get_ablation_scores` which can use the cache to assist with the ablation.\n",
        "    \"\"\"\n",
        "    ablation_scores = t.zeros((len(layers), model.cfg.n_heads), device=model.cfg.device)\n",
        "\n",
        "    model.reset_hooks()\n",
        "    seq_len = (tokens.shape[1] - 1) // 2\n",
        "    logits, cache = model.run_with_cache(tokens, return_type=\"logits\")\n",
        "    loss_no_ablation = -get_log_probs(logits, tokens)[:, -(seq_len - 1) :].mean()\n",
        "\n",
        "    for layer in layers:\n",
        "        for head in range(model.cfg.n_heads):\n",
        "            temp_hook_fn = functools.partial(ablation_function, head_index_to_ablate=head, cache=cache, seq_posns=seq_posns)\n",
        "            ablated_logits = model.run_with_hooks(tokens, fwd_hooks=[(utils.get_act_name(\"z\", layer), temp_hook_fn)])\n",
        "            loss = -get_log_probs(ablated_logits, tokens)[:, -(seq_len - 1) :].mean()\n",
        "            ablation_scores[layer, head] = loss - loss_no_ablation\n",
        "\n",
        "    return ablation_scores\n",
        "\n",
        "\n",
        "rep_tokens_batch = run_and_cache_model_repeated_tokens(model, seq_len=50, batch_size=50)[0]\n",
        "\n",
        "offsets = [[0], [1], [2], [3], [1, 2], [1, 2, 3]]\n",
        "z_ablation_scores = [\n",
        "    get_ablation_scores_cache_assisted(model, rep_tokens_batch, head_z_ablation_hook, offset).squeeze()\n",
        "    for offset in tqdm(offsets)\n",
        "]\n",
        "\n",
        "imshow(\n",
        "    t.stack(z_ablation_scores),\n",
        "    labels={\"x\": \"Head\", \"y\": \"Position offset\", \"color\": \"Logit diff\"},\n",
        "    title=\"Loss Difference (ablating heads everywhere except for certain offset positions)\",\n",
        "    text_auto=\".2f\",\n",
        "    y=[str(offset) for offset in offsets],\n",
        "    width=900,\n",
        "    height=400,\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "Some observations from the result of this code:\n",
        "\n",
        "- **Head `0.7` is truly a previous token head.** The second row shows that mean ablating all its inputs except for those that come from the previous token has no effect on loss, so this is all the information it's using.\n",
        "- **Head `0.11` is only a current token head.** The first row shows that mean ablating all its inputs except for those that come from self-attending (i.e. to the current token) has no effect on loss, so this is all the information it's using.\n",
        "- **Head `0.4` is only using information from positions 1, 2 or 3 tokens back.** This is shown from the 5th row of the plot above - the effect of ablating all inputs except for those that come from tokens 1 or 2 positions back is very small. Note that it's important we draw this conclusion from an ablation experiment, not just from looking at attention patterns - because attending to a token doesn't tell you whether that token is being used for a way that's important in the context of this particular distribution (induction).\n",
        "\n",
        "Starting with `0.11` - we know that there are heads in layer 1 whose job it is to copy tokens - i.e. in sequences `[A][B]...[A][B]`, they attend from the second `[A]` back to the first `[B]` and copy its value to use as a prediction. And if head `0.11` always self-attends, then it actually makes sense to consider `(embedding of B) + (output of head 0.11 when it attends to token B)` as the \"true embedding of `B`\", since this is always the thing that the layer 1 head will be learning to copy. This idea of an **extended embedding** or **effective embedding** will come up again later in the course, when we look at GPT2-Small. As for whether the output of `0.11` is more important in the QK circuit of the layer-1 copying head, or the OV copying head, we'll leave as an exercise to the reader!\n",
        "\n",
        "Next, `0.4` - it's using information from both 1 and 2 tokens back. Using the previous token makes sense, since induction circuits contain previous token heads. But what could it be doing with the information 2 positions back? One theory we might have is that it's also creating an induction circuit, but using 3 tokens rather than 2 tokens! In other words, rather than having sequences like `[A][B]...[A][B]` where the second `[A]` attends back to \"token that came immediately after the value of this token\", we might have sequences like `[Z][A][B]...[Z][A][B]` where the second `[A]` attends back to \"token that came 2 positions after the value of the previous token\". One way to test this would be to construct random induction sequences which have a maximum of 2 repetitions, i.e. they're constructed with the first half being random sequences and the second half being pairs of randomly chosen tokens which appear in the first half adjacent to each other. To illustrate, for vocab size of 10 and half seq len of 10, we might have a sequence like:\n",
        "\n",
        "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">0 5 8 3 1 8 2 2 4 6 (5 8) (4 6) (3 1) (2 4) (0 5)</pre>\n",
        "\n",
        "Based on our theory about head `0.4`, we should expect that mean ablating it in this kind of sequence should have nearly zero effect on loss (because it's designed to support induction sequences of length at least 3), even though all the other heads which were identified as important in the induction experiment (`0.7`, `0.11`, `1.4`, `1.10`) should still be important. This is in fact what we find - you can try this for yourself with the code below.\n",
        "\n",
        "```python\n",
        "def generate_repeated_tokens_maxrep(\n",
        "    model: HookedTransformer,\n",
        "    seq_len: int,\n",
        "    batch_size: int = 1,\n",
        "    maxrep: int = 2,\n",
        ") -> Int[Tensor, \"batch_size full_seq_len\"]:\n",
        "    \"\"\"\n",
        "    Same as previous function, but contains a max number of allowed repetitions. For example, maxrep=2 means we can have\n",
        "    sequences like `[A][B]...[A][B]`, but not `[A][B][C]...[A][B][C]`.\n",
        "    \"\"\"\n",
        "    prefix = (t.ones(batch_size, 1) * model.tokenizer.bos_token_id).long()\n",
        "    rep_tokens_half = t.randint(0, model.cfg.d_vocab, (batch_size, seq_len), dtype=t.int64)\n",
        "    rep_tokens = t.cat([prefix, rep_tokens_half], dim=-1)\n",
        "    for _ in range(seq_len // maxrep + 1):\n",
        "        random_start_posn = t.randint(0, seq_len - 2, (batch_size,)).tolist()\n",
        "        rep_tokens_repeated = t.stack([rep_tokens_half[b, s : s + maxrep] for b, s in enumerate(random_start_posn)])\n",
        "        rep_tokens = t.cat([rep_tokens, rep_tokens_repeated], dim=-1)\n",
        "\n",
        "    return rep_tokens[:, : 2 * seq_len + 1].to(device)\n",
        "\n",
        "\n",
        "rep_tokens_max2 = generate_repeated_tokens_maxrep(model, seq_len=50, batch_size=50, maxrep=2)\n",
        "\n",
        "mean_ablation_scores = get_ablation_scores(model, rep_tokens_max2, ablation_fn=head_mean_ablation_hook)\n",
        "\n",
        "imshow(\n",
        "    mean_ablation_scores,\n",
        "    labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Logit diff\"},\n",
        "    title=\"Loss Difference After Ablating Heads\",\n",
        "    text_auto=\".2f\",\n",
        "    width=900,\n",
        "    height=350,\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiEIobpHQGx_"
      },
      "source": [
        "# 4️⃣ Reverse-engineering induction circuits\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand the difference between investigating a circuit by looking at activation patterns, and reverse-engineering a circuit by looking directly at the weights\n",
        "> - Use the factored matrix class to inspect the QK and OV circuits within an induction circuit\n",
        "> - Perform further exploration of induction circuits: composition scores, and targeted ablations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tud8fkJWQGyA"
      },
      "source": [
        "In previous exercises, we looked at the attention patterns and attributions of attention heads to try and identify which ones were important in the induction circuit. This might be a good way to get a feel for the circuit, but it's not a very rigorous way to understand it. It would be better described as **feature analysis**, where we observe *that* a particular head seems to be performing some task on a certain class of inputs, without identifying *why* it does so.\n",
        "\n",
        "Now we're going to do some more rigorous mechanistic analysis - digging into the weights and using them to reverse engineer the induction head algorithm and verify that it is really doing what we think it is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teNhHGcNQGyA"
      },
      "source": [
        "## Refresher - the induction circuit\n",
        "\n",
        "Before we get into the meat of this section, let's refresh the results we've gotten so far from investigating induction heads. We've found:\n",
        "\n",
        "* When fed repeated sequences of tokens, heads `1.4` and `1.10` have the characteristic induction head attention pattern of a diagonal stripe with offset `seq_len - 1`.\n",
        "    * We saw this both from the CircuitsVis results, and from the fact that these heads had high induction scores by our chosen metric (with all other heads having much lower scores).\n",
        "* We also saw that head `0.7` strongly attends to the previous token in the sequence (even on non-repeated sequences).\n",
        "* We performed **logit attribution** on the model, and found that the values written to the residual stream by heads `1.4` and `1.10` were both important for getting us correct predictions in the second half of the sequence.\n",
        "* We performed **zero-ablation** on the model, and found that heads `0.7`, `1.4` and `1.10` all resulted in a large accuracy degradation on the repeated sequence task when they were ablated.\n",
        "\n",
        "Based on all these observations, try and summarise the induction circuit and how it works, in your own words. You should try and link your explanation to the QK and OV circuits for particular heads, and describe what type (or types) of attention head composition are taking place.\n",
        "\n",
        "You can use the dropdown below to check your understanding.\n",
        "\n",
        "<details>\n",
        "<summary>My summary of the algorithm</summary>\n",
        "\n",
        "* Head `0.7` is a previous token head (the QK-circuit ensures it always attends to the previous token).\n",
        "* The OV circuit of head `0.7` writes a copy of the previous token in a *different* subspace to the one used by the embedding.\n",
        "* The output of head `0.7` is used by the *key* input of head `1.10` via K-Composition to attend to 'the source token whose previous token is the destination token'.\n",
        "* The OV-circuit of head `1.10` copies the *value* of the source token to the same output logit.\n",
        "    * Note that this is copying from the embedding subspace, *not* the `0.7` output subspace - it is not using V-Composition at all.\n",
        "* `1.4` is also performing the same role as `1.10` (so together they can be more accurate - we'll see exactly how later).\n",
        "\n",
        "To emphasise - the sophisticated hard part is computing the *attention* pattern of the induction head - this takes careful composition. The previous token and copying parts are fairly easy. This is a good illustrative example of how the QK circuits and OV circuits act semi-independently, and are often best thought of somewhat separately. And that computing the attention patterns can involve real and sophisticated computation!\n",
        "\n",
        "Below is a diagram of the induction circuit, with the heads indicated in the weight matrices.\n",
        "\n",
        "![kcomp_diagram_3.png](https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/kcomp_diagram_described_3.png)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTP26UjHQGyB"
      },
      "source": [
        "## Refresher - QK and OV circuits\n",
        "\n",
        "Before we start, a brief terminology note. I'll refer to weight matrices for a particular layer and head using superscript notation, e.g. $W_Q^{1.4}$ is the query matrix for the 4th head in layer 1, and it has shape `[d_model, d_head]` (remember that we multiply with weight matrices on the right). Similarly, attention patterns will be denoted $A^{1.4}$ (remember that these are **activations**, not parameters, since they're given by the formula $A^h = x W_{QK}^h x^T$, where $x$ is the residual stream (with shape `[seq_len, d_model]`).\n",
        "\n",
        "As a shorthand, I'll often have $A$ denote the one-hot encoding of token `A` (i.e. the vector with zeros everywhere except a one at the index of `A`), so $A^T W_E$ is the embedding vector for `A`.\n",
        "\n",
        "Lastly, I'll refer to special matrix products as follows:\n",
        "\n",
        "* $W_{OV}^{h} := W_V^{h}W_O^{h}$ is the **OV circuit** for head $h$, and $W_E W_{OV}^h W_U$ is the **full OV circuit**.\n",
        "* $W_{QK}^h := W_Q^h (W_K^h)^T$ is the **QK circuit** for head $h$, and $W_E W_{QK}^h W_E^T$ is the **full QK circuit**.\n",
        "\n",
        "Note that the order of these matrices are slightly different from the **Mathematical Frameworks** paper - this is a consequence of the way TransformerLens stores its weight matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAX55VeFQGyB"
      },
      "source": [
        "#### Question - what is the interpretation of each of the following matrices?\n",
        "\n",
        "*There are quite a lot of questions here, but they are conceptually important. If you're confused, you might want to read the answers to the first few questions and then try the later ones.*\n",
        "\n",
        "In your answers, you should describe the type of input it takes, and what the outputs represent.\n",
        "\n",
        "#### $W_{OV}^{h}$\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "$W_{OV}^{h}$ has size $(d_\\text{model}, d_\\text{model})$, it is a linear map describing **what information gets moved from source to destination, in the residual stream.**\n",
        "\n",
        "In other words, if $x$ is a vector in the residual stream, then $x^T W_{OV}^{h}$ is the vector written to the residual stream at the destination position, if the destination token only pays attention to the source token at the position of the vector $x$.\n",
        "</details>\n",
        "\n",
        "#### $W_E W_{OV}^h W_U$\n",
        "\n",
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "If $A$ is the one-hot encoding for token `A` (i.e. the vector with zeros everywhere except for a one in the position corresponding to token `A`), then think about what $A^T W_E W_{OV}^h W_U$ represents. You can evaluate this expression from left to right (e.g. start with thinking about what $A^T W_E$ represents, then multiply by the other two matrices).\n",
        "</details>\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "$W_E W_{OV}^h W_U$ has size $(d_\\text{vocab}, d_\\text{vocab})$, it is a linear map describing **what information gets moved from source to destination, in a start-to-end sense.**\n",
        "\n",
        "If $A$ is the one-hot encoding for token `A`, then:\n",
        "\n",
        "* $A^T W_E$ is the embedding vector for `A`.\n",
        "* $A^T W_E W_{OV}^h$ is the vector which would get written to the residual stream at the destination position, if the destination token only pays attention to `A`.\n",
        "* $A^T W_E W_{OV}^h W_U$ is the unembedding of this vector, i.e. the thing which gets added to the final logits.\n",
        "\n",
        "</details>\n",
        "\n",
        "#### $W_{QK}^{h}$\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "$W_{QK}^{h}$ has size $(d_\\text{model}, d_\\text{model})$, it is a bilinear form describing **where information is moved to and from** in the residual stream (i.e. which residual stream vectors attend to which others).\n",
        "\n",
        "$x_i^T W_{QK}^h x_j = (x_i^T W_Q^h) (x_j^T W_K^h)^T$ is the attention score paid by token $i$ to token $j$.\n",
        "</details>\n",
        "\n",
        "#### $W_E W_{QK}^h W_E^T$\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "$W_E W_{QK}^h W_E^T$ has size $(d_\\text{vocab}, d_\\text{vocab})$, it is a bilinear form describing **where information is moved to and from**, among words in our vocabulary (i.e. which tokens pay attention to which others).\n",
        "\n",
        "If $A$ and $B$ are one-hot encodings for tokens `A` and `B`, then $A^T W_E W_{QK}^h W_E^T B$ is the attention score paid by token `A` to token `B`:\n",
        "\n",
        "$$\n",
        "A^T \\, W_E\\, W_{QK}^{h}\\, W_E^T \\, B = \\underbrace{(A^T W_E W_Q^{h})}_{\\text{query for token } A}  \\underbrace{(B^T W_E W_K^{h})^T}_{\\text{key for token }B}\n",
        "$$\n",
        "</details>\n",
        "\n",
        "#### $W_{pos} W_{QK}^h W_{pos}^T$\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "$W_{pos} W_{QK}^h W_{pos}^T$ has size $(n_\\text{ctx}, n_\\text{ctx})$, it is a bilinear form describing **where information is moved to and from**, among tokens in our context (i.e. which token positions pay attention to other positions).\n",
        "\n",
        "If $i$ and $j$ are one-hot encodings for positions `i` and `j` (in other words they are just the ith and jth basis vectors), then $i^T W_{pos} W_{QK}^h W_{pos}^T j$ is the attention score paid by the token with position `i` to the token with position `j`:\n",
        "\n",
        "$$\n",
        "i^T \\, W_{pos}\\, W_{QK}^{h}\\, W_{pos}^T \\, j = \\underbrace{(i^T W_{pos} W_Q^{h})}_{\\text{query for i-th token}}  \\underbrace{(j^T W_{pos} W_K^{h})^T}_{\\text{key for j-th token}}\n",
        "$$\n",
        "\n",
        "</details>\n",
        "\n",
        "#### $W_E W_{OV}^{h_1} W_{QK}^{h_2} W_E^T$\n",
        "\n",
        "where $h_1$ is in an earlier layer than $h_2$.\n",
        "\n",
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "This matrix is best seen as a bilinear form of size $(d_\\text{vocab}, d_\\text{vocab})$. The $(A, B)$-th element is:\n",
        "\n",
        "$$\n",
        "(A^T W_E W_{OV}^{h_1}) W_{QK}^{h_2} (B^T W_E)^T\n",
        "$$\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "$W_E W_{OV}^{h_1} W_{QK}^{h_2} W_E^T$ has size $(d_\\text{vocab}, d_\\text{vocab})$, it is a bilinear form describing where information is moved to and from in head $h_2$, given that the **query-side vector** is formed from the output of head $h_1$. In other words, this is an instance of **Q-composition**.\n",
        "\n",
        "If $A$ and $B$ are one-hot encodings for tokens `A` and `B`, then $A^T W_E W_{OV}^{h_1} W_{QK}^{h_2} W_E^T B$ is the attention score paid **to** token `B`, **by** any token which attended strongly to an `A`-token in head $h_1$.\n",
        "\n",
        "---\n",
        "\n",
        "To further break this down, if it still seems confusing:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "A^T \\, W_E\\, W_{OV}^{h_1} W_{QK}^{h_2}\\, W_E^T \\, B &= \\underbrace{(A^T W_E W_{OV}^{h_1}W_Q^{h_2})}_{\\text{query of token which attended to A}}  \\underbrace{(B^T W_E W_K^{h_2})^T}_\\text{key of token B} \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "Note that the actual attention score will be a sum of multiple terms, not just this one (in fact, we'd have a different term for every combination of query and key input). But this term describes the **particular contribution** to the attention score from this combination of query and key input, and it might be the case that this term is the only one that matters (i.e. all other terms don't much affect the final probabilities). We'll see something exactly like this later on.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67rYIHxiQGyC"
      },
      "source": [
        "Before we start, there's a problem that we might run into when calculating all these matrices. Some of them are massive, and might not fit on our GPU. For instance, both full circuit matrices have shape $(d_\\text{vocab}, d_\\text{vocab})$, which in our case means $50278\\times 50278 \\approx 2.5\\times 10^{9}$ elements. Even if your GPU can handle this, it still seems inefficient. Is there any way we can meaningfully analyse these matrices, without actually having to calculate them?\n",
        "\n",
        "## Factored Matrix class\n",
        "\n",
        "In transformer interpretability, we often need to analyse low rank factorized matrices - a matrix $M = AB$, where M is `[large, large]`, but A is `[large, small]` and B is `[small, large]`. This is a common structure in transformers.\n",
        "\n",
        "For instance, we can factorise the OV circuit above as $W_{OV}^h = W_V^h W_O^h$, where $W_V^h$ has shape `[768, 64]` and $W_O^h$ has shape `[64, 768]`. For an even more extreme example, the full OV circuit can be written as $(W_E W_V^h) (W_O^h W_U)$, where these two matrices have shape `[50278, 64]` and `[64, 50278]` respectively. Similarly, we can write the full QK circuit as $(W_E W_Q^h) (W_E W_K^h)^T$.\n",
        "\n",
        "The `FactoredMatrix` class is a convenient way to work with these. It implements efficient algorithms for various operations on these, such as computing the trace, eigenvalues, Frobenius norm, singular value decomposition, and products with other matrices. It can (approximately) act as a drop-in replacement for the original matrix.\n",
        "\n",
        "This is all possible because knowing the factorisation of a matrix gives us a much easier way of computing its important properties. Intuitively, since $M=AB$ is a very large matrix that operates on very small subspaces, we shouldn't expect knowing the actual values $M_{ij}$ to be the most efficient way of storing it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAnuvusKQGyC"
      },
      "source": [
        "### Exercise - deriving properties of a factored matrix\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You shouldn't spend more than 10-25 minutes on this exercise.\n",
        ">\n",
        "> If you're less interested in the maths, you can skip these exercises.\n",
        "> ```\n",
        "\n",
        "To give you an idea of what kinds of properties you can easily compute if you have a factored matrix, let's try and derive some ourselves.\n",
        "\n",
        "Suppose we have $M=AB$, where $A$ has shape $(m, n)$, $B$ has shape $(n, m)$, and $m > n$. So $M$ is a size-$(m, m)$ matrix with rank at most $n$.\n",
        "\n",
        "**Question - how can you easily compute the trace of $M$?**\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "We have:\n",
        "\n",
        "$$\n",
        "\\text{Tr}(M) = \\text{Tr}(AB)\n",
        "= \\sum_{i=1}^m \\sum_{j=1}^n A_{ij} B_{ji}\n",
        "$$\n",
        "\n",
        "so evaluation of the trace is $O(mn)$.\n",
        "\n",
        "Note that, by cyclicity of the trace, we can also show that $\\text{Tr}(M) = \\text{Tr}(BA)$ (although we don't even need to calculate the product $AB$ to evaluate the trace).\n",
        "</details>\n",
        "\n",
        "**Question - how can you easily compute the eigenvalues of $M$?**\n",
        "\n",
        "(As you'll see in later exercises, eigenvalues are very important for evaluating matrices, for instance we can assess the [copying scores](https://transformer-circuits.pub/2021/framework/index.html#copying-matrix) of an OV circuit by looking at the eigenvalues of $W_{OV}$.)\n",
        "\n",
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "It's computationally cheaper to find the eigenvalues of $BA$ rather than $AB$.\n",
        "\n",
        "How are the eigenvalues of $AB$ and $BA$ related?\n",
        "</details>\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "The eigenvalues of $AB$ and $BA$ are related as follows: if $\\mathbf{v}$ is an eigenvector of $AB$ with $ABv = \\lambda \\mathbf{v}$, then $B\\mathbf{v}$ is an eigenvector of $BA$ with the same eigenvalue:\n",
        "\n",
        "$$\n",
        "BA(B\\mathbf{v}) = B (AB\\mathbf{v}) = B (\\lambda \\mathbf{v}) = \\lambda (B\\mathbf{v})\n",
        "$$\n",
        "\n",
        "This only fails when $B\\mathbf{v} = \\mathbf{0}$, but in this case $AB\\mathbf{v} = \\mathbf{0}$ so $\\lambda = 0$. Thus, we can conclude that any non-zero eigenvalues of $AB$ are also eigenvalues of $BA$.\n",
        "\n",
        "It's much computationally cheaper to compute the eigenvalues of $BA$ (since it's a much smaller matrix), and this gives us all the non-zero eigenvalues of $AB$.\n",
        "</details>\n",
        "\n",
        "**Question (hard) - how can you easily compute the SVD of $M$?**\n",
        "\n",
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "For a size-$(m, n)$ matrix with $m > n$, the [algorithmic complexity of finding SVD](https://en.wikipedia.org/wiki/Singular_value_decomposition#Numerical_approach) is $O(mn^2)$. So it's relatively cheap to find the SVD of $A$ and $B$ (complexity $mn^2$ vs $m^3$). Can you use that to find the SVD of $M$?\n",
        "</details>\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "It's much cheaper to compute the SVD of the small matrices $A$ and $B$. Denote these SVDs by:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "A &= U_A S_A V_A^T \\\\\n",
        "B &= U_B S_B V_B^T\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $U_A$ and $V_B$ are $(m, n)$, and the other matrices are $(n, n)$.\n",
        "\n",
        "Then we have:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\quad\\quad\\quad\\quad M &= AB \\\\\n",
        "&= U_A (S_A V_A^T U_B S_B) V_B^T\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Note that the matrix in the middle has size $(n, n)$ (i.e. small), so we can compute its SVD cheaply:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\; S_A V_A^T U_B S_B &= U' S' {V'}^T \\quad\\quad\\quad\\quad\\quad\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "and finally, this gives us the SVD of $M$:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\quad\\quad M &= U_A U' S' {V'}^T V_B^T \\\\\n",
        "&= U S {V'}^T\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $U = U_A U'$, $V = V_B V'$, and $S = S'$.\n",
        "\n",
        "All our SVD calculations and matrix multiplications had complexity at most $O(mn^2)$, which is much better than $O(m^3)$ (remember that we don't need to compute all the values of $U = U_A U'$, only the ones which correspond to non-zero singular values).\n",
        "</details>\n",
        "\n",
        "If you're curious, you can go to the `FactoredMatrix` documentation to see the implementation of the SVD calculation, as well as other properties and operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf3jsQcDQGyC"
      },
      "source": [
        "Now that we've discussed some of the motivations behind having a `FactoredMatrix` class, let's see it in action.\n",
        "\n",
        "### Basic Examples\n",
        "\n",
        "We can use the basic class directly - let's make a factored matrix directly and look at the basic operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liIMqS64QGyD"
      },
      "outputs": [],
      "source": [
        "A = t.randn(5, 2)\n",
        "B = t.randn(2, 5)\n",
        "AB = A @ B\n",
        "AB_factor = FactoredMatrix(A, B)\n",
        "print(\"Norms:\")\n",
        "print(AB.norm())\n",
        "print(AB_factor.norm())\n",
        "\n",
        "print(f\"Right dimension: {AB_factor.rdim}, Left dimension: {AB_factor.ldim}, Hidden dimension: {AB_factor.mdim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AynsKTzcQGyD"
      },
      "source": [
        "We can also look at the eigenvalues and singular values of the matrix. Note that, because the matrix is rank 2 but 5 by 5, the final 3 eigenvalues and singular values are zero - the factored class omits the zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DCCBkh0QGyD"
      },
      "outputs": [],
      "source": [
        "print(\"Eigenvalues:\")\n",
        "print(t.linalg.eig(AB).eigenvalues)\n",
        "print(AB_factor.eigenvalues)\n",
        "\n",
        "print(\"\\nSingular Values:\")\n",
        "print(t.linalg.svd(AB).S)\n",
        "print(AB_factor.S)\n",
        "\n",
        "print(\"\\nFull SVD:\")\n",
        "print(AB_factor.svd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7AJgnz7QGyD"
      },
      "source": [
        "<details>\n",
        "<summary>Aside - the sizes of objects returned by the SVD method.</summary>\n",
        "\n",
        "If $M = USV^T$, and `M.shape = (m, n)` and the rank is `r`, then the SVD method returns the matrices $U, S, V$. They have shape `(m, r)`, `(r,)`, and `(n, r)` respectively, because:\n",
        "\n",
        "* We don't bother storing the off-diagonal entries of $S$, since they're all zero.\n",
        "* We don't bother storing the columns of $U$ and $V$ which correspond to zero singular values, since these won't affect the value of $USV^T$.\n",
        "</details>\n",
        "\n",
        "We can multiply a factored matrix with an unfactored matrix to get another factored matrix (as in example below). We can also multiply two factored matrices together to get another factored matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTJWotTKQGyE"
      },
      "outputs": [],
      "source": [
        "C = t.randn(5, 300)\n",
        "ABC = AB @ C\n",
        "ABC_factor = AB_factor @ C\n",
        "\n",
        "print(f\"Unfactored: shape={ABC.shape}, norm={ABC.norm()}\")\n",
        "print(f\"Factored: shape={ABC_factor.shape}, norm={ABC_factor.norm()}\")\n",
        "print(f\"\\nRight dimension: {ABC_factor.rdim}, Left dimension: {ABC_factor.ldim}, Hidden dimension: {ABC_factor.mdim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCSCd3r5QGyE"
      },
      "source": [
        "If we want to collapse this back to an unfactored matrix, we can use the `AB` property to get the product:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFM1bzAaQGyE"
      },
      "outputs": [],
      "source": [
        "AB_unfactored = AB_factor.AB\n",
        "t.testing.assert_close(AB_unfactored, AB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqqDBTe0QGyF"
      },
      "source": [
        "## Reverse-engineering circuits\n",
        "\n",
        "Within our induction circuit, we have four individual circuits: the OV and QK circuits in our previous token head, and the OV and QK circuits in our induction head. In the following sections of the exercise, we'll reverse-engineer each of these circuits in turn.\n",
        "\n",
        "* In the section **OV copying circuit**, we'll look at the layer-1 OV circuit.\n",
        "* In the section **QK prev-token circuit**, we'll look at the layer-0 QK circuit.\n",
        "* The third section (**K-composition**) is a bit trickier, because it involves looking at the composition of the layer-0 OV circuit **and** layer-1 QK circuit. We will have to do two things:\n",
        "    1. Show that these two circuits are composing (i.e. that the output of the layer-0 OV circuit is the main determinant of the key vectors in the layer-1 QK circuit).\n",
        "    2. Show that the joint operation of these two circuits is \"make the second instance of a token attend to the token *following* an earlier instance.\n",
        "\n",
        "The dropdown below contains a diagram explaining how the three sections relate to the different components of the induction circuit. You might have to open it in a new tab to see it clearly.\n",
        "\n",
        "<details>\n",
        "<summary>Diagram</summary>\n",
        "\n",
        "![kcomp](https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/kcomp_diagram_described_2_new.png)\n",
        "</details>\n",
        "\n",
        "After this, we'll have a look at composition scores, which are a more mathematically justified way of showing that two attention heads are composing (without having to look at their behaviour on any particular class of inputs, since it is a property of the actual model weights)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A6oqaOjQGyF"
      },
      "source": [
        "## [1] OV copying circuit\n",
        "\n",
        "Let's start with an easy parts of the circuit - the copying OV circuit of `1.4` and `1.10`. Let's start with head 4. The only interpretable (read: **privileged basis**) things here are the input tokens and output logits, so we want to study the matrix:\n",
        "\n",
        "$$\n",
        "W_E W_{OV}^{1.4} W_U\n",
        "$$\n",
        "\n",
        "(and same for `1.10`). This is the $(d_\\text{vocab}, d_\\text{vocab})$-shape matrix that combines with the attention pattern to get us from input to output.\n",
        "\n",
        "We want to calculate this matrix, and inspect it. We should find that its diagonal values are very high, and its non-diagonal values are much lower.\n",
        "\n",
        "**Question - why should we expect this observation?** (you may find it helpful to refer back to the previous section, where you described what the interpretation of different matrices was.)\n",
        "\n",
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Suppose our repeating sequence is `A B ... A B`. Let $A$, $B$ be the corresponding one-hot encoded tokens. The `B`-th row of this matrix is:\n",
        "\n",
        "$$\n",
        "B^T W_E W_{OV}^{1.4} W_U\n",
        "$$\n",
        "\n",
        "What is the interpretation of this expression, in the context of our attention head?\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "If our repeating sequence is `A B ... A B`, then:\n",
        "\n",
        "$$\n",
        "B^T W_E W_{OV}^{1.4} W_U\n",
        "$$\n",
        "\n",
        "is the **vector of logits which gets moved from the first `B` token to the second `A` token, to be used as the prediction for the token following the second `A` token**. It should result in a high prediction for `B`, and a low prediction for everything else. In other words, the `(B, X)`-th element of this matrix should be highest for `X=B`, which is exactly what we claimed.\n",
        "\n",
        "If this still seems confusing, the diagram below might help:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/kcomp_diagram_described-OV-v3.png\" width=\"750\">\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5b18WQXQGyG"
      },
      "source": [
        "### Exercise - compute OV circuit for `1.4`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "*This is the first of several similar exercises where you calculate a circuit by multiplying matrices. This exercise is pretty important (in particular, you should make sure you understand what this matrix represents and why we're interested in it), but the actual calculation shouldn't take very long.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWGLmc1OQGyG"
      },
      "source": [
        "You should compute it as a `FactoredMatrix` object.\n",
        "\n",
        "Remember, you can access the model's weights directly e.g. using `model.W_E` or `model.W_Q` (the latter gives you all the `W_Q` matrices, indexed by layer and head)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2SVejb1QGyG"
      },
      "outputs": [],
      "source": [
        "head_index = 4\n",
        "layer = 1\n",
        "\n",
        "# YOUR CODE HERE - complete the `full_OV_circuit` object\n",
        "\n",
        "tests.test_full_OV_circuit(full_OV_circuit, model, layer, head_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arPIQv5PQGyH"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to use this class to compute a product of more than 2 matrices.</summary>\n",
        "\n",
        "You can compute it directly, as:\n",
        "\n",
        "```python\n",
        "full_OV_circuit = FactoredMatrix(W_E @ W_V, W_O @ W_U)\n",
        "```\n",
        "\n",
        "Alternatively, another nice feature about the `FactoredMatrix` class is that you can chain together matrix multiplications. The following code defines exactly the same `FactoredMatrix` object:\n",
        "\n",
        "```python\n",
        "OV_circuit = FactoredMatrix(W_V, W_O)\n",
        "full_OV_circuit = W_E @ OV_circuit @ W_U\n",
        "```\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "head_index = 4\n",
        "layer = 1\n",
        "\n",
        "W_O = model.W_O[layer, head_index]\n",
        "W_V = model.W_V[layer, head_index]\n",
        "W_E = model.W_E\n",
        "W_U = model.W_U\n",
        "\n",
        "OV_circuit = FactoredMatrix(W_V, W_O)\n",
        "full_OV_circuit = W_E @ OV_circuit @ W_U\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN4ZoY3xQGyH"
      },
      "source": [
        "Now we want to check that this matrix is the identity. Since it's in factored matrix form, this is a bit tricky, but there are still things we can do.\n",
        "\n",
        "First, to validate that it looks diagonal-ish, let's pick 200 random rows and columns and visualise that - it should at least look identity-ish here! We're using the indexing method of the `FactoredMatrix` class - you can index into it before returning the actual `.AB` value, to avoid having to compute the whole thing (we take advantage of the fact that `A[left_indices, :] @ B[:, right_indices]` is the same as `(A @ B)[left_indices, right_indices]`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHDzhJlrQGyH"
      },
      "outputs": [],
      "source": [
        "indices = t.randint(0, model.cfg.d_vocab, (200,))\n",
        "full_OV_circuit_sample = full_OV_circuit[indices, indices].AB\n",
        "\n",
        "imshow(\n",
        "    full_OV_circuit_sample,\n",
        "    labels={\"x\": \"Logits on output token\", \"y\": \"Input token\"},\n",
        "    title=\"Full OV circuit for copying head\",\n",
        "    width=700,\n",
        "    height=600,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URzr_AiJQGyH"
      },
      "source": [
        "<details>\n",
        "<summary>Aside - indexing factored matrices</summary>\n",
        "\n",
        "Yet another nice thing about factored matrices is that you can evaluate small submatrices without having to compute the entire matrix. This is based on the fact that the `[i, j]`-th element of matrix `AB` is `A[i, :] @ B[:, j]`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCWed23cQGyH"
      },
      "source": [
        "### Exercise - compute circuit accuracy\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend approximately 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "When you index a factored matrix, you get back another factored matrix. So rather than explicitly calculating `A[left_indices, :] @ B[:, left_indices]`, we can just write `AB[left_indices, left_indices]`.\n",
        "\n",
        "You should observe a pretty distinct diagonal pattern here, which is a good sign. However, the matrix is pretty noisy so it probably won't be exactly the identity. Instead, we should come up with a summary statistic to capture a rough sense of \"closeness to the identity\".\n",
        "\n",
        "**Accuracy** is a good summary statistic - what fraction of the time is the largest logit on the diagonal? Even if there's lots of noise, you'd probably still expect the largest logit to be on the diagonal a good deal of the time.\n",
        "\n",
        "If you're on a Colab or have a powerful GPU, you should be able to compute the full matrix and perform this test. However, it's better practice to iterate through this matrix when we can, so that we avoid CUDA issues. We've given you a `batch_size` argument in the function below, and you should try to only explicitly calculate matrices of size `batch_size * d_vocab` rather than the massive matrix of `d_vocab * d_vocab`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zg8aKU44QGyI"
      },
      "outputs": [],
      "source": [
        "def top_1_acc(full_OV_circuit: FactoredMatrix, batch_size: int = 1000) -> float:\n",
        "    \"\"\"\n",
        "    Return the fraction of the time that the maximum value is on the circuit diagonal.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "print(f\"Fraction of the time that the best logit is on the diagonal: {top_1_acc(full_OV_circuit):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJax6avBQGyI"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure whether to take the argmax over rows or columns.</summary>\n",
        "\n",
        "The OV circuit is defined as `W_E @ W_OV @ W_U`. We can see the i-th row `W_E[i] @ W_OV @ W_U` as the vector representing **the logit vector added at any token which attends to the `i`-th token**, via the attention head with OV matrix `W_OV`.\n",
        "\n",
        "So we want to take the argmax over rows (i.e. over `dim=1`), because we're interested in the number of tokens `tok` in the vocabulary such that when `tok` is attended to, it is also the top prediction.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def top_1_acc(full_OV_circuit: FactoredMatrix, batch_size: int = 1000) -> float:\n",
        "    \"\"\"\n",
        "    Return the fraction of the time that the maximum value is on the circuit diagonal.\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "\n",
        "    for indices in t.split(t.arange(full_OV_circuit.shape[0], device=device), batch_size):\n",
        "        AB_slice = full_OV_circuit[indices].AB\n",
        "        total += (t.argmax(AB_slice, dim=1) == indices).float().sum().item()\n",
        "\n",
        "    return total / full_OV_circuit.shape[0]\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB6uxfASQGyI"
      },
      "source": [
        "This should return about 30.79% - pretty underwhelming. It goes up to 47.73% for top-5, but still not great. What's up with that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QyGQc_AQGyI"
      },
      "source": [
        "### Exercise - compute effective circuit\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You shouldn't spend more than 5-10 minutes on this exercise.\n",
        "> This exercise should be very short; it only requires 2 lines of code. Understanding it conceptually is more important than the actual coding.\n",
        "> ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vde5gtpEQGyJ"
      },
      "source": [
        "Now we return to why we have *two* induction heads. If both have the same attention pattern, the effective OV circuit is actually $W_E(W_V^{1.4}W_O^{1.4}+W_V^{1.10}W_O^{1.10})W_U$, and this is what matters. So let's re-run our analysis on this!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/effective_ov_circuit.png\" width=\"650\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqq5KJgcQGyJ"
      },
      "source": [
        "<details>\n",
        "<summary>Question - why might the model want to split the circuit across two heads?</summary>\n",
        "\n",
        "Because $W_V W_O$ is a rank 64 matrix. The sum of two is a rank 128 matrix. This can be a significantly better approximation to the desired 50K x 50K matrix!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8MT5rxLQGyJ"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE - compute the effective OV circuit, and run `top_1_acc` on it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SalPbQoUQGyK"
      },
      "source": [
        "<details>\n",
        "<summary>Expected output</summary>\n",
        "\n",
        "You should get an accuracy of 95.6% for top-1 - much better!\n",
        "\n",
        "Note that you can also try top 5 accuracy, which improves your result to 98%.\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "W_O_both = einops.rearrange(model.W_O[1, [4, 10]], \"head d_head d_model -> (head d_head) d_model\")\n",
        "W_V_both = einops.rearrange(model.W_V[1, [4, 10]], \"head d_model d_head -> d_model (head d_head)\")\n",
        "\n",
        "W_OV_eff = W_E @ FactoredMatrix(W_V_both, W_O_both) @ W_U\n",
        "\n",
        "print(f\"Fraction of the time that the best logit is on the diagonal: {top_1_acc(W_OV_eff):.4f}\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX-avY-YQGyK"
      },
      "source": [
        "## [2] QK prev-token circuit\n",
        "\n",
        "The other easy circuit is the QK-circuit of L0H7 - how does it know to be a previous token circuit?\n",
        "\n",
        "We can multiply out the full QK circuit via the positional embeddings:\n",
        "\n",
        "$$\n",
        "W_\\text{pos} W_Q^{0.7} (W_K^{0.7})^T W_\\text{pos}^T\n",
        "$$\n",
        "\n",
        "to get a matrix `pos_by_pos` of shape `[max_ctx, max_ctx]` (max ctx = max context length, i.e. maximum length of a sequence we're allowing, which is set by our choice of dimensions in $W_\\text{pos}$).\n",
        "\n",
        "Note that in this case, our max context window is 2048 (we can check this via `model.cfg.n_ctx`). This is much smaller than the 50k-size matrices we were working with in the previous section, so we shouldn't need to use the factored matrix class here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyQ1qz1HQGyK"
      },
      "source": [
        "### Exercise - interpret full QK-circuit for `0.7`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You shouldn't spend more than 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "The code below plots the full QK circuit for head `0.7` (including a scaling and softmax step, which is meant to mirror how the QK bilinear form will be used in actual attention layers). You should run the code, and interpret the results in the context of the induction circuit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COzwvYJhQGyK"
      },
      "outputs": [],
      "source": [
        "layer = 0\n",
        "head_index = 7\n",
        "\n",
        "# Compute full QK matrix (for positional embeddings)\n",
        "W_pos = model.W_pos\n",
        "W_QK = model.W_Q[layer, head_index] @ model.W_K[layer, head_index].T\n",
        "pos_by_pos_scores = W_pos @ W_QK @ W_pos.T\n",
        "\n",
        "# Mask, scale and softmax the scores\n",
        "mask = t.tril(t.ones_like(pos_by_pos_scores)).bool()\n",
        "pos_by_pos_pattern = t.where(mask, pos_by_pos_scores / model.cfg.d_head**0.5, -1.0e6).softmax(-1)\n",
        "\n",
        "# Plot the results\n",
        "print(f\"Avg lower-diagonal value: {pos_by_pos_pattern.diag(-1).mean():.4f}\")\n",
        "imshow(\n",
        "    utils.to_numpy(pos_by_pos_pattern[:200, :200]),\n",
        "    labels={\"x\": \"Key\", \"y\": \"Query\"},\n",
        "    title=\"Attention patterns for prev-token QK circuit, first 100 indices\",\n",
        "    width=700,\n",
        "    height=600,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCCw7pCQQGyL"
      },
      "source": [
        "## [3] K-composition circuit\n",
        "\n",
        "We now dig into the hard part of the circuit - demonstrating the K-Composition between the previous token head and the induction head.\n",
        "\n",
        "#### Splitting activations\n",
        "\n",
        "We can repeat the trick from the logit attribution scores. The QK-input for layer 1 is the sum of 14 terms (2+n_heads) - the token embedding, the positional embedding, and the results of each layer 0 head. So for each head $\\text{H}$ in layer 1, the query tensor (ditto key) corresponding to sequence position $i$ is:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "x W^\\text{1.H}_Q &= (e + pe + \\sum_{h=0}^{11} x^\\text{0.h}) W^\\text{1.H}_Q \\\\\n",
        "&= e W^\\text{1.H}_Q + pe W^\\text{1.H}_Q + \\sum_{h=0}^{11} x^\\text{0.h} W^\\text{1.H}_Q\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "where $e$ stands for the token embedding, $pe$ for the positional embedding, and $x^\\text{0.h}$ for the output of head $h$ in layer 0 (and the sum of these tensors equals the residual stream $x$). All these tensors have shape `[seq, d_model]`. So we can treat the expression above as a sum of matrix multiplications `[seq, d_model] @ [d_model, d_head] -> [seq, d_head]`.\n",
        "\n",
        "For ease of notation, I'll refer to the 14 inputs as $(y_0, y_1, ..., y_{13})$ rather than $(e, pe, x^\\text{0.h}, ..., x^{h.11})$. So we have:\n",
        "\n",
        "$$\n",
        "x W^h_Q = \\sum_{i=0}^{13} y_i W^h_Q\n",
        "$$\n",
        "\n",
        "with each $y_i$ having shape `[seq, d_model]`, and the sum of $y_i$s being the full residual stream $x$. Here is a diagram to illustrate:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/components.png\" width=\"520\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3tSGy-dQGyL"
      },
      "source": [
        "### Exercise - analyse the relative importance\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You shouldn't spend more than 15-25 minutes on these exercises.\n",
        "> Most of these functions just involve indexing and einsums, but conceptual understanding / figuring out exactly what the question is asking for is the hard part!\n",
        "> ```\n",
        "\n",
        "We can now analyse the relative importance of these 14 terms! A very crude measure is to take the norm of each term (by component and position).\n",
        "\n",
        "Note that this is a pretty dodgy metric - q and k are not inherently interpretable! But it can be a good and easy-to-compute proxy.\n",
        "\n",
        "<details>\n",
        "<summary>Question - why are Q and K not inherently interpretable? Why might the norm be a good metric in spite of this?</summary>\n",
        "\n",
        "They are not inherently interpretable because they operate on the residual stream, which doesn't have a **privileged basis**. You could stick a rotation matrix $R$ after all of the $Q$, $K$ and $V$ weights (and stick a rotation matrix before everything that writes to the residual stream), and the model would still behave exactly the same.\n",
        "\n",
        "The reason taking the norm is still a reasonable thing to do is that, despite the individual elements of these vectors not being inherently interpretable, it's still a safe bet that if they are larger than they will have a greater overall effect on the residual stream. So looking at the norm doesn't tell us how they work, but it does indicate which ones are more important.\n",
        "</details>\n",
        "\n",
        "Fill in the functions below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srxlT27OQGyM"
      },
      "outputs": [],
      "source": [
        "def decompose_qk_input(cache: ActivationCache) -> Float[Tensor, \"n_heads+2 posn d_model\"]:\n",
        "    \"\"\"\n",
        "    Retrieves all the input tensors to the first attention layer, and concatenates them along the 0th dim.\n",
        "\n",
        "    The [i, :, :]th element is y_i (from notation above). The sum of these tensors along the 0th dim should\n",
        "    be the input to the first attention layer.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def decompose_q(\n",
        "    decomposed_qk_input: Float[Tensor, \"n_heads+2 posn d_model\"],\n",
        "    ind_head_index: int,\n",
        "    model: HookedTransformer,\n",
        ") -> Float[Tensor, \"n_heads+2 posn d_head\"]:\n",
        "    \"\"\"\n",
        "    Computes the tensor of query vectors for each decomposed QK input.\n",
        "\n",
        "    The [i, :, :]th element is y_i @ W_Q (so the sum along axis 0 is just the q-values).\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def decompose_k(\n",
        "    decomposed_qk_input: Float[Tensor, \"n_heads+2 posn d_model\"],\n",
        "    ind_head_index: int,\n",
        "    model: HookedTransformer,\n",
        ") -> Float[Tensor, \"n_heads+2 posn d_head\"]:\n",
        "    \"\"\"\n",
        "    Computes the tensor of key vectors for each decomposed QK input.\n",
        "\n",
        "    The [i, :, :]th element is y_i @ W_K(so the sum along axis 0 is just the k-values)\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "# Recompute rep tokens/logits/cache, if we haven't already\n",
        "seq_len = 50\n",
        "batch_size = 1\n",
        "(rep_tokens, rep_logits, rep_cache) = run_and_cache_model_repeated_tokens(model, seq_len, batch_size)\n",
        "rep_cache.remove_batch_dim()\n",
        "\n",
        "ind_head_index = 4\n",
        "\n",
        "# First we get decomposed q and k input, and check they're what we expect\n",
        "decomposed_qk_input = decompose_qk_input(rep_cache)\n",
        "decomposed_q = decompose_q(decomposed_qk_input, ind_head_index, model)\n",
        "decomposed_k = decompose_k(decomposed_qk_input, ind_head_index, model)\n",
        "t.testing.assert_close(\n",
        "    decomposed_qk_input.sum(0), rep_cache[\"resid_pre\", 1] + rep_cache[\"pos_embed\"], rtol=0.01, atol=1e-05\n",
        ")\n",
        "t.testing.assert_close(decomposed_q.sum(0), rep_cache[\"q\", 1][:, ind_head_index], rtol=0.01, atol=0.001)\n",
        "t.testing.assert_close(decomposed_k.sum(0), rep_cache[\"k\", 1][:, ind_head_index], rtol=0.01, atol=0.01)\n",
        "\n",
        "# Second, we plot our results\n",
        "component_labels = [\"Embed\", \"PosEmbed\"] + [f\"0.{h}\" for h in range(model.cfg.n_heads)]\n",
        "for decomposed_input, name in [(decomposed_q, \"query\"), (decomposed_k, \"key\")]:\n",
        "    imshow(\n",
        "        utils.to_numpy(decomposed_input.pow(2).sum([-1])),\n",
        "        labels={\"x\": \"Position\", \"y\": \"Component\"},\n",
        "        title=f\"Norms of components of {name}\",\n",
        "        y=component_labels,\n",
        "        width=800,\n",
        "        height=400,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt-jWboiQGyM"
      },
      "source": [
        "<details>\n",
        "<summary>What you should see</summary>\n",
        "\n",
        "\n",
        "You should see that the most important query components are the token and positional embeddings. The most important key components are those from $y_9$, which is $x_7$, i.e. from head `0.7`.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>A technical note on the positional embeddings - optional, feel free to skip this.</summary>\n",
        "\n",
        "You might be wondering why the tests compare the decomposed qk sum with the sum of the `resid_pre + pos_embed`, rather than just `resid_pre`. The answer lies in how we defined the transformer, specifically in this line from the config:\n",
        "\n",
        "```python\n",
        "positional_embedding_type=\"shortformer\"\n",
        "```\n",
        "\n",
        "The result of this is that the positional embedding isn't added to the residual stream. Instead, it's added as inputs to the Q and K calculation (i.e. we calculate `(resid_pre + pos_embed) @ W_Q` and same for `W_K`), but **not** as inputs to the V calculation (i.e. we just calculate `resid_pre @ W_V`). This isn't actually how attention works in general, but for our purposes it makes the analysis of induction heads cleaner because we don't have positional embeddings interfering with the OV circuit.\n",
        "\n",
        "**Question - this type of embedding actually makes it impossible for attention heads to form via Q-composition. Can you see why?**\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def decompose_qk_input(cache: ActivationCache) -> Float[Tensor, \"n_heads+2 posn d_model\"]:\n",
        "    \"\"\"\n",
        "    Retrieves all the input tensors to the first attention layer, and concatenates them along the 0th dim.\n",
        "\n",
        "    The [i, :, :]th element is y_i (from notation above). The sum of these tensors along the 0th dim should\n",
        "    be the input to the first attention layer.\n",
        "    \"\"\"\n",
        "    y0 = cache[\"embed\"].unsqueeze(0)  # shape (1, seq, d_model)\n",
        "    y1 = cache[\"pos_embed\"].unsqueeze(0)  # shape (1, seq, d_model)\n",
        "    y_rest = cache[\"result\", 0].transpose(0, 1)  # shape (12, seq, d_model)\n",
        "\n",
        "    return t.concat([y0, y1, y_rest], dim=0)\n",
        "\n",
        "\n",
        "def decompose_q(\n",
        "    decomposed_qk_input: Float[Tensor, \"n_heads+2 posn d_model\"],\n",
        "    ind_head_index: int,\n",
        "    model: HookedTransformer,\n",
        ") -> Float[Tensor, \"n_heads+2 posn d_head\"]:\n",
        "    \"\"\"\n",
        "    Computes the tensor of query vectors for each decomposed QK input.\n",
        "\n",
        "    The [i, :, :]th element is y_i @ W_Q (so the sum along axis 0 is just the q-values).\n",
        "    \"\"\"\n",
        "    W_Q = model.W_Q[1, ind_head_index]\n",
        "\n",
        "    return einops.einsum(decomposed_qk_input, W_Q, \"n seq d_model, d_model d_head -> n seq d_head\")\n",
        "\n",
        "\n",
        "def decompose_k(\n",
        "    decomposed_qk_input: Float[Tensor, \"n_heads+2 posn d_model\"],\n",
        "    ind_head_index: int,\n",
        "    model: HookedTransformer,\n",
        ") -> Float[Tensor, \"n_heads+2 posn d_head\"]:\n",
        "    \"\"\"\n",
        "    Computes the tensor of key vectors for each decomposed QK input.\n",
        "\n",
        "    The [i, :, :]th element is y_i @ W_K(so the sum along axis 0 is just the k-values)\n",
        "    \"\"\"\n",
        "    W_K = model.W_K[1, ind_head_index]\n",
        "\n",
        "    return einops.einsum(decomposed_qk_input, W_K, \"n seq d_model, d_model d_head -> n seq d_head\")\n",
        "\n",
        "\n",
        "# Recompute rep tokens/logits/cache, if we haven't already\n",
        "seq_len = 50\n",
        "batch_size = 1\n",
        "(rep_tokens, rep_logits, rep_cache) = run_and_cache_model_repeated_tokens(model, seq_len, batch_size)\n",
        "rep_cache.remove_batch_dim()\n",
        "\n",
        "ind_head_index = 4\n",
        "\n",
        "# First we get decomposed q and k input, and check they're what we expect\n",
        "decomposed_qk_input = decompose_qk_input(rep_cache)\n",
        "decomposed_q = decompose_q(decomposed_qk_input, ind_head_index, model)\n",
        "decomposed_k = decompose_k(decomposed_qk_input, ind_head_index, model)\n",
        "t.testing.assert_close(\n",
        "    decomposed_qk_input.sum(0), rep_cache[\"resid_pre\", 1] + rep_cache[\"pos_embed\"], rtol=0.01, atol=1e-05\n",
        ")\n",
        "t.testing.assert_close(decomposed_q.sum(0), rep_cache[\"q\", 1][:, ind_head_index], rtol=0.01, atol=0.001)\n",
        "t.testing.assert_close(decomposed_k.sum(0), rep_cache[\"k\", 1][:, ind_head_index], rtol=0.01, atol=0.01)\n",
        "\n",
        "# Second, we plot our results\n",
        "component_labels = [\"Embed\", \"PosEmbed\"] + [f\"0.{h}\" for h in range(model.cfg.n_heads)]\n",
        "for decomposed_input, name in [(decomposed_q, \"query\"), (decomposed_k, \"key\")]:\n",
        "    imshow(\n",
        "        utils.to_numpy(decomposed_input.pow(2).sum([-1])),\n",
        "        labels={\"x\": \"Position\", \"y\": \"Component\"},\n",
        "        title=f\"Norms of components of {name}\",\n",
        "        y=component_labels,\n",
        "        width=800,\n",
        "        height=400,\n",
        "    )\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJEDJV5kQGyN"
      },
      "source": [
        "This tells us which heads are probably important, but we can do better than that. Rather than looking at the query and key components separately, we can see how they combine together - i.e. take the decomposed attention scores.\n",
        "\n",
        "This is a bilinear function of q and k, and so we will end up with a `decomposed_scores` tensor with shape `[query_component, key_component, query_pos, key_pos]`, where summing along BOTH of the first axes will give us the original attention scores (pre-mask)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLh1J-yaQGyN"
      },
      "source": [
        "### Exercise - decompose attention scores\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You shouldn't spend more than 5-10 minutes on this exercise.\n",
        "> Having already done the previous exercises, this one should be easier.\n",
        "> ```\n",
        "\n",
        "Implement the function giving the decomposed scores (remember to scale by `sqrt(d_head)`!) For now, don't mask it.\n",
        "\n",
        "<details>\n",
        "<summary>Question - why do I focus on the attention scores, not the attention pattern? (i.e. pre softmax not post softmax)</summary>\n",
        "\n",
        "Because the decomposition trick *only* works for things that are linear - softmax isn't linear and so we can no longer consider each component independently.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm confused about what we're doing / why we're doing it.</summary>\n",
        "\n",
        "Remember that each of our components writes to the residual stream separately. So after layer 1, we have:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/components.png\" width=\"650\">\n",
        "\n",
        "We're particularly interested in the attention scores computed in head `1.4`, and how they depend on the inputs into that head. We've already decomposed the residual stream value $x$ into its terms $e$, $pe$, and $x^ 0$ through $x^{11}$ (which we've labelled $y_0, ..., y_{13}$ for simplicity), and we've done the same for key and query terms. We can picture these terms being passed into head `1.4` as:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/components-2.png\" width=\"650\">\n",
        "\n",
        "So when we expand `attn_scores` out in full, they are a sum of $14^2 = 196$ terms - one for each combination of `(query_component, key_component)`.\n",
        "\n",
        "---\n",
        "\n",
        "#### Why is this decomposition useful?\n",
        "\n",
        "We have a theory about a particular circuit in our model. We think that head `1.4` is an induction head, and the most important components that feed into this head are the prev token head `0.7` (as key) and the token embedding (as query). This is already supported by the evidence of our magnitude plots above (because we saw that `0.7` as key and token embeddings as query were large), but we still don't know how this particular key and query work **together**; we've only looked at them separately.\n",
        "\n",
        "By decomposing `attn_scores` like this, we can check whether the contribution from combination `(query=tok_emb, key=0.7)` is indeed producing the characteristic induction head pattern which we've observed (and the other 195 terms don't really matter).\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f57ZgwNQGyN"
      },
      "outputs": [],
      "source": [
        "def decompose_attn_scores(\n",
        "    decomposed_q: Float[Tensor, \"q_comp q_pos d_head\"],\n",
        "    decomposed_k: Float[Tensor, \"k_comp k_pos d_head\"],\n",
        "    model: HookedTransformer,\n",
        ") -> Float[Tensor, \"q_comp k_comp q_pos k_pos\"]:\n",
        "    \"\"\"\n",
        "    Output is decomposed_scores with shape [query_component, key_component, query_pos, key_pos]\n",
        "\n",
        "    The [i, j, 0, 0]th element is y_i @ W_QK @ y_j^T (so the sum along both first axes are the attention scores)\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_decompose_attn_scores(decompose_attn_scores, decomposed_q, decomposed_k, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae2K1PjOQGyO"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def decompose_attn_scores(\n",
        "    decomposed_q: Float[Tensor, \"q_comp q_pos d_head\"],\n",
        "    decomposed_k: Float[Tensor, \"k_comp k_pos d_head\"],\n",
        "    model: HookedTransformer,\n",
        ") -> Float[Tensor, \"q_comp k_comp q_pos k_pos\"]:\n",
        "    \"\"\"\n",
        "    Output is decomposed_scores with shape [query_component, key_component, query_pos, key_pos]\n",
        "\n",
        "    The [i, j, 0, 0]th element is y_i @ W_QK @ y_j^T (so the sum along both first axes are the attention scores)\n",
        "    \"\"\"\n",
        "    return einops.einsum(\n",
        "        decomposed_q,\n",
        "        decomposed_k,\n",
        "        \"q_comp q_pos d_head, k_comp k_pos d_head -> q_comp k_comp q_pos k_pos\",\n",
        "    ) / (model.cfg.d_head**0.5)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClFtEUJGQGyO"
      },
      "source": [
        "Once these tests have passed, you can plot the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEhw_IjPQGyO"
      },
      "outputs": [],
      "source": [
        "# First plot: attention score contribution from (query_component, key_component) = (Embed, L0H7), you can replace this\n",
        "# with any other pair and see that the values are generally much smaller, i.e. this pair dominates the attention score\n",
        "# calculation\n",
        "decomposed_scores = decompose_attn_scores(decomposed_q, decomposed_k, model)\n",
        "\n",
        "q_label = \"Embed\"\n",
        "k_label = \"0.7\"\n",
        "decomposed_scores_from_pair = decomposed_scores[component_labels.index(q_label), component_labels.index(k_label)]\n",
        "\n",
        "imshow(\n",
        "    utils.to_numpy(t.tril(decomposed_scores_from_pair)),\n",
        "    title=f\"Attention score contributions from query = {q_label}, key = {k_label}<br>(by query & key sequence positions)\",\n",
        "    width=700,\n",
        ")\n",
        "\n",
        "\n",
        "# Second plot: std dev over query and key positions, shown by component. This shows us that the other pairs of\n",
        "# (query_component, key_component) are much less important, without us having to look at each one individually like we\n",
        "# did in the first plot!\n",
        "decomposed_stds = einops.reduce(\n",
        "    decomposed_scores, \"query_decomp key_decomp query_pos key_pos -> query_decomp key_decomp\", t.std\n",
        ")\n",
        "imshow(\n",
        "    utils.to_numpy(decomposed_stds),\n",
        "    labels={\"x\": \"Key Component\", \"y\": \"Query Component\"},\n",
        "    title=\"Std dev of attn score contributions across sequence positions<br>(by query & key component)\",\n",
        "    x=component_labels,\n",
        "    y=component_labels,\n",
        "    width=700,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY9iHU4NQGyP"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I don't understand the interpretation of these plots.</summary>\n",
        "\n",
        "The first plot tells you that the term $e W_{QK}^{1.4} (x^{0.7})^T$ (i.e. the component of the attention scores for head `1.4` where the query is supplied by the token embeddings and the key is supplied by the output of head `0.7`) produces the distinctive attention pattern we see in the induction head: a strong diagonal stripe.\n",
        "\n",
        "Although this tells us that this this component would probably be sufficient to implement the induction mechanism, it doesn't tell us the whole story. Ideally, we'd like to show that the other 195 terms are unimportant. Taking the standard deviation across the attention scores for a particular pair of components is a decent proxy for how important this term is in the overall attention pattern. The second plot shows us that the standard deviation is very small for all the other components, so we can be confident that the other components are unimportant.\n",
        "\n",
        "To summarise:\n",
        "\n",
        "* The first plot tells us that the pair `(q_component=tok_emb, k_component=0.7)` produces the characteristic induction-head pattern we see in attention head `1.4`.\n",
        "* The second plot confirms that this pair is the only important one for influencing the attention pattern in `1.4`; all other pairs have very small contributions.\n",
        "</details>\n",
        "\n",
        "Note that plots like the ones above are often the most concise way of presenting a summary of the important information, and understanding what to plot is a valuable skill in any model internals-based work. However, if you want to see the \"full plot\" which the two plots above are both simplifications of in some sense, you can run the code below, which gives you the matrix of every single pair of components' contribution to the attention scores. So the first plot above is just a slice of the full plot below, and the second plot above is just the plot below after reducing over each slice with the standard deviation operation.\n",
        "\n",
        "(Note - the plot you'll generate below is pretty big, so you'll want to clear it after you're done with it. If your machine is still working slowly when rendering it, you can use `fig.show(config={\"staticPlot\": True})` to display a non-interactive version of it.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HVFjtt5QGyP"
      },
      "outputs": [],
      "source": [
        "decomposed_scores_centered = t.tril(decomposed_scores - decomposed_scores.mean(dim=-1, keepdim=True))\n",
        "\n",
        "decomposed_scores_reshaped = einops.rearrange(\n",
        "    decomposed_scores_centered,\n",
        "    \"q_comp k_comp q_token k_token -> (q_comp q_token) (k_comp k_token)\",\n",
        ")\n",
        "\n",
        "fig = imshow(\n",
        "    decomposed_scores_reshaped,\n",
        "    title=\"Attention score contributions from all pairs of (key, query) components\",\n",
        "    width=1200,\n",
        "    height=1200,\n",
        "    return_fig=True,\n",
        ")\n",
        "full_seq_len = seq_len * 2 + 1\n",
        "for i in range(0, full_seq_len * len(component_labels), full_seq_len):\n",
        "    fig.add_hline(y=i, line_color=\"black\", line_width=1)\n",
        "    fig.add_vline(x=i, line_color=\"black\", line_width=1)\n",
        "\n",
        "fig.show(config={\"staticPlot\": True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4UCOxDgQGyQ"
      },
      "source": [
        "### Interpreting the full circuit\n",
        "\n",
        "Now we know that head `1.4` is composing with head `0.7` via K composition, we can multiply through to create a full circuit:\n",
        "\n",
        "$$\n",
        "W_E\\, W_{QK}^{1.4}\\, (W_{OV}^{0.7})^T\\, W_E^T\n",
        "$$\n",
        "\n",
        "and verify that it's the identity. (Note, when we say identity here, we're again thinking about it as a distribution over logits, so this should be taken to mean \"high diagonal values\", and we'll be using our previous metric of `top_1_acc`.)\n",
        "\n",
        "#### Question - why should this be the identity?\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "This matrix is a bilinear form. Its diagonal elements $(A, A)$ are:\n",
        "\n",
        "$$\n",
        "A^T \\, W_E\\, W_{QK}^{1.4}\\, W_{OV}^{0.7}\\, W_E^T \\, A = \\underbrace{(A^T W_E W_Q^{1.4})}_{\\text{query}} \\underbrace{(A^T W_E W_{OV}^{0.7} W_K^{1.4})^T}_{\\text{key}}\n",
        "$$\n",
        "\n",
        "Intuitively, the query is saying **\"I'm looking for a token which followed $A$\"**, and the key is saying **\"I *am* a token which folllowed $A$\"** (recall that $A^T W_E W_{OV}^{0.7}$ is the vector which gets moved one position forward by our prev token head `0.7`).\n",
        "\n",
        "Now, consider the off-diagonal elements $(A, X)$ (for $X \\neq A$). We expect these to be small, because the key doesn't match the query:\n",
        "\n",
        "$$\n",
        "A^T \\, W_E\\, W_{QK}^{1.4}\\, W_{OV}^{0.7}\\, W_E^T \\, X = \\underbrace{(\\text{I'm looking for a token which followed A})}_\\text{query} \\boldsymbol{\\cdot} \\underbrace{(\\text{I am a token which followed X})}_{\\text{key}}\n",
        "$$\n",
        "\n",
        "\n",
        "Hence, we expect this to be the identity.\n",
        "\n",
        "An illustration:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/kcomp_diagram_described-K-last.png\" width=\"700\">\n",
        "\n",
        "<!-- ![kcomp_diagram_described-K.png](https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/kcomp_diagram_described-K.png) -->\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iklAg4EgQGyQ"
      },
      "source": [
        "### Exercise - compute the K-comp circuit\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You shouldn't spend more than 10-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Calculate the matrix above, as a `FactoredMatrix` object.\n",
        "\n",
        "<details>\n",
        "<summary>Aside about multiplying FactoredMatrix objects together.</summary>\n",
        "\n",
        "If  `M1 = A1 @ B1` and `M2 = A2 @ B2` are factored matrices, then `M = M1 @ M2` returns a new factored matrix. This might be:\n",
        "\n",
        "```python\n",
        "FactoredMatrix(M1.AB @ M2.A, M2.B)\n",
        "```\n",
        "\n",
        "or it might be:\n",
        "\n",
        "```python\n",
        "FactoredMatrix(M1.A, M1.B @ M2.AB)\n",
        "```\n",
        "\n",
        "with these two objects corresponding to the factorisations $M = (A_1 B_1 A_2) (B_2)$ and $M = (A_1) (B_1 A_2 B_2)$ respectively.\n",
        "\n",
        "Which one gets returned depends on the size of the hidden dimension, e.g. `M1.mdim < M2.mdim` then the factorisation used will be $M = A_1 B_1 (A_2 B_2)$.\n",
        "\n",
        "Remember that both these factorisations are valid, and will give you the exact same SVD. The only reason to prefer one over the other is for computational efficiency (we prefer a smaller bottleneck dimension, because this determines the computational complexity of operations like finding SVD).\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPZIpYSoQGyQ"
      },
      "outputs": [],
      "source": [
        "def find_K_comp_full_circuit(\n",
        "    model: HookedTransformer, prev_token_head_index: int, ind_head_index: int\n",
        ") -> FactoredMatrix:\n",
        "    \"\"\"\n",
        "    Returns a (vocab, vocab)-size FactoredMatrix, with the first dimension being the query side (direct from token\n",
        "    embeddings) and the second dimension being the key side (going via the previous token head).\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "prev_token_head_index = 7\n",
        "ind_head_index = 4\n",
        "K_comp_circuit = find_K_comp_full_circuit(model, prev_token_head_index, ind_head_index)\n",
        "\n",
        "tests.test_find_K_comp_full_circuit(find_K_comp_full_circuit, model)\n",
        "\n",
        "print(f\"Fraction of tokens where the highest activating key is the same token: {top_1_acc(K_comp_circuit.T):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZa8r0DLQGyR"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def find_K_comp_full_circuit(\n",
        "    model: HookedTransformer, prev_token_head_index: int, ind_head_index: int\n",
        ") -> FactoredMatrix:\n",
        "    \"\"\"\n",
        "    Returns a (vocab, vocab)-size FactoredMatrix, with the first dimension being the query side (direct from token\n",
        "    embeddings) and the second dimension being the key side (going via the previous token head).\n",
        "    \"\"\"\n",
        "    W_E = model.W_E\n",
        "    W_Q = model.W_Q[1, ind_head_index]\n",
        "    W_K = model.W_K[1, ind_head_index]\n",
        "    W_O = model.W_O[0, prev_token_head_index]\n",
        "    W_V = model.W_V[0, prev_token_head_index]\n",
        "\n",
        "    Q = W_E @ W_Q\n",
        "    K = W_E @ W_V @ W_O @ W_K\n",
        "    return FactoredMatrix(Q, K.T)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVWGBJMOQGyR"
      },
      "source": [
        "You can also try this out for our other induction head `ind_head_index=10`, which should also return a relatively high result. Is it higher than for head `1.4` ?\n",
        "\n",
        "<details>\n",
        "<summary>Note - unlike last time, it doesn't make sense to consider the \"effective circuit\" formed by adding together the weight matrices for heads <code>1.4</code> and <code>1.10</code>. Can you see why?</summary>\n",
        "\n",
        "Because the weight matrices we're dealing with here are from the QK circuit, not the OV circuit. These don't get combined in a linear way; instead we take softmax over each head's QK-circuit output individually.\n",
        "</details>\n",
        "\n",
        "## Further Exploration of Induction Circuits\n",
        "\n",
        "I now consider us to have fully reverse engineered an induction circuit - by both interpreting the features and by reverse engineering the circuit from the weights. But there's a bunch more ideas that we can apply for finding circuits in networks that are fun to practice on induction heads, so here's some bonus content - feel free to skip to the later bonus ideas though.\n",
        "\n",
        "### Composition scores\n",
        "\n",
        "A particularly cool idea in the paper is the idea of [virtual weights](https://transformer-circuits.pub/2021/framework/index.html#residual-comms), or compositional scores. (Though I came up with it, so I'm deeply biased!). This is used [to identify induction heads](https://transformer-circuits.pub/2021/framework/index.html#analyzing-a-two-layer-model).\n",
        "\n",
        "The key idea of compositional scores is that the residual stream is a large space, and each head is reading and writing from small subspaces. By default, any two heads will have little overlap between their subspaces (in the same way that any two random vectors have almost zero dot product in a large vector space). But if two heads are deliberately composing, then they will likely want to ensure they write and read from similar subspaces, so that minimal information is lost. As a result, we can just directly look at \"how much overlap there is\" between the output space of the earlier head and the K, Q, or V input space of the later head.\n",
        "\n",
        "We represent the **output space** with $W_{OV}=W_V W_O$. Call matrices like this $W_A$.\n",
        "\n",
        "We represent the **input space** with $W_{QK}=W_Q W_K^T$ (for Q-composition), $W_{QK}^T=W_K  W_Q^T$ (for K-Composition) or $W_{OV}=W_V W_O$ (for V-Composition, of the later head). Call matrices like these $W_B$ (we've used this notation so that $W_B$ refers to a later head, and $W_A$ to an earlier head).\n",
        "\n",
        "<details>\n",
        "<summary>Help - I don't understand what motivates these definitions.</summary>\n",
        "\n",
        "Recall that we can view each head as having three input wires (keys, queries and values), and one output wire (the outputs). The different forms of composition come from the fact that keys, queries and values can all be supplied from the output of a different head.\n",
        "\n",
        "Here is an illustration which shows the three different cases, and should also explain why we use this terminology. You might have to open it in a new tab to see it clearly.\n",
        "\n",
        "![composition](https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/composition_new.png)\n",
        "\n",
        "</details>\n",
        "\n",
        "How do we formalise overlap? This is basically an open question, but a surprisingly good metric is $\\frac{\\|W_AW_B\\|_F}{\\|W_B\\|_F\\|W_A\\|_F}$ where $\\|W\\|_F=\\sqrt{\\sum_{i,j}W_{i,j}^2}$ is the Frobenius norm, the square root of the sum of squared elements. (If you're dying of curiosity as to what makes this a good metric, you can jump to the section immediately after the exercises below.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwYhi9mzQGyR"
      },
      "source": [
        "### Exercise - calculate composition scores\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You shouldn't spend more than 15-25 minutes on these exercises.\n",
        "> Writing a composition score function should be fairly easy. The harder part is getting the right weight matrices in the exercises that come after.\n",
        "> ```\n",
        "\n",
        "Let's calculate this metric for all pairs of heads in layer 0 and layer 1 for each of K, Q and V composition and plot it.\n",
        "\n",
        "We'll start by implementing this using plain old tensors (later on we'll see how this can be sped up using the `FactoredMatrix` class). We also won't worry about batching our calculations yet; we'll just do one matrix at a time.\n",
        "\n",
        "We've given you tensors `q_comp_scores` etc. to hold the composition scores for each of Q, K and V composition (i.e. the `[i, j]`th element of `q_comp_scores` is the Q-composition score between the output from the `i`th head in layer 0 and the input to the `j`th head in layer 1). You should complete the function `get_comp_score`, and then fill in each of these tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLR5OwlSQGyS"
      },
      "outputs": [],
      "source": [
        "def get_comp_score(W_A: Float[Tensor, \"in_A out_A\"], W_B: Float[Tensor, \"out_A out_B\"]) -> float:\n",
        "    \"\"\"\n",
        "    Return the composition score between W_A and W_B.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_get_comp_score(get_comp_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5THoXcoQGyS"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def get_comp_score(W_A: Float[Tensor, \"in_A out_A\"], W_B: Float[Tensor, \"out_A out_B\"]) -> float:\n",
        "    \"\"\"\n",
        "    Return the composition score between W_A and W_B.\n",
        "    \"\"\"\n",
        "    W_A_norm = W_A.pow(2).sum().sqrt()\n",
        "    W_B_norm = W_B.pow(2).sum().sqrt()\n",
        "    W_AB_norm = (W_A @ W_B).pow(2).sum().sqrt()\n",
        "\n",
        "    return (W_AB_norm / (W_A_norm * W_B_norm)).item()\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVQQo0DlQGyS"
      },
      "source": [
        "Once you've passed the tests, you can fill in all the composition scores. Here you should just use a for loop, iterating over all possible pairs of `W_A` in layer 0 and `W_B` in layer 1, for each type of composition. Later on, we'll look at ways to batch this computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u22aXhMJQGyS"
      },
      "outputs": [],
      "source": [
        "# Get all QK and OV matrices\n",
        "W_QK = model.W_Q @ model.W_K.transpose(-1, -2)\n",
        "W_OV = model.W_V @ model.W_O\n",
        "\n",
        "# Define tensors to hold the composition scores\n",
        "composition_scores = {\n",
        "    \"Q\": t.zeros(model.cfg.n_heads, model.cfg.n_heads).to(device),\n",
        "    \"K\": t.zeros(model.cfg.n_heads, model.cfg.n_heads).to(device),\n",
        "    \"V\": t.zeros(model.cfg.n_heads, model.cfg.n_heads).to(device),\n",
        "}\n",
        "\n",
        "# YOUR CODE HERE - fill in the values of the `composition_scores` dict, using the `get_comp_score` function\n",
        "\n",
        "# Plot the composition scores\n",
        "for comp_type in [\"Q\", \"K\", \"V\"]:\n",
        "    plot_comp_scores(model, composition_scores[comp_type], f\"{comp_type} Composition Scores\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buXYrioRQGyT"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "for i in tqdm(range(model.cfg.n_heads)):\n",
        "    for j in range(model.cfg.n_heads):\n",
        "        composition_scores[\"Q\"][i, j] = get_comp_score(W_OV[0, i], W_QK[1, j])\n",
        "        composition_scores[\"K\"][i, j] = get_comp_score(W_OV[0, i], W_QK[1, j].T)\n",
        "        composition_scores[\"V\"][i, j] = get_comp_score(W_OV[0, i], W_OV[1, j])\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9XoQLElQGyT"
      },
      "source": [
        "### Exercise - Setting a Baseline\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You shouldn't spend more than ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "To interpret the above graphs we need a baseline! A good one is what the scores look like at initialisation. Make a function that randomly generates a composition score 200 times and tries this. Remember to generate 4 `[d_head, d_model]` matrices, not 2 `[d_model, d_model]` matrices! This model was initialised with **Kaiming Uniform Initialisation**:\n",
        "\n",
        "```python\n",
        "W = t.empty(shape)\n",
        "nn.init.kaiming_uniform_(W, a=np.sqrt(5))\n",
        "```\n",
        "\n",
        "(Ideally we'd do a more efficient generation involving batching, and more samples, but we won't worry about that yet.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peg0xRc7QGyT"
      },
      "outputs": [],
      "source": [
        "def generate_single_random_comp_score() -> float:\n",
        "    \"\"\"\n",
        "    Write a function which generates a single composition score for random matrices\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "n_samples = 300\n",
        "comp_scores_baseline = np.zeros(n_samples)\n",
        "for i in tqdm(range(n_samples)):\n",
        "    comp_scores_baseline[i] = generate_single_random_comp_score()\n",
        "\n",
        "print(\"\\nMean:\", comp_scores_baseline.mean())\n",
        "print(\"Std:\", comp_scores_baseline.std())\n",
        "\n",
        "hist(\n",
        "    comp_scores_baseline,\n",
        "    nbins=50,\n",
        "    width=800,\n",
        "    labels={\"x\": \"Composition score\"},\n",
        "    title=\"Random composition scores\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUsdivsBQGyV"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def generate_single_random_comp_score() -> float:\n",
        "    \"\"\"\n",
        "    Write a function which generates a single composition score for random matrices\n",
        "    \"\"\"\n",
        "    W_A_left = t.empty(model.cfg.d_model, model.cfg.d_head)\n",
        "    W_B_left = t.empty(model.cfg.d_model, model.cfg.d_head)\n",
        "    W_A_right = t.empty(model.cfg.d_model, model.cfg.d_head)\n",
        "    W_B_right = t.empty(model.cfg.d_model, model.cfg.d_head)\n",
        "\n",
        "    for W in [W_A_left, W_B_left, W_A_right, W_B_right]:\n",
        "        nn.init.kaiming_uniform_(W, a=np.sqrt(5))\n",
        "\n",
        "    W_A = W_A_left @ W_A_right.T\n",
        "    W_B = W_B_left @ W_B_right.T\n",
        "\n",
        "    return get_comp_score(W_A, W_B)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_GVVxhXQGyV"
      },
      "source": [
        "We can re-plot our above graphs with this baseline set to white. Look for interesting things in this graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXzNN7TBQGyV"
      },
      "outputs": [],
      "source": [
        "baseline = comp_scores_baseline.mean()\n",
        "for comp_type, comp_scores in composition_scores.items():\n",
        "    plot_comp_scores(model, comp_scores, f\"{comp_type} Composition Scores\", baseline=baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU17Vb24QGyV"
      },
      "source": [
        "<details>\n",
        "<summary>Some interesting things to observe:</summary>\n",
        "\n",
        "The most obvious thing that jumps out (when considered in the context of all the analysis we've done so far) is the K-composition scores. `0.7` (the prev token head) is strongly composing with `1.4` and `1.10` (the two attention heads). This is what we expect, and is a good indication that our composition scores are working as intended.\n",
        "\n",
        "Another interesting thing to note is that the V-composition scores for heads `1.4` and `1.10` with all other heads in layer 0 are very low. In the context of the induction circuit, this is a good thing - the OV circuits of our induction heads should be operating on the **embeddings**, rather than the outputs of the layer-0 heads. (If our repeating sequence is `A B ... A B`, then it's the QK circuit's job to make sure the second `A` attends to the first `B`, and it's the OV circuit's job to project the residual vector at that position onto the **embedding space** in order to extract the `B`-information, while hopefully ignoring anything else that has been written to that position by the heads in layer 0). So once again, this is a good sign for our composition scores.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/small_comp_diagram_last.png\" width=\"900\">\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsg33dV3QGyW"
      },
      "source": [
        "#### Theory + Efficient Implementation\n",
        "\n",
        "So, what's up with that metric? The key is a cute linear algebra result that the squared Frobenius norm is equal to the sum of the squared singular values.\n",
        "\n",
        "<details>\n",
        "<summary>Proof</summary>\n",
        "\n",
        "We'll give three different proofs:\n",
        "\n",
        "---\n",
        "\n",
        "##### Short sketch of proof\n",
        "\n",
        "Clearly $\\|M\\|_F^2$ equals the sum of squared singular values when $M$ is diagonal. The singular values of $M$ don't change when we multiply it by an orthogonal matrix (only the matrices $U$ and $V$ will change, not $S$), so it remains to show that the Frobenius norm also won't change when we multiply $M$ by an orthogonal matrix. But this follows from the fact that the Frobenius norm is the sum of the squared $l_2$ norms of the column vectors of $M$, and orthogonal matrices preserve $l_2$ norms. (If we're right-multiplying $M$ by an orthogonal matrix, then we instead view this as performing orthogonal operations on the row vectors of $M$, and the same argument holds.)\n",
        "\n",
        "---\n",
        "\n",
        "##### Long proof\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\|M\\|_F^2 &= \\sum_{ij}M_{ij}^2 \\\\\n",
        "&= \\sum_{ij}((USV^T)_{ij})^2 \\\\\n",
        "&= \\sum_{ij}\\bigg(\\sum_k U_{ik}S_{kk}V_{jk}\\bigg)^2 \\\\\n",
        "&= \\sum_{ijk_1 k_2}S_{k_1 k_1} S_{k_2 k_2} U_{i k_1} U_{i k_2} V_{j k_2} V_{j k_2} \\\\\n",
        "&= \\sum_{k_1 k_2}S_{k_1 k_1} S_{k_2 k_2} \\bigg(\\sum_i U_{i k_1} U_{i k_2}\\bigg)\\bigg(\\sum_j V_{j k_2} V_{j k_2}\\bigg) \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Each of the terms in large brackets is actually the dot product of columns of $U$ and $V$ respectively. Since these are orthogonal matrices, these terms evaluate to 1 when $k_1=k_2$ and 0 otherwise. So we are left with:\n",
        "\n",
        "$$\n",
        "\\|M\\|_F^2 = \\sum_{k}S_{k k}^2\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "##### Cute proof which uses the fact that the squared Frobenius norm $|M|^2$ is the same as the trace of $MM^T$\n",
        "\n",
        "$$\n",
        "\\|M\\|_F^2 = \\text{Tr}(MM^T) = \\text{Tr}(USV^TVSU^T) = \\text{Tr}(US^2U^T) = \\text{Tr}(S^2 U^T U) = \\text{Tr}(S^2) = \\|S\\|_F^2\n",
        "$$\n",
        "\n",
        "where we used the cyclicity of trace, and the fact that $U$ is orthogonal so $U^TU=I$ (and same for $V$). We finish by observing that $\\|S\\|_F^2$ is precisely the sum of the squared singular values.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tjN3MQWQGyW"
      },
      "source": [
        "So if $W_A=U_AS_AV_A^T$, $W_B=U_BS_BV_B^T$, then $\\|W_A\\|_F=\\|S_A\\|_F$, $\\|W_B\\|_F=\\|S_B\\|_F$ and $\\|W_AW_B\\|_F=\\|S_AV_A^TU_BS_B\\|_F$. In some sense, $V_A^TU_B$ represents how aligned the subspaces written to and read from are, and the $S_A$ and $S_B$ terms weights by the importance of those subspaces.\n",
        "\n",
        "<details>\n",
        "<summary>Click here, if this explanation still seems confusing.</summary>\n",
        "\n",
        "$U_B$ is a matrix of shape `[d_model, d_head]`. It represents **the subspace being read from**, i.e. our later head reads from the residual stream by projecting it onto the `d_head` columns of this matrix.\n",
        "\n",
        "$V_A$ is a matrix of shape `[d_model, d_head]`. It represents **the subspace being written to**, i.e. the thing written to the residual stream by our earlier head is a linear combination of the `d_head` column-vectors of $V_A$.\n",
        "\n",
        "$V_A^T U_B$ is a matrix of shape `[d_head, d_head]`. Each element of this matrix is formed by taking the dot product of two vectors of length `d_model`:\n",
        "\n",
        "* $v_i^A$, a column of $V_A$ (one of the vectors our earlier head embeds into the residual stream)\n",
        "* $u_j^B$, a column of $U_B$ (one of the vectors our later head projects the residual stream onto)\n",
        "\n",
        "Let the singular values of $S_A$ be $\\sigma_1^A, ..., \\sigma_k^A$ and similarly for $S_B$. Then:\n",
        "\n",
        "$$\n",
        "\\|S_A V_A^T U_B S_B\\|_F^2 = \\sum_{i,j=1}^k (\\sigma_i^A \\sigma_j^B)^2 \\|v^A_i \\cdot u^B_j\\|_F^2\n",
        "$$\n",
        "\n",
        "This is a weighted sum of the squared cosine similarity of the columns of $V_A$ and $U_B$ (i.e. the output directions of the earlier head and the input directions of the later head). The weights in this sum are given by the singular values of both $S_A$ and $S_B$ - i.e. if $v^A_i$ is an important output direction, **and** $u_B^i$ is an important input direction, then the composition score will be much higher when these two directions are aligned with each other.\n",
        "\n",
        "---\n",
        "\n",
        "To build intuition, let's consider a couple of extreme examples.\n",
        "\n",
        "* If there was no overlap between the spaces being written to and read from, then $V_A^T U_B$ would be a matrix of zeros (since every $v_i^A \\cdot u_j^B$ would be zero). This would mean that the composition score would be zero.\n",
        "* If there was perfect overlap, i.e. the span of the $v_i^A$ vectors and $u_j^B$ vectors is the same, then the composition score is large. It is as large as possible when the most important input directions and most important output directions line up (i.e. when the singular values $\\sigma_i^A$ and $\\sigma_j^B$ are in the same order).\n",
        "* If our matrices $W_A$ and $W_B$ were just rank 1 (i.e. $W_A = \\sigma_A u_A v_A^T$, and $W_B = \\sigma_B u_B v_B^T$), then the composition score is $|v_A^T u_B|$, in other words just the cosine similarity of the single output direction of $W_A$ and the single input direction of $W_B$.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOoJuB8JQGyW"
      },
      "source": [
        "### Exercise - batching, and using the `FactoredMatrix` class\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵⚪⚪⚪⚪\n",
        ">\n",
        "> This exercise is optional, and not a super important part of this section conceptually.\n",
        "> It's also quite messy to rearrange our tensors in the right way! You are invited to skip it if you want.\n",
        "> ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6rRWwTeQGyX"
      },
      "source": [
        "We can also use this insight to write a more efficient way to calculate composition scores - this is extremely useful if you want to do this analysis at scale! The key is that we know that our matrices have a low rank factorisation, and it's much cheaper to calculate the SVD of a narrow matrix than one that's large in both dimensions. See the [algorithm described at the end of the paper](https://transformer-circuits.pub/2021/framework/index.html#induction-heads:~:text=Working%20with%20Low%2DRank%20Matrices) (search for SVD).\n",
        "\n",
        "So we can work with the `FactoredMatrix` class. This also provides the method `.norm()` which returns the Frobenium norm. This is also a good opportunity to bring back batching - this will sometimes be useful in our analysis. In the function below, `W_As` and `W_Bs` are both >2D factored matrices (e.g. they might represent the OV circuits for all heads in a particular layer, or across multiple layers), and the function's output should be a tensor of composition scores for each pair of matrices `(W_A, W_B)` in the >2D tensors `(W_As, W_Bs)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Hb65W6nQGyX"
      },
      "outputs": [],
      "source": [
        "def get_batched_comp_scores(W_As: FactoredMatrix, W_Bs: FactoredMatrix) -> Tensor:\n",
        "    \"\"\"\n",
        "    Computes the compositional scores from indexed factored matrices W_As and W_Bs.\n",
        "\n",
        "    Each of W_As and W_Bs is a FactoredMatrix object which is indexed by all but its last 2 dimensions, i.e.:\n",
        "        W_As.shape == (*A_idx, A_in, A_out)\n",
        "        W_Bs.shape == (*B_idx, B_in, B_out)\n",
        "        A_out == B_in\n",
        "\n",
        "    Return: tensor of shape (*A_idx, *B_idx) where the [*a_idx, *b_idx]th element is the compositional score from\n",
        "    W_As[*a_idx] to W_Bs[*b_idx].\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "W_QK = FactoredMatrix(model.W_Q, model.W_K.transpose(-1, -2))\n",
        "W_OV = FactoredMatrix(model.W_V, model.W_O)\n",
        "\n",
        "composition_scores_batched = dict()\n",
        "composition_scores_batched[\"Q\"] = get_batched_comp_scores(W_OV[0], W_QK[1])\n",
        "composition_scores_batched[\"K\"] = get_batched_comp_scores(\n",
        "    W_OV[0], W_QK[1].T\n",
        ")  # Factored matrix: .T is interpreted as transpose of the last two axes\n",
        "composition_scores_batched[\"V\"] = get_batched_comp_scores(W_OV[0], W_OV[1])\n",
        "\n",
        "t.testing.assert_close(composition_scores_batched[\"Q\"], composition_scores[\"Q\"])\n",
        "t.testing.assert_close(composition_scores_batched[\"K\"], composition_scores[\"K\"])\n",
        "t.testing.assert_close(composition_scores_batched[\"V\"], composition_scores[\"V\"])\n",
        "print(\"Tests passed - your `get_batched_comp_scores` function is working!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6i60TBHQGyX"
      },
      "source": [
        "<details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Suppose `W_As` has shape `(A1, A2, ..., Am, A_in, A_out)` and `W_Bs` has shape `(B1, B2, ..., Bn, B_in, B_out)` (where `A_out == B_in`).\n",
        "\n",
        "It will be helpful to reshape these two tensors so that:\n",
        "\n",
        "```python\n",
        "W_As.shape == (A1*A2*...*Am, 1, A_in, A_out)\n",
        "W_Bs.shape == (1, B1*B2*...*Bn, B_in, B_out)\n",
        "```\n",
        "\n",
        "since we can then multiply them together as `W_As @ W_Bs` (broadcasting will take care of this for us!).\n",
        "\n",
        "To do the reshaping, the easiest way is to reshape `W_As.A` and `W_As.B`, and define a new `FactoredMatrix` from these reshaped tensors (and same for `W_Bs`).\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def get_batched_comp_scores(W_As: FactoredMatrix, W_Bs: FactoredMatrix) -> Tensor:\n",
        "    \"\"\"\n",
        "    Computes the compositional scores from indexed factored matrices W_As and W_Bs.\n",
        "\n",
        "    Each of W_As and W_Bs is a FactoredMatrix object which is indexed by all but its last 2 dimensions, i.e.:\n",
        "        W_As.shape == (*A_idx, A_in, A_out)\n",
        "        W_Bs.shape == (*B_idx, B_in, B_out)\n",
        "        A_out == B_in\n",
        "\n",
        "    Return: tensor of shape (*A_idx, *B_idx) where the [*a_idx, *b_idx]th element is the compositional score from\n",
        "    W_As[*a_idx] to W_Bs[*b_idx].\n",
        "    \"\"\"\n",
        "    # Flatten W_As into (single_A_idx, 1, A_in, A_out)\n",
        "    W_As = FactoredMatrix(\n",
        "        W_As.A.reshape(-1, 1, *W_As.A.shape[-2:]),\n",
        "        W_As.B.reshape(-1, 1, *W_As.B.shape[-2:]),\n",
        "    )\n",
        "    # Flatten W_Bs into (1, single_B_idx, B_in(=A_out), B_out)\n",
        "    W_Bs = FactoredMatrix(\n",
        "        W_Bs.A.reshape(1, -1, *W_Bs.A.shape[-2:]),\n",
        "        W_Bs.B.reshape(1, -1, *W_Bs.B.shape[-2:]),\n",
        "    )\n",
        "\n",
        "    # Compute the product, with shape (single_A_idx, single_B_idx, A_in, B_out)\n",
        "    W_ABs = W_As @ W_Bs\n",
        "\n",
        "    # Compute the norms, and return the metric\n",
        "    return W_ABs.norm() / (W_As.norm() * W_Bs.norm())\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMGSZ1z6QGyX"
      },
      "source": [
        "### Targeted Ablations\n",
        "\n",
        "We can refine the ablation technique to detect composition by looking at the effect of the ablation on the attention pattern of an induction head, rather than the loss. Let's implement this!\n",
        "\n",
        "Gotcha - by default, `run_with_hooks` removes any existing hooks when it runs. If you want to use caching, set the `reset_hooks_start` flag to False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU-NRc5JQGyY"
      },
      "outputs": [],
      "source": [
        "seq_len = 50\n",
        "\n",
        "\n",
        "def ablation_induction_score(prev_head_index: int | None, ind_head_index: int) -> float:\n",
        "    \"\"\"\n",
        "    Takes as input the index of the L0 head and the index of the L1 head, and then runs with the previous token head ablated and returns the induction score for the ind_head_index now.\n",
        "    \"\"\"\n",
        "\n",
        "    def ablation_hook(v, hook):\n",
        "        if prev_head_index is not None:\n",
        "            v[:, :, prev_head_index] = 0.0\n",
        "        return v\n",
        "\n",
        "    def induction_pattern_hook(attn, hook):\n",
        "        hook.ctx[prev_head_index] = attn[0, ind_head_index].diag(-(seq_len - 1)).mean()\n",
        "\n",
        "    model.run_with_hooks(\n",
        "        rep_tokens,\n",
        "        fwd_hooks=[\n",
        "            (utils.get_act_name(\"v\", 0), ablation_hook),\n",
        "            (utils.get_act_name(\"pattern\", 1), induction_pattern_hook),\n",
        "        ],\n",
        "    )\n",
        "    return model.blocks[1].attn.hook_pattern.ctx[prev_head_index].item()\n",
        "\n",
        "\n",
        "baseline_induction_score = ablation_induction_score(None, 4)\n",
        "print(f\"Induction score for no ablations: {baseline_induction_score:.5f}\\n\")\n",
        "for i in range(model.cfg.n_heads):\n",
        "    new_induction_score = ablation_induction_score(i, 4)\n",
        "    induction_score_change = new_induction_score - baseline_induction_score\n",
        "    print(f\"Ablation score change for head {i:02}: {induction_score_change:+.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuXsZaoOQGyY"
      },
      "source": [
        "<details>\n",
        "<summary>Question - what is the interpretation of the results you're getting?</summary>\n",
        "\n",
        "You should have found that the induction score without any ablations is about 0.68, and that most other heads don't change the induction score by much when they are ablated, except for head 7 which reduces the induction score to nearly zero.\n",
        "\n",
        "This is another strong piece of evidence that head `0.7` is the prev token head in this induction circuit.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqJo7323QGyY"
      },
      "source": [
        "## Bonus\n",
        "\n",
        "### Looking for Circuits in Real LLMs\n",
        "\n",
        "A particularly cool application of these techniques is looking for real examples of circuits in large language models. Fortunately, there's a bunch of open source ones you can play around with in the `TransformerLens` library! Many of the techniques we've been using for our 2L transformer carry over to ones with more layers.\n",
        "\n",
        "This library should make it moderately easy to play around with these models - I recommend going wild and looking for interesting circuits!\n",
        "\n",
        "Some fun things you might want to try:\n",
        "\n",
        "- Look for induction heads - try repeating all of the steps from above. Do they follow the same algorithm?\n",
        "- Look for neurons that erase info\n",
        "    - i.e. having a high negative cosine similarity between the input and output weights\n",
        "- Try to interpret a position embedding.\n",
        "\n",
        "<details>\n",
        "<summary>Positional Embedding Hint</summary>\n",
        "\n",
        "Look at the singular value decomposition `t.svd` and plot the principal components over position space. High ones tend to be sine and cosine waves of different frequencies.\n",
        "</details>\n",
        "\n",
        "- Look for heads with interpretable attention patterns: e.g. heads that attend to the same word (or subsequent word) when given text in different languages, or the most recent proper noun, or the most recent full-stop, or the subject of the sentence, etc.\n",
        "    - Pick a head, ablate it, and run the model on a load of text with and without the head. Look for tokens with the largest difference in loss, and try to interpret what the head is doing.\n",
        "- Try replicating some of Kevin's work on indirect object identification.\n",
        "- Inspired by the [ROME paper](https://rome.baulab.info/), use the causal tracing technique of patching in the residual stream - can you analyse how the network answers different facts?\n",
        "\n",
        "Note: I apply several simplifications to the resulting transformer - these leave the model mathematically equivalent and doesn't change the output log probs, but does somewhat change the structure of the model and one change translates the output logits by a constant.\n",
        "\n",
        "<details>\n",
        "<summary>Model simplifications</summary>\n",
        "\n",
        "#### Centering $W_U$\n",
        "\n",
        "The output of $W_U$ is a $d_{vocab}$ vector (or tensor with that as the final dimension) which is fed into a softmax\n",
        "\n",
        "#### LayerNorm Folding\n",
        "\n",
        "LayerNorm is only applied at the start of a linear layer reading from the residual stream (eg query, key, value, mlp_in or unembed calculations)\n",
        "\n",
        "Each LayerNorm has the functional form $LN:\\mathbb{R}^n\\to\\mathbb{R}^n$,\n",
        "$LN(x)=s(x) * w_{ln} + b_{ln}$, where $*$ is element-wise multiply and $s(x)=\\frac{x-\\bar{x}}{|x-\\bar{x}|}$, and $w_{ln},b_{ln}$ are both vectors in $\\mathbb{R}^n$\n",
        "\n",
        "The linear layer has form $l:\\mathbb{R}^n\\to\\mathbb{R}^m$, $l(y)=Wy+b$ where $W\\in \\mathbb{R}^{m\\times n},b\\in \\mathbb{R}^m,y\\in\\mathbb{R}^n$\n",
        "\n",
        "So $f(LN(x))=W(w_{ln} * s(x)+b_{ln})+b=(W * w_{ln})s(x)+(Wb_{ln}+b)=W_{eff}s(x)+b_{eff}$, where $W_{eff}$ is the elementwise product of $W$ and $w_{ln}$ (showing that elementwise multiplication commutes like this is left as an exercise) and $b_{eff}=Wb_{ln}+b\\in \\mathbb{R}^m$.\n",
        "\n",
        "From the perspective of interpretability, it's much nicer to interpret the folded layer $W_{eff},b_{eff}$ - fundamentally, this is the computation being done, and there's no reason to expect $W$ or $w_{ln}$ to be meaningful on their own.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc2E6PC_QGyY"
      },
      "source": [
        "### Training Your Own Toy Models\n",
        "\n",
        "A fun exercise is training models on the minimal task that'll produce induction heads - predicting the next token in a sequence of random tokens with repeated subsequences. You can get a small 2L Attention-Only model to do this.\n",
        "\n",
        "<details>\n",
        "<summary>Tips</summary>\n",
        "\n",
        "* Make sure to randomise the positions that are repeated! Otherwise the model can just learn the boring algorithm of attending to fixed positions\n",
        "* It works better if you *only* evaluate loss on the repeated tokens, this makes the task less noisy.\n",
        "* It works best with several repeats of the same sequence rather than just one.\n",
        "* If you do things right, and give it finite data + weight decay, you *should* be able to get it to grok - this may take some hyper-parameter tuning though.\n",
        "* When I've done this I get weird franken-induction heads, where each head has 1/3 of an induction stripe, and together cover all tokens.\n",
        "* It'll work better if you only let the queries and keys access the positional embeddings, but *should* work either way.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH33ab6rQGyZ"
      },
      "source": [
        "### Interpreting Induction Heads During Training\n",
        "\n",
        "A particularly striking result about induction heads is that they consistently [form very abruptly in training as a phase change](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html#argument-phase-change), and are such an important capability that there is a [visible non-convex bump in the loss curve](https://wandb.ai/mechanistic-interpretability/attn-only/reports/loss_ewma-22-08-24-22-08-00---VmlldzoyNTI2MDM0?accessToken=r6v951q0e1l4q4o70wb2q67wopdyo3v69kz54siuw7lwb4jz6u732vo56h6dr7c2) (in this model, approx 2B to 4B tokens). I have a bunch of checkpoints for this model, you can try re-running the induction head detection techniques on intermediate checkpoints and see what happens. (Bonus points if you have good ideas for how to efficiently send a bunch of 300MB checkpoints from Wandb lol)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ung4qXoIQGyZ"
      },
      "source": [
        "### Further discussion / investigation\n",
        "\n",
        "Anthropic has written a post on [In-context Learning and Induction Heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html) which goes into much deeper discussion on induction heads. The post is structured around six different points of evidence for the hypothesis that **induction heads are the main source of in-context learning in transformer models**, even large ones. Briefly, these are:\n",
        "\n",
        "1. Transformers undergo a \"phase change\" where they suddenly become much better at in-context learning, and this is around the same time induction heads appear.\n",
        "2. When we change the transformer's architecture to make it easier for induction heads to form, we get a corresponding improvement in in-context learning.\n",
        "3. When we ablate induction heads at runtime, in-context learning gets worse.\n",
        "4. We have specific examples of induction heads performing more complex in-context learning algorithms (you'll have the opportunity to investigate one of these later - **indirect object identification**).\n",
        "5. We have a mechanistic explanation of induction heads, which suggests natural extensions to more general forms of in-context learning.\n",
        "6. In-context learning-related behaviour is generally smoothly continuous between small and large models, suggesting that the underlying mechanism is also the same.\n",
        "\n",
        "Here are a few questions for you:\n",
        "\n",
        "* How compelling do you find this evidence? Discuss with your partner.\n",
        "    * Which points do you find most compelling?\n",
        "    * Which do you find least compelling?\n",
        "    * Are there any subset of these which would be enough to convince you of the hypothesis, in the absence of others?\n",
        "* In point 3, the paper observes that in-context learning performance degrades when you ablate induction heads. While we measured this by testing the model's ability to copy a duplicated random sequence, the paper used **in-context learning score** (the loss of the 500th token in the context, minus the loss on the 50th token).\n",
        "    * Can you see why this is a reasonable metric?\n",
        "    * Can you replicate these results (maybe on a larger model than the 2-layer one we've been using)?\n",
        "* In point 4 (more complex forms of in-context learning), the paper suggests the natural extension of \"fuzzy induction heads\", which match patterns like `[A*][B*]...[A][B]` rather than `[A][B]...[A][B]` (where the `*` indicates some form of linguistic similarity, not necessarily being the same token).\n",
        "    * Can you think of any forms this might take, i.e. any kinds of similarity which induction heads might pick up on? Can you generate examples?"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f664e47eec8b41b0ae2a14c93945bf9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc4bbe816fc6472a849b8cae1b1151e8",
              "IPY_MODEL_74beaf972a9341ae9becc7c6c06b00d1",
              "IPY_MODEL_6f9844d3c95148de80fec60f35928148"
            ],
            "layout": "IPY_MODEL_6bb66e06a110480db6449eab45c055c6"
          }
        },
        "bc4bbe816fc6472a849b8cae1b1151e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_633aa12e0ba34548a4b49117a28f7027",
            "placeholder": "​",
            "style": "IPY_MODEL_0464cdf2b799410eb1a08bb52117792b",
            "value": "attn_only_2L_half.pth: 100%"
          }
        },
        "74beaf972a9341ae9becc7c6c06b00d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_501c2537b4614bf1ba7803f4720a4244",
            "max": 183933661,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1935a0d49074f67b43089c490561bd4",
            "value": 183933661
          }
        },
        "6f9844d3c95148de80fec60f35928148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d450b8542b74b7a883c22d9d4ecddb3",
            "placeholder": "​",
            "style": "IPY_MODEL_d158ce376c34488bba9ecf5f302daca3",
            "value": " 184M/184M [00:01&lt;00:00, 194MB/s]"
          }
        },
        "6bb66e06a110480db6449eab45c055c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "633aa12e0ba34548a4b49117a28f7027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0464cdf2b799410eb1a08bb52117792b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "501c2537b4614bf1ba7803f4720a4244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1935a0d49074f67b43089c490561bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d450b8542b74b7a883c22d9d4ecddb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d158ce376c34488bba9ecf5f302daca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89249b7c251e4c56827cd33c6aff2c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29b5adf995d744b9975124e9a670d186",
              "IPY_MODEL_4b0041ca10ab4ccd94d79f56b875cfca",
              "IPY_MODEL_2653d7dd7509406797785faa25ed1631"
            ],
            "layout": "IPY_MODEL_f0f9bf20533e40b999a4f7d0aaef16fb"
          }
        },
        "29b5adf995d744b9975124e9a670d186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e98e9311e6d423fb9b52dcaeede3cc2",
            "placeholder": "​",
            "style": "IPY_MODEL_397645cfbde942e198a2f92d820640c5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4b0041ca10ab4ccd94d79f56b875cfca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe71550bf8de43f0ad581b319f741a3c",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d4bdd208f8647ffb2c63bc1745a08b4",
            "value": 156
          }
        },
        "2653d7dd7509406797785faa25ed1631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d1078b7b40248438dc3abb9e00324dd",
            "placeholder": "​",
            "style": "IPY_MODEL_5b09a1bb20a047d2919093bdd217d203",
            "value": " 156/156 [00:00&lt;00:00, 11.6kB/s]"
          }
        },
        "f0f9bf20533e40b999a4f7d0aaef16fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e98e9311e6d423fb9b52dcaeede3cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397645cfbde942e198a2f92d820640c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe71550bf8de43f0ad581b319f741a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d4bdd208f8647ffb2c63bc1745a08b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d1078b7b40248438dc3abb9e00324dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b09a1bb20a047d2919093bdd217d203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51b87bb187094498b9986dbb0b5d31e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32444aa7200645bd893c5e6e13d304b3",
              "IPY_MODEL_72543015962e4a95b8e91e2c4461ff97",
              "IPY_MODEL_9a1b40e2f08f4827a53f42c1fa4bcdf0"
            ],
            "layout": "IPY_MODEL_5683e88ef9fd40baa382e619709faf15"
          }
        },
        "32444aa7200645bd893c5e6e13d304b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de73fc84da642359b805744389b6d90",
            "placeholder": "​",
            "style": "IPY_MODEL_0216077d09a24a4bb0a8abd3ee9127f6",
            "value": "vocab.json: "
          }
        },
        "72543015962e4a95b8e91e2c4461ff97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85834d46fa1841cb8a7bb9aba59b07d4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69c80621e4724115bc4125c952d74279",
            "value": 1
          }
        },
        "9a1b40e2f08f4827a53f42c1fa4bcdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4c4e38f95824cfe9b6c842a1879fbb5",
            "placeholder": "​",
            "style": "IPY_MODEL_0e55fd8ef7574ad9a1af55457a278bab",
            "value": " 1.08M/? [00:00&lt;00:00, 30.9MB/s]"
          }
        },
        "5683e88ef9fd40baa382e619709faf15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de73fc84da642359b805744389b6d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0216077d09a24a4bb0a8abd3ee9127f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85834d46fa1841cb8a7bb9aba59b07d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "69c80621e4724115bc4125c952d74279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4c4e38f95824cfe9b6c842a1879fbb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e55fd8ef7574ad9a1af55457a278bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50de34c5d7ae4de190d619490be42512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df2d943c66a04911bfab2355419cac17",
              "IPY_MODEL_3bad63f31e414522ba2166b43392073d",
              "IPY_MODEL_da8ebd42422b4040ad922b7450c78de7"
            ],
            "layout": "IPY_MODEL_eba9112a84c14f62934293b2ff7978c1"
          }
        },
        "df2d943c66a04911bfab2355419cac17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_945a91da8b124b449a51f01d2533c200",
            "placeholder": "​",
            "style": "IPY_MODEL_187a7574540c470086a8dc52121f6a9d",
            "value": "merges.txt: "
          }
        },
        "3bad63f31e414522ba2166b43392073d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83d0c0c5f2fa4c25bb783f0cc326d939",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_723303fc94504efd9f06aa533e641eb1",
            "value": 1
          }
        },
        "da8ebd42422b4040ad922b7450c78de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efe60bca2a47490eb73c2a2e79d2d002",
            "placeholder": "​",
            "style": "IPY_MODEL_b496b881d9ff4107b32d67bc157946bc",
            "value": " 457k/? [00:00&lt;00:00, 14.4MB/s]"
          }
        },
        "eba9112a84c14f62934293b2ff7978c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945a91da8b124b449a51f01d2533c200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "187a7574540c470086a8dc52121f6a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83d0c0c5f2fa4c25bb783f0cc326d939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "723303fc94504efd9f06aa533e641eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efe60bca2a47490eb73c2a2e79d2d002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b496b881d9ff4107b32d67bc157946bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26011d39888d4dca862492ca4595de62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60a0e5bd2bab41a693568b13904b53b6",
              "IPY_MODEL_36dff6de227145bca4a9bea2e843d9f3",
              "IPY_MODEL_1bc94989803540a79feb97a9ed976c06"
            ],
            "layout": "IPY_MODEL_3193da9e981441d5904c0c8b3c7e7d15"
          }
        },
        "60a0e5bd2bab41a693568b13904b53b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5da7d32368543ea9a5959f167b9d895",
            "placeholder": "​",
            "style": "IPY_MODEL_484adfa463b645ea902307aa2832cf89",
            "value": "tokenizer.json: "
          }
        },
        "36dff6de227145bca4a9bea2e843d9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e45fca3153604a93a7ea955d0d46468f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dda3c1429714c848c5c345d7eeabc21",
            "value": 1
          }
        },
        "1bc94989803540a79feb97a9ed976c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7409c0db8d8f4f80ac02ffaa968efa17",
            "placeholder": "​",
            "style": "IPY_MODEL_56ea7afa569f47499944bbc3397673b2",
            "value": " 2.11M/? [00:00&lt;00:00, 48.4MB/s]"
          }
        },
        "3193da9e981441d5904c0c8b3c7e7d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5da7d32368543ea9a5959f167b9d895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484adfa463b645ea902307aa2832cf89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e45fca3153604a93a7ea955d0d46468f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0dda3c1429714c848c5c345d7eeabc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7409c0db8d8f4f80ac02ffaa968efa17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ea7afa569f47499944bbc3397673b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22c22b56d541478fa4cdee721fdf0a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7579a364c10146538eb8a3a44d322b5b",
              "IPY_MODEL_db26cd153b6b4957bb439a77b582c9f3",
              "IPY_MODEL_d5034dab075d4a9cb9447ea953b2132f"
            ],
            "layout": "IPY_MODEL_da86734aec2e4b43924cab031b2f22d3"
          }
        },
        "7579a364c10146538eb8a3a44d322b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5518c7d9894d489c8bbf9c0b4008b89e",
            "placeholder": "​",
            "style": "IPY_MODEL_d805c5d573164c22be7f312f2a382f5f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "db26cd153b6b4957bb439a77b582c9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3fa600f457b442a8a033e4e25071814",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f0b4081bb2a44618af4cdd259e08028",
            "value": 90
          }
        },
        "d5034dab075d4a9cb9447ea953b2132f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_668ed89f4e364d098d751336a7207bbf",
            "placeholder": "​",
            "style": "IPY_MODEL_a9b0adaf198b4d9aafbfde630bbab8e1",
            "value": " 90.0/90.0 [00:00&lt;00:00, 7.58kB/s]"
          }
        },
        "da86734aec2e4b43924cab031b2f22d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5518c7d9894d489c8bbf9c0b4008b89e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d805c5d573164c22be7f312f2a382f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3fa600f457b442a8a033e4e25071814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f0b4081bb2a44618af4cdd259e08028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "668ed89f4e364d098d751336a7207bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9b0adaf198b4d9aafbfde630bbab8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}